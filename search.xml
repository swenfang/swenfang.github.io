<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[LinkedList 源码分析]]></title>
    <url>%2F2017%2F12%2F09%2FLinkedList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LinkedList 源码分析前言有了ArrayList，自然少不了LinkedList了。 下面我就以面试问答的形式学习我们的常用的装载容器——LinkedList（源码分析基于JDK8） 问答内容LinkedList 用来做什么，怎么使用？问：请简单介绍一下您所了解的LinkedList，它可以用来做什么，怎么使用？ 答： LinkedList底层是双向链表，同时实现了List接口和Deque接口，所以它既可以看作是一个顺序容器，也可以看作是一个队列(Queue)，同时也可以看作是一个栈(Stack)，但如果想使用栈或队列等数据结构的话，推荐使用ArrayDeque，它作为栈或队列会比LinkedList有更好的使用性能。 示例代码： 12345678910111213141516171819// 创建一个LinkedList，链表的每个节点的内存空间都是实时分配的，所以无须事先指定容器大小LinkedList&lt;String&gt; linkedList = new LinkedList&lt;String&gt;();// 往容器里面添加元素linkedList.add("张三");linkedList.add("李四");// 在张三与李四之间插入一个王五linkedList.add(1, "王五");// 在头部插入一个小三linkedList.addFirst("小三");// 获取index下标为2的元素 王五String element = linkedList.get(2);// 修改index下标为2的元素 王五 为小四linkedList.set(2, "小四");// 删除index下标为1的元素 张三String removeElement = linkedList.remove(1);// 删除第一个元素String removeFirstElement = linkedList.removeFirst();// 删除最后一个元素String removeLastElement = linkedList.removeLast(); LinkedList底层实现是双向链表，核心组成元素有：int size = 0用于记录链表长度；Node&lt;E&gt; first;用于记录头（第一个）结点（储存的是头结点的引用）；Node&lt;E&gt; last;用于记录尾（最后一个）结点（储存的是尾结点的引用）。 示例代码： 123456789101112131415161718192021public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; // 记录链表长度 transient int size = 0; /** * Pointer to first node. 指向第一个结点 * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. 指向最后一个结点 * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last;&#125; 双向链表的核心组成元素还有一个最重要的Node&lt;E&gt;，Node&lt;E&gt;包含：E item; 用于存储元素数据，Node&lt;E&gt; next; 指向当前元素的后继结点，Node&lt;E&gt; prev; 指向当前元素的前驱结点。 示例代码： 1234567891011121314151617/** * 定义LinkedList底层的结点实现 */private static class Node&lt;E&gt; &#123; E item; // 存储元素数据 Node&lt;E&gt; next;// 指向当前元素的后继结点 Node&lt;E&gt; prev;// 指向当前元素的前驱结点 /** * Node结点构造方法 */ Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element;// 存储的元素 this.next = next;// 后继结点 this.prev = prev;// 前驱结点 &#125;&#125; 双向链表底层实现，图片来自网络 上图中的head即Node first; tail即Node last; LinkedList 的操作和对应的时间复杂度。问：请分别分析一下它是如何获取元素，修改元素，新增元素与删除元素，并分析这些操作对应的时间复杂度。 答： 获取元素：LinkedList提供了三种获取元素的方法，分别是： 获取第一个元素getFirst()，获取第一个元素，直接返回Node&lt;E&gt; first指向的结点即可，所以时间复杂度为O(1)。 获取最后一个元素getLast()，获取最后一个元素，直接返回Node&lt;E&gt; last指向的结点即可，所以时间复杂度也为O(1)。 获取指定索引index位置的元素get(int index)，由于Node&lt;E&gt;结点在内存中存储的空间不是连续存储的，所以查找某一位置的结点，只能通过遍历链表的方式查找结点，因此LinkedList会先通过判断index &lt; (size &gt;&gt; 1)，size&gt;&gt;1即为size/2当前链表长度的一半，判断index的位置是在链表的前半部分还是后半部分。决定是从头部遍历查找数据还是从尾部遍历查找数据。最坏情况下，获取中间元素，则需要遍历n/2次才能获取到对应元素，所以此方法的时间复杂度为O(n)。 综上所述，LinkedList获取元素的时间复杂度为O(n)。 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 返回列表中指定位置的元素 * * @param index 指定index位置 * @return 返回指定位置的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 遍历列表获取对应index位置的元素 return node(index).item;&#125;/** * 检查下标是否合法 */private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size;&#125;/** * 返回指定位置的结点元素（重点） */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 判断index位置是在链表的前半部分还是后半部分 if (index &lt; (size &gt;&gt; 1)) &#123; // 从头结点开始，从前往后遍历找到对应位置的结点元素 Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; // 从尾结点开始，从后往前遍历找到对应位置的结点元素 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 修改元素：LinkedList提供了一种修改元素数据的方法set(int index, E element)，修改元素数据的步骤是：1.检查index索引是否合法[0,size)。2.折半查询获取对应索引元素。3.将新元素赋值，返回旧元素。由获取元素的分析可知，折半查询的时间复杂度为O(n)，故修改元素数据的时间复杂度为O(n)。 示例代码： 123456789101112131415161718/** * 修改指定位置结点的存储数据 * * @param index 指定位置 * @param element 修改的存储数据 * @return 返回未修改前的存储数据 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 折半查询获取对应索引元素 Node&lt;E&gt; x = node(index); // 将新元素赋值，返回旧元素 E oldVal = x.item; x.item = element; return oldVal;&#125; 新增元素：LinkedList提供了四种新增元素的方法，分别是： 将指定元素插入到链表的第一个位置中addFirst(E e)，只需将头结点first指向新元素结点，将原第一结点的前驱指针指向新元素结点即可。不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度为O(1)。 将指定元素插入到链表的最后一个位置中addLast(E e)，只需将尾结点last指向新元素结点，将原最后一个结点的后继指针指向新元素结点即可。不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 添加元素方法add(E e) 等价于addLast(E e)。 将指定元素插入到链表的指定位置index中add(int index, E element)，需要先根据位置index调用node(index)遍历链表获取该位置的原结点，然后将新结点插入至原该位置结点的前面，不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 综上所述，LinkedList新增元素的时间复杂度为O(1)，单纯论插入新元素，操作是非常高效的，特别是插入至头部或插入到尾部。但如果是通过索引index的方式插入，插入的位置越靠近链表中间所费时间越长，因为需要对链表进行遍历查找。 添加元素结点示意图，图片来自《大话数据结构》 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/** * 将指定元素插入到链表的第一个位置中 * * @param e 要插入的元素 */public void addFirst(E e) &#123; linkFirst(e);&#125;/** * 将元素e作为第一个元素 */private void linkFirst(E e) &#123; // 获取原头结点 final Node&lt;E&gt; f = first; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); // 头指针指向新元素结点 first = newNode; // 如果是第一个元素（链表为空） if (f == null) // 将尾指针也指向新元素结点 last = newNode; else // 链表不会空 // 原头结点的前驱指针指向新结点 f.prev = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125;/** * 将指定元素插入到链表的最后一个位置中 * * &lt;p&gt;此方法等同与add(E e)方法 &#123;@link #add&#125;. * * @param e 要插入的元素 */public void addLast(E e) &#123; linkLast(e);&#125;/** * 将指定元素插入到链表的最后一个位置中 * * &lt;p&gt;此方法等同与addLast(E e)方法 &#123;@link #addLast&#125;. * * @param e 要插入的元素 * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** * 将元素e作为最后一个元素 */void linkLast(E e) &#123; // 获取原尾结点 final Node&lt;E&gt; l = last; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 位指针指向新元素结点 last = newNode; // 如果是第一个元素（链表为空） if (l == null) // 将头指针也指向新元素结点 first = newNode; else // 链表不会空 // 原尾结点的后继指针指向新结点 l.next = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125;/** * 将指定元素插入到链表的指定位置index中 * * @param index 元素要插入的位置index * @param element 要插入的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; // 检查插入位置是否合法[0,size] checkPositionIndex(index); // 如果插入的位置和当前链表长度相等，则直接将元素插入至链表的尾部 if (index == size) // 将元素插入至链表的尾部 linkLast(element); else //将元素插入至指定位置,node(index)先获取占有该index位置的原结点 linkBefore(element, node(index));&#125;/** * 检查位置是否合法 */private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;/** * 检查位置是否合法 */private boolean isPositionIndex(int index) &#123; //合法位置为[0,size] return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;/** * 将新元素e插入至旧元素succ前面 */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; // 记录旧元素结点succ的前驱指针 final Node&lt;E&gt; pred = succ.prev; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 旧元素结点的前驱指针指向新元素结点(即新元素结点放至在旧元素结点的前面，取代了原本旧元素的位置) succ.prev = newNode; // 如果旧元素结点的前驱指针为空，则证明旧元素结点是头结点， // 将新元素结点插入至旧元素结点前面，所以现时新的头结点是新元素结点 if (pred == null) first = newNode; else //不是插入至头部 // 旧元素的前驱结点的后继指针指向新元素结点 pred.next = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125; 删除元素：LinkedList提供了四种删除元素的方法，分别是： 删除链表中的第一个元素removeFirst()，只需将头结点first指向删除元素结点的后继结点并将其前驱结点指针信息prev清空即可。不需要移动原数据存储位置，只需操作相关结点的指针域信息即可。所以时间复杂度为O(1)。 删除链表中的最后一个元素removeLast()，只需将尾结点last指向删除元素结点的前驱结点并将其后继结点指针信息next清空即可。不需要移动原数据存储位置，只需操作相关结点的指针域信息即可，所以时间复杂度也为O(1)。 将指定位置index的元素删除remove(int index)，需要先根据位置index调用node(index)遍历链表获取该位置的原结点，然后将删除元素结点的前驱结点的next后继结点指针域指向删除元素结点的后继结点node.prev.next = node.next，删除元素结点的后继结点的prev前驱结点指针域指向删除元素结点的前驱结点即可node.next.prev = node.prev（此处可能有些绕，不太理解的同学自行学习一下双向链表的数据结构吧），不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 删除元素结点示意图，图片来自《大话数据结构》 删除传入的Object o指定对象，比较对象是否一致通过o.equals方法比较remove(Object o)，和3.的思路基本差不多，关键是比较对象是通过o.equals方法，记住这点即可。 综上所述，LinkedList删除元素的时间复杂度为O(1)，单纯论删除元素，操作是非常高效的，特别是删除第一个结点或删除最后一个结点。但如果是通过索引index的方式或者object对象的方式删除，则需要对链表进行遍历查找对应index索引的对象或者利用equals方法判断对象。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169/** * 删除链表中的第一个元素并返回 * * @return 链表中的第一个元素 * @throws NoSuchElementException if this list is empty */public E removeFirst() &#123; //根据头结点获取第一个元素结点 final Node&lt;E&gt; f = first; if (f == null) // 没有元素结点则抛出异常 throw new NoSuchElementException(); return unlinkFirst(f);&#125;/** * 移除第一个元素 */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; // 记录要移除元素结点的数据域 final E element = f.item; // 记录要移除元素结点的后继结点指针 final Node&lt;E&gt; next = f.next; // 清空要删除结点的数据域和next指针域信息，以帮助垃圾回收 f.item = null; f.next = null; // help GC // 头结点指向要移除元素结点的后继结点 first = next; // 如果要移除元素结点的后继结点为空，则证明链表只有一个元素 // 所以需要将尾结点的指针信息也要清空 if (next == null) last = null; else // 将新的第一个结点的前驱结点指针信息清空 next.prev = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125;/** * 删除链表中的最后一个元素并返回 * * @return 链表中的最后一个元素 * @throws NoSuchElementException if this list is empty */public E removeLast() &#123; // 根据尾结点获取最后一个元素结点 final Node&lt;E&gt; l = last; if (l == null)// 没有元素结点则抛出异常 throw new NoSuchElementException(); return unlinkLast(l);&#125;/** * 移除最后一个元素 */private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; // 记录要移除元素结点的数据域 final E element = l.item; // 记录要移除元素结点的前驱结点指针 final Node&lt;E&gt; prev = l.prev; // 清空要删除结点的数据域和prev指针域信息，以帮助垃圾回收 l.item = null; l.prev = null; // help GC // 头结点指向要移除元素结点的前驱结点 last = prev; // 如果要移除元素结点的前驱结点为空，则证明链表只有一个元素 // 所以需要将头结点的指针信息也要清空 if (prev == null) first = null; else // 将新的最后一个结点的后继结点指针信息清空 prev.next = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125;/** * 将指定位置index的元素删除 * * @param index 要删除的位置index * @return 要删除位置的原元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 根据index进行遍历链表获取要删除的结点，再调用unlink方法进行删除 return unlink(node(index));&#125;/** * 删除传入的Object o指定对象，比较对象是否一致通过o.equals方法比较 * @param o 要删除的Object o指定对象 * @return &#123;@code true&#125; 是否存在要删除对象o */public boolean remove(Object o) &#123; // 如果删除对象为null，则遍历链表查找node.item数据域为null的结点并移除 if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 从头开始遍历链表，并通过equals方法逐一比较node.item是否相等 // 相等则对象一致，删除此对象。 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;/** * 移除指定结点x */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; // 记录要移除元素结点的数据域 final E element = x.item; // 记录要移除元素结点的后继结点指针 final Node&lt;E&gt; next = x.next; // 记录要移除元素结点的前驱结点指针 final Node&lt;E&gt; prev = x.prev; // 如果要移除元素结点的前驱结点为空，则证明要删除结点为第一个结点 if (prev == null) &#123; // 头结点指向要删除元素结点的后继结点 first = next; &#125; else &#123; // 要删除元素结点的前驱结点的后继指针指向要删除元素结点的后继结点 prev.next = next; // 清空要删除结点的前驱结点指针信息，以帮助GC x.prev = null; &#125; // 如果要移除元素结点的后继结点为空，则证明要删除结点为最后一个结点 if (next == null) &#123; // 尾结点指向要删除元素结点的前驱结点 last = prev; &#125; else &#123; // 要删除元素结点的后继结点的前驱指针指向要删除元素结点的前驱结点 next.prev = prev; // 清空要删除结点的后继结点指针信息，以帮助GC x.next = null; &#125; // 清空要删除元素的数据域，以帮助GC x.item = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125; ArrayList和LinkedList 的区别问：那您可以比较一下ArrayList和LinkedList吗? 答： LinkedList内部存储的是Node&lt;E&gt;，不仅要维护数据域，还要维护prev和next，如果LinkedList中的结点特别多，则LinkedList比ArrayList更占内存。 插入删除操作效率：LinkedList在做插入和删除操作时，插入或删除头部或尾部时是高效的，操作越靠近中间位置的元素时，需要遍历查找，速度相对慢一些，如果在数据量较大时，每次插入或删除时遍历查找比较费时。所以LinkedList插入与删除，慢在遍历查找，快在只需要更改相关结点的引用地址。ArrayList在做插入和删除操作时，插入或删除尾部时也一样是高效的，操作其他位置，则需要批量移动元素，所以ArrayList插入与删除，快在遍历查找，慢在需要批量移动元素。 循环遍历效率： 由于ArrayList实现了RandomAccess随机访问接口，所以使用for(int i = 0; i &lt; size; i++)遍历会比使用Iterator迭代器来遍历快： 12345678for (int i=0, n=list.size(); i &lt; n; i++) &#123; list.get(i);&#125;runs faster than this loop:for (Iterator i=list.iterator(); i.hasNext(); ) &#123; i.next();&#125; 而由于LinkedList未实现RandomAccess接口，所以推荐使用Iterator迭代器来遍历数据。 因此，如果我们需要频繁在列表的中部改变插入或删除元素时，建议使用LinkedList，否则，建议使用ArrayList，因为ArrayList遍历查找元素较快，并且只需存储元素的数据域，不需要额外记录其他数据的位置信息，可以节省内存空间。 LinkedList是线程安全的吗？问：LinkedList是线程安全的吗？ 答：LinkedList不是线程安全的，如果多个线程同时对同一个LinkedList更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，LinkedList会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个LinkedList进行遍历时，在遍历期间，我们是不能对LinkedList进行添加，删除等更改数据结构的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在add,remove等更改LinkedList数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑调用Collections.synchronizedCollection(Collection&lt;T&gt; c)方法。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; public boolean hasPrevious() &#123; return nextIndex &gt; 0; &#125; public E previous() &#123; checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; &#125; public int nextIndex() &#123; return nextIndex; &#125; public int previousIndex() &#123; return nextIndex - 1; &#125; public void remove() &#123; checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; &#125; public void set(E e) &#123; if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; &#125; public void add(E e) &#123; checkForComodification(); lastReturned = null; if (next == null) linkLast(e); else linkBefore(e, next); nextIndex++; expectedModCount++; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &#123; action.accept(next.item); lastReturned = next; next = next.next; nextIndex++; &#125; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 总结LinkedList的结论已在第三个问题中展现了一部分了，所以不再重复说明了，我以面试问答的形式和大家一同学习了LinkedList，由于没有时间画图，可能此次没有ArrayList说的那么清楚，如果大家有看不懂的地方，请自行看一下关于链表的数据结构吧。如果此文对你有帮助，麻烦点个喜欢，谢谢各位。]]></content>
      <categories>
        <category>LinkedList</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 的详细分析]]></title>
    <url>%2F2017%2F12%2F09%2FHashMap%20%E7%9A%84%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap 的详细分析前言这次我和大家一起学习HashMap，HashMap我们在工作中经常会使用，而且面试中也很频繁会问到，因为它里面蕴含着很多知识点，可以很好的考察个人基础。但一个这么重要的东西，我为什么没有在一开始就去学习它呢，因为它是由多种基础的数据结构和一些代码设计思想组成的。我们要学习了这些基础，再学习HashMap，这样我们才能更好的去理解它。古人云：无欲速，无见小利。欲速则不达，见小利则大事不成。 HashMap其实就是ArrayList和LinkedList的数据结构加上hashCode和equals方法的思想设计出来的。没有理解上述说的知识点的同学可以翻开我过往的文章记录。 下面我就以面试问答的形式学习我们的——HashMap（源码分析基于JDK8，辅以JDK7），问答内容只是对HashMap的一个总结归纳，因为现时已经有大牛把HashMap通俗易懂的剖析了一遍，我学习HashMap也是主要通过这篇文章学习的，强烈推荐：美团点评技术团队的Java 8系列之重新认识HashMap 问答内容HashMap 的主要用途问：HashMap有用过吗？您能给我说说他的主要用途吗？ 答： 有用过，我在平常工作中经常会用到HashMap这种数据结构，HashMap是基于Map接口实现的一种键-值对&lt;key,value&gt;的存储结构，允许null值，同时非有序，非同步(即线程不安全)。HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分）。它存储和查找数据时，是根据键key的hashCode的值计算出具体的存储位置。HashMap最多只允许一条记录的键key为null，HashMap增删改查等常规操作都有不错的执行效率，是ArrayList和LinkedList等数据结构的一种折中实现。 示例代码： 12345678910111213141516171819202122232425262728293031323334// 创建一个HashMap，如果没有指定初始大小，默认底层hash表数组的大小为16HashMap&lt;String, String&gt; hashMap = new HashMap&lt;String, String&gt;();// 往容器里面添加元素hashMap.put("小明", "好帅");hashMap.put("老王", "坑爹货");hashMap.put("老铁", "没毛病");hashMap.put("掘金", "好地方");hashMap.put("王五", "别搞事");// 获取key为小明的元素 好帅String element = hashMap.get("小明");// value : 好帅System.out.println(element);// 移除key为王五的元素String removeElement = hashMap.remove("王五");// value : 别搞事System.out.println(removeElement);// 修改key为小明的元素的值value 为 其实有点丑hashMap.replace("小明", "其实有点丑");// &#123;老铁=没毛病, 小明=其实有点丑, 老王=坑爹货, 掘金=好地方&#125;System.out.println(hashMap);// 通过put方法也可以达到修改对应元素的值的效果hashMap.put("小明", "其实还可以啦,开玩笑的");// &#123;老铁=没毛病, 小明=其实还可以啦,开玩笑的, 老王=坑爹货, 掘金=好地方&#125;System.out.println(hashMap);// 判断key为老王的元素是否存在(捉奸老王)boolean isExist = hashMap.containsKey("老王");// true , 老王竟然来搞事System.out.println(isExist);// 判断是否有 value = "坑爹货" 的人boolean isHasSomeOne = hashMap.containsValue("坑爹货");// true 老王是坑爹货System.out.println(isHasSomeOne);// 查看这个容器里面还有几个家伙 value : 4System.out.println(hashMap.size()); HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分），核心组成元素有： int size;用于记录HashMap实际存储元素的个数； float loadFactor;负载因子（默认是0.75，此属性后面详细解释）。 int threshold;下一次扩容时的阈值，达到阈值便会触发扩容机制resize（阈值 threshold = 容器容量 capacity * 负载因子 load factor）。也就是说，在容器定义好容量之后，负载因子越大，所能容纳的键值对元素个数就越多。 Node&lt;K,V&gt;[] table; 底层数组，充当哈希表的作用，用于存储对应hash位置的元素Node&lt;K,V&gt;，此数组长度总是2的N次幂。（具体原因后面详细解释） 示例代码： 12345678910111213141516171819202122232425262728293031323334public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123;····· /* ---------------- Fields -------------- */ /** * 哈希表，在第一次使用到时进行初始化，重置大小是必要的操作， * 当分配容量时，长度总是2的N次幂。 */ transient Node&lt;K,V&gt;[] table; /** * 实际存储的key - value 键值对 个数 */ transient int size; /** * 下一次扩容时的阈值 * (阈值 threshold = 容器容量 capacity * 负载因子 load factor). * @serial */ int threshold; /** * 哈希表的负载因子 * * @serial */ final float loadFactor;·····&#125; 其中Node&lt;K,V&gt;[] table;哈希表存储的核心元素是Node&lt;K,V&gt;,Node&lt;K,V&gt;包含： final int hash;元素的哈希值，决定元素存储在Node&lt;K,V&gt;[] table;哈希表中的位置。由final修饰可知，当hash的值确定后，就不能再修改。 final K key; 键，由final修饰可知，当key的值确定后，就不能再修改。 V value; 值 Node&lt;K,V&gt; next; 记录下一个元素结点(单链表结构，用于解决hash冲突) 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 定义HashMap存储元素结点的底层实现 */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash;//元素的哈希值 由final修饰可知，当hash的值确定后，就不能再修改 final K key;// 键，由final修饰可知，当key的值确定后，就不能再修改 V value; // 值 Node&lt;K,V&gt; next; // 记录下一个元素结点(单链表结构，用于解决hash冲突) /** * Node结点构造方法 */ Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash;//元素的哈希值 this.key = key;// 键 this.value = value; // 值 this.next = next;// 记录下一个元素结点 &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; /** * 为Node重写hashCode方法，值为：key的hashCode 异或 value的hashCode * 运算作用就是将2个hashCode的二进制中，同一位置相同的值为0，不同的为1。 */ public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; /** * 修改某一元素的值 */ public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; /** * 为Node重写equals方法 */ public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; hashMap内存结构图 - 图片来自于《美团点评技术团队文章》 HashMap 常用操作的底层实现原理问：您能说说HashMap常用操作的底层实现原理吗？如存储put(K key, V value)，查找get(Object key)，删除remove(Object key)，修改replace(K key, V value)等操作。 答： 调用put(K key, V value)操作添加key-value键值对时，进行了如下操作： 判断哈希表Node&lt;K,V&gt;[] table是否为空或者null，是则执行resize()方法进行扩容。 根据插入的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]。如果存储位置没有元素存放，则将新增结点存储在此位置table[i]。 如果存储位置已经有键值对元素存在，则判断该位置元素的hash值和key值是否和当前操作元素一致，一致则证明是修改value操作，覆盖value即可。 当前存储位置即有元素，又不和当前操作元素一致，则证明此位置table[i]已经发生了hash冲突，则通过判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，已红黑树的方式新增结点。 如果不是红黑树，则证明是单链表，将新增结点插入至链表的最后位置，随后判断当前链表长度是否 大于等于 8，是则将当前存储位置的链表转化为红黑树。遍历过程中如果发现key已经存在，则直接覆盖value。 插入成功后，判断当前存储键值对的数量 大于 阈值threshold 是则扩容。 hashMap put方法执行流程图- 图片来自于《美团点评技术团队文章》 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * 添加key-value键值对 * * @param key 键 * @param value 值 * @return 如果原本存在此key，则返回旧的value值，如果是新增的key- * value，则返回nulll */public V put(K key, V value) &#123; //实际调用putVal方法进行添加 key-value 键值对操作 return putVal(hash(key), key, value, false, true);&#125;/** * 根据key 键 的 hashCode 通过 “扰动函数” 生成对应的 hash值 * 经过此操作后，使每一个key对应的hash值生成的更均匀， * 减少元素之间的碰撞几率（后面详细说明） */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;/** * 添加key-value键值对的实际调用方法（重点） * * @param hash key 键的hash值 * @param key 键 * @param value 值 * @param onlyIfAbsent 此值如果是true, 则如果此key已存在value，则不执 * 行修改操作 * @param evict 此值如果是false，哈希表是在初始化模式 * @return 返回原本的旧值, 如果是新增，则返回null */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // 用于记录当前的链表结点 Node&lt;K,V&gt; p; // n用于记录hash表的长度，i用于记录当前操作索引index int n, i; // 当前hash表为空 if ((tab = table) == null || (n = tab.length) == 0) // 初始化hash表，并把初始化后的hash表长度值赋值给n n = (tab = resize()).length; // 1）通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 2）确定当前元素的存储位置，此运算等价于 当前元素的hash值 % hash表的长度 // 3）计算出的存储位置没有元素存在 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 4) 则新建一个Node结点，在该位置存储此元素 tab[i] = newNode(hash, key, value, null); else &#123; // 当前存储位置已经有元素存在了(不考虑是修改的情况的话，就代表发生hash冲突了) // 用于存放新增结点 Node&lt;K,V&gt; e; // 用于临时存在某个key值 K k; // 1)如果当前位置已存在元素的hash值和新增元素的hash值相等 // 2)并且key也相等，则证明是同一个key元素，想执行修改value操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;// 将当前结点引用赋值给e else if (p instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构，则已红黑树结点结构新增元素 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123;// 排除上述情况，则证明已发生hash冲突，并hash冲突位置现时的结构是单链表结构 for (int binCount = 0; ; ++binCount) &#123; //遍历单链表，将新元素结点放置此链表的最后一位 if ((e = p.next) == null) &#123; // 将新元素结点放在此链表的最后一位 p.next = newNode(hash, key, value, null); // 新增结点后，当前结点数量是否大于等于 阈值 8 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 大于等于8则将链表转换成红黑树 treeifyBin(tab, hash); break; &#125; // 如果链表中已经存在对应的key，则覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // 已存在对应key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //如果允许修改，则修改value为新值 e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 当前存储键值对的数量 大于 阈值 是则扩容 if (++size &gt; threshold) // 重置hash大小，将旧hash表的数据逐一复制到新的hash表中（后面详细讲解） resize(); afterNodeInsertion(evict); // 返回null，则证明是新增操作，而不是修改操作 return null;&#125; 调用get(Object key)操作根据键key查找对应的key-value键值对时，进行了如下操作： 1.先调用 hash(key)方法计算出 key 的 hash值 2.根据查找的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]，判断存储位置是否有元素存在 。 如果存储位置有元素存放，则首先比较头结点元素，如果头结点的key的hash值 和 要获取的key的hash值相等，并且 头结点的key本身 和要获取的 key 相等，则返回该位置的头结点。 如果存储位置没有元素存放，则返回null。 3.如果存储位置有元素存放，但是头结点元素不是要查找的元素，则需要遍历该位置进行查找。 4.先判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，以红色树的方式遍历查找该结点，没有则返回null。 5.如果不是红黑树，则证明是单链表。遍历单链表，逐一比较链表结点，链表结点的key的hash值 和 要获取的key的hash值相等，并且 链表结点的key本身 和要获取的 key 相等，则返回该结点，遍历结束仍未找到对应key的结点，则返回null。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 返回指定 key 所映射的 value 值 * 或者 返回 null 如果容器里不存在对应的key * * 更确切地讲，如果此映射包含一个满足 (key==null ? k==null :key.equals(k)) * 的从 k 键到 v 值的映射关系， * 则此方法返回 v；否则返回 null。（最多只能有一个这样的映射关系。） * * 返回 null 值并不一定 表明该映射不包含该键的映射关系； * 也可能该映射将该键显示地映射为 null。可使用containsKey操作来区分这两种情况。 * * @see #put(Object, Object) */public V get(Object key) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用getNode方法获取对应key所映射的value值 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * 获取哈希表结点的方法实现 * * @param hash key 键的hash值 * @param key 键 * @return 返回对应的结点，如果结点不存在，则返回null */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // first用于记录对应hash位置的第一个结点，e充当工作结点的作用 Node&lt;K,V&gt; first, e; // n用于记录hash表的长度 int n; // 用于临时存放Key K k; // 通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 判断当前元素的存储位置是否有元素存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123;//元素存在的情况 // 如果头结点的key的hash值 和 要获取的key的hash值相等 // 并且 头结点的key本身 和要获取的 key 相等 if (first.hash == hash &amp;&amp; // always check first node 总是检查头结点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 返回该位置的头结点 return first; if ((e = first.next) != null) &#123;// 头结点不相等 if (first instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式获取对应key结点 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123;// 当前位置不是红黑树，则证明是单链表 // 遍历单链表，逐一比较链表结点 // 链表结点的key的hash值 和 要获取的key的hash值相等 // 并且 链表结点的key本身 和要获取的 key 相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 找到对应的结点则返回 return e; &#125; while ((e = e.next) != null); &#125; &#125; // 通过上述查找均无找到，则返回null return null;&#125; 调用remove(Object key)操作根据键key删除对应的key-value键值对时，进行了如下操作： 1.先调用 hash(key)方法计算出 key 的 hash值 2.根据查找的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]，判断存储位置是否有元素存在 。 如果存储位置有元素存放，则首先比较头结点元素，如果头结点的key的hash值 和 要获取的key的hash值相等，并且 头结点的key本身 和要获取的 key 相等，则该位置的头结点即为要删除的结点，记录此结点至变量node中。 如果存储位置没有元素存放，则没有找到对应要删除的结点，则返回null。 3.如果存储位置有元素存放，但是头结点元素不是要删除的元素，则需要遍历该位置进行查找。 4.先判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，以红色树的方式遍历查找并删除该结点，没有则返回null。 5.如果不是红黑树，则证明是单链表。遍历单链表，逐一比较链表结点，链表结点的key的hash值 和 要获取的key的hash值相等，并且 链表结点的key本身 和要获取的 key 相等，则此为要删除的结点，记录此结点至变量node中，遍历结束仍未找到对应key的结点，则返回null。 6.如果找到要删除的结点node，则判断是否需要比较value也是否一致，如果value值一致或者不需要比较value值，则执行删除结点操作，删除操作根据不同的情况与结构进行不同的处理。 如果当前结点是树结点，则证明当前位置的链表已变成红黑树结构，通过红黑树结点的方式删除对应结点。 如果不是红黑树，则证明是单链表。如果要删除的是头结点，则当前存储位置table[i]的头结点指向删除结点的下一个结点。 如果要删除的结点不是头结点，则将要删除的结点的后继结点node.next赋值给要删除结点的前驱结点的next域，即p.next = node.next;。 7.HashMap当前存储键值对的数量 - 1，并返回删除结点。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/** * 从此映射中移除指定键的映射关系（如果存在）。 * * @param key 其映射关系要从映射中移除的键 * @return 与 key 关联的旧值；如果 key 没有任何映射关系，则返回 null。 * （返回 null 还可能表示该映射之前将 null 与 key 关联。） */public V remove(Object key) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用removeNode方法删除对应key所映射的结点 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * 删除哈希表结点的方法实现 * * @param hash 键的hash值 * @param key 键 * @param value 用于比较的value值，当matchValue 是 true时才有效, 否则忽略 * @param matchValue 如果是 true 只有当value相等时才会移除 * @param movable 如果是 false当执行移除操作时，不删除其他结点 * @return 返回删除结点node，不存在则返回null */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // 用于记录当前的链表结点 Node&lt;K,V&gt; p; // n用于记录hash表的长度，index用于记录当前操作索引index int n, index; // 通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 判断当前元素的存储位置是否有元素存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123;// 元素存在的情况 // node 用于记录找到的结点，e为工作结点 Node&lt;K,V&gt; node = null, e; K k; V v; // 如果头结点的key的hash值 和 要获取的key的hash值相等 // 并且 头结点的key本身 和要获取的 key 相等 // 则证明此头结点就是要删除的结点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 记录要删除的结点的引用地址至node中 node = p; else if ((e = p.next) != null) &#123;// 头结点不相等 if (p instanceof TreeNode)// 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式获取对应key结点 // 记录要删除的结点的引用地址至node中 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123;// 当前位置不是红黑树，则证明是单链表 do &#123; // 遍历单链表，逐一比较链表结点 // 链表结点的key的hash值 和 要获取的key的hash值相等 // 并且 链表结点的key本身 和要获取的 key 相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; // 找到则记录要删除的结点的引用地址至node中，中断遍历 node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 如果找到要删除的结点，则判断是否需要比较value也是否一致 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; // value值一致或者不需要比较value值，则执行删除结点操作 if (node instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式删除对应结点 ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) // node 和 p相等，则证明删除的是头结点 // 当前存储位置的头结点指向删除结点的下一个结点 tab[index] = node.next; else // 删除的不是头结点 // p是删除结点node的前驱结点，p的next改为记录要删除结点node的后继结点 p.next = node.next; ++modCount; // 当前存储键值对的数量 - 1 --size; afterNodeRemoval(node); // 返回删除结点 return node; &#125; &#125; // 不存在要删除的结点，则返回null return null;&#125; 调用replace(K key, V value)操作根据键key查找对应的key-value键值对，随后替换对应的值value，进行了如下操作： 先调用 hash(key)方法计算出 key 的 hash值 随后调用getNode方法获取对应key所映射的value值 。 记录元素旧值，将新值赋值给元素，返回元素旧值，如果没有找到元素，则返回null。 示例代码： 123456789101112131415161718192021222324/** * 替换指定 key 所映射的 value 值 * * @param key 对应要替换value值元素的key键 * @param value 要替换对应元素的新value值 * @return 返回原本的旧值，如果没有找到key对应的元素，则返回null * @since 1.8 JDK1.8新增方法 */public V replace(K key, V value) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用getNode方法获取对应key所映射的value值 if ((e = getNode(hash(key), key)) != null) &#123;// 如果找到对应的元素 // 元素旧值 V oldValue = e.value; // 将新值赋值给元素 e.value = value; afterNodeAccess(e); // 返回元素旧值 return oldValue; &#125; // 没有找到元素，则返回null return null;&#125; HashMap 若要新增的这个元素存在了或hash冲突了怎么办问 1：您上面说，存放一个元素时，先计算它的hash值确定它的存储位置，然后再把这个元素放到对应的位置上，那万一这个位置上面已经有元素存在呢，新增的这个元素怎么办？ 问 2：hash冲突（或者叫hash碰撞）是什么？为什么会出现这种现象，如何解决hash冲突？ 答： hash冲突： 当我们调用put(K key, V value)操作添加key-value键值对，这个key-value键值对存放在的位置是通过扰动函数(key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16)计算键key的hash值。随后将 这个hash值 % 模上 哈希表Node&lt;K,V&gt;[] table的长度 得到具体的存放位置。所以put(K key, V value)多个元素，是有可能计算出相同的存放位置。此现象就是hash冲突或者叫hash碰撞。 例子如下：元素 A 的hash值 为 9，元素 B 的hash值 为 17。哈希表Node&lt;K,V&gt;[] table的长度为8。则元素 A 的存放位置为9 % 8 = 1，元素 B 的存放位置为17 % 8 = 1。两个元素的存放位置均为table[1]，发生了hash冲突。 hash冲突的避免：既然会发生hash冲突，我们就应该想办法避免此现象的发生，解决这个问题最关键就是如果生成元素的hash值。Java是使用“扰动函数”生成元素的hash值。 示例代码： 123456789101112131415161718/** * JDK 7 的 hash方法 */ final int hash(int h) &#123; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125;/** * JDK 8 的 hash方法 */ static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; Java7做了4次16位右位移异或混合，Java 8中这步已经简化了，只做一次16位右位移异或混合，而不是四次，但原理是不变的。例子如下： 扰动函数执行例子 - 图片来自于《知乎》 右位移16位，正好是32bit的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。 上述扰动函数的解释参考自：JDK 源码中 HashMap 的 hash 方法原理是什么？ hash冲突解决：解决hash冲突的方法有很多，常见的有：开发定址法，再散列法，链地址法，公共溢出区法（详细说明请查看我的文章JAVA基础-自问自答学hashCode和equals）。HashMap是使用链地址法解决hash冲突的，当有冲突元素放进来时，会将此元素插入至此位置链表的最后一位，形成单链表。但是由于是单链表的缘故，每当通过hash % length找到该位置的元素时，均需要从头遍历链表，通过逐一比较hash值，找到对应元素。如果此位置元素过多，造成链表过长，遍历时间会大大增加，最坏情况下的时间复杂度为O(N)，造成查找效率过低。所以当存在位置的链表长度 大于等于 8 时，HashMap会将链表 转变为 红黑树，红黑树最坏情况下的时间复杂度为O(logn)。以此提高查找效率。 HashMap 的容量为什么一定要是2的n次方问：HashMap的容量为什么一定要是2的n次方？ 答： 因为调用put(K key, V value)操作添加key-value键值对时，具体确定此元素的位置是通过 hash值 % 模上 哈希表Node&lt;K,V&gt;[] table的长度 hash % length 计算的。但是”模”运算的消耗相对较大，通过位运算h &amp; (length-1)也可以得到取模后的存放位置，而位运算的运行效率高，但只有length的长度是2的n次方时，h &amp; (length-1) 才等价于 h % length。 而且当数组长度为2的n次幂的时候，不同的key算出的index相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。 例子： hash &amp; (length-1)运算过程.jpg 上图中，左边两组的数组长度是16（2的4次方），右边两组的数组长度是15。两组的hash值均为8和9。 当数组长度是15时，当它们和1110进行&amp;与运算（相同为1，不同为0）时，计算的结果都是1000，所以他们都会存放在相同的位置table[8]中，这样就发生了hash冲突，那么查询时就要遍历链表，逐一比较hash值，降低了查询的效率。 同时，我们可以发现，当数组长度为15的时候，hash值均会与14（1110）进行&amp;与运算，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率。 所以，HashMap的容量是2的n次方，有利于提高计算元素存放位置时的效率，也降低了hash冲突的几率。因此，我们使用HashMap存储大量数据的时候，最好先预先指定容器的大小为2的n次方，即使我们不指定为2的n次方，HashMap也会把容器的大小设置成最接近设置数的2的n次方，如，设置HashMap的大小为 7 ，则HashMap会将容器大小设置成最接近7的一个2的n次方数，此值为 8 。 上述回答参考自：深入理解HashMap 示例代码： 12345678910111213/** * 返回一个比指定数cap大的，并且大小是2的n次方的数 * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; HashMap 的负载因子是什么，有什么作用问：HashMap的负载因子是什么，有什么作用？ 答：负载因子表示哈希表空间的使用程度（或者说是哈希表空间的利用率）。 例子如下：底层哈希表Node&lt;K,V&gt;[] table的容量大小capacity为 16，负载因子load factor为 0.75，则当存储的元素个数size = capacity 16 * load factor 0.75等于 12 时，则会触发HashMap的扩容机制，调用resize()方法进行扩容。 当负载因子越大，则HashMap的装载程度就越高。也就是能容纳更多的元素，元素多了，发生hash碰撞的几率就会加大，从而链表就会拉长，此时的查询效率就会降低。 当负载因子越小，则链表中的数据量就越稀疏，此时会对空间造成浪费，但是此时查询效率高。 我们可以在创建HashMap 时根据实际需要适当地调整load factor 的值；如果程序比较关心空间开销、内存比较紧张，可以适当地增加负载因子；如果程序比较关心时间开销，内存比较宽裕则可以适当的减少负载因子。通常情况下，默认负载因子 (0.75) 在时间和空间成本上寻求一种折衷，程序员无需改变负载因子的值。 因此，如果我们在初始化HashMap时，就预估知道需要装载key-value键值对的容量size，我们可以通过size / load factor 计算出我们需要初始化的容量大小initialCapacity，这样就可以避免HashMap因为存放的元素达到阈值threshold而频繁调用resize()方法进行扩容。从而保证了较好的性能。 HashMap 和 HashTable 的区别问：您能说说HashMap和HashTable的区别吗？ 答：HashMap和HashTable有如下区别： 1）容器整体结构： HashMap的key和value都允许为null，HashMap遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理。 Hashtable的key和value都不允许为null。Hashtable遇到null，直接返回NullPointerException。 2） 容量设定与扩容机制： HashMap默认初始化容量为 16，并且容器容量一定是2的n次方，扩容时，是以原容量 2倍 的方式 进行扩容。 Hashtable默认初始化容量为 11，扩容时，是以原容量 2倍 再加 1的方式进行扩容。即int newCapacity = (oldCapacity &lt;&lt; 1) + 1;。 3） 散列分布方式（计算存储位置）： HashMap是先将key键的hashCode经过扰动函数扰动后得到hash值，然后再利用 hash &amp; (length - 1)的方式代替取模，得到元素的存储位置。 Hashtable则是除留余数法进行计算存储位置的（因为其默认容量也不是2的n次方。所以也无法用位运算替代模运算），int index = (hash &amp; 0x7FFFFFFF) % tab.length;。 由于HashMap的容器容量一定是2的n次方，所以能使用hash &amp; (length - 1)的方式代替取模的方式计算元素的位置提高运算效率，但Hashtable的容器容量不一定是2的n次方，所以不能使用此运算方式代替。 4）线程安全（最重要）： HashMap 不是线程安全，如果想线程安全，可以通过调用synchronizedMap(Map&lt;K,V&gt; m)使其线程安全。但是使用时的运行效率会下降，所以建议使用ConcurrentHashMap容器以此达到线程安全。 Hashtable则是线程安全的，每个操作方法前都有synchronized修饰使其同步，但运行效率也不高，所以还是建议使用ConcurrentHashMap容器以此达到线程安全。 因此，Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 此处不再对Hashtable的源码进行逐一分析了，如果想深入了解的同学，可以参考此文章Hashtable源码剖析 HashMap 在多线程下如何处理，啥时会发生线程不安全问：您说HashMap不是线程安全的，那如果多线程下，它是如何处理的？并且什么情况下会发生线程不安全的情况？ 答： HashMap不是线程安全的，如果多个线程同时对同一个HashMap更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，HashMap会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个HashMap进行遍历时，在遍历期间，我们是不能对HashMap进行添加，删除等更改数据的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在put,remove等更改HashMap数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑使用ConcurrentHashMap。 而且，在多线程下操作HashMap，由于存在扩容机制，当HashMap调用resize()进行自动扩容时，可能会导致死循环的发生。 由于时间关系，我暂不带着大家一起去分析resize()方法导致死循环发生的现象造成原因了，迟点有空我会再补充上去，请见谅，大家可以参考如下文章： Java 8系列之重新认识HashMap 谈谈HashMap线程不安全的体现 使用 HashMap ，选取什么对象作为 key 键比较好问：我们在使用HashMap时，选取什么对象作为key键比较好，为什么？ 答： 可变对象：指创建后自身状态能改变的对象。换句话说，可变对象是该对象在创建后它的哈希值可能被改变。 我们在使用HashMap时，最好选择不可变对象作为key。例如String，Integer等不可变类型作为key是非常明智的。 如果key对象是可变的，那么key的哈希值就可能改变。在HashMap中可变对象作为Key会造成数据丢失。因为我们再进行hash &amp; (length - 1)取模运算计算位置查找对应元素时，位置可能已经发生改变，导致数据丢失。 详细例子说明请参考：危险！在HashMap中将可变对象用作Key 总结 HashMap是基于Map接口实现的一种键-值对&lt;key,value&gt;的存储结构，允许null值，同时非有序，非同步(即线程不安全)。HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分）。 HashMap定位元素位置是通过键key经过扰动函数扰动后得到hash值，然后再通过hash &amp; (length - 1)代替取模的方式进行元素定位的。 HashMap是使用链地址法解决hash冲突的，当有冲突元素放进来时，会将此元素插入至此位置链表的最后一位，形成单链表。当存在位置的链表长度 大于等于 8 时，HashMap会将链表 转变为 红黑树，以此提高查找效率。 HashMap的容量是2的n次方，有利于提高计算元素存放位置时的效率，也降低了hash冲突的几率。因此，我们使用HashMap存储大量数据的时候，最好先预先指定容器的大小为2的n次方，即使我们不指定为2的n次方，HashMap也会把容器的大小设置成最接近设置数的2的n次方，如，设置HashMap的大小为 7 ，则HashMap会将容器大小设置成最接近7的一个2的n次方数，此值为 8 。 HashMap的负载因子表示哈希表空间的使用程度（或者说是哈希表空间的利用率）。当负载因子越大，则HashMap的装载程度就越高。也就是能容纳更多的元素，元素多了，发生hash碰撞的几率就会加大，从而链表就会拉长，此时的查询效率就会降低。当负载因子越小，则链表中的数据量就越稀疏，此时会对空间造成浪费，但是此时查询效率高。 HashMap不是线程安全的，Hashtable则是线程安全的。但Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 在多线程下操作HashMap，由于存在扩容机制，当HashMap调用resize()进行自动扩容时，可能会导致死循环的发生。 我们在使用HashMap时，最好选择不可变对象作为key。例如String，Integer等不可变类型作为key是非常明智的。 由于最近工作较忙，也有拖延症发作的问题，所以文章迟迟未能完成发布，现时完成的文章其实对我而言，也不算太好，但还是打算先发出来让大家看看，一起学习学习，看有什么不好的地方，我再慢慢改进，如果此文对你有帮助，请给个赞，谢谢大家。 参考文章Java 8系列之重新认识HashMapJDK 源码中 HashMap 的 hash 方法原理是什么？深入理解HashMapHashMap负载因子Hashtable源码剖析危险！在HashMap中将可变对象用作Key谈谈HashMap线程不安全的体现]]></content>
      <categories>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList 源码分析]]></title>
    <url>%2F2017%2F12%2F09%2FArrayList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ArrayList 源码分析 前言以面试问答的形式学习我们的最常用的装载容器——ArrayList（源码分析基于JDK8） 问答内容ArrayList是什么，可以用来干嘛？问：ArrayList有用过吗？它是一个什么东西？可以用来干嘛？ 答：有用过，ArrayList就是数组列表，主要用来装载数据，当我们装载的是基本类型的数据int,long,boolean,short,byte...的时候我们只能存储他们对应的包装类，它的主要底层实现是数组Object[] elementData。与它类似的是LinkedList，和LinkedList相比，它的查找和访问元素的速度较快，但新增，删除的速度较慢。 示例代码： 12345678910// 创建一个ArrayList，如果没有指定初始大小，默认容器大小为10ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();// 往容器里面添加元素arrayList.add("张三");arrayList.add("李四");arrayList.add("王五");// 获取index下标为0的元素 张三String element = arrayList.get(0);// 删除index下标为1的元素 李四String removeElement = arrayList.remove(1); ArrayList底层实现示意图 ArrayList中不断添加数据会有什么问题吗？问：您说它的底层实现是数组，但是数组的大小是定长的，如果我们不断的往里面添加数据的话，不会有问题吗？ 答：ArrayList可以通过构造方法在初始化的时候指定底层数组的大小。 通过无参构造方法的方式ArrayList()初始化，则赋值底层数组Object[] elementData为一个默认空数组Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}所以数组容量为0，只有真正对数据进行添加add时，才分配默认DEFAULT_CAPACITY = 10的初始容量。示例代码： 12345678910111213141516// 定义ArrayList默认容量为10private static final int DEFAULT_CAPACITY = 10;// 空数组，当调用无参构造方法时默认复制这个空数组private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;// 真正保存数据的底层数组transient Object[] elementData; // ArrayList的实际元素数量private int size;public ArrayList() &#123; // 无参构造方法默认为空数组 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 通过指定容量初始大小的构造方法方式ArrayList(int initialCapacity)初始化，则赋值底层数组Object[] elementData为指定大小的数组this.elementData = new Object[initialCapacity];示例代码： 12345678910111213private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;// 通过构造方法出入指定的容量来设置默认底层数组大小 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125; 当我们添加的元素数量已经达到底层数组Object[] elementData的上限时，我们再往ArrayList元素，则会触发ArrayList的自动扩容机制，ArrayList会通过位运算int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);以1.5倍的方式初始化一个新的数组（如初始化数组大小为10，则扩容后的数组大小为15），然后使用Arrays.copyOf(elementData, newCapacity);方法将原数据的数据逐一复制到新数组上面去，以此达到ArrayList扩容的效果。虽然，Arrays.copyOf(elementData, newCapacity);方法最终调用的是native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length)是一个底层方法，效率还算可以，但如果我们在知道ArrayList想装多少个元素的情况下，却没有指定容器大小，则就会导致ArrayList频繁触发扩容机制，频繁进行底层数组之间的数据复制，大大降低使用效率。示例代码： 123456789101112131415161718192021222324252627282930313233public boolean add(E e) &#123; //确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); elementData[size++] = e; return true;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 容量不足，则调用grow方法进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * 扩容方法(重点) */private void grow(int minCapacity) &#123; // 获得原容量大小 int oldCapacity = elementData.length; // 新容量为原容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 再判断新容量是否已足够，如果扩容后仍然不足够，则复制为最小容量长度 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 判断是否超过最大长度限制 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 将原数组的数据复制至新数组， ArrayList的底层数组引用指向新数组 // 如果数据量很大，重复扩容，则会影响效率 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 因此，在我们使用ArrayList的时候，如果知道最终的存储容量capacity，则应该在初始化的时候就指定ArrayList的容量ArrayList(int initialCapacity)，如果初始化时无法预知装载容量，但在使用过程中，得知最终容量，我们可以通过调用ensureCapacity(int minCapacity)方法来指定ArrayList的容量，并且，如果我们在使用途中，如果确定容量大小，但是由于之前每次扩容都扩充50%，所以会造成一定的存储空间浪费，我们可以调用trimToSize()方法将容器最小化到存储元素容量，进而消除这些存储空间浪费。例如：我们当前存储了11个元素，我们不会再添加但是当前的ArrayList的大小为15，有4个存储空间没有被使用，则调用trimToSize()方法后，则会重新创建一个容量为11的数组Object[] elementData，将原有的11个元素复制至新数组，达到节省内存空间的效果。示例代码： 123456789101112131415161718192021222324252627/** * 将底层数组一次性指定到指定容量的大小 */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125;/** * 将容器最小化到存储元素容量 */public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125; ArrayList怎么 删除数据，为什么访问速度快，删除新增速度慢 ？问：那它是怎么样删除元素的？您上面说到ArrayList访问元素速度较快，但是新增和删除的速度较慢，为什么呢？ 答： 通过源码我们可以得知，ArrayList删除元素时，先获取对应的删除元素，然后把要删除元素对应索引index后的元素逐一往前移动1位，最后将最后一个存储元素清空并返回删除元素，以此达到删除元素的效果。 当我们通过下标的方式去访问元素时，我们假设访问一个元素所花费的时间为K，则通过下标一步到位的方式访问元素，时间则为1K，用“大O”表示法表示，则时间复杂度为O(1)。所以ArrayList的访问数据的数据是比较快的。 当我们去添加元素add(E e)时，我们是把元素添加至末尾，不需要移动元素，此时的时间复杂度为O(1)，但我们把元素添加到指定位置，最坏情况下，我们将元素添加至第一个位置add(int index, E element)，则整个ArrayList的n-1个元素都要往前移动位置，导致底层数组发生n-1次复制。通常情况下，我们说的时间复杂度都是按最坏情况度量的，此时的时间复杂度为O(n)。删除元素同理，删除最后一个元素不需要移动元素，时间复杂度为O(1)，但删除第一个元素，则需要移动n-1个元素，最坏情况下的时间复杂度也是O(n)。 所以ArrayList访问元素速度较快，但是新增和删除的速度较慢。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 将元素添加至末尾 */public boolean add(E e) &#123; // 确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;/** * 将元素添加至指定下标位置 */public void add(int index, E element) &#123; // 检查下标是否在合法范围内 rangeCheckForAdd(index); // 确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 将要添加的元素下标后的元素通过复制的方式逐一往后移动，腾出对应index下标的存储位置 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 将新增元素存储至指定下标索引index elementData[index] = element; // ArrayList的大小 + 1 size++;&#125;/** * 通过下标索引的方式删除元素 */public E remove(int index) &#123; // 检查下标是否在合法范围内 rangeCheck(index); modCount++; // 直接通过下标去访问底层数组的元素 E oldValue = elementData(index); // 计算数组需要移动的元素个数 int numMoved = size - index - 1; if (numMoved &gt; 0) // 将要删除的元素下标后的元素通过复制的方式逐一往前移动 System.arraycopy(elementData, index+1, elementData, index, numMoved); //将底层数组长度减1，并清空最后一个存储元素。 elementData[--size] = null; // clear to let GC do its work // 返回移除元素 return oldValue;&#125; ArrayList是线程安全的吗？问：ArrayList是线程安全的吗？ 答：ArrayList不是线程安全的，如果多个线程同时对同一个ArrayList更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，ArrayList会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个ArrayList进行遍历时，在遍历期间，我们是不能对ArrayList进行添加，修改，删除等更改数据的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在add,remove,clear等更改ArrayList数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑使用Vector、CopyOnWriteArrayList。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * AbstractList.Itr 的迭代器实现 */private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such //期望的modCount int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings("unchecked") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings("unchecked") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 总结 如果在初始化的时候知道ArrayList的初始容量，请一开始就指定容量ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(20);,如果一开始不知道容量，中途才得知，请调用list.ensureCapacity(20);来扩充容量，如果数据已经添加完毕，但仍需要保存在内存中一段时间，请调用list.trimToSize()将容器最小化到存储元素容量，进而消除这些存储空间浪费。 ArrayList是以1.5倍的容量去扩容的，如初始容量是10，则容量依次递增扩充为：15，22，33，49。扩容后把原始数据从旧数组复制至新数组中。 ArrayList访问元素速度较快，下标方式访问元素，时间复杂度为O(1)，添加与删除速度较慢，时间复杂度均为O(n)。 ArrayList不是线程安全的，但是在发生并发行为时，它会尽可能的抛出ConcurrentModificationException，此为fail-fast机制。]]></content>
      <categories>
        <category>ArrayList</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven仓库理解和优先级]]></title>
    <url>%2F2017%2F09%2F03%2FMaven-Priority%2F</url>
    <content type="text"><![CDATA[5 Seven 2017 前言使用 maven 也有一段时间了，有时候在配置 repository,mirror,profile的时候，总会导致 jar 拉取不到。所以认真的分析了 maven 获取 jar 包时候的优先级。 Maven 仓库的分类仓库分类：本地仓库和远程仓库。Maven根据坐标寻找构件的时候，它先会查看本地仓库，如果本地仓库存在构件，则直接使用；如果没有，则从远程仓库查找，找到后，下载到本地。 1）本地仓库默认情况下，每个用户在自己的用户目录下都有一个路径名为.m2/repository/的仓库目录。我们也可以在 settings.xml 文件配置本地仓库的地址 2）远程仓库本地仓库好比书房，而远程仓库就像是书店。对于Maven来说，每个用户只有一个本地仓库，但是可以配置多个远程仓库。下· 我们可以在 pom 文件配置多个 repository，但是随着项目越来也多我们每次都要在 pom 文件配置比较麻烦，所以我们可以在settings 文件配置 profile （私服）。这样我们每次创建新项目的时候就可以不用配置 repository。 3）中央仓库Maven必须要知道至少一个可用的远程仓库，中央仓库就是这样一个默认的远程仓库，Maven 默认有一个 super pom 文件。maven super pom 文件位置D:\apache-maven-3.0.4\lib 下的 maven-model-builder-3.0.4.jar 中的 org/apache/maven/model/pom-4.0.0.xml12345678910111213··· 省略其他 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;··· 这个时候我们就明白了，我们在 settings 文件配置一个 mirror 的 mirrorOf 为 central 的镜像就会替代 ‘中央仓库’ 的原因了。 Maven 镜像镜像（Mirroring）是冗余的一种类型，一个磁盘上的数据在另一个磁盘上存在一个完全相同的副本即为镜像。为什么配置镜像? 1.一句话，你有的我也有，你没有的我也有。（拥有远程仓库的所有 jar，包括远程仓库没有的 jar）2.还是一句话，我跑的比你快。（有时候远程仓库获取 jar 的速度可能比镜像慢，这也是为什么我们一般要配置中央仓库的原因，外国的 maven 仓库一般获取速度比较慢） 如果你配置 maven 镜像不是为了以上两点，那基本就不用配置镜像了。注意:当远程仓库被镜像匹配到的，则在获取 jar 包将从镜像仓库获取，而不是我们配置的 repository 仓库, repository 将失去作用 mirrorOf 标签mirrorOf 标签里面放置的是 repository 配置的 id,为了满足一些复杂的需求，Maven还支持更高级的镜像配置： external:* = 不在本地仓库的文件才从该镜像获取 repo,repo1 = 远程仓库 repo 和 repo1 从该镜像获取 *,!repo1 = 所有远程仓库都从该镜像获取，除 repo1 远程仓库以外 * = 所用远程仓库都从该镜像获取 私服私服是一种特殊的远程Maven仓库，它是架设在局域网内的仓库服务，私服一般被配置为互联网远程仓库的镜像，供局域网内的Maven用户使用。当Maven需要下载构件的时候，先向私服请求，如果私服上不存在该构件，则从外部的远程仓库下载，同时缓存在私服之上，然后为Maven下载请求提供下载服务，另外，对于自定义或第三方的jar可以从本地上传到私服，供局域网内其他maven用户使用。优点主要有： 1. 节省外网宽带 2. 加速Maven构建 3. 部署第三方构件：可以将公司项目的 jar 发布到私服上，方便项目与项目之间的调用 4. 提高稳定性、增强控制：原因是外网不稳定 5. 降低中央仓库的负荷：原因是中央仓库访问量太大 上面大概介绍了 Maven 仓库概念，接下来我们进入正题 Maven 仓库优先级为了方便测试，我准备了以下几个仓库 172.16.xxx.xxx 远程仓库 （私服） dev.xxx.wiki 远程仓库 （远程） localhost 仓库 是我自己在本机搭建的一个仓库 （镜像） maven.aliyun.com 中央仓库（中央） 本地仓库优先级Maven 本地仓库拥有该包，而远程、镜像、中央、私服都不包含该包。我们来看下 Maven 是怎么获取的123456789101112131415161718192021222324.......// 使用本地仓库，优先级(priority)为 10[DEBUG] Using local repository at E:\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\OperSource[INFO] Scanning for projects..........[INFO] Installing C:\Users\swipal\Desktop\abc\demo\target\demo-1.0-SNAPSHOT.jar to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[INFO] Installing C:\Users\swipal\Desktop\abc\demo\pom.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\OperSource\com\cjf\demo\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 1.874 s[INFO] Finished at: 2017-07-07T10:37:32+08:00[INFO] Final Memory: 23M/219M[INFO] ------------------------------------------------------------------------Process finished with exit code 0 从上面可以看出 Maven 一开始就使用本地仓库，并将本地仓库的优先级定制为 10 , 最后 jar 包也在本地仓库找到，Maven 成功打包。 远程仓库优先级前面我们知道了，本地仓库的优先级是最高的，现在我们继续研究远程仓库的优先级（以下的所有例子，都默认本地仓库不拥有我们需要的包） 这一次我们默认配置 profile（私服）为 172.16.xxx.xxx 远程仓库, repository 为 dev.xxx.wiki 远程仓库,mirror 为本地 localhost 仓库，还配置了一个 mirrorOf 为 central 远程仓库为 maven.aliyun.com 的中央仓库, 以下是配置信息settings.xml 文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253······&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;localhost&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo&lt;/mirrorOf&gt; &lt;!--拦截 pom 文件配置的 repository--&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;localhost2&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo2&lt;/mirrorOf&gt; &lt;!--配置一个拦截 foo2 的远程仓库的镜像--&gt; &lt;url&gt;http://localhost:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;!--覆盖 Maven 默认的配置的中央仓库--&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;!--配置私服--&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt;&lt;/activeProfiles&gt;······ pom.xml 文件 12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;!--xxx-cif-api 存在 172.16.xxx.xxx 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.xxx.cif&lt;/groupId&gt; &lt;artifactId&gt;xxx-cif-api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--Chapter1 存在 localhost 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--配置远程仓库--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;foo&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://dev.xxx.wiki:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 以下是 Maven 拉取包的日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108······· 省略部分日志信息[DEBUG] Using local repository at E:\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\OperSource[INFO] Scanning for projects...// 从这里可以看出我们配置的镜像替代了我们在 pom 配置的远程仓库[DEBUG] Using mirror localhost (http://localhost:8081/repository/maven-public/) for foo (http://dev.xxx.wiki:8081/nexus/content/groups/public/).替代了默认的中央仓库[DEBUG] Using mirror alimaven (http://maven.aliyun.com/nexus/content/groups/public/) for central (https://repo.maven.apache.org/maven2).// 从这里可以看出 Maven 使用哪些 dependencies 和 plugins 的地址，我们可以看出优先级最高的是 172.16.xxx.xxx,然后就是 localhost 最后才是 maven.aliyun.com// 注意：alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases) 从这里可以看出中央仓库只能获取 releases 包，所有的 snapshots 包都不从中央仓库获取。（可以看前面 central 的配置信息）[DEBUG] === PROJECT BUILD PLAN ================================================[DEBUG] Project: com.cjf:demo:1.0-SNAPSHOT[DEBUG] Dependencies (collect): [][DEBUG] Dependencies (resolve): [compile, runtime, test][DEBUG] Repositories (dependencies): [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public/, default, releases+snapshots), localhost (http://localhost:8081/repository/maven-public/, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] Repositories (plugins) : [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] =======================================================================// 寻找本地是否有 maven-metadata.xml 配置文件 ，从这里可以看出寻找不到（后面会详细讲该文件作用）[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\OperSource)// 由于寻找不到 Maven 只能从我们配置的远程仓库寻找，由于 Maven 也不知道那个仓库才有，所以同时寻找两个仓库[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\resolver-status.properties// 从这里可以看出在 172.16.xxx.xxx 找到 xxx-cif-api 的 maven-metadata.xml 文件并下载下来Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml (781 B at 7.0 KB/sec)// 追踪文件，resolver-status.properties 配置了 jar 包下载地址和时间[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\resolver-status.properties[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in localhost (http://localhost:8081/repository/maven-public/)// 在 localhost 远程仓库寻找不到 xxx-cif-api 的 maven-metadata.xml[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\OperSource)// 跳过的远程请求 [DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.[DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.// 默认以后获取 xxx-cif-api 的时候将不在从 localhost 寻找了，除非强制获取才会再次从 localhost 寻找这个包[DEBUG] Failure to find com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in http://localhost:8081/repository/maven-public/ was cached in the local repository, resolution will not be reattempted until the update interval of localhost has elapsed or updates are forced// 将 172.16.xxx.xxx 优先级升为 0 ，并下载 xxx-cif-api 的 pom 文件[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pomDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pom (930 B at 82.6 KB/sec)// _remote.repositories 记录的以后使用那个远程仓库获取 （ps:这个文件作用我要不是很清楚作用，以上观点是自己推测出来的。）[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\xxx-cif-api-0.0.1-20170515.040917-89.pom.lastUpdated// 后面获取 Chapter1 包的流程跟 com.xxx.cif 是一样的，不过最后是在 localhost 寻找到而已，所以这分日志就不贴出来了。// 最后在下载包的时候，都到对应的仓库下载[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jarDownloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jarDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jar (26 KB at 324.2 KB/sec)Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jar (68 KB at 756.6 KB/sec)[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\xxx-cif-api-0.0.1-20170515.040917-89.jar.lastUpdated[DEBUG] Writing tracking file E:\OperSource\com\xxx\util\xxx-util\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\util\xxx-util\0.0.1-SNAPSHOT\xxx-util-0.0.1-20170514.091041-31.jar.lastUpdated[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/Downloading: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jarDownloaded: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jar (8 KB at 167.0 KB/sec)[DEBUG] Writing tracking file E:\OperSource\com\cjf\Chapter1\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\cjf\Chapter1\0.0.1-SNAPSHOT\Chapter1-0.0.1-20170708.092339-1.jar.lastUpdated[INFO] Installing C:\Users\swipal\Desktop\abc\demo\target\demo-1.0-SNAPSHOT.jar to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[INFO] Installing C:\Users\swipal\Desktop\abc\demo\pom.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\OperSource\com\cjf\demo\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 10.549 s[INFO] Finished at: 2017-07-09T18:13:20+08:00[INFO] Final Memory: 26M/219M[INFO] ------------------------------------------------------------------------······· 好了，看了这么多的配置文件信息和日志信息，我们也总结一下 Maven 远程仓库优先级了。 主要有以下几点：1.从日志信息我们得出这几种maven仓库的优先级别为 本地仓库 &gt; 私服 （profile）&gt; 远程仓库（repository）和 镜像 （mirror） &gt; 中央仓库 （central） 2.镜像是一个特殊的配置，其实镜像等同与远程仓库，没有匹配远程仓库的镜像就毫无作用（如 foo2）。3.总结上面所说的，Maven 仓库的优先级就是 私服和远程仓库 的对比，没有其它的仓库类型。为什么这么说是因为，镜像等同远程，而中央其实也是 maven super xml 配置的一个repository 的一个而且。所以 maven 仓库真正的优先级为 本地仓库 &gt; 私服（profile）&gt; 远程仓库（repository） maven-metadata.xml 文件Maven Repository Metadata 可用于表示： 1. 一个没有版本的工件：它提供有关该工件的可用版本的信息 2. 快照伪像：它提供有关快照的精确信息 3. 包含Maven插件工件的组：它提供了有关此组中可用插件的信息。 元数据文件名是： 远程存储库中的 maven-metadata.xml， maven-metadata- &lt;repo-id&gt;.xml在本地存储库中，用于具有repo-id标识符的存储库中的元标记。 以上是 Maven 官网对该文件的解释。 作用问题：有时候我们更新最新包的时候，会发现最新的包被拉取下来的，但是项目使用的包还是旧的包。所以我们要分析下是什么原因导致的。 首先我们先大概的了解下 maven-metadata.xml 文件。1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;metadata modelVersion="1.1.0"&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;!--当前版本下的最新快照信息--&gt; &lt;timestamp&gt;20170710.071727&lt;/timestamp&gt; &lt;!--快照的时间戳--&gt; &lt;buildNumber&gt;6&lt;/buildNumber&gt; &lt;!--构件号--&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20170710071727&lt;/lastUpdated&gt;&lt;!--metadata文件被更新的时间--&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;!--当前版本下可用的子快照版本信息--&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt;&lt;!--子快照版本的信息--&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;!--这个子快照版本的更新时间--&gt; &lt;/snapshotVersion&gt; &lt;snapshotVersion&gt; &lt;extension&gt;pom&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/snapshotVersions&gt; &lt;/versioning&gt;&lt;/metadata&gt; 其中 lastUpdated 是最中要的一个属性，Maven 更新工程的 jar包时，会比较 lastUpdated 时间戳值，哪个值更大，就以哪个文件为准。 接下来我们看下 Maven 为我们生成了那些文件我们可以看到 maven-metadata.xml 一共有三个 1. maven-metadata-local.xml 本地的元数据, Maven install 的时候就会生成。 2. maven-metadata-snapshots.xml Maven deploy 时会生成 3. maven-metadata-localhost.xml 远程仓库获取的时候生成 (repository 的 id = localhost) 以上的文件其实都是 Maven 的过渡文件而已 例如 maven-metadata-snapshots 就是 Maven deploy 先从远程仓库对应包的 maven-metadata.xml 下载下来，然后修改快照信息后在上传到远程仓库上。 例如 maven-metadata-localhost 的作用是在 Maven 在拉取包的时候，会先跟本地 maven-metadata-local 比较下 lastUpdated 时间戳值，值大用哪个。如果是 Mavne 强制更新 的时候(没有强制更新是不会) 会下载远程的 maven-metadata.xml 比较远程，本地，和之前远程保存下来的 maven-metadata 文件。 所以有时候 maven 库上的 jar 包已经更新，而我们总是拉取不到 maven 的包原因就是本地的 maven-metadata-local 的 lastUpdated 比较大。 我们验证下 Maven deploy 例子123456789101112131415161718192021222324[INFO] --- maven-deploy-plugin:2.8.2:deploy (default-deploy) @ Chapter1 ---// 先从远程下载快照 maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 3.3 KB/sec)// 将项目的 jar 和 pom 文件更新到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jarUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jar (8 KB at 14.1 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pomUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pom (2 KB at 2.0 KB/sec)Downloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 1.6 KB/sec)// 上传 maven-metadata.xml 到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 1.0 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 0.4 KB/sec)[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.231 s[INFO] Finished at: 2017-07-10T20:13:13+08:00[INFO] Final Memory: 19M/226M[INFO] ------------------------------------------------------------------------ 总结原本以为两天就写好这篇文章，在自己理清思路的时候总是被自己绕晕了。比如在 Nexus 的 Central 配置的中央仓库获取，和 maven-metadata.xml 是如何比较的。 如果以上文章有误，等博客的评论系统搭建起来后欢迎大家指认出来。]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LogBack 使用]]></title>
    <url>%2F2017%2F09%2F03%2FLogback%2F</url>
    <content type="text"><![CDATA[26 Seven 2017 前言之前项目一直使用 logback ,现在大概写下了 logback 基础配置。 简介LogBack是一个日志框架，它是Log4j作者Ceki的又一个日志组件。 LogBack,Slf4j,Log4j之间的关系 slf4j是The Simple Logging Facade for Java的简称，是一个简单日志门面抽象框架，它本身只提供了日志Facade API和一个简单的日志类实现，一般常配合Log4j，LogBack，java.util.logging使用。Slf4j作为应用层的Log接入时，程序可以根据实际应用场景动态调整底层的日志实现框架(Log4j/LogBack/JdkLog…)； LogBack和Log4j都是开源日记工具库，LogBack是Log4j的改良版本，比Log4j拥有更多的特性，同时也带来很大性能提升。 LogBack官方建议配合Slf4j使用，这样可以灵活地替换底层日志框架。 LogBack的结构LogBack分为3个组件，logback-core, logback-classic 和 logback-access。其中logback-core提供了LogBack的核心功能，是另外两个组件的基础。logback-classic则实现了Slf4j的API，所以当想配合Slf4j使用时，则需要引入这个包。logback-access是为了集成Servlet环境而准备的，可提供HTTP-access的日志接口。 Log的行为级别：OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL从下向上，当选择了其中一个级别，则该级别向下的行为是不会被打印出来。举个例子，当选择了INFO级别，则INFO以下的行为则不会被打印出来。 获取 Logger 对象 我们先从获取 logger 对象开始1Logger logger = LoggerFactory.getLogger(xxx.class.getName()); LoggerFactory 是 slf4j 的日志工厂，获取 logger 方法就来自这里。123456以下代码摘自：org.slf4j.LoggerFactorypublic static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 这个方法里面有分为两个过程。第一个过程是获取ILoggerFactory，就是真正的日志工厂。第二个过程就是从真正的日志工厂中获取logger。接下来我们看下到底是怎么获取的12345678910111213141516171819202122232425262728以下代码摘自：org.slf4j.LoggerFactorypublic static ILoggerFactory getILoggerFactory() &#123;if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; // 第一次调用会去加载 StaticLoggerBinder.class 文件来决定 LoggerFactory 的实现类 // （补充下：不同日志包下都有 StaticLoggerBinder 这个类文件，这个会决定 LoggerFactory 初始化那种类型的日志） performInitialization();&#125;// INITIALIZATION_STATE 值判断是否有加载初始化过 ILoggerFactory 实例。switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: // 返回对应的 ILoggerFactory 实例 return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: // 当加载不到一个 StaticLoggerBinder 时，会走这里 // 返回一个 NOPLoggerFactory 实例 return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: // 初始化异常 throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://bugzilla.slf4j.org/show_bug.cgi?id=106 return TEMP_FACTORY;&#125;throw new IllegalStateException("Unreachable code");&#125; 接下来我们来看下是怎么加载 StaticLoggerBinder.class 文件的 1234567891011121314151617181920212223242526272829303132333435以下代码摘自：org.slf4j.LoggerFactory private final static void bind() &#123; try &#123; // 加载 StaticLoggerBinder Set staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); // 最后会随机选择一个StaticLoggerBinder.class来创建一个单例 StaticLoggerBinder.getSingleton(); // 改变 INITIALIZATION_STATE 值，表示成功初始化 Factory。 // 并且以后在获取 Logger 的时候并不会再次加载该方法 INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); emitSubstituteLoggerWarning(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; // 加载不到 StaticLoggerBinder 文件 INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.indexOf("org.slf4j.impl.StaticLoggerBinder.getSingleton()") != -1) &#123; // 初始化异常 INITIALIZATION_STATE = FAILED_INITIALIZATION; &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException("Unexpected initialization failure", e); &#125; &#125; 加载 StaticLoggerBinder.class12345678910111213141516以下代码摘自：org.slf4j.LoggerFactory.findPossibleStaticLoggerBinderPathSetprivate static String STATIC_LOGGER_BINDER_PATH = "org/slf4j/impl/StaticLoggerBinder.class";···if (loggerFactoryClassLoader == null) &#123; paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); &#125; else &#123; paths = loggerFactoryClassLoader .getResources(STATIC_LOGGER_BINDER_PATH); &#125; while (paths.hasMoreElements()) &#123; URL path = (URL) paths.nextElement(); staticLoggerBinderPathSet.add(path); &#125;··· 当项目中存在多个StaticLoggerBinder.class文件时，运行项目会出现以下日志：（这里获取的规则就近原则，如果在 maven 先配置 slf4j 而后面在配置 logback，则这里初始化的是 slf4j）12345SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/E:/OperSource/org/slf4j/slf4j-log4j12/1.7.12/slf4j-log4j12-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/E:/OperSource/ch/qos/logback/logback-classic/1.1.3/logback-classic-1.1.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] 返回实例123以下代码摘自：org.slf4j.LoggerFactory.getILoggerFactoryStaticLoggerBinder.getSingleton().getLoggerFactory(); LogBack 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 项目名称配置 --&gt; &lt;contextName&gt;example&lt;/contextName&gt; &lt;!-- 属性 --&gt; &lt;property name="APP_Name" value="example" /&gt; &lt;!-- 统一的时间格式，用于日志头输出 --&gt; &lt;timestamp key="timeStyle" datePattern="yyyy-MM-dd HH:mm:ss.SSS"/&gt; &lt;!--配置控制台输出,开发环境有--&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- encoder 默认配置为PatternLayoutEncoder --&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--文件输出配置--&gt; &lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_run.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_run.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="BUSINESS_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_business.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_business.%i.business.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt;&lt;!-- 只打印错误日志 --&gt; &lt;level&gt;WARE&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 异步输出 --&gt; &lt;appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref="FILE"/&gt; &lt;/appender&gt; &lt;appender name="BUSINESS_ASYNC" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref="BUSINESS_FILE"/&gt; &lt;/appender&gt; &lt;!-- 为数据库开启显示sql --&gt; &lt;logger name="com.cjf.example.repository" level="DEBUG"&gt;&lt;/logger&gt; &lt;logger name="com.cjf" level="INFO"&gt;&lt;/logger&gt; &lt;!--日志的root目录，用于定位日志输出级别--&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="ASYNC"/&gt; &lt;appender-ref ref="STDOUT"/&gt; &lt;/root&gt;&lt;/configuration&gt; 上面就是一个常用的日志配置模版，下面就从跟节点来解析每个节点 1.configurationscan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod：监测配置文件是否有修改的时间间隔，默认 60s。debug：是否打印 logback 内部日志，默认 false.2.contextName 项目名称logger 上下文容器名称，默认 ‘default’，用于区分不同应用程序的记录。（可以在日志输出的时候将项目名称打印处理方便系统间交互 比如上面配置的 %cn）3.property 设置变量定义变量后，可以使${}来使用变量。4.timestamp 设置时间戳格式key:标识此 的名字；datePattern：设置将当前时间（解析配置文件的时间）转换为字符串的模式，遵循Java.txt.SimpleDateFormat的格式。5.logger用来设置某一个包或者具体的某一个类的日志打印级别、以及指定。仅有一个name属性，一个可选的level和一个可选的addtivity属性。name: 用来指定受此loger约束的某一个包或者具体的某一个类。level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。如果未设置此属性，那么当前loger将会继承上级的级别。addtivity:是否向上级loger传递打印信息。默认是true。loger可以包含零个或多个appender-ref元素，标识这个appender将会添加到这个loger。6.root也是 loger 元素，但是它是根 loger。只有一个 level 属性，应为已经被命名为 “root”.root 可以包含零个或多个 appender-ref 元素，标识这个 appender 将会添加到这个 loger。 什么是 Appender？logback 将日志记录事件写入到名为 appender 的组件的任务,不同 appender 决定了日志的记录方式。appender 有多种实现的方式，下面简单介绍几种比较常用的配置。 更多详情请参考官方文档 ConsoleAppender把日志添加到控制台，有以下子节点： encoder：对日志进行格式化 target：字符串 System.out 或者 System.err ，默认 System.out; withJansi：日志彩色输出 例如123456789101112&lt;configuration&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="DEBUG"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/root&gt; &lt;/configuration&gt; RollingFileAppender滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。file：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。append：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。encoder：对记录事件进行格式化。rollingPolicy：当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名。triggeringPolicy：告知 RollingFileAppender 合适激活滚动。prudent：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。 rollingPolicy 有两种类型，分别是 TimeBasedRollingPolicy，FixedWindowRollingPolicy。 例如 TimeBasedRollingPolicy 配置123456789101112&lt;!--输出到文件--&gt;&lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.path&#125;&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;logback.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; fileNamePattern 定义了日志的切分方式——把每一天的日志归档到一个文件中maxHistory 表示只保留最近30天的日志，以防止日志填满整个磁盘空间。totalSizeCap 用来指定日志文件的上限大小，例如设置为1GB的话，那么到了这个值，就会删除旧的日志。 例如 FixedWindowRollingPolicy 配置1234567891011121314&lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_run.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_run.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 这里多了一个 SizeBasedTriggeringPolicy 触发机制，但 log 文件大于 10MB 的时候，就开始执行 rolling。minIndex 和 maxIndex 表示保存日志数量，但大于 maxIndex 的时候，会开始删除旧的日志。 必须包含“%i”例如，假设最小值和最大值分别为1和2，命名模式为mylog%i.log,会产生归档文件mylog1.log和mylog2.log。还可以指定文件压缩选项，例如，mylog%i.log.gz或者 没有log%i.log.zip AsyncAppender 异步输出这里就不写了，可以参考文章。 总结由于没有深入去了解 logback ,许多内容都是网上摘来的，写文章的时候也很费劲。思路不清晰。]]></content>
      <categories>
        <category>LogBack</category>
      </categories>
      <tags>
        <tag>LogBack</tag>
      </tags>
  </entry>
</search>