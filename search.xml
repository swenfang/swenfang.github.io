<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java选择题【1~60】]]></title>
    <url>%2F2018%2F03%2F18%2FJava%E9%80%89%E6%8B%A9%E9%A2%98%E3%80%901~60%E3%80%91%2F</url>
    <content type="text"><![CDATA[Java选择题【1~60】原文地址：http://blog.csdn.net/qq_36075612/article/details/71126487 1.下面中哪两个可以在A的子类中使用：（ ） 123456789class A &#123;protected int method1 (int a, int b) &#123;return 0;&#125;&#125; A. public int method 1 (int a, int b) { return 0; } B. private int method1 (int a, int b) { return 0; } C. private int method1 (int a, long b) { return 0; } D. public short method1 (int a, int b) { return 0; } 解答：AC 主要考查子类重写父类的方法的原则 B，子类重写父类的方法，访问权限不能降低 C，属于重载 D，子类重写父类的方法 返回值类型要相同或是父类方法返回值类型的子类 2.Abstract method cannot be static. True or False ? A True B False 解答：A 抽象方法可以在子类中被重写，但是静态方法不能在子类中被重写，静态方法和静态属性与对象是无关的，只与类有关，这与abstract是矛盾的，所以abstract是不能被修饰为static，否则就失去了abstract的意义了 3.What will be the output when you compile and execute the following program. 12345678910111213141516171819202122232425262728293031class Base&#123;void test() &#123;System.out.println(“Base.test()”);&#125;&#125;public class Child extends Base &#123;void test() &#123;System.out.println(“Child.test()”);&#125;static public void main(String[] a) &#123;Child anObj = new Child();Base baseObj = (Base)anObj;baseObj.test();&#125;&#125; Select most appropriate answer. A . Child.test() Base.test() B. Base.test() Child.test() C. Base.test() D. Child.test() 解答：D 测试代码相当于：Base baseObj = new Child();父类的引用指向子类的实例，子类又重写了父类 的test方法，因此调用子类的test方法。 4.What will be the output when you compile and execute the following program. 1234567891011121314151617181920212223242526272829class Base&#123;static void test() &#123;System.out.println(“Base.test()”);&#125;&#125;public class Child extends Base &#123;void test() &#123;System.out.println(“Child.test()”);Base.test(); //Call the parent method&#125;static public void main(String[] a) &#123;new Child().test();&#125;&#125; Select most appropriate answer. A . Child.test() 、Base.test() B . Child.test()、Child.test() C. Compilation error. Cannot override a static method by an instance method D. Runtime error. Cannot override a static method by an instance method 解答：C 静态方法不能在子类中被重写 5.What will be the output when you compile and execute the following program. 123456789101112131415public class Base&#123;private void test() &#123;System.out.println(6 + 6 + “(Result)”);&#125;static public void main(String[] a) &#123;new Base().test();&#125;&#125; Select most appropriate answer. A. 66(Result) B . 12(Result) C . Runtime Error.Incompatible type for +. Can’t convert an int to a string. D . Compilation Error.Incompatible type for +. Can’t add a string to an int. 解答：B 字符串与基本数据类型链接的问题,如果第一个是字符串那么后续就都按字符串处理，比如上边例子要是System.out.println(“(Result)”+6 + 6 );那么结果就是(Result)66，如果第一个和第二个。。。第n个都是基本数据第n+1是字符串类型，那么前n个都按加法计算出结果在与字符串连接 6..What will be the output when you compile and execute the following program. The symbol ’ ?’ means space. 12345678910111213141516171819202122232425262728291:public class Base&#123;2:3: private void test() &#123;4:5: String aStr = “?One?”;6: String bStr = aStr;7: aStr.toUpperCase();8: aStr.trim();9: System.out.println(“[" + aStr + "," + bStr + "]“);7: &#125;8:9: static public void main(String[] a) &#123;10: new Base().test();11: &#125;12: &#125; Select most appropriate answer. A. [ONE,?One?] B . [?One?,One] C . [ONE,One] D . [ONE,ONE] E . [?One?,?One?] 解答：E 通过 String bStr = aStr; 这句代码使 bStr 和 aStr 指向同一个地址空间，所以最后 aStr 和 bStr 的结果应该是一样，String 类是定长字符串，调用一个字符串的方法以后会形成一个新的字符串。 7.下面关于变量及其范围的陈述哪些是不正确的（ ）： A．实例变量是类的成员变量 B．实例变量用关键字static声明 C．在方法中定义的局部变量在该方法被执行时创建 D．局部变量在使用前必须被初始化 解答：BC 由static修饰的变量称为类变量或是静态变量 方法加载的时候创建局部变量 8.下列关于修饰符混用的说法，错误的是（ ）： A．abstract不能与final并列修饰同一个类 B．abstract类中可以有private的成员 C．abstract方法必须在abstract类中 D．static方法中能处理非static的属性 解答 D 静态方法中不能引用非静态的成员 9.执行完以下代码 int [ ] x = new int[25]; 后，以下哪项说明是正确的（ ）： A、 x[24]为0 B、 x[24]未定义 C、 x[25]为0 D、 x[0]为空 解答：A x 属于引用类型，该引用类型的每一个成员是 int 类型，默认值为：0 10.编译运行以下程序后，关于输出结果的说明正确的是 （ ）： 1234567891011public class Conditional&#123;public static void main(String args[ ])&#123;int x=4;System.out.println(“value is “+ ((x&gt;4) ? 99.9 :9));&#125;&#125; A、 输出结果为：value is 99.99 B、 输出结果为：value is 9 C、 输出结果为：value is 9.0 D、 编译错误 解答：C 三目运算符中：第二个表达式和第三个表达式中如果都为基本数据类型，整个表达式的运算结果 由容量高的决定。99.9是double类型 而9是int类型，double容量高。 11.关于以下 application 的说明，正确的是（ ）： 123456789101112131415161718191． class StaticStuff2． &#123;3． static int x=10；4． static &#123; x+=5；&#125;5． public static void main（String args[ ]）6． &#123;7． System.out.println(“x=” + x);8． &#125;9． static &#123; x/=3;&#125;10. &#125; A、 4行与9行不能通过编译，因为缺少方法名和返回类型 B、 9行不能通过编译，因为只能有一个静态初始化器 C、 编译通过，执行结果为：x=5 D、编译通过，执行结果为：x=3 解答：C 自由块是类加载的时候就会被执行到的，自由块的执行顺序是按照在类中出现的先后顺序执行。 12.关于以下程序代码的说明正确的是（ ）： 123456789101112131415161718192021222324251．class HasStatic&#123;2． private static int x=100；3． public static void main(String args[ ])&#123;4． HasStatic hs1=new HasStatic( );5． hs1.x++;6． HasStatic hs2=new HasStatic( );7． hs2.x++;8． hs1=new HasStatic( );9． hs1.x++;10． HasStatic.x–;11． System.out.println(“x=”+x);12． &#125;13．&#125; A、5行不能通过编译，因为引用了私有静态变量 B、10行不能通过编译，因为x是私有静态变量 C、程序通过编译，输出结果为：x=103 D、程序通过编译，输出结果为：x=102 解答：D 静态变量是所有对象所共享的，所以上述代码中的几个对象操作是同一静态变量x， 静态变量可以通过类名调用。 13.下列说法正确的有（） A． class 中的constructor不可省略 B． constructor 必须与 class同名，但方法不能与class同名 C． constructor 在一个对象被 new 时执行 D．一个 class 只能定义一个constructor 解答：C 构造方法的作用是在实例化对象的时候给数据成员进行初始化 A．类中如果没有显示的给出构造方法，系统会提供一个无参构造方法 B．构造方法与类同名，类中可以有和类名相同的方法 D．构造方法可以重载 14.下列哪种说法是正确的（） A．实例方法可直接调用超类的实例方法 B．实例方法可直接调用超类的类方法 C．实例方法可直接调用其他类的实例方法 D．实例方法可直接调用本类的类方法 解答：D A. 实例方法不可直接调用超类的私有实例方法 B. 实例方法不可直接调用超类的私有的类方法 C．要看访问权限 15.下列哪一种叙述是正确的（ ） A． abstract修饰符可修饰字段、方法和类 B． 抽象方法的body部分必须用一对大括号{ }包住 C． 声明抽象方法，大括号可有可无 D． 声明抽象方法不可写出大括号 解答：D abstract可以修饰方法和类，不能修饰属性。抽象方法没有方法体，即没有大括号{} 16.下面代码的执行结果是？ 12345678910111213141516171819202122232425import java.util.*;public class ShortSet&#123;public static void main(String args[])&#123;Set&lt;Short&gt; s=new HashSet&lt;Short&gt;();for(Short i=0;i&lt;100;i++)&#123;s.add(i);s.remove(i-1);&#125;System.out.println(s.size());&#125;&#125; A. 1 B. 100 C. Throws Exception D. None of the Above 解答：B i 是 Short 类型 i-1 是int类型,其包装类为 Integer ，所以 s.remove(i-1); 不能移除Set集合中Short类型对象。 17.链表具有的特点是：(选择3项) A、不必事先估计存储空间 B、可随机访问任一元素 C、插入删除不需要移动元素 D、所需空间与线性表长度成正比 解答：ACD A.采用动态存储分配，不会造成内存浪费和溢出。 B. 不能随机访问，查找时要从头指针开始遍历 C. 插入、删除时，只要找到对应前驱结点，修改指针即可，无需移动元素 D. 需要用额外空间存储线性表的关系，存储密度小 18.Java语言中，String类的IndexOf()方法返回的类型是？ A、Int16 B、Int32 C、int D、long 解答：C indexOf方法的声明为：public int indexOf(int ch) 在此对象表示的字符序列中第一次出现该字符的索引；如果未出现该字符，则返回 -1。 19.以下关于面向对象概念的描述中，不正确的一项是（）。(选择1项) A.在现实生活中，对象是指客观世界的实体 B.程序中的对象就是现实生活中的对象 C.在程序中，对象是通过一种抽象数据类型来描述的，这种抽象数据类型称为类（class） D.在程序中，对象是一组变量和相关方法的集合 解答：B 20..执行下列代码后,哪个结论是正确的 String[] s=new String[10]; A． s[9] 为 null; B． s[10] 为 “”; C． s[0] 为 未定义 D． s.length 为10 解答：AD s是引用类型，s中的每一个成员都是引用类型，即String类型，String类型默认的值为null s数组的长度为10。 21.属性的可见性有。(选择3项) A.公有的 B.私有的 C.私有保护的 D.保护的 解答：ABD 属性的可见性有四种：公有的（public） 保护的（protected） 默认的 私有的（private） 22..在字符串前面加上_符号，则字符串中的转义字符将不被处理。(选择1项) A @ B \ C # D % 解答：B 23.下列代码哪行会出错: (选择1项) 123456789101) public void modify() &#123; 2) int I, j, k; 3) I = 100; 4) while ( I &gt; 0 ) &#123; 5) j = I * 2; 6) System.out.println (” The value of j is ” + j ); 7) k = k + 1; 8) I–; 9) &#125; 10) &#125; A. 4 B. 6 C. 7 D. 8 解答：C k没有初始化就使用了 24.对记录序列{314，298，508，123，486，145}按从小到大的顺序进行插入排序，经过两趟排序后的结果为：(选择1项) A {314，298，508，123，145，486} B {298，314，508，123，486，145} C {298，123，314，508，486，145} D {123、298，314，508，486，145} 解答：B 插入排序算法： 123456789101112131415161718192021222324252627public static void injectionSort(int[] number) &#123;// 第一个元素作为一部分，对后面的部分进行循环for (int j = 1; j &lt; number.length; j++) &#123;int tmp = number[j];int i = j – 1;while (tmp &lt; number[i]) &#123;number[i + 1] = number[i];i–;if (i == -1)break;&#125;number[i + 1] = tmp;&#125;&#125; 25.栈是一种。(选择1项) A 存取受限的线性结构 B 存取不受限的线性结构 C 存取受限的非线性结构 D 存取不受限的非线性结构 解答：A 栈（stack）在计算机科学中是限定仅在表尾进行插入或删除操作的线性表。 26.下列哪些语句关于内存回收的说明是正确的。(选择1项) A. 程序员必须创建一个线程来释放内存 B. 内存回收程序负责释放无用内存 C. 内存回收程序允许程序员直接释放内存 D. 内存回收程序可以在指定的时间释放内存对象 解答：B 垃圾收集器在一个Java程序中的执行是自动的，不能强制执行，即使程序员能明确地判断出有一块内存已经无用了，是应该回收的，程序员也不能强制垃圾收集器回收该内存块。程序员唯一能做的就是通过调用System. gc 方法来”建议”执行垃圾收集器，但其是否可以执行，什么时候执行却都是不可知的。 27.Which method must be defined by a class implementing the java.lang.Runnable interface? A. void run() B. public void run() C. public void start() D. void run(int priority) E. public void run(int priority) F. public void start(int priority) 解答：B 实现Runnable接口，接口中有一个抽象方法run，实现类中实现该方法。 28 Given: 123456789101112131415public static void main(String[] args) &#123;Object obj = new Object() &#123;public int hashCode() &#123;return 42;&#125;&#125;;System.out.println(obj.hashCode());&#125; What is the result? A. 42 B. An exception is thrown at runtime. C. Compilation fails because of an error on line 12. D. Compilation fails because of an error on line 16. E. Compilation fails because of an error on line 17. 解答：A 匿名内部类覆盖hashCode方法。 29.哪两个是Java编程语言中的保留字 ? (Choose two) A. run B. import C. default D. implements 解答：BD import导入包的保留字，implements实现接口的保留字。 Which two statements are true regarding the return values of property written hashCodeand equals methods from two instances of the same class? (Choose two) A. If the hashCode values are different, the objects might be equal. B. If the hashCode values are the same, the object must be equal. C. If the hashCode values are the same, the objects might be equal. D. If the hashCode values are different, the objects must be unequal. 解答：CD 先通过 hashcode 来判断某个对象是否存放某个桶里，但这个桶里可能有很多对象，那么我们就需要再通过 equals 来在这个桶里找到我们要的对象。 字符的数字范围是什么? A. 0 … 32767 B. 0 … 65535 C. –256 … 255 D. –32768 … 32767 E. Range is platform dependent. 解答：B 在Java中，char是一个无符号16位类型，取值范围为0到65535。 Given: 1234567891011public class Test &#123;private static float[] f = new float[2];public static void main(String args[]) &#123;System.out.println(“f[0] = “ + f[0]);&#125;&#125; What is the result? A. f[0] = 0 B. f[0] = 0.0 C. Compilation fails. D. An exception is thrown at runtime. 解答：B Given: 1234567891011public class Test &#123;public static void main(String[] args) &#123;String str = NULL;System.out.println(str);&#125;&#125; What is the result? A. NULL B. 编译失败 C. 运行代码没有输出 D. 运行时抛出异常 解答：B null应该小写 34、Exhibit: 123456789101112131415161718192021222324252627282930311.public class X implements Runnable &#123;2. private int x;3. private int y;4. public static void main(String [] args) &#123;5. X that = new X();6. (new Thread(that)).start();7. (new Thread(that)).start();8. &#125;9. public synchronized void run( )&#123;10. for (;;) &#123;11. x++;12. y++;13. System.out.println(“x = “ + x + “, y = “ + y);14. &#125;15. &#125;16.&#125; What is the result? A. 第11行的错误导致编译失败 B. 第7行和第8行的错误导致编译失败。 C. 该程序打印 x 和 y 的值对，这些值在同一行上可能不总是相同的 (例如, “x=2, y=1”) D. 该程序在同一行上打印x和y的值总是一对相同的值(例如, “x=1, y=1”. 此外,每个值出现两次(例如, “x=1, y=1” 其次是“x=1, y=1”) E. 该程序在同一行上打印x和y的值总是一对相同的值 (例如, “x=1, y=1”.此外,每个值出现两次 (例如, “x=1, y=1” 其次 “x=2, y=2”) 解答：E 多线程共享相同的数据，使用 synchronized 实现数据同步。 35、哪两个不能直接导致线程停止执行? (Choose Two) A. 使用 synchronized block. B. 在对象上调用 wait 方法 C. 调用对象的 notify 方法 D. 在InputStream对象上调用read方法。 E. 调用Thread对象上的SetPriority方法。 解答：AD stop方法.这个方法将终止所有未结束的方法，包括run方法。当一个线程停止时候，他会立即释 放 所有他锁住对象上的锁。这会导致对象处于不一致的状态。 当线程想终止另一个线程的时 候，它无法知道何时调用stop是安全的，何时会导致对象被破坏。所以这个方法被弃用了。你应 该中断一个线程而不是停止他。被中断的线程会在安全的时候停止。 36、 关于创建默认构造函数描述正确的是? (Choose Two) A. 默认构造函数初始化方法变量 B. 默认构造函数调用超类的无参数构造函数 C. 默认构造函数初始化在类中声明的实例变量 D. 如果一个类缺少一个无参数构造函数，但有其他构造函数，编译器会创建一个默认构造函数。 E. 编译器只有在没有其他构造函数是才会创建构造函数 解答：CE 构造方法的作用是实例化对象的时候给数据成员初始化，如果类中没有显示的提供构造方法，系统会提供默认的无参构造方法，如果有了其它构造方法，默认的构造方法不再提供。 37、 Given: 1234567public class OuterClass &#123;private double d1 = 1.0;//insert code here&#125; 您需要在第2行插入内部类声明。 哪两个内部类声明是有效的？ A. static class InnerOne { public double methoda() {return d1;} } B. static class InnerOne { static double methoda() {return d1;} } C. private class InnerOne { public double methoda() {return d1;} } D. protected class InnerOne { static double methoda() {return d1;} } E. public abstract class InnerOne { public abstract double methoda(); } 解答：CE AB.内部类可以声明为static的，但此时就不能再使用外层封装类的非static的成员变量； D.非static的内部类中的成员不能声明为static的，只有在顶层类或static的内部类中 才可声明static成员 38、哪两个声明可以防止重写方法？ (Choose Two) A. final void methoda() {} B. void final methoda() {} C. static void methoda() {} D. static final void methoda() {} E. final abstract void methoda() {} 解答：AD final修饰方法，在子类中不能被重写。 39、Given: 12345678910111213141516171819public class Test &#123;public static void main (String args[]) &#123;class Foo &#123;public int i = 3;&#125;Object o = (Object) new Foo();Foo foo = (Foo)o;System.out.println(foo.i);&#125;&#125; What is the result? A. 编译将失败。 B. 编译将成功，程序将打印“3” C. 编译会成功，但程序会在第6行抛出ClassCastException。 D. 编译会成功，但程序会在第7行抛出ClassCastException。 解答：B 局部内部类的使用 40、 Given: 123456789101112131415public class Test &#123;public static void main (String [] args) &#123;String foo = “blue”;String bar = foo;foo = “green”;System.out.println(bar);&#125;&#125; What is the result? A. 抛出异常。 B. 代码不会编译。 C. 该程序打印“null” D. 该程序打印“blue” E. 该程序打印“green” 解答：D 采用String foo = “blue”定义方式定义的字符串放在字符串池中，通过String bar = foo; 他们指向了同一地址空间，就是同一个池子，当执行foo = “green”; foo指向新的地址空间。 41、Which code determines the int value foo closest to a double value bar? A. int foo = (int) Math.max(bar); B. int foo = (int) Math.min(bar); C. int foo = (int) Math.abs(bar); D. int foo = (int) Math.ceil(bar); E. int foo = (int) Math.floor(bar); F. int foo = (int) Math.round(bar); 解答：DEF A B两个选项方法是用错误，都是两个参数。 abs方法是取bar的绝对值， ceil方法返回最小的（最接近负无穷大）double 值，该值大于等于参数，并等于某个整数。 floor方法返回最大的（最接近正无穷大）double 值，该值小于等于参数，并等于某个整数。 round方法 返回最接近参数的 long。 42、 Exhibit: 123456789101112131415161718192021222324252627282930311.package foo;2.import java.util.Vector;3.private class MyVector extends Vector &#123;4.int i = 1;5.public MyVector() &#123;6.i = 2;7. &#125;8.&#125;9.public class MyNewVector extends MyVector &#123;10.public MyNewVector () &#123;11. i = 4;12.&#125;13.public static void main (String args []) &#123;14.MyVector v = new MyNewVector();15. &#125;16.&#125; The file MyNewVector.java is shown in the exhibit. What is the result? A. 汇编将会成功。 B. 编译到第3行的时候失败。 C. 编译到第6行的时候失败。 D. 编译到第9行的时候失败。 E. 编译到第14行的时候失败。 解答：B 类MyVector不能是私有的 43、Given: 12345678910111213141516171819public class Test &#123;public static void main (String[]args) &#123;String foo = args[1];String bar = args[2];String baz = args[3];System.out.println(“baz = ” + baz);&#125;&#125;And the output:Baz = 2 Which command line invocation will produce the output? A. java Test 2222 B. java Test 1 2 3 4 C. java Test 4 2 4 2 D. java Test 4 3 2 1 解答：C 数组下标从0开始 44、 Given: 123451. public interface Foo&#123;2.int k = 4;3. &#125; 哪三个相当于第2行? (Choose Three) A. final int k = 4; B. Public int k = 4; C. static int k = 4; D. Private int k = 4; E. Abstract int k = 4; F. Volatile int k = 4; G. Transient int k = 4; H. protected int k = 4; 解答：BDE static：修饰的静态变量 final 修饰的是常量 abstract不能修饰变量 Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。 而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻， 两个不同的线程总是看到某个成员变量的同一个值。 Transient：对不需序列化的类的域使用transient关键字,以减少序列化的数据量。 int k=4相当于public static final int k=4; 在接口中可以不写static final 45、 Given: 1234567891011public class foo &#123;static String s;public static void main (String[]args) &#123;System.out.println (“s=” + s);&#125;&#125; What is the result? A. 代码编译并打印“s =”。 B. 代码编译并打印“s = null”。 C. 该代码不会编译，因为字符串s未初始化。 D.代码不编译，因为字符串不能被引用。 E. 代码编译，但调用toString时会引发NullPointerException。 解答：B String为禁用数据类型，引用类型数据成员的默认值为null 46、哪两个创建一个数组的实例? (Choose Two) A. int[] ia = new int [15]; B. float fa = new float [20]; C. char[] ca = “Some String”; D. Object oa = new float[20]; E. Int ia [][] = (4, 5, 6) (1, 2, 3) 解答：AD 任何类的父类都是 Object，数组也有数据引用类型，Object oa = new float[20];这种写法相当于父类的用指向之类的实例。 47、Given: 12345678910111213public class ExceptionTest &#123;class TestException extends Exception &#123;&#125;public void runTest () throws TestException &#123;&#125;public void test () /* Point X*/ &#123;runTest ();&#125;&#125; 在第4行的X点上，可以添加哪些代码来编译代码？ A. throws Exception B. Catch (Exception e). C. Throws RuntimeException. D. Catch (TestException e). E. No code is necessary. 解答：A 方法上使用throws抛出异常，Exception是异常类的超类。 48、Exhibit: 123456789101112131415161718192021222324252627282930313233public class SwitchTest &#123;public static void main (String []args) &#123;System.out.println (“value =” +switchIt(4));&#125;public static int switchIt(int x) &#123;int j = 1;switch (x) &#123;case 1: j++;case 2: j++;case 3: j++;case 4: j++;case 5: j++;default:j++;&#125;return j + x;&#125;&#125; 第3行的输出是什么? A. Value =3 B. Value =4 C. Value =5 D. Value =6 E. Value =7 F. Value =8 解答：F 由于case块没有break语句，那么从case 4：向下的代码都会执行。 49、使用 throw 语句可以抛出哪四种类型的对象? (Choose Four) A. Error B. Event C. Object D. Exception E. Throwable F. RuntimeException 解答：ADEF 能够抛出的对象类型要是 Throwable 或是 Throwable 的子类 50．在下面程序的第6行补充上下列哪个方法,会导致在编译过程中发生错误? 1234567891011121314151) class Super&#123;2) public float getNum()&#123;3) return 3.0f;4) &#125;&#125;5) pubhc class Sub extends Super&#123;6)7) &#125; A. public float getNum(){retun 4.0f;} B. public void getNum(){} C. public void getNum(double d){} D. public double getNum(float d){ retun 4.0f ;} 解答：B 方法重写的问题。子类中有和父类的方法名相同，但是参数不同，不会出编译错误，认为是子类 的特有的方法，但是如果子类中方法和父类的方法名，参数，访问权限，异常都相同，只有返回值 类型不同会编译不通过。 51.下面关于import, class和package的声明顺序哪个正确？( ) A. package, import, class B. class, import, package C. import, package, class D. package, class, import 解答：A 52.下面哪个是正确的？( ) A. String temp [] = new String {“a” “b” “c”}; B. String temp [] = {“a” “b” “c”} C. String temp = {“a”, “b”, “c”} D. String temp [] = {“a”, “b”, “c”} 解答：D 53.关于java.lang.String类，以下描述正确的一项是（ ） A. String类是final类故不可以继承； B. String类是final类故可以继承； C. String类不是final类故不可以继承； D. String类不是final类故可以继承； 解答：A String类是final的，在java中final修饰类的不能被继承 54.关于实例方法和类方法，以下描述正确的是：( ) A. 实例方法只能访问实例变量 B. 类方法既可以访问类变量，也可以访问实例变量 C. 类方法只能通过类名来调用 D. 实例方法只能通过对象来调用 解答：D A 实例方法可以访问类变量 B类方法只能访问类变量 C类方法可以通过对象调用 55.接口是Java面向对象的实现机制之一，以下说法正确的是：( ) A. Java支持多重继承，一个类可以实现多个接口； B. Java只支持单重继承，一个类可以实现多个接口； C. Java只支持单重继承，一个类只可以实现一个接口； D. Java支持多重继承，但一个类只可以实现一个接口。 解答：B Java支持单重继承，一个类只能继承自另外的一个类，但是一个类可以实现多个接口。 56.下列关于 interface 的说法正确的是：( ) A. interface中可以有private方法 B. interface中可以有final方法 C. interface中可以有function实现 D. interface可以继承其他interface 解答：D A. 接口中不可以有private的方法 B．接口中不可以有final的方法 接口中的方法默认是 public abstract的 C．接口中的方法不可以有实现 57.已知A类被打包在packageA , B类被打包在packageB ，且B类被声明为public ，且有一个成员变量x被声明为, protected控制方式 。C类也位于packageA包，且继承了B类 。则以下说话正确的是（ ） A. A类的实例不能访问到B类的实例 B. A类的实例能够访问到B类一个实例的x成员 C. C类的实例可以访问到B类一个实例的x成员 D. C类的实例不能访问到B类的实例 解答：C 不同包子类的关系， 可以访问到父类B的protected成员 58.以下程序正确的输出是（ ） 123456789101112131415161718192021222324252627282930313233package test;public class FatherClass &#123;public FatherClass() &#123;System.out.println(“FatherClass Create”);&#125;&#125;package test;import test.FatherClass;public class ChildClass extends FatherClass &#123;public ChildClass() &#123;System.out.println(“ChildClass Create”);&#125;public static void main(String[] args) &#123;FatherClass fc = new FatherClass();ChildClass cc = new ChildClass();&#125;&#125; A. FatherClass Create FatherClass Create ChildClass Create B. FatherClass Create ChildClass Create FatherClass Create C. ChildClass Create ChildClass Create FatherClass Create D. ChildClass Create FatherClass Create FatherClass Create 解答：A 在子类构造方法的开始默认情况下有一句super();来调用父类的构造方法 59.给定如下代码，下面哪个可以作为该类的构造函数 ( ) 123public class Test &#123;&#125; A. public void Test() {?} B. public Test() {?} C. public static Test() {?} D. public static void Test() {?} 解答：B 构造方法：与类同名没有放回类型 60.题目: 123456789101112131. public class test (2. public static void main (String args[]) &#123;3. int i = 0xFFFFFFF1;4. int j = -i;5.6. &#125;7. ) 程序运行到第5行时,j的值为 多少?( ) A. –15 B. 0 C. 1 D. 14 E. 在第三行的错误导致编译失败 解答：D int i = 0xFFFFFFF1;相当于 int i=-15 然后对i进行取反即取绝对值再减一]]></content>
      <categories>
        <category>选择题</category>
      </categories>
      <tags>
        <tag>Java 笔试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal 源码解析和使用场景]]></title>
    <url>%2F2018%2F03%2F18%2FThreadLocal%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[ThreadLocal 源码解析和使用场景ThreadLocal 主要用途ThreadLocal 是在 JDK 包里面提供的，它提供了线程本地变量，也就是如果你创建了一个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的一个本地拷贝，多个线程操作这个变量的时候，实际是操作的自己本地内存里面的变量，从而避免了线程安全问题，创建一个ThreadLocal变量后每个线程会拷贝一个变量到自己本地内存，如下图： 从JAVA官方对 ThreadLocal 类的说明定义（定义在示例代码中）：ThreadLocal 类用来提供线程内部的局部变量。这种变量在多线程环境下访问（通过 get 和 set 方法访问）时能保证各个线程的变量相对独立于其他线程内的变量。ThreadLocal 实例通常来说都是 private static 类型的，用于关联线程和线程上下文。 我们可以得知 ThreadLocal 的作用是：ThreadLocal 的作用是提供线程内的局部变量，不同的线程之间不会相互干扰，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或组件之间一些公共变量的传递的复杂度。 上述可以概述为：ThreadLocal 提供线程内部的局部变量，在本线程内随时随地可取，隔离其他线程。 ThreadLocal使用实例使用例子来调试，看下ThreadLocal如何使用，从而加深理解。例子开启了两个线程，每个线程内部设置了本地变量的值，然后调用print函数打印当前本地变量的值，如果打印后调用了本地变量额remove方法则会删除本地内存中的该变量，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041public class ThreadLocalTest &#123; //(1)打印函数 static void print(String str)&#123; //1.1 打印当前线程本地内存中localVariable变量的值 System.out.println(str + ":" +localVariable.get()); //1.2 清除当前线程本地内存中localVariable变量 //localVariable.remove(); &#125; //(2) 创建ThreadLocal变量 static ThreadLocal&lt;String&gt; localVariable = new ThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; //(3) 创建线程one Thread threadOne = new Thread(new Runnable() &#123; public void run() &#123; //3.1 设置线程one中本地变量localVariable的值 localVariable.set("threadOne local variable"); //3.2 调用打印函数 print("threadOne"); //3.3打印本地变量值 System.out.println("threadOne remove after" + ":" +localVariable.get()); &#125; &#125;); //(4) 创建线程two Thread threadTwo = new Thread(new Runnable() &#123; public void run() &#123; //4.1 设置线程one中本地变量localVariable的值 localVariable.set("threadTwo local variable"); //4.2 调用打印函数 print("threadTwo"); //4.3打印本地变量值 System.out.println("threadTwo remove after" + ":" +localVariable.get()); &#125; &#125;); //(5)启动线程 threadOne.start(); threadTwo.start(); &#125; 运行结果： 1234threadOne:threadOne local variablethreadTwo:threadTwo local variablethreadOne remove after:threadOne local variablethreadTwo remove after:threadTwo local variable 代码（2）创建了一个ThreadLocal变量 代码（3）（4）分别创建了线程one和two 代码（5）启动了两个线程。 线程one中代码3.1通过set方法设置了localVariable的值，这个设置的其实是线程one本地内存中的一个拷贝，这个拷贝线程two是访问不了的。然后代码3.2调用了print函数，代码1.1通过get函数获取了当前线程（线程one）本地内存中localVariable的值。 线程two执行类似线程one 解开代码1.2的注释后，再次运行，运行结果为： 1234threadOne:threadOne local variablethreadOne remove after:nullthreadTwo:threadTwo local variablethreadTwo remove after:null ThreadLocal实现原理首先看下ThreadLocal相关的类的类图结构 如上类图可知 Thread 类中有一个 threadLocals 和 inheritableThreadLocals 都是 ThreadLocalMap 类型的变量，而 ThreadLocalMap 是一个定制化的 HashMap，默认每个线程中这个两个变量都为null。 只有当前线程第一次调用了 ThreadLocal 的set或者get方法时候才会进行创建。其实每个线程的本地变量不是存放到 ThreadLocal 实例里面的，而是存放到调用线程的 threadLocals 变量里面。 也就是说 ThreadLocal 类型的本地变量是存放到具体的线程内存空间的。 ThreadLocal 就是一个工具壳，它通过 set 方法把 value 值放入调用线程的 threadLocals 里面存放起来，当调用线程调用它的 get 方法时候再从当前线程的 threadLocals 变量里面拿出来使用。 如果调用线程一直不终止那么这个本地变量会一直存放到调用线程的 threadLocals 变量里面，所以当不需要使用本地变量时候可以通过调用ThreadLocal 变量的 remove 方法，从当前线程的 threadLocals 里面删除该本地变量。 另外 Thread 里面的threadLocals 为何设计为 map 结构那？很明显是因为每个线程里面可以关联多个 ThreadLocal 变量。 为什么使用了弱引用ThreadLocalMap 中的存储实体 Entry 使用 ThreadLocal 作为 key，但这个 Entry 是继承弱引用 WeakReference 的，为什么要这样设计，使用了弱引用 WeakReference 会造成内存泄露问题吗？ 首先，回答这个问题之前，我需要解释一下什么是强引用，什么是弱引用。 我们在正常情况下，普遍使用的是强引用： 123A a = new A();B b = new B(); 当 a = null;b = null; 时，一段时间后，JAVA垃圾回收机制GC会将 a 和 b 对应所分配的内存空间给回收。 但考虑这样一种情况： 12C c = new C(b);b = null; 当 b 被设置成 null 时，那么是否意味这一段时间后GC工作可以回收 b 所分配的内存空间呢？答案是否定的，因为即使 b 被设置成 null ，但 c 仍然持有对 b 的引用，而且还是强引用，所以GC不会回收 b 原先所分配的空间，既不能回收，又不能使用，这就造成了 内存泄露。 那么我们该如何处理呢？ 可以通过 c = null;，也可以使用弱引用 WeakReference w = new WeakReference(b); 。因为使用了弱引用 WeakReference，GC 是可以回收 b 原先所分配的空间的。 上述解释主要参考自：对ThreadLocal实现原理的一点思考 回到 ThreadLocal 的层面上，ThreadLocalMap 使用 ThreadLocal 的弱引用作为key，如果一个ThreadLocal 没有外部强引用来引用它，那么系统 GC 的时候，这个 ThreadLocal 势必会被回收，这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry，就没有办法访问这些 key 为 null 的 Entry 的 value，如果当前线程再迟迟不结束的话，这些 key 为 null 的 Entry 的 value 就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在 ThreadLocal 的get(), set(), remove() 的时候都会清除线程 ThreadLocalMap 里所有 key 为null 的 value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏（参考ThreadLocal 内存泄露的实例分析）。 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。 从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析 ThreadLocal 使用了弱引用会导致内存泄漏，但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？ 我们先来看看官方文档的说法： 12To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys. 为了应对非常大和长时间的用途，哈希表使用弱引用的 key。 下面我们分两种情况讨论： key 使用强引用：引用的 ThreadLocal 的对象被回收了，但是 ThreadLocalMap 还持有 ThreadLocal 的强引用，如果没有手动删除，ThreadLocal 不会被回收，导致 Entry 内存泄漏。 key 使用弱引用：引用的 ThreadLocal 的对象被回收了，由于 ThreadLocalMap 持有 ThreadLocal 的弱引用，即使没有手动删除，ThreadLocal 也会被回收。value 在下一次 ThreadLocalMap 调用get() ,set(),remove()的时候会被清除。 比较两种情况，我们可以发现：由于 ThreadLocalMap 的生命周期跟 Thread 一样长，如果都没有手动删除对应 key ，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用 ThreadLocal 不会内存泄漏，对应的 value 在下一次 ThreadLocalMap 调用 get() ,set(),remove()的时候会被清除。 因此， ThreadLocal 内存泄漏的根源是：由于 ThreadLocalMap 的生命周期跟 Thread 一样长，如果没有手动删除对应 key 就会导致内存泄漏，而不是因为弱引用。 综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的 remove() 方法，清除数据。 在使用线程池的情况下，没有及时清理 ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用 ThreadLocal 就跟加锁完要解锁一样，用完就清理。 上述解释主要参考自：深入分析 ThreadLocal 内存泄漏问题 常用操作的底层实现原理根据上面的例子，我们进行调试，看看一下几个常用操作的实现原理。 get() 方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192/** * 返回当前线程对应的ThreadLocal的初始值 * 此方法的第一次调用发生在，当线程通过&#123;@link #get&#125;方法访问此线程的ThreadLocal值时 * 除非线程先调用了 &#123;@link #set&#125;方法，在这种情况下， * &#123;@code initialValue&#125; 才不会被这个线程调用。 * 通常情况下，每个线程最多调用一次这个方法， * 但也可能再次调用，发生在调用&#123;@link #remove&#125;方法后， * 紧接着调用&#123;@link #get&#125;方法。 * * &lt;p&gt;这个方法仅仅简单的返回null &#123;@code null&#125;; * 如果程序员想ThreadLocal线程局部变量有一个除null以外的初始值， * 必须通过子类继承&#123;@code ThreadLocal&#125; 的方式去重写此方法 * 通常, 可以通过匿名内部类的方式实现 * * @return 当前ThreadLocal的初始值 */protected T initialValue() &#123; return null;&#125;/** * 创建一个ThreadLocal * @see #withInitial(java.util.function.Supplier) */public ThreadLocal() &#123;&#125;/** * 返回当前线程中保存ThreadLocal的值 * 如果当前线程没有此ThreadLocal变量， * 则它会通过调用&#123;@link #initialValue&#125; 方法进行初始化值 * * @return 返回当前线程对应此ThreadLocal的值 */public T get() &#123; // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取此线程对象中维护的ThreadLocalMap对象 ThreadLocalMap map = getMap(t); // 如果此map存在 if (map != null) &#123; // 以当前的ThreadLocal 为 key，调用getEntry获取对应的存储实体e ThreadLocalMap.Entry e = map.getEntry(this); // 找到对应的存储实体 e if (e != null) &#123; @SuppressWarnings("unchecked") // 获取存储实体 e 对应的 value值 // 即为我们想要的当前线程对应此ThreadLocal的值 T result = (T)e.value; return result; &#125; &#125; // 如果map不存在，则证明此线程没有维护的ThreadLocalMap对象 // 调用setInitialValue进行初始化 return setInitialValue();&#125;/** * set的变样实现，用于初始化值initialValue， * 用于代替防止用户重写set()方法 * * @return the initial value 初始化后的值 */private T setInitialValue() &#123; // 调用initialValue获取初始化的值 T value = initialValue(); // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取此线程对象中维护的ThreadLocalMap对象 ThreadLocalMap map = getMap(t); // 如果此map存在 if (map != null) // 存在则调用map.set设置此实体entry map.set(this, value); else // 1）当前线程Thread 不存在ThreadLocalMap对象 // 2）则调用createMap进行ThreadLocalMap对象的初始化 // 3）并将此实体entry作为第一个值存放至ThreadLocalMap中 createMap(t, value); // 返回设置的值value return value;&#125;/** * 获取当前线程Thread对应维护的ThreadLocalMap * * @param t the current thread 当前线程 * @return the map 对应维护的ThreadLocalMap */ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 调用 get() 操作获取 ThreadLocal 中对应当前线程存储的值时，进行了如下操作： 1 ) 获取当前线程 Thread 对象，进而获取此线程对象中维护的 ThreadLocalMap 对象。 2 ) 判断当前的 ThreadLocalMap 是否存在： 如果存在，则以当前的ThreadLocal为 key，调用ThreadLocalMap中的getEntry方法获取对应的存储实体 e。找到对应的存储实体 e，获取存储实体 e 对应的 value 值，即为我们想要的当前线程对应此ThreadLocal的值，返回结果值。 如果不存在，则证明此线程没有维护的 ThreadLocalMap 对象，调用 setInitialValue 方法进行初始化。返回setInitialValue 初始化的值。 setInitialValue 方法的操作如下： 1 ) 调用initialValue获取初始化的值。 2 ) 获取当前线程Thread对象，进而获取此线程对象中维护的ThreadLocalMap对象。 3 ) 判断当前的ThreadLocalMap是否存在： 如果存在，则调用map.set 设置此实体entry。 如果不存在，则调用createMap 进行 ThreadLocalMap 对象的初始化，并将此实体 entry 作为第一个值存放至 ThreadLocalMap 中。 set() 方法123456789101112131415161718192021222324252627282930313233/** * 设置当前线程对应的ThreadLocal的值 * 大多数子类都不需要重写此方法， * 只需要重写 &#123;@link #initialValue&#125;方法代替设置当前线程对应的ThreadLocal的值 * * @param value 将要保存在当前线程对应的 ThreadLocal 的值 * */public void set(T value) &#123; // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取此线程对象中维护的 ThreadLocalMap 对象 ThreadLocalMap map = getMap(t); // 如果此map存在 if (map != null) // 存在则调用map.set设置此实体entry map.set(this, value); else // 1）当前线程Thread 不存在ThreadLocalMap对象 // 2）则调用createMap进行ThreadLocalMap对象的初始化 // 3）并将此实体entry作为第一个值存放至ThreadLocalMap中 createMap(t, value);&#125;/** * 为当前线程Thread 创建对应维护的ThreadLocalMap. * * @param t the current thread 当前线程 * @param firstValue 第一个要存放的ThreadLocal变量值 */void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 调用 set(T value) 操作设置ThreadLocal中对应当前线程要存储的值时，进行了如下操作： 1 ) 获取当前线程 Thread 对象，进而获取此线程对象中维护的 ThreadLocalMap 对象。 2 ) 判断当前的 ThreadLocalMap 是否存在： 如果存在，则调用 map.set 设置此实体 entry。 如果不存在，则调用 createMap 进行 ThreadLocalMap 对象的初始化，并将此实体 entry 作为第一个值存放至 ThreadLocalMap 中。 remove() 方法123456789101112131415161718/** * 删除当前线程中保存的ThreadLocal对应的实体entry * 如果此ThreadLocal变量在当前线程中调用 &#123;@linkplain #get read&#125;方法 * 则会通过调用&#123;@link #initialValue&#125;进行再次初始化， * 除非此值value是通过当前线程内置调用 &#123;@linkplain #set set&#125;设置的 * 这可能会导致在当前线程中多次调用&#123;@code initialValue&#125;方法 * * @since 1.5 */ public void remove() &#123; // 获取当前线程对象中维护的ThreadLocalMap对象 ThreadLocalMap m = getMap(Thread.currentThread()); // 如果此map存在 if (m != null) // 存在则调用map.remove // 以当前ThreadLocal为key删除对应的实体entry m.remove(this); &#125; 调用 remove() 操作删除ThreadLocal中对应当前线程已存储的值时，进行了如下操作： 获取当前线程 Thread 对象，进而获取此线程对象中维护的 ThreadLocalMap 对象。 判断当前的 ThreadLocalMap 是否存在， 如果存在，则调用 map.remove ，以当前 ThreadLocal 为 key 删除对应的实体 entry。 ThreadLocalMap的内部底层实现对 ThreadLocal 的常用操作实际是对线程Thread中的ThreadLocalMap进行操作，核心是ThreadLocalMap这个哈希表，接着我们来谈谈ThreadLocalMap的内部底层实现。 源代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * ThreadLocalMap 是一个定制的自定义 hashMap 哈希表，只适合用于维护 * 线程对应ThreadLocal的值. 此类的方法没有在ThreadLocal 类外部暴露， * 此类是私有的，允许在 Thread 类中以字段的形式声明 ， * 以助于处理存储量大，生命周期长的使用用途， * 此类定制的哈希表实体键值对使用弱引用WeakReferences 作为key， * 但是, 一旦引用不在被使用， * 只有当哈希表中的空间被耗尽时，对应不再使用的键值对实体才会确保被 移除回收。 */static class ThreadLocalMap &#123; /** * 实体entries在此hash map中是继承弱引用 WeakReference, * 使用ThreadLocal 作为 key 键. 请注意，当key为null（i.e. entry.get() * == null) 意味着此key不再被引用,此时实体entry 会从哈希表中删除。 */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** 当前 ThreadLocal 对应储存的值value. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; /** * 初始容量大小 16 -- 必须是2的n次方. */ private static final int INITIAL_CAPACITY = 16; /** * 底层哈希表 table, 必要时需要进行扩容. * 底层哈希表 table.length 长度必须是2的n次方. */ private Entry[] table; /** * 实际存储键值对元素个数 entries. */ private int size = 0; /** * 下一次扩容时的阈值 */ private int threshold; // 默认为 0 /** * 设置触发扩容时的阈值 threshold * 阈值 threshold = 底层哈希表table的长度 len * 2 / 3 */ private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; /** * 获取该位置i对应的下一个位置index */ private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0); &#125; /** * 获取该位置i对应的上一个位置index */ private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1); &#125;&#125; ThreadLocalMap 的底层实现是一个定制的自定义 HashMap 哈希表，核心组成元素有： 1 ) Entry[] table; ：底层哈希表 table, 必要时需要进行扩容，底层哈希表 table.length 长度必须是2的n次方。 2 ) int size;：实际存储键值对元素个数 entries 3 ) int threshold;：下一次扩容时的阈值，阈值 threshold = len 2 / 3 (底层哈希表table的长度)。当size &gt;= threshold时，遍历 table 并删除 key 为 null 的元素，如果删除后`size &gt;= threshold3/4`时，需要对table 进行扩容 其中 Entry[] table; 哈希表存储的核心元素是 Entry ，Entry 包含： 1 ) ThreadLocal&lt;?&gt; k；：当前存储的 ThreadLocal 实例对象 2 ) Object value;：当前 ThreadLocal 对应储存的值value 需要注意的是，此 Entry 继承了弱引用 WeakReference ，所以在使用 ThreadLocalMap 时，发现key == null，则意味着此 key ThreadLocal 不在被引用，需要将其从 ThreadLocalMap 哈希表中移除。 12345678910111213141516171819/** * 用于创建一个新的hash map包含 (firstKey, firstValue). * ThreadLocalMaps 构造方法是延迟加载的,所以我们只会在至少有一个 * 实体entry存放时，才初始化创建一次（仅初始化一次）。 */ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; // 初始化 table 初始容量为 16 table = new Entry[INITIAL_CAPACITY]; // 计算当前entry的存储位置 // 存储位置计算等价于： // ThreadLocal 的 hash 值 threadLocalHashCode % 哈希表的长度 length int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 存储当前的实体，key 为 : 当前ThreadLocal value：真正要存储的值 table[i] = new Entry(firstKey, firstValue); // 设置当前实际存储元素个数 size 为 1 size = 1; // 设置阈值，为初始化容量 16 的 2/3。 setThreshold(INITIAL_CAPACITY);&#125; ThreadLocalMap 的构造方法是延迟加载的，也就是说，只有当线程需要存储对应的 ThreadLocal 的值时，才初始化创建一次（仅初始化一次）。初始化步骤如下： 1） 初始化底层数组 table 的初始容量为 16。 2） 获取 ThreadLocal 中的 threadLocalHashCode ，通过threadLocalHashCode &amp; (INITIAL_CAPACITY - 1)，即ThreadLocal 的 hash 值 threadLocalHashCode % 哈希表的长度 length 的方式计算该实体的存储位置。 3） 存储当前的实体，key 为 : 当前ThreadLocal value：真正要存储的值 4）设置当前实际存储元素个数 size 为 1 5）设置阈值setThreshold(INITIAL_CAPACITY)，为初始化容量 16 的 2/3。 源代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/** * 根据key 获取对应的实体 entry. 此方法快速适用于获取某一存在key的 * 实体 entry，否则，应该调用getEntryAfterMiss方法获取，这样做是为 * 了最大限制地提高直接命中的性能 * * @param key 当前thread local 对象 * @return the entry 对应key的 实体entry, 如果不存在，则返回null */private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 计算要获取的entry的存储位置 // 存储位置计算等价于： // ThreadLocal 的 hash 值 threadLocalHashCode % 哈希表 的长度 length int i = key.threadLocalHashCode &amp; (table.length - 1); // 获取到对应的实体 Entry Entry e = table[i]; // 存在对应实体并且对应key相等，即同一ThreadLocal if (e != null &amp;&amp; e.get() == key) // 返回对应的实体Entry return e; else // 不存在 或 key不一致，则通过调用getEntryAfterMiss继续查找 return getEntryAfterMiss(key, i, e);&#125;/** * 当根据key找不到对应的实体entry 时，调用此方法。 * 直接定位到对应的哈希表位置 * * @param key 当前thread local 对象 * @param i 此对象在哈希表 table中的存储位置 index * @param e the entry 实体对象 * @return the entry 对应key的 实体entry, 如果不存在，则返回null */private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 循环遍历当前位置的所有实体entry while (e != null) &#123; // 获取当前entry 的 key ThreadLocal ThreadLocal&lt;?&gt; k = e.get(); // 比较key是否一致，一致则返回 if (k == key) return e; // 找到对应的entry ，但其key 为 null，则证明引用已经不存在 // 这是因为Entry继承的是WeakReference，这是弱引用带来的坑 if (k == null) // 删除过期(stale)的entry expungeStaleEntry(i); else // key不一致 ，key也不为空，则遍历下一个位置，继续查找 i = nextIndex(i, len); // 获取下一个位置的实体 entry e = tab[i]; &#125; // 遍历完毕，找不到则返回null return null;&#125;/** * 删除对应位置的过期实体，并删除此位置后对应相关联位置key = null的实体 * * @param staleSlot 已知的key = null 的对应的位置索引 * @return 对应过期实体位置索引的下一个key = null的位置 * (所有的对应位置都会被检查) */private int expungeStaleEntry(int staleSlot) &#123; // 获取对应的底层哈希表 table Entry[] tab = table; // 获取哈希表长度 int len = tab.length; // 擦除这个位置上的脏数据 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // 直到我们找到 Entry e = null，才执行rehash操作 // 就是遍历完该位置的所有关联位置的实体 Entry e; int i; // 查找该位置对应所有关联位置的过期实体，进行擦除操作 for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // 我们必须一直遍历直到最后 // 因为还可能存在多个过期的实体 while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125;/** * 删除所有过期的实体 */private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125;&#125; ThreadLocal 的 get() 操作实际是调用 ThreadLocalMap 的 getEntry(ThreadLocal&lt;?&gt; key) 方法,此方法快速适用于获取某一存在 key 的实体 entry，否则，应该调用getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e)方法获取，这样做是为了最大限制地提高直接命中的性能，该方法进行了如下操作： 1 ) 计算要获取的 entry 的存储位置，存储位置计算等价于：ThreadLocal 的 hash 值 threadLocalHashCode % 哈希表的长度 length。 2 ) 根据计算的存储位置，获取到对应的实体 Entry。判断对应实体 Entry 是否存在 并且 key 是否相等： 存在对应实体 Entry 并且对应 key 相等，即同一 ThreadLocal ，返回对应的实体 Entry。 不存在对应实体 Entry 或者 key 不相等，则通过调用getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e)方法继续查找。 getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e)方法操作如下： 1 ) 获取底层哈希表数组 table，循环遍历对应要查找的实体 Entry 所关联的位置。 2 ) 获取当前遍历的 entry 的 key ThreadLocal ，比较 key 是否一致，一致则返回。 3 ) 如果 key 不一致 并且 key 为 null，则证明引用已经不存在，这是因为 Entry 继承的是 WeakReference，这是弱引用带来的坑。调用expungeStaleEntry(int staleSlot)方法删除过期的实体 Entry（此方法不单独解释，请查看示例代码，有详细注释说明）。 4 ) key不一致 ，key也不为空，则遍历下一个位置，继续查找。 5 ) 遍历完毕，仍然找不到则返回null。 ​ 源代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/** * 设置对应ThreadLocal的值 * * @param key 当前thread local 对象 * @param value 要设置的值 */ private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // 我们不会像get()方法那样使用快速设置的方式， // 因为通常很少使用set()方法去创建新的实体 // 相对于替换一个已经存在的实体, 在这种情况下, // 快速设置方案会经常失败。 // 获取对应的底层哈希表 table Entry[] tab = table; // 获取哈希表长度 int len = tab.length; // 计算对应threalocal的存储位置 int i = key.threadLocalHashCode &amp; (len-1); // 循环遍历table对应该位置的实体，查找对应的threadLocal for (Entry e = tab[i];e != null;e = tab[i = nextIndex(i, len)]) &#123; // 获取当前位置的ThreadLocal ThreadLocal&lt;?&gt; k = e.get(); // 如果key threadLocal一致，则证明找到对应的threadLocal if (k == key) &#123; // 赋予新值 e.value = value; // 结束 return; &#125; // 如果当前位置的key threadLocal为null if (k == null) &#123; // 替换该位置key == null 的实体为当前要设置的实体 replaceStaleEntry(key, value, i); // 结束 return; &#125; &#125; // 当前位置的k ！= key &amp;&amp; k != null // 创建新的实体，并存放至当前位置i tab[i] = new Entry(key, value); // 实际存储键值对元素个数 + 1 int sz = ++size; // 由于弱引用带来了这个问题，所以先要清除无用数据，才能判断现在的size有没有达到阀值threshhold // 如果没有要清除的数据，存储元素个数仍然 大于 阈值 则扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) // 扩容 rehash(); &#125; /** * 当执行set操作时，获取对应的key threadLocal，并替换过期的实体 * 将这个value值存储在对应key threadLocal的实体中，无论是否已经存在体 * 对应的key threadLocal * * 有一个副作用, 此方法会删除该位置下和该位置nextIndex对应的所有过期的实体 * * @param key 当前thread local 对象 * @param value 当前thread local 对象对应存储的值 * @param staleSlot 第一次找到此过期的实体对应的位置索引index * . */ private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; // 获取对应的底层哈希表 table Entry[] tab = table; // 获取哈希表长度 int len = tab.length; Entry e; // 往前找，找到table中第一个过期的实体的下标 // 清理整个table是为了避免因为垃圾回收带来的连续增长哈希的危险 // 也就是说，哈希表没有清理干净，当GC到来的时候，后果很严重 // 记录要清除的位置的起始首位置 int slotToExpunge = staleSlot; // 从该位置开始，往前遍历查找第一个过期的实体的下标 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 找到key一致的ThreadLocal或找到一个key为 null的 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 如果我们找到了key，那么我们就需要把它跟新的过期数据交换来保持哈希表的顺序 // 那么剩下的过期Entry呢，就可以交给expungeStaleEntry方法来擦除掉 // 将新设置的实体放置在此过期的实体的位置上 if (k == key) &#123; // 替换，将要设置的值放在此过期的实体中 e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 如果存在，则开始清除之前过期的实体 if (slotToExpunge == staleSlot) slotToExpunge = i; // 在这里开始清除过期数据 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // / 如果我们没有在往后查找中找没有找到过期的实体， // 那么slotToExpunge就是第一个过期Entry的下标了 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // 最后key仍没有找到，则将要设置的新实体放置 // 在原过期的实体对应的位置上。 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 如果该位置对应的其他关联位置存在过期实体，则清除 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125; 12345678910111213141516171819202122232425262728293031323334/** * 启发式的扫描查找一些过期的实体并清除， * 此方法会再添加新实体的时候被调用, * 或者过期的元素被清除时也会被调用. * 如果实在没有过期数据，那么这个算法的时间复杂度就是O(log n) * 如果有过期数据，那么这个算法的时间复杂度就是O(n) * * @param i 一个确定不是过期的实体的位置，从这个位置i开始扫描 * * @param n 扫描控制: 有&#123;@code log2(n)&#125; 单元会被扫描, * 除非找到了过期的实体, 在这种情况下 * 有&#123;@code log2(table.length)-1&#125; 的格外单元会被扫描. * 当调用插入时, 这个参数的值是存储实体的个数， * 但如果调用 replaceStaleEntry方法, 这个值是哈希表table的长度 * (注意: 所有的这些都可能或多或少的影响n的权重 * 但是这个版本简单，快速，而且似乎执行效率还可以） * * @return true 返回true，如果有任何过期的实体被删除。 */private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 哈希表扩容方法 * 首先扫描整个哈希表table，删除过期的实体 * 缩小哈希表table大小 或 扩大哈希表table大小，扩大的容量是加倍. */private void rehash() &#123; // 删除所有过期的实体 expungeStaleEntries(); // 使用较低的阈值threshold加倍以避免滞后 // 存储实体个数 大于等于 阈值的3/4则扩容 if (size &gt;= threshold - threshold / 4) resize();&#125;/** * 扩容方法，以2倍的大小进行扩容 * 扩容的思想跟HashMap很相似，都是把容量扩大两倍 * 不同之处还是因为WeakReference带来的 */private void resize() &#123; // 记录旧的哈希表 Entry[] oldTab = table; // 记录旧的哈希表长度 int oldLen = oldTab.length; // 新的哈希表长度为旧的哈希表长度的2倍 int newLen = oldLen * 2; // 创建新的哈希表 Entry[] newTab = new Entry[newLen]; int count = 0; // 逐一遍历旧的哈希表table的每个实体，重新分配至新的哈希表中 for (int j = 0; j &lt; oldLen; ++j) &#123; // 获取对应位置的实体 Entry e = oldTab[j]; // 如果实体不会null if (e != null) &#123; // 获取实体对应的ThreadLocal ThreadLocal&lt;?&gt; k = e.get(); // 如果该ThreadLocal 为 null if (k == null) &#123; // 则对应的值也要清除 // 就算是扩容，也不能忘了为擦除过期数据做准备 e.value = null; // Help the GC &#125; else &#123; // 如果不是过期实体，则根据新的长度重新计算存储位置 int h = k.threadLocalHashCode &amp; (newLen - 1); // 将该实体存储在对应ThreadLocal的最后一个位置 while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; // 重新分配位置完毕，则重新计算阈值Threshold setThreshold(newLen); // 记录实际存储元素个数 size = count; // 将新的哈希表赋值至底层table table = newTab;&#125; ThreadLocal 的set(T value)操作实际是调用 ThreadLocalMap 的set(ThreadLocal&lt;?&gt; key, Object value)方法，该方法进行了如下操作： 1 ) 获取对应的底层哈希表 table ，计算对应 threalocal 的存储位置。 2 ) 循环遍历 table 对应该位置的实体，查找对应的 threadLocal。 3 ) 获取当前位置的 threadLocal，如果 key threadLocal 一致，则证明找到对应的 threadLocal，将新值赋值给找到的当前实体 Entry 的 value 中，结束。 4 ) 如果当前位置的 key threadLocal 不一致，并且 key threadLocal 为 null，则调用replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value,int staleSlot)方法（此方法不单独解释，请查看示例代码，有详细注释说明），替换该位置key == null 的实体为当前要设置的实体，结束。 5 ) 如果当前位置的 key threadLocal 不一致，并且 key threadLocal 不为 null ，则创建新的实体，并存放至当前位置 i tab[i] = new Entry(key, value);，实际存储键值对元素个数size + 1，由于弱引用带来了这个问题，所以要调用cleanSomeSlots(int i, int n)方法清除无用数据（此方法不单独解释，请查看示例代码，有详细注释说明），才能判断现在的 size 有没有达到阀值 threshhold ，如果没有要清除的数据，存储元素个数仍然 大于 阈值 则调用 rehash 方法进行扩容（此方法不单独解释，请查看示例代码，有详细注释说明）。 1234567891011121314151617181920212223/** * 移除对应ThreadLocal的实体 */private void remove(ThreadLocal&lt;?&gt; key) &#123; // 获取对应的底层哈希表 table Entry[] tab = table; // 获取哈希表长度 int len = tab.length; // 计算对应threalocal的存储位置 int i = key.threadLocalHashCode &amp; (len-1); // 循环遍历table对应该位置的实体，查找对应的threadLocal for (Entry e = tab[i];e != null;e = tab[i = nextIndex(i, len)]) &#123; // 如果key threadLocal一致，则证明找到对应的threadLocal if (e.get() == key) &#123; // 执行清除操作 e.clear(); // 清除此位置的实体 expungeStaleEntry(i); // 结束 return; &#125; &#125;&#125; ThreadLocal 的remove()操作实际是调用 ThreadLocalMap 的remove(ThreadLocal&lt;?&gt; key)方法，该方法进行了如下操作： 1 ) 获取对应的底层哈希表 table，计算对应 threalocal 的存储位置。 2 ) 循环遍历 table 对应该位置的实体，查找对应的 threadLocal。 3 ) 获取当前位置的threadLocal，如果 key threadLocal 一致，则证明找到对应的 threadLocal，执行删除操作，删除此位置的实体，结束。 ThreadLocal 在现时有什么应用场景总的来说 ThreadLocal 主要是解决2种类型的问题： 解决并发问题：使用 ThreadLocal 代替 synchronized 来保证线程安全。同步机制采用了“以时间换空间”的方式，而ThreadLocal 采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 解决数据存储问题：ThreadLocal 为变量在每个线程中都创建了一个副本，所以每个线程可以访问自己内部的副本变量，不同线程之间不会互相干扰。如一个Parameter对象的数据需要在多个模块中使用，如果采用参数传递的方式，显然会增加模块之间的耦合性。此时我们可以使用 ThreadLocal 解决。 应用场景： Spring 使用 ThreadLocal 解决线程安全问题 我们知道在一般情况下，只有无状态的 Bean 才可以在多线程环境下共享，在 Spring 中，绝大部分 Bean 都可以声明为 singleton 作用域。就是因为 Spring 对一些 Bean（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态采用ThreadLocal进行处理，让它们也成为线程安全的状态，因为有状态的 Bean 就可以在多线程中共享了。 一般的 Web 应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程ThreadLocal 是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal 比直接使用 synchronized 同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。 示例代码： 1234567891011121314public abstract class RequestContextHolder &#123;···· private static final boolean jsfPresent = ClassUtils.isPresent("javax.faces.context.FacesContext", RequestContextHolder.class.getClassLoader()); private static final ThreadLocal&lt;RequestAttributes&gt; requestAttributesHolder = new NamedThreadLocal&lt;RequestAttributes&gt;("Request attributes"); private static final ThreadLocal&lt;RequestAttributes&gt; inheritableRequestAttributesHolder = new NamedInheritableThreadLocal&lt;RequestAttributes&gt;("Request context");·····&#125; ThreadLocal 和 synchronized 的区别ThreadLocal 和 synchronized 关键字都用于处理多线程并发访问变量的问题，只是二者处理问题的角度和思路不同。 ThreadLocal是一个Java类,通过对当前线程中的局部变量的操作来解决不同线程的变量访问的冲突问题。所以，ThreadLocal提供了线程安全的共享对象机制，每个线程都拥有其副本。 Java中的synchronized是一个保留字，它依靠JVM的锁机制来实现临界区的函数或者变量的访问中的原子性。在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。此时，被用作“锁机制”的变量时多个线程共享的。 同步机制(synchronized关键字)采用了以“时间换空间”的方式，提供一份变量，让不同的线程排队访问。而ThreadLocal采用了“以空间换时间”的方式，为每一个线程都提供一份变量的副本，从而实现同时访问而互不影响。 总结： ThreadLocal提供线程内部的局部变量，在本线程内随时随地可取，隔离其他线程。 ThreadLocal的设计是：每个Thread维护一个ThreadLocalMap哈希表，这个哈希表的key是ThreadLocal实例本身，value才是真正要存储的值Object。 对ThreadLocal 的常用操作实际是对线程 Thread 中的 ThreadLocalMap 进行操作。 ThreadLocalMap 的底层实现是一个定制的自定义哈希表，ThreadLocalMap 的阈值threshold = 底层哈希表 table 的长度 len * 2 / 3，当实际存储元素个数 size 大于或等于 阈值 threshold 的 3/4 时size &gt;= threshold*3/4，则对底层哈希表数组 table 进行扩容操作。 ThreadLocalMap 中的哈希表 Entry[] table 存储的核心元素是 Entry ，存储的 key 是 ThreadLocal 实例对象，value 是ThreadLocal 对应储存的值value。需要注意的是，此Entry继承了弱引用 WeakReference，所以在使用ThreadLocalMap时，发现key == null，则意味着此key ThreadLocal不在被引用，需要将其从ThreadLocalMap哈希表中移除。 ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收。所以，在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。如果我们不主动调用上述操作，则会导致内存泄露。 为了安全地使用ThreadLocal，必须要像每次使用完锁就解锁一样，在每次使用完ThreadLocal后都要调用remove() 来清理无用的Entry。这在操作在使用线程池时尤为重要。 ThreadLocal 和synchronized的区别：同步机制(synchronized关键字)采用了以“时间换空间”的方式，提供一份变量，让不同的线程排队访问。而ThreadLocal采用了“以空间换时间”的方式，为每一个线程都提供一份变量的副本，从而实现同时访问而互不影响。 ThreadLocal主要是解决2种类型的问题：A. 解决并发问题：使用ThreadLocal代替同步机制解决并发问题。B. 解决数据存储问题：如一个Parameter对象的数据需要在多个模块中使用，如果采用参数传递的方式，显然会增加模块之间的耦合性。此时我们可以使用ThreadLocal解决。 每个线程内部都有一个名字为threadLocals的成员变量，该变量类型为HashMap，其中key为我们定义的ThreadLocal变量的this引用，value则为我们set时候的值，每个线程的本地变量是存到到线程自己的内存变量threadLocals里面的，如果当前线程一直不消失那么这些本地变量会一直存到，所以可能会造成内存溢出，所以使用完毕后要记得调用ThreadLocal的remove方法删除对应线程的threadLocals中的本地变量。如果子线程中想要使用父线程中的threadlocal变量该如何做那？敬请期待 Java中高并发编程必备基础之并发包源码剖析 一书出版 原文地址：https://juejin.im/entry/5a4c753a6fb9a0451a76c538]]></content>
      <categories>
        <category>ThreadLocal</category>
      </categories>
      <tags>
        <tag>Java 源码解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 vue 框架的使用环境]]></title>
    <url>%2F2018%2F03%2F18%2F%E6%90%AD%E5%BB%BA%20vue%20%E6%A1%86%E6%9E%B6%E7%9A%84%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[搭建 vue 框架的使用环境安装 nodejsnode 附带了 npm 指令。 查询是否安装了 nodejs ,输入以下命令： 1node -v 这里我们是需要 npm 命令才安装的 nodejs 。 安装 webpackwebpack：自动化。对于需要反复重复的任务，例如压缩（minification）、编译、单元测试、linting等，自动化工具可以减轻你的劳动，简化你的工作。 webpack 可以通过 https://webpack.js.org/ 中的 DOCUMENTATION 来学习它。 安装 淘宝 NPM 镜像注意：我们不使用 npm ，因为 npm 在国外速度非常慢，所以我们使用 cnpm (淘宝的镜像代替)。 1$ npm install -g cnpm --registry=https://registry.npm.taobao.org 命令安装 淘宝 NPM 镜像 查看淘宝 NPM 镜像是否安装成功 1cnpm 说明安装成功。 安装 webpack1cnpm install -g webpack 测试 webpack 是否安装成功 1webpack 全局安装 vue-cli 这是 vue 提供的一种创建项目架构的方式，使用命令就可以生成。 安装 vue-cli 使用命令： 1cnpm install --global vue-cli 安装会出现此结果。 判断是否安装成功 1vue 说明安装成功。 创建项目创建一个基于 webpack 模板的新项目 1vue init webpack my-project 初始化项目生成 package.json 文件 1cnpm install 创建完成可以在我们的项目目录下看到 package.json 文件： 完整的项目结构 运行项目1cnpm run dev 访问：http://localhost:8080]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime Text新建.vue模板并高亮]]></title>
    <url>%2F2018%2F03%2F11%2FSublime%20Text%E6%96%B0%E5%BB%BA.vue%E6%A8%A1%E6%9D%BF%E5%B9%B6%E9%AB%98%E4%BA%AE%2F</url>
    <content type="text"><![CDATA[Sublime Text新建.vue模板并高亮准备工作 下载安装新建文件模板插件 SublimeTmpl 下载安装vue语法高亮插件 Vue Syntax Highlight Sublime Text安装插件的方法有两种： 使用Sublime Text自带的安装库 Package Control 去安装点击菜单栏的 Preferences -&gt; Package Control 或使用快捷键 CTRL+SHIFT+P 打开终端窗口，输入Install选择Package Control: Install Package来安装 下载直接放入包目录 (Preferences / Browse Packages) 中文:(首选项 / 包浏览器) 文件夹里面 SublimeTmpl Vue Syntax Highlight 创建.vue模板并让语法高亮安装完Vue Syntax Highlight之后，你打开.vue格式的文件就已经可以高亮了，我们现在来设置用快捷键直接创建.vue格式的文件。 SublimeTmpl 默认只有6种语法模板： html ctrl+alt+h javascript ctrl+alt+j css ctrl+alt+c php ctrl+alt+p ruby ctrl+alt+r python ctrl+alt+shift+p 我们现在新增创建 vue 格式的模板 创建vue文件模板 直接打开插件包的文件夹 Preferences -&gt; Browse Packages ​ 首选项 -&gt; 浏览程序包 ​ ​ 包文件夹 打开存放模板的文件夹 templates，随便复制一项，改名为vue.tmpl ​ 创建vue.tmpl vue.tmpl内容改为你想要的模板 ​ vue.tmpl内容 修改新建菜单，增加新建vue选项 SublimeTmpl新建菜单默认是没有vue的，如图 ​ 新建 -&gt; New File (SublimeTmpl) 点击上图的 Menu 选项，或者打开 Preferences -&gt; Package Settings -&gt; SublimeTmpl -&gt; Settings - Menu，如图 ​ 打开菜单配置项 复制一项，然后粘贴修改为 vue 项，如图 ​ 新增vue项 保存修改，就会在新建菜单里面出现vue项，如图 ​ 出现vue项 点击上图vue新建项，就会出现之前设置的模板内容，只不过没有语法高亮，并且是纯文本格式，如图 ​ 新建vue文件 模板绑定vue语法高亮 打开 Preferences -&gt; Package Settings -&gt; SublimeTmpl -&gt; Settings - Default，如图 ​ 打开默认设置项 复制一项并修改为vue，路径如下 ​ 绑定vue语法 绑定语法关联文件路径请查看目录 Sublime Text3\Data\Cache，寻找vue高亮语法插件名，并打开，如图 ​ Sublime Text3\Data\Cache目录 ​ ​ Sublime Text3\Data\Cache\vue-syntax-highlight 再次菜单新建vue就语法高亮了，如图 ​ 新建vue文件 绑定新建vue文件快捷键 打开 Preferences -&gt; Package Settings -&gt; SublimeTmpl -&gt; Key Bindings - Default，如图 ​ 打开设置快捷键文件 复制一项，粘贴创建新建vue快捷键为 ctrl+alt+v，如图 ​ 创建快捷键 保存后，菜单新建里也有了，如图 ​ 新建文件菜单 试试，完美！ ​ 完美 最后Preferences -&gt; Package Settings -&gt; SublimeTmpl -&gt; Settings - Commands 文件好像是配置命令的，配置方法也跟上面相同，照猫画虎即可~ 最后的最后通过这种方法，其他的语言模板也可以自己去创建。]]></content>
      <categories>
        <category>Sublime Text</category>
      </categories>
      <tags>
        <tag>开发工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐观锁与悲观锁的应用]]></title>
    <url>%2F2018%2F03%2F11%2F%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[乐观锁与悲观锁的应用概念悲观锁(Pessimistic Lock)每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 乐观锁(Optimistic Lock)每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。 实例假设一个业务场景：数据库中有一条数据，需要获取到当前的值，在当前值的基础上+10，然后再更新回去。如果此时有两个线程同时并发处理，第一个线程拿到数据是10，+10=20更新回去。第二个线程原本是要在第一个线程的基础上再+20=40,结果由于并发访问取到更新前的数据为10，+20=30。 这就是典型的存在中间状态，导致数据不正确。来看以下的例子： 并发所带来的问题和上文提到的类似，这里有一张price表，表结构如下： 1234567CREATE TABLE `price` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `total` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;总值&apos;, `front` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费前&apos;, `end` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费后&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1268 DEFAULT CHARSET=utf8 我这里写了一个单测：就一个主线程，循环100次，每次把 front 的值减去10，再写入一次流水记录，正常情况是写入的每条记录都会每次减去10。 1234567891011121314151617181920212223242526272829303132333435 /** * 单线程消费 */ @Test public void singleCounsumerTest1()&#123;// 使用 Mybaits /* for (int i=0 ;i&lt;100 ;i++)&#123; Price price = priceMapper.selectByPrimaryKey(1); int ron = 10 ; price.setFront(price.getFront().subtract(new BigDecimal(ron))); price.setEnd(price.getEnd().add(new BigDecimal(ron))); price.setTotal(price.getFront().add(price.getEnd())); priceMapper.updateByPrimaryKey(price) ; price.setId(null); priceMapper.insertSelective(price) ; &#125;*/ // 使用 hibernate for (int i=0 ;i&lt;100 ;i++)&#123; Price price = priceDao.selectByPrimaryKey("1"); int ron = 10 ; price.setFront(price.getFront().subtract(new BigDecimal(ron))); price.setEnd(price.getEnd().add(new BigDecimal(ron))); price.setTotal(price.getFront().add(price.getEnd())); priceDao.updateByPrimaryKey(price) ; // price.setId(null); priceDao.insertSelective(price) ; &#125; &#125; 初始化数据库中的值： 执行结果如下： 但是如果是多线程的情况下会是如何呢： 我这里新建了一个 PriceController 123456789101112131415161718192021222324252627282930313233343536373839/** * @Author shenwenfang * @Date 2018/3/8 10:50 * @Description: 线程池 无锁 */@RestController@RequestMapping(value="threadPrice")public class ThreadPoolConfigController &#123; @Autowired PriceDao priceDao; @Autowired ThreadPoolConfig config; @RequestMapping(value = "/threadPrice.do") @ApiOperation(value = "锁的应用",httpMethod = "POST") public void threadPrice()&#123; try &#123; for(int i= 0;i &lt;10;i++)&#123; Thread t = new Thread(new Runnable() &#123; public void run() &#123; Price price = priceDao.selectByPrimaryKey("1"); int ron = 10; price.setFront(price.getFront().subtract(new BigDecimal(ron))); price.setEnd(price.getEnd().add(new BigDecimal(ron))); priceDao.updateByPrimaryKey(price); priceDao.insertSelective(price); &#125; &#125;); config.submit(t); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 其中为了节省资源使用了一个线程池: 123456789101112131415161718192021222324import java.util.concurrent.TimeUnit;/** * @Author shenwenfang * @Date 2018/3/8 10:40 * @Description: 为了节省资源使用一个线程池 */@Servicepublic class ThreadPoolConfig &#123; private static final int MAX_SIZE = 10; private static final int CORE_SIZE = 5; private static final int SECOND = 1000; private ThreadPoolExecutor executor; public ThreadPoolConfig()&#123; executor = new ThreadPoolExecutor(CORE_SIZE,MAX_SIZE,SECOND,TimeUnit.MICROSECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public void submit(Thread thread)&#123; executor.submit(thread); &#125;&#125; 关于线程池的使用今后会仔细探讨。这里就简单理解为有10个线程并发去处理上面单线程的逻辑，来看看结果怎么样： 会看到明显的数据错误，导致错误的原因自然就是有线程读取到了中间状态进行了错误的更新。 进而有了以下两种解决方案：悲观锁和乐观锁。 悲观锁简单理解下悲观锁：当一个事务锁定了一些数据之后，只有当当前锁提交了事务，释放了锁，其他事务才能获得锁并执行操作。 使用方式如下：首先要关闭 MySQL 的自动提交：set autocommit = 0; 123456bigen --开启事务select id, total, front, end from price where id=1 for update insert into price values(?,?,?,?,?)commit --提交事务 这里使用select for update的方式利用数据库开启了悲观锁，锁定了id=1的这条数据(注意:这里除非是使用了索引会启用行级锁，不然是会使用表锁，将整张表都锁住。)。之后使用commit提交事务并释放锁，这样下一个线程过来拿到的就是正确的数据。 悲观锁一般是用于并发不是很高，并且不允许脏读等情况。但是对数据库资源消耗较大。 优点与不足 悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数 乐观锁那么有没有性能好，支持的并发也更多的方式呢？ 那就是乐观锁。 乐观锁是首先假设数据冲突很少，只有在数据提交修改的时候才进行校验，如果冲突了则不会进行更新。 通常的实现方式增加一个version字段，为每一条数据加上版本。每次更新的时候version+1，并且更新时候带上版本号。实现方式如下： 新建了一张price_version表： 12345678CREATE TABLE `price_version` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `total` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;总值&apos;, `front` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费前&apos;, `end` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费后&apos;, `version` int(11) DEFAULT &apos;0&apos; COMMENT &apos;并发版本控制&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1268 DEFAULT CHARSET=utf8 更新数据的SQL： 12345678&lt;!-- Mubatis --&gt;&lt;update id=&quot;updateByVersion&quot; parameterType=&quot;com.crossoverJie.pojo.PriceVersion&quot;&gt; UPDATE price_version SET front = #&#123;front,jdbcType=DECIMAL&#125;, version= version + 1 WHERE id = #&#123;id,jdbcType=INTEGER&#125; AND version = #&#123;version,jdbcType=INTEGER&#125; &lt;/update&gt; 123456789101112@Transactionalpublic int updateByPrimaryKey(PriceVersion priceVersion)&#123; String sql = "UPDATE price_version\n" + "SET front = :front, version= version + 1\n" + "WHERE id = :id AND version = :version"; Map&lt;String,Object&gt; param = new HashMap&lt;String,Object&gt;(); param.put("front",priceVersion.getFront()); param.put("id",priceVersion.getId()); param.put("version",priceVersion.getVersion()); int count = getCurrentSession().createSQLQuery(sql).setProperties(param).executeUpdate(); return count;&#125; 调用方式： 12345678910111213141516171819202122232425/** * 线程池，乐观锁 * @param redisContentReq * @return */@RequestMapping(value = "/threadPriceVersion.do")@ApiOperation(value = "乐观锁的应用",httpMethod = "POST")public void threadPriceVersion()&#123; for(int i = 0;i&lt;3;i++)&#123; Thread t = new Thread(new Runnable() &#123; public void run() &#123; PriceVersion priceVersion = goodStoreDao.vselectByPrimaryKey("1"); int ron = new Random().nextInt(20); System.out.println("本次消费="+ron); priceVersion.setFront(new BigDecimal(ron)); int count = goodStoreDao.vupdateByPrimaryKey(priceVersion); if(count == 0) System.out.println("更新失败！"); else System.out.println("更新成功！"); &#125; &#125;); config.submit(t); &#125;&#125; 处理逻辑：开了三个线程生成了20以内的随机数更新到 front 字段。 当调用该接口时日志如下： 可以看到线程1、4、5分别生成了15，2，11三个随机数。最后线程4、5都更新失败了，只有线程1更新成功了。 查看数据库： 发现也确实是更新的6。 乐观锁在实际应用相对较多，它可以提供更好的并发访问，并且数据库开销较少，但是有可能存在脏读的情况。 优点与不足 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。 补充1.我们经常会在访问数据库的时候用到锁，怎么实现乐观锁和悲观锁呢？以Hibernate为例，可以通过为记录添加版本或时间戳字段来实现乐观锁。可以用session.Lock()锁定对象来实现悲观锁（本质上就是执行了SELECT * FROM t FOR UPDATE语句）。 2.如果把乐观锁看作是关于冲突检测的，那么悲观锁就是关于冲突避免的。在实际应用的源代码控制系统中， 这两种策略都可以被使用，但是现在大多数源代码开发者更倾向于使用乐观锁策略。（有一种很有道理的说法：乐观锁并不是真正的锁定，但是这种叫法很方便并且广泛流传，以至于不容忽略。） 在乐观锁和悲观锁之间进行选择的标准是：冲突的频率与严重性。如果冲突很少，或者冲突的后果不会很严重，那么通常情况下应该选择乐观锁，因为它能得到更好的并发性，而且更容易实现。但是，如果冲突的结果对于用户来说痛苦的，那么就需要使用悲观策略。]]></content>
      <categories>
        <category>乐观锁与悲观锁</category>
      </categories>
      <tags>
        <tag>Java 高级应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Map 用法、遍历、排序和常用 API]]></title>
    <url>%2F2018%2F03%2F06%2FJava%20Map%20%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Java map 用法、遍历、排序和常用APIjava.util 中的集合类包含 Java 中某些最常用的类。最常用的集合类是 List 和 Map。 Map 提供了一个更通用的元素存储方法。Map 集合类用于存储元素对（称作“键”和“值”），其中每个键映射到一个值。 本文主要介绍java map的初始化、用法、map的四种常用的遍历方式、map的排序以及常用api。 Map用法类型介绍Java 自带了各种 Map 类。这些 Map 类可归为三种类型： 通用Map，用于在应用程序中管理映射，通常在 java.util 程序包中实现HashMap、Hashtable、Properties、LinkedHashMap、IdentityHashMap、TreeMap、WeakHashMap、ConcurrentHashMap 专用Map，通常我们不必亲自创建此类Map，而是通过某些其他类对其进行访 java.util.jar.Attributes、 javax.print.attribute.standard.PrinterStateReasons、 java.security.Provider、 java.awt.RenderingHints、 javax.swing.UIDefaults 一个用于帮助我们实现自己的Map类的抽象类 AbstractMap 类型区别HashMap 最常用的 Map ,它根据键的 HashCode 值存储数据,根据键可以直接获取它的值，具有很快的访问速度。HashMap 最多只允许一条记录的键为 Null(多条会覆盖);不允许多条记录的值为 Null。非同步的。 TreeMap 能够把它保存的记录根据键(key)排序,默认是按升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。TreeMap不允许key的值为null。非同步的。Hashtable 与 HashMap类似,不同的是:key和value的值均不允许为null;它支持线程的同步，即任一时刻只有一个线程能写Hashtable,因此也导致了Hashtale在写入时会比较慢。LinkedHashMap 保存了记录的插入顺序，在用 Iterator 遍历 LinkedHashMap 时，先得到的记录肯定是先插入的.在遍历的时候会比 HashMap 慢。key 和 value 均允许为空，非同步的。 四种常用Map插入与读取性能比较测试环境jdk1.7.0_80 测试结果 插入10次平均(ms) 读取10次平均(ms) 1W 10W 100W 1W 10W 100W HashMap 56 261 3030 2 21 220 LinkedHashMap 25 229 3069 2 20 216 TreeMap 29 295 4117 5 103 1446 Hashtable 24 234 3275 2 22 259 测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class Test &#123; static int hashMapW = 0; static int hashMapR = 0; static int linkMapW = 0; static int linkMapR = 0; static int treeMapW = 0; static int treeMapR = 0; static int hashTableW = 0; static int hashTableR = 0; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; Test test = new Test(); test.test(100 * 10000); System.out.println(); &#125; System.out.println("hashMapW = " + hashMapW / 10); System.out.println("hashMapR = " + hashMapR / 10); System.out.println("linkMapW = " + linkMapW / 10); System.out.println("linkMapR = " + linkMapR / 10); System.out.println("treeMapW = " + treeMapW / 10); System.out.println("treeMapR = " + treeMapR / 10); System.out.println("hashTableW = " + hashTableW / 10); System.out.println("hashTableR = " + hashTableR / 10); &#125; public void test(int size) &#123; int index; Random random = new Random(); String[] key = new String[size]; // HashMap 插入 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); long start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; key[i] = UUID.randomUUID().toString(); map.put(key[i], UUID.randomUUID().toString()); &#125; long end = System.currentTimeMillis(); hashMapW += (end - start); System.out.println("HashMap插入耗时 = " + (end - start) + " ms"); // HashMap 读取 start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; index = random.nextInt(size); map.get(key[index]); &#125; end = System.currentTimeMillis(); hashMapR += (end - start); System.out.println("HashMap读取耗时 = " + (end - start) + " ms"); // LinkedHashMap 插入 map = new LinkedHashMap&lt;String, String&gt;(); start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; key[i] = UUID.randomUUID().toString(); map.put(key[i], UUID.randomUUID().toString()); &#125; end = System.currentTimeMillis(); linkMapW += (end - start); System.out.println("LinkedHashMap插入耗时 = " + (end - start) + " ms"); // LinkedHashMap 读取 start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; index = random.nextInt(size); map.get(key[index]); &#125; end = System.currentTimeMillis(); linkMapR += (end - start); System.out.println("LinkedHashMap读取耗时 = " + (end - start) + " ms"); // TreeMap 插入 key = new String[size]; map = new TreeMap&lt;String, String&gt;(); start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; key[i] = UUID.randomUUID().toString(); map.put(key[i], UUID.randomUUID().toString()); &#125; end = System.currentTimeMillis(); treeMapW += (end - start); System.out.println("TreeMap插入耗时 = " + (end - start) + " ms"); // TreeMap 读取 start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; index = random.nextInt(size); map.get(key[index]); &#125; end = System.currentTimeMillis(); treeMapR += (end - start); System.out.println("TreeMap读取耗时 = " + (end - start) + " ms"); // Hashtable 插入 key = new String[size]; map = new Hashtable&lt;String, String&gt;(); start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; key[i] = UUID.randomUUID().toString(); map.put(key[i], UUID.randomUUID().toString()); &#125; end = System.currentTimeMillis(); hashTableW += (end - start); System.out.println("Hashtable插入耗时 = " + (end - start) + " ms"); // Hashtable 读取 start = System.currentTimeMillis(); for (int i = 0; i &lt; size; i++) &#123; index = random.nextInt(size); map.get(key[index]); &#125; end = System.currentTimeMillis(); hashTableR += (end - start); System.out.println("Hashtable读取耗时 = " + (end - start) + " ms"); &#125;&#125; Map 遍历初始化数据123Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();map.put("key1", "value1");map.put("key2", "value2"); 增强for循环遍历使用keySet()遍历 12345Iterator&lt;String&gt; iterator = map.keySet().iterator();while (iterator.hasNext()) &#123; String key = iterator.next(); System.out.println(key + " ：" + map.get(key));&#125; 使用entrySet()遍历 12345Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = map.entrySet().iterator();while (iterator.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = iterator.next(); System.out.println(entry.getKey() + " ：" + entry.getValue());&#125; 迭代器遍历使用keySet()遍历 12345Iterator&lt;String&gt; iterator = map.keySet().iterator();while (iterator.hasNext()) &#123; String key = iterator.next(); System.out.println(key + " ：" + map.get(key));&#125; 使用entrySet()遍历 12345Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = map.entrySet().iterator();while (iterator.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = iterator.next(); System.out.println(entry.getKey() + " ：" + entry.getValue());&#125; HashMap四种遍历方式性能比较比较方式 分别对四种遍历方式进行10W次迭代，比较用时。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package net.xsoftlab.baike; import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Map.Entry; public class TestMap &#123; public static void main(String[] args) &#123; // 初始化，10W次赋值 Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for (int i = 0; i &lt; 100000; i++) map.put(i, i); /** 增强for循环，keySet迭代 */ long start = System.currentTimeMillis(); for (Integer key : map.keySet()) &#123; map.get(key); &#125; long end = System.currentTimeMillis(); System.out.println("增强for循环，keySet迭代 -&gt; " + (end - start) + " ms"); /** 增强for循环，entrySet迭代 */ start = System.currentTimeMillis(); for (Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123; entry.getKey(); entry.getValue(); &#125; end = System.currentTimeMillis(); System.out.println("增强for循环，entrySet迭代 -&gt; " + (end - start) + " ms"); /** 迭代器，keySet迭代 */ start = System.currentTimeMillis(); Iterator&lt;Integer&gt; iterator = map.keySet().iterator(); Integer key; while (iterator.hasNext()) &#123; key = iterator.next(); map.get(key); &#125; end = System.currentTimeMillis(); System.out.println("迭代器，keySet迭代 -&gt; " + (end - start) + " ms"); /** 迭代器，entrySet迭代 */ start = System.currentTimeMillis(); Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; iterator1 = map.entrySet().iterator(); Map.Entry&lt;Integer, Integer&gt; entry; while (iterator1.hasNext()) &#123; entry = iterator1.next(); entry.getKey(); entry.getValue(); &#125; end = System.currentTimeMillis(); System.out.println("迭代器，entrySet迭代 -&gt; " + (end - start) + " ms"); &#125;&#125; 运行三次，比较结果 第一次 1234增强 for 循环 keySet 迭代 -&gt; 18ms增强 for 循环， entrySet - &gt;4ms迭代器，keySet 迭代 - &gt;4ms迭代器，entrySet 迭代 - &gt;3ms 第二次 1234增强 for 循环 keySet 迭代 -&gt; 8ms增强 for 循环， entrySet - &gt;5ms迭代器，keySet 迭代 - &gt;5ms迭代器，entrySet 迭代 - &gt;4ms 第三次 1234增强 for 循环 keySet 迭代 -&gt; 30ms增强 for 循环， entrySet - &gt;38ms迭代器，keySet 迭代 - &gt;7ms迭代器，entrySet 迭代 - &gt;2ms 平均值 1234增强for循环，keySet迭代 -&gt; 31 ms增强for循环，entrySet迭代 -&gt; 20 ms迭代器，keySet迭代 -&gt; 17 ms迭代器，entrySet迭代 -&gt; 10.33 ms 总结 增强for循环使用方便，但性能较差，不适合处理超大量级的数据。 迭代器的遍历速度要比增强for循环快很多，是增强for循环的2倍左右。 使用entrySet遍历的速度要比keySet快很多，是keySet的1.5倍左右。 Map 排序HashMap、Hashtable、LinkedHashMap 排序注： TreeMap 也可以使用此方法进行排序，但是更推荐下面的方法。 1234567891011121314151617Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();map.put("a", "c");map.put("b", "b");map.put("c", "a"); // 通过ArrayList构造函数把map.entrySet()转换成listList&lt;Map.Entry&lt;String, String&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;String, String&gt;&gt;(map.entrySet());// 通过比较器实现比较排序Collections.sort(list, new Comparator&lt;Map.Entry&lt;String, String&gt;&gt;() &#123; public int compare(Map.Entry&lt;String, String&gt; mapping1, Map.Entry&lt;String, String&gt; mapping2) &#123; return mapping1.getKey().compareTo(mapping2.getKey()); &#125;&#125;); for (Map.Entry&lt;String, String&gt; mapping : list) &#123; System.out.println(mapping.getKey() + " ：" + mapping.getValue());&#125; TreeMap排序TreeMap默认按key进行升序排序，如果想改变默认的顺序，可以使用比较器: 12345678910111213Map&lt;String, String&gt; map = new TreeMap&lt;String, String&gt;(new Comparator&lt;String&gt;() &#123; public int compare(String obj1, String obj2) &#123; return obj2.compareTo(obj1);// 降序排序 &#125;&#125;);map.put("a", "c");map.put("b", "b");map.put("c", "a"); for (String key : map.keySet()) &#123; System.out.println(key + " ：" + map.get(key));&#125; 按value排序(通用)1234567891011121314151617Map&lt;String, String&gt; map = new TreeMap&lt;String, String&gt;(); map.put("a", "c"); map.put("b", "b"); map.put("c", "a"); // 通过ArrayList构造函数把map.entrySet()转换成list List&lt;Map.Entry&lt;String, String&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;String, String&gt;&gt;(map.entrySet()); // 通过比较器实现比较排序 Collections.sort(list, new Comparator&lt;Map.Entry&lt;String, String&gt;&gt;() &#123; public int compare(Map.Entry&lt;String, String&gt; mapping1, Map.Entry&lt;String, String&gt; mapping2) &#123; return mapping1.getValue().compareTo(mapping2.getValue()); &#125; &#125;); for (String key : map.keySet()) &#123; System.out.println(key + " ：" + map.get(key)); &#125; 常用API clear() 从 Map 中删除所有映射 remove(Object key) 从 Map 中删除键和关联的值 put(Object key, Object value) 将指定值与指定键相关联 putAll(Map t) 将指定 Map 中的所有映射复制到此 map entrySet() 返回 Map 中所包含映射的 Set 视图。Set 中的每个元素都是一个 Map.Entry 对象，可以使用 getKey() 和 getValue() 方法（还有一个 setValue() 方法）访问后者的键元素和值元素 keySet() 返回 Map 中所包含键的 Set 视图。删除 Set 中的元素还将删除 Map 中相应的映射（键和值） values() 返回 map 中所包含值的 Collection 视图。删除 Collection 中的元素还将删除 Map 中相应的映射（键和值） get(Object key) 返回与指定键关联的值 containsKey(Object key) 如果 Map 包含指定键的映射，则返回 true containsValue(Object value) 如果此 Map 将一个或多个键映射到指定值，则返回 true isEmpty() 如果 Map 不包含键-值映射，则返回 true size() 返回 Map 中的键-值映射的数目]]></content>
      <categories>
        <category>Map</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 的源码分析]]></title>
    <url>%2F2018%2F03%2F06%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[JDK1.8 HashMap源码分析HahsMap实现了Map接口。其继承关系如下图： HashMap有两个影响性能的重要参数：初始容量和加载因子。容量是Hash表中桶的个数，当HashMap初始化时，容量就是初始容量。加载因子是衡量hash表多满的一个指标，用来判断是否需要增加容量。当HashMap需要增加容量时，将会导致rehash操作。默认情况下，0.75的加载因子在时间和空间方面提供了很好的平衡。加载因子越大，增加了空间利用率但是也增加了查询的时间。 构造器底层结构JDK1.8之前的结构在JDK1.7之前，HashMap采用的是数组+链表的结构，其结构图如下：左边部分代表Hash表，数组的每一个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。 JDK1.8的结构JDK1.8 之前的 HashMap 都采用上图的结构，都是基于一个数组和多个单链表，hash 值冲突的时候，就将对应节点以链表形式存储。如果在一个链表中查找一个节点时，将会花费 O(n) 的查找时间，会有很大的性能损失。到了JDK1.8，当同一个Hash值的节点数不小于8时，不再采用单链表形式存储，而是采用红黑树，如下图所示： Node介绍Node是map的接口中的内部接口Map.Entry的实现类,用于存储HashMap中键值对的对象,是HashMap中非常重要的一个内部类,随便提一下,HashMap中有非常多的内部类,本文没做过多的介绍,读者可以自己翻看一下源码,因为篇幅实在太长了…在这里就简单的讲一下,大部分的内部类都是用于集合操作的,如keySet,values,entrySet等方法. 内部组成 12345678910static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;//key是不可变的final K key;//valueV value;//指向下一个entry对象,具体作用后面介绍Node&lt;K,V&gt; next;//hash值int hash;&#125; 重要的字段HashMap中有几个重要的字段，如下： 1234567891011121314151617181920212223242526 //Hash表结构 transient Node&lt;K,V&gt;[] table; //元素个数 transient int size; //确保fail-fast机制 transient int modCount; //下一次增容前的阈值 int threshold; //加载因子 final float loadFactor; //默认初始容量 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16//最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //加载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; //链表转红黑树的阈值 static final int TREEIFY_THRESHOLD = 8; 红黑树的关键参数123456789101112131415//一个桶的树化阈值//当桶中元素个数超过这个值时，需要使用红黑树节点替换链表节点//这个值必须为 8，要不然频繁转换效率也不高static final int TREEIFY_THRESHOLD = 8;//一个树的链表还原阈值//当扩容时，桶中元素个数小于这个值，就会把树形的桶元素 还原（切分）为链表结构//这个值应该比上面那个小，至少为 6，避免频繁转换static final int UNTREEIFY_THRESHOLD = 6;//哈希表的最小树形化容量//当哈希表中的容量大于这个值时，表中的桶才能进行树形化//否则桶内元素太多时会扩容，而不是树形化//为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLDstatic final int MIN_TREEIFY_CAPACITY = 64; 构造方法HashMap一共有4个构造方法，主要的工作就是完成容量和加载因子的赋值。Hash表都是采用的懒加载方式，当第一次插入数据时才会创建。 1234567891011121314151617181920212223242526272829//构造方法 初始化负载因子和阈值public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); //容量判断 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //负载银子判断 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125;//为空时候使用默认分配的大小16,负载因子0.75f,默认的容量为12,当size&gt;threshold默认容量时候就会去扩容 public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125; public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 基本操作确定哈希桶数组索引位置不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过 HashMap 的数据结构是数组和链表的结合，所以我们当然希望这个 HashMap 里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用 hash 算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap 定位数组索引位置，直接决定了 hash 方法的离散性能。先看看源码的实现(方法一+方法二): 1234567891011方法一：static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的 Hash 算法本质上就是三步：取 key 的 hashCode 值、高位运算、取模运算。 对于任意给定的对象，只要它的 hashCode() 返回值相同，那么程序调用方法一所计算得到的 Hash 码值总是相同的。我们首先想到的就是把 hash 值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在 HashMap 中是这样做的：调用方法二来计算该对象应该保存在 table 数组的哪个索引处。 这个方法非常巧妙，它通过 h &amp; (table.length -1) 来得到该对象的保存位，而 HashMap 底层数组的长度总是 2 的n 次方，这是 HashMap 在速度上的优化。当 length 总是 2 的 n 次方时，h&amp; (length-1) 运算等价于对 length 取模，也就是 h%length ，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。 下面举例说明下，n为table的长度。 添加一个元素put(K k,V v)HashMap 允许K和V为 null，添加一个键值对时使用 put 方法，如果之前已经存在K的键值，那么旧值将会被新值替换。实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;/** * onlyIfAbsent 是否替换,为true时,如果存在值则替换 * evict 主要用于LinkedHashMap移除最近未使用的节点 */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果哈希表为空或长度为0，调用resize()方法创建哈希表 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果哈希表中K对应的桶为空，那么该K，V对将成为该桶的头节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //该桶处已有节点，即发生了哈希冲突 else &#123; Node&lt;K,V&gt; e; K k; //如果添加的值与头节点相同，将e指向p if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果与头节点不同，并且该桶目前已经是红黑树状态，调用putTreeVal()方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //桶中仍是链表阶段 else &#123; //遍历，要比较是否与已有节点相同 for (int binCount = 0; ; ++binCount) &#123; //将e指向下一个节点，如果是null，说明链表中没有相同节点，添加到链表尾部即可 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果此时链表个数达到了8，那么需要将该桶处链表转换成红黑树，treeifyBin()方法将hash处的桶转成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //如果与已有节点相同，跳出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果有重复节点，那么需要返回旧值 if (e != null) &#123; V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; //子类实现(用于linkedHashMap) afterNodeAccess(e); return oldValue; &#125; &#125; //是一个全新节点，那么size需要+1 ++modCount; //如果超过了阈值，那么需要resize()扩大容量 if (++size &gt; threshold) resize(); //子类实现(用于linkedHashMap) afterNodeInsertion(evict); return null; &#125; 从上面代码可以看到 putVal() 方法的流程： 判断哈希表是否为空，如果为空，调用 resize() 方法进行创建哈希表 根据 hash 值得到哈希表中桶的头节点，如果为 null ，说明是第一个节点，直接调用 newNode() 方法添加节点即可 如果发生了哈希冲突，那么首先会得到头节点，比较是否相同，如果相同，则进行节点值的替换返回 如果头节点不相同，但是头节点已经是 TreeNode 了，说明该桶处已经是红黑树了，那么调用 putTreeVal() 方法将该结点加入到红黑树中 如果头节点不是 TreeNode，说明仍然是链表阶段，那么就需要从头开始遍历，一旦找到了相同的节点就跳出循环或者直到了链表尾部，那么将该节点插入到链表尾部 如果插入到链表尾部后，链表个数达到了阈值8，那么将会将该链表转换成红黑树，调用 treeifyBin() 方法 如果是新加一个数据，那么将 size+1，此时如果 size 超过了阈值，那么需要调用 resize() 方法进行扩容 resize()方法下面我们一个一个分析上面提到的方法。首先是 resize() 方法，resize() 在哈希表为 null 时将会初始化，但是在已经初始化后就会进行容量扩展。下面是resize()的具体实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146/** * 有几种情况 * 1.当为空的时候,也就是没有初始化的时候 * 2.当到达最大值时候 * 3.普通扩容时候 */final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length;//旧表容量 int oldThr = threshold;//旧表与之 int newCap, newThr = 0; //旧表存在 if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 //旧表已经达到了最大容量，不能再大，直接返回旧表 //大于2&lt;&lt;30 最大容量设置为2&lt;&lt;32 - 1 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //但是不移动.,没有空间移动 threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 //否则，新容量为旧容量2倍，新阈值为旧阈值2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //如果就阈值&gt;0，说明构造方法中指定了容量 //用户自己设定了初始化大小 else if (oldThr &gt; 0) newCap = oldThr; //初始化时没有指定阈值和容量，使用默认的容量16和阈值16*0.75=12 //如果没使用,使用默认值初始化 else &#123; newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 //用户自定义了map的初始化操作 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //更新阈值 //新的容量 threshold = newThr; //创建表,初始化或更新表 @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果属于容量扩展，rehash操作 if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 //遍历旧表 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果该桶处存在数据 if ((e = oldTab[j]) != null) &#123; //将旧表数据置为null，帮助gc oldTab[j] = null; //如果只有一个节点，直接在新表中赋值 //如果当前位置只有一个元素,直接移动到新的位置 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果该节点已经为红黑树 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果没超过8个 是链表 //如果该桶处仍为链表 // 链表优化重hash的代码块 else &#123; //下面这段暂时没有太明白，通过e.hash &amp; oldCap将链表分为两队，参考知乎上的一段解释 /** * 把链表上的键值对按hash值分成lo和hi两串，lo串的新索引位置与原先相同[原先位 * j]，hi串的新索引位置为[原先位置j+oldCap]； * 链表的键值对加入lo还是hi串取决于 判断条件if ((e.hash &amp; oldCap) == 0)，因为* capacity是2的幂，所以oldCap为10...0的二进制形式，若判断条件为真，意味着 * oldCap为1的那位对应的hash位为0，对新索引的计算没有影响（新索引 * =hash&amp;(newCap-*1)，newCap=oldCap&lt;&lt;2）；若判断条件为假，则 oldCap为1的那位* 对应的hash位为1， * 即新索引=hash&amp;( newCap-1 )= hash&amp;( (oldCap&lt;&lt;2) - 1)，相当于多了10...0， * 即 oldCap * 例子： * 旧容量=16，二进制10000；新容量=32，二进制100000 * 旧索引的计算： * hash = xxxx xxxx xxxy xxxx * 旧容量-1 1111 * &amp;运算 xxxx * 新索引的计算： * hash = xxxx xxxx xxxy xxxx * 新容量-1 1 1111 * &amp;运算 y xxxx * 新索引 = 旧索引 + y0000，若判断条件为真，则y=0(lo串索引不变)，否则y=1(hi串 * 索引=旧索引+旧容量10000) */ Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next;//此处的操作是这样子的 因为是扩容一倍的操作,所以与旧的容量进行与操作后只有两个值0 和 1//如果是0就位置不变,如果是1就移动n+old的位置,//个人认为这么做的好处是:/*** 1.不会像之前1.7发生循环依赖的问题* 2.从概率的角度上来看可以均匀分配,(一般来说高位和低位比例差不多)* 3.提高效率*/ do &#123; next = e.next; // 原索引 //如果和旧容量位运算后的值是0,记得当前节点和存放在链表的尾部 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //同上 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 //为0的还是存放在当前位置 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 //为1的就放在扩容的j + oldCap那边去 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 因为不像Java8之前的HashMap有初始化操作,此处选择将初始化和扩容放在了一起,并且又增加了红黑树的概念,所以导致整个方法的判断次数非常多,也是这个方法比较庞大的主要原因. 值得一体的是,在扩容后重新计算位置的时候,对链表进行优化,有兴趣可以搜索一下HashMap导致cpu百分之百的问题 而在Java中通过巧妙的进行&amp;操作,然后获得高位是为0还是1.最终移动的位置就是低位的链表留在原地,高位的放在index+oldsize的地方就可以了,不用为每一个元素计算hash值,然后移动到对应的位置,再判断是否是链表,是否需要转换成树的操作.如下所示. 12hashcode: 1111111111111101212oldcap: 0000000000000010000 很容易知道这个&amp;操作之后就是为0,因为oldcap都是2的倍数,只有高位为1,所以通过&amp;确认高位要比%取余高效. 此时在看一下上面的扩容操作也许就更清晰了. resize()首先获取新容量以及新阈值，然后根据新容量创建新表。如果是扩容操作，则需要进行rehash操作，通过e.hash&amp;oldCap将链表分为两列，更好地均匀分布在新表中。 newNode()方法下面介绍一些newNode方法.就是新建一个节点.可以思考一下为什么要把newNode抽离出来? 123Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next);&#125; putTreeVal() 方法添加节点到红黑树的方法是Java8中新添加的,需要满足链表的长度到8,才会转换成红黑树,其主要目的是防止某个下标处的链表太长,导致在找到的时候速度很慢,下面看一下实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//尝试着往树节点添加值final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; //找到根节点 TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; //存在的话直接返回,用于替换 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //判断节点类型是否相同,不相同 else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; //没有搜索过,搜索子节点,搜过了说明没有就跳过. if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; //去子节点去找 if (((ch = p.left) != null &amp;&amp;(q = ch.find(h, k, kc)) != null) ||((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; //对比hash值,决定查找的方向 dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; //找到子节点为空,就可以加进去,设置层级关系 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125;&#125; 这里简单的梳理一下流程. 1.从根节点查找,找到了返回,如果没找到,找字节点 2.判断往哪个方向去查找 3.如果不存在,在子节点末端添加新节点 split() 方法树的 split() 方法,主要是扩容操作,重新结算位置需要分裂树,之前讲过,扩容会根据和旧 map 容量进行&amp;操作,移动高位为1的节点.并且验证新的节点列表是否需要重新转换成链表的形式. 当头节点是TreeNode时，将调用TreeNode的split方法将红黑树复制到新表中，代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this;//就是上面的头结点e // 设置记录高低位的node,和链表一样都是计算高位是0还是1 //与链表rehash时类似，将红黑树分为两部分 TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; //遍历 for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; //还是和旧的容量做位运算,为0的放在lo中 //分散规则与rehash中相同 if ((e.hash &amp; bit) == 0) &#123; //判断是否为头部 if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; //获取为1的放在hi中 else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; //lo链表的处理 //如果存在低端 if (loHead != null) &#123; //如果小于7,那么当做链表处理 //如果分散后的红黑树节点小于等于6，将红黑树节点转换成链表节点 if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; //转换成树 tab[index] = loHead; //将链表转换成红黑树 if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; //同上 //如果存在高端 if (hiHead != null) &#123; //如果分散后的红黑树节点小于等于6，将红黑树节点转换成链表节点 if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; //将链表转换成红黑树节点 if (loHead != null) hiHead.treeify(tab); &#125; &#125; &#125;//把树转换成链表final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125; TreeNode的split方法首先将头节点从头开始遍历，区分出两条单链表，再根据如果节点数小于等于6，那么将单链表的每个TreeNode转换成Node节点；否则将单链表转换成红黑树结构。至此，resize()方法结束。需要注意的是rehash时，由于容量扩大一倍，本来一条链表有可能会分成两条链表，而如果将红黑树结构复制到新表时，有可能需要完成红黑树到单链表的转换。 treeifyBin()方法treeifyBin()方法将表中某一个桶处的单链表结果转换成红黑树结构，其实现如下： 12345678910111213141516171819202122232425final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //如果哈希表不存在，或者哈希表尺寸小于64，进行resize()扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //如果桶处头节点不为null else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; //将单链表节点转换成TreeNode结构的单链表 do &#123; //将Node转换成TreeNode TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); //调用treeify将该TreeNode结构的单链表转换成红黑树 if ((tab[index] = hd) != null) hd.treeify(tab); &#125; &#125; 上述操作做了这些事: 根据哈希表中元素个数确定是扩容还是树形化 如果是树形化 遍历桶中的元素，创建相同个数的树形节点，复制内容，建立起联系 然后让桶第一个元素指向新建的树头结点，替换桶的链表内容为树形内容 treeify() 方法但是我们发现，之前的操作并没有设置红黑树的颜色值，现在得到的只能算是个二叉树。在 最后调用树形节点 hd.treeify(tab) 方法进行塑造红黑树，来看看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 final void treeify(Node[] tab) &#123; TreeNode root = null; for (TreeNode x = this, next; x != null; x = next) &#123; next = (TreeNode)x.next; x.left = x.right = null; if (root == null) &#123; //头回进入循环，确定头结点，为黑色 x.parent = null; x.red = false; root = x; &#125; else &#123; //后面进入循环走的逻辑，x 指向树中的某个节点 K k = x.key; int h = x.hash; Class kc = null; //又一个循环，从根节点开始，遍历所有节点跟当前节点 x 比较，调整位置，有点像冒泡排序 for (TreeNode p = root;;) &#123; int dir, ph; //这个 dir K pk = p.key; if ((ph = p.hash) &gt; h) //当比较节点的哈希值比 x 大时， dir 为 -1 dir = -1; else if (ph &lt; h) //哈希值比 x 小时 dir 为 1 dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) // 如果比较节点的哈希值、 x dir = tieBreakOrder(k, pk); //把 当前节点变成 x 的父亲 //如果当前比较节点的哈希值比 x 大，x 就是左孩子，否则 x 是右孩子 TreeNode xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; moveRootToFront(tab, root);&#125; put操作总结当调用put插入一个键值对时，在表为空时，会创建表。如果桶为空时，直接插入节点，如果桶不为空时，则需要对当前桶中包含的结构做判断，如果已是红黑树结构，那么需要使用红黑树的插入方法；如果不是红黑树结构，则需要遍历链表，如果添加到链表后端，如果该条链表达到了8，那么需要将该链表转换成红黑树，从treeifyBin方法可以看到，当容量小于64时，不会进行红黑树转换，只会扩容。当成功新加一个桶，那么需要将尺寸和阈值进行判断，是否需要进行resize()操作。 get(K k)操作get(K k)根据键得到值，如果值不存在，那么返回null。其实现如下： 12345678910111213141516171819202122232425262728293031public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;//根据键的hash值和键得到对应节点final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //可以从桶中得到对应hash值的第一个节点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //检查首节点，如果首节点匹配，那么直接返回首节点 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //如果首节点还有后续节点 if ((e = first.next) != null) &#123; //如果首节点是红黑树节点，调用getTreeNode()方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //首节点是链表结构，从前往后遍历 do &#123; //一旦匹配，返回节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 从上面代码可以看到getNode()方法中有多种情况：\1. 表为空或表的长度为0或表中不存在key对应的hash值桶，那么返回null\2. 如果表中有key对应hash值的桶，得到首节点，如果首节点匹配，那么直接返回；\3. 如果首节点不匹配，并且没有后续节点，那么返回null\4. 如果首节点有后续节点并且首节点是TreeNode,调用getTreeNode方法寻找节点\5. 如果首节点有后续节点并且是链表结构，那么从前往后遍历，一旦找到则返回节点，否则返回null remove()操作remove(K k)用于根据键值删除键值对，如果哈希表中存在该键，那么返回键对应的值，否则返回null。其实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125;//按照hash和key删除节点，如果不存在节点，则返回nullfinal Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果哈希表不为空并且存在桶与hash值匹配,p为桶中的头节点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //case 1：如果头节点匹配 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; //case2：如果头节点不匹配，且头节点是TreeNode，即桶中的结构为红黑树结构 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; //case 3:如果头节点不匹配，且头节点是Node，即桶中的结构为链表结构，遍历链表 do &#123; //一旦匹配，跳出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //如果存在待删除节点节点 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //如果节点是TreeNode，使用红黑树的方法 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果待删除节点是头节点，更改桶中的头节点即可 else if (node == p) tab[index] = node.next; //在链表遍历过程中，p代表node节点的前驱节点 else p.next = node.next; ++modCount; --size; //子类实现 afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; 从上面的代码可以看出，removeNode()方法首先是找到待删除的节点，如果存在待删除节点，接下来再执行删除操作。查询时流程与getNode()方法的流程类似，只不过多了在遍历链表时还需要保存前驱节点，因为后面删除时要用到（单链表结构）。删除节点时就比较简单了，三种情况三种处理方式,分别是：\1. 如果待删除节点是TreeNode，那么调用removeTreeNode()方法\2. 如果待删除节点是Node，并且待删除节点就是头节点，那么将头节点更改为原有节点的下一个节点就可以了\3. 如果待删除节点是Node且待删除节点不是头节点，那么将遍历过程中保存的前驱节点p的后继节点设为node的后继节点就可以了 红黑树中查找元素 getTreeNode()HashMap 的查找方法是 get(): 1234public V get(Object key) &#123; Node e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 它通过计算指定 key 的哈希值后，调用内部方法 getNode()； 12345678910111213141516171819final Node getNode(int hash, Object key) &#123; Node[] tab; Node first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 这个 getNode() 方法就是根据哈希表元素个数与哈希值求模（使用的公式是 (n - 1) &amp;hash）得到 key 所在的桶的头结点，如果头节点恰好是红黑树节点，就调用红黑树节点的 getTreeNode() 方法，否则就遍历链表节点。 123final TreeNode getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null);&#125; getTreeNode 方法使通过调用树形节点的 find() 方法进行查找： 123456789101112131415161718192021222324252627//从根节点根据 哈希值和 key 进行查找final TreeNode find(int h, Object k, Class kc) &#123; TreeNode p = this; do &#123; int ph, dir; K pk; TreeNode pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); return null;&#125; 由于之前添加时已经保证这个树是有序的，因此查找时基本就是折半查找，效率很高。 这里和插入时一样，如果对比节点的哈希值和要查找的哈希值相等，就会判断 key 是否相等，相等就直接返回（也没有判断值哎）；不相等就从子树中递归查找。 HashMap总结至此，我们分析完了HashMap的主要方法：构造器、put、get和remove。只需要明白JDK1.8的HashMap底层结构，那么就很好理解了。需要注意的是什么时候应该将链表结构转换成红黑树结构，什么时候又应该将红黑树结构重新转换成链表结构，本文没有具体解释有关红黑树的结构，但是这并不影响理解HashMap的基本原理。另外需要注意的是，本文的源码是基于JDK1.8的。]]></content>
      <categories>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 的扩容机制]]></title>
    <url>%2F2018%2F03%2F06%2FHashMap1.7%20%E5%92%8C%201.8%20%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6%E7%9A%84%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[扩容机制扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。 12345678910111213 1 void resize(int newCapacity) &#123; //传入新的容量 2 Entry[] oldTable = table; //引用扩容前的Entry数组 3 int oldCapacity = oldTable.length; 4 if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 5 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 6 return; 7 &#125; 8 9 Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组10 transfer(newTable); //！！将数据转移到新的Entry数组里11 table = newTable; //HashMap的table属性引用新的Entry数组12 threshold = (int)(newCapacity * loadFactor);//修改阈值13 &#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 1234567891011121314151617 1 void transfer(Entry[] newTable) &#123; 2 Entry[] src = table; //src引用了旧的Entry数组 3 int newCapacity = newTable.length; 4 for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 5 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 6 if (e != null) &#123; 7 src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） 8 do &#123; 9 Entry&lt;K,V&gt; next = e.next;10 int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置11 e.next = newTable[i]; //标记[1]12 newTable[i] = e; //将元素放在数组上13 e = next; //访问下一个Entry链上的元素14 &#125; while (e != null);15 &#125;16 &#125;17 &#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182 1 final Node&lt;K,V&gt;[] resize() &#123; 2 Node&lt;K,V&gt;[] oldTab = table; 3 int oldCap = (oldTab == null) ? 0 : oldTab.length; 4 int oldThr = threshold; 5 int newCap, newThr = 0; 6 if (oldCap &gt; 0) &#123; 7 // 超过最大值就不再扩充了，就只好随你碰撞去吧 8 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; 9 threshold = Integer.MAX_VALUE;10 return oldTab;11 &#125;12 // 没超过最大值，就扩充为原来的2倍13 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;14 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)15 newThr = oldThr &lt;&lt; 1; // double threshold16 &#125;17 else if (oldThr &gt; 0) // initial capacity was placed in threshold18 newCap = oldThr;19 else &#123; // zero initial threshold signifies using defaults20 newCap = DEFAULT_INITIAL_CAPACITY;21 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);22 &#125;23 // 计算新的resize上限24 if (newThr == 0) &#123;25 26 float ft = (float)newCap * loadFactor;27 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?28 (int)ft : Integer.MAX_VALUE);29 &#125;30 threshold = newThr;31 @SuppressWarnings(&#123;"rawtypes"，"unchecked"&#125;)32 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];33 table = newTab;34 if (oldTab != null) &#123;35 // 把每个bucket都移动到新的buckets中36 for (int j = 0; j &lt; oldCap; ++j) &#123;37 Node&lt;K,V&gt; e;38 if ((e = oldTab[j]) != null) &#123;39 oldTab[j] = null;40 if (e.next == null)41 newTab[e.hash &amp; (newCap - 1)] = e;42 else if (e instanceof TreeNode)43 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);44 else &#123; // 链表优化重hash的代码块45 Node&lt;K,V&gt; loHead = null, loTail = null;46 Node&lt;K,V&gt; hiHead = null, hiTail = null;47 Node&lt;K,V&gt; next;48 do &#123;49 next = e.next;50 // 原索引51 if ((e.hash &amp; oldCap) == 0) &#123;52 if (loTail == null)53 loHead = e;54 else55 loTail.next = e;56 loTail = e;57 &#125;58 // 原索引+oldCap59 else &#123;60 if (hiTail == null)61 hiHead = e;62 else63 hiTail.next = e;64 hiTail = e;65 &#125;66 &#125; while ((e = next) != null);67 // 原索引放到bucket里68 if (loTail != null) &#123;69 loTail.next = null;70 newTab[j] = loHead;71 &#125;72 // 原索引+oldCap放到bucket里73 if (hiTail != null) &#123;74 hiTail.next = null;75 newTab[j + oldCap] = hiHead;76 &#125;77 &#125;78 &#125;79 &#125;80 &#125;81 return newTab;82 &#125;]]></content>
      <categories>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 的线程安全]]></title>
    <url>%2F2018%2F03%2F05%2FHashMap%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%2F</url>
    <content type="text"><![CDATA[线程安全性在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)： 1234567891011121314151617181920public class HashMapInfiniteLoop &#123; private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f); public static void main(String[] args) &#123; map.put(5， "C"); new Thread("Thread1") &#123; public void run() &#123; map.put(7, "B"); System.out.println(map); &#125;; &#125;.start(); new Thread("Thread2") &#123; public void run() &#123; map.put(3, "A); System.out.println(map); &#125;; &#125;.start(); &#125; &#125; 其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。 通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。 注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。 线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。 e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。 于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。 JDK1.8与JDK1.7的性能对比HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7，下面我们从两个方面用例子证明这一点。 Hash较均匀的情况为了便于测试，我们先写一个类Key，如下： 123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; &#123; private final int value; Key(int value) &#123; this.value = value; &#125; @Override public int compareTo(Key o) &#123; return Integer.compare(this.value, o.value); &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; &#125; @Override public int hashCode() &#123; return value; &#125;&#125; 这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同，因为直接使用value当做hashcode。为了避免频繁的GC，我将不变的Key实例缓存了起来，而不是一遍一遍的创建它们。代码如下： 123456789101112131415public class Keys &#123; public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static &#123; for (int i = 0; i &lt; MAX_KEY; ++i) &#123; KEYS_CACHE[i] = new Key(i); &#125; &#125; public static Key of(int value) &#123; return KEYS_CACHE[value]; &#125;&#125; 现在开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……10000000），屏蔽了扩容的情况，代码如下： 1234567891011121314151617181920static void test(int mapSize) &#123; HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) &#123; map.put(Keys.of(i), i); &#125; long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) &#123; map.get(Keys.of(i)); &#125; long endTime = System.nanoTime(); System.out.println(endTime - beginTime); &#125; public static void main(String[] args) &#123; for(int i=10;i&lt;= 1000 0000;i*= 10)&#123; test(i); &#125; &#125; 在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响。结果如下： 通过观测测试结果可知，JDK1.8的性能要高于JDK1.7 15%以上，在某些size的区域上，甚至高于100%。由于Hash算法较均匀，JDK1.8引入的红黑树效果不明显，下面我们看看Hash不均匀的的情况。 Hash极不均匀的情况假设我们又一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下： 123456789class Key implements Comparable&lt;Key&gt; &#123; //... @Override public int hashCode() &#123; return 1; &#125;&#125; 仍然执行main方法，得出的结果如下表所示： 从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个链表太长的时候，HashMap会动态的将它替换成一个红黑树，这话的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。 ​ 测试环境：处理器为2.2 GHz Intel Core i7，内存为16 GB 1600 MHz DDR3，SSD硬盘，使用默认的JVM参数，运行在64位的OS X 10.10.1上。 小结(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。 (2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 (3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。 (4) JDK1.8引入红黑树大程度优化了HashMap的性能。 (5) 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。]]></content>
      <categories>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap 的锁定分离技术]]></title>
    <url>%2F2018%2F03%2F05%2FConcurrentHashMap%E7%9A%84%E9%94%81%E5%88%86%E7%A6%BB%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap的锁分离技术 ​ 对比上图，HashTable实现锁的方式是锁整个hash表，而ConcurrentHashMap的实现方式是锁桶（简单理解就是将整个hash表想象成一大缸水，现在将这大缸里的水分到了几个水桶里，hashTable每次都锁定这个大缸，而ConcurrentHashMap则每次只锁定其中一个 桶）。 ​ ConcurrentHashMap将hash表分为16个桶（默认值），诸如get,put,remove等常用操作只锁当前需要用到的桶。试想，原来 只能一个线程进入，现在却能同时16个写线程进入，并发性的提升是显而易见的。 ​ 值得一提的是当对ConcurrentHashMap进行remove操作时，并不是进行简单的节点删除操作，对比上图，当对ConcurrentHashMap的一个segment也就是一个桶中的节点进行remove后，例如删除节点C，C节点实际并没有被销毁，而是将C节点前面的反转并拷贝到新的链表中，C节点后面的不需要被克隆。这样来保持并发的读线程不受并发的写线程的干扰。例如现在有一个读线程读到了A节点，写线程把C删掉了，但是看上图，读线程仍然可以继续读下去；当然，如果在删除C之前读线程读到的是D，那么更不会有影响。 ​ 根据上面所提到的ConcurrentHashMap中删除一个节点并不会立刻被读线程感受到的效果，就是传说中的弱一致性，所以ConcurrentHashMap的迭代器是弱一致性迭代器]]></content>
      <categories>
        <category>ConcurrentHashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础面试题]]></title>
    <url>%2F2018%2F01%2F21%2F%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[基础面试题引言：以下各方面知识点的面试题，是为了将要出来工作的小师妹和小师弟而精心整理的。希望对你们都帮助。这些面试题都是很基础的，希望你们能够好好利用起来。有问题，或者不对的地方欢迎给我留言哈！ forward 和redirect的区别forward是服务器请求资源，服务器直接访问目标地址的URL，把那个URL的响应内容读取过来，然后把这些内容再发给浏览器，浏览器根本不知道服务器发送的内容是从哪儿来的，所以它的地址栏中还是原来的地址。 redirect就是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址，一般来说浏览器会用刚才请求的所有参数重新请求，所以session,request参数都可以获取。 int 和 Integer 有什么区别Java 提供两种不同的类型：引用类型和原始类型（或内置类型）。Int 是 java 的原始数据类型，Integer 是 java为int提供的封装类。Java为每个原始类型提供了封装类。原始类型封装类，booleanBoolean,charCharacter,byteByte,shortShort,intInteger,longLong,floatFloat,doubleDouble引用类型和原始类型的行为完全不同，并且它们具有不同的语义。引用类型和原始类型具有不同的特征和用法，它们包括：大小和速度问题，这种类型以哪种类型的数据结构存储，当引用类型和原始类型用作某个类的实例数据时所指定的缺省值。对象引用实例变量的缺省值为 null，而原始类型实例变量的缺省值与它们的类型有关 error和exception有什么区别error 表示恢复不是不可能但很困难的情况下的一种严重问题。比如说内存溢出。不可能指望程序能处理这样的情况。exception 表示一种设计或实现问题。也就是说，它表示如果程序运行正常，从不会发生的情况。 最常见到的runtime exception1234567891011121314ArithmeticException, ArrayStoreException, BufferOverflowException, BufferUnderflowException, CannotRedoException, CannotUndoException, ClassCastException, CMMException, ConcurrentModificationException, DOMException, EmptyStackException, IllegalArgumentException, IllegalMonitorStateException, IllegalPathStateException, IllegalStateException, ImagingOpException, IndexOutOfBoundsException, MissingResourceException, NegativeArraySizeException, NoSuchElementException, NullPointerException, ProfileDataException, ProviderException, RasterFormatException, SecurityException, SystemException, UndeclaredThrowableException, UnmodifiableSetException, UnsupportedOperationException Overload和Override区别，Overloaded方法可以改变返回值的类型吗方法的重写Overriding和重载Overloading是Java多态性的不同表现。重写Overriding是父类与子类之间多态性的一种表现，重载Overloading是一个类中多态性的一种表现。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写 (Overriding)。子类的对象使用这个方法时，将调用子类中的定义，对它而言，父类中的定义如同被”屏蔽”了。如果在一个类中定义了多个同名的方法，它们或有不同的参数个数或有不同的参数类型，则称为方法的重载(Overloading)。Overloaded的方法是可以改变返回值的类型。 OOP是什么OOP面向对象编程，针对业务处理过程的实体及其属性和行为进行抽象封装，以获得更加清晰高效的逻辑单元划分。 java中有哪些集合，主要方法有哪些主要有LinkedList，ArrayList，Vector等。下面是详细：Collection├List│├LinkedList│├ArrayList│└Vector│ └Stack└SetMap├Hashtable├HashMap└WeakHashMap最常用的集合类是 List 和 Map。 List 的具体实现包括 ArrayList 和 Vector，它们是可变大小的列表，比较适合构建、存储和操作任何类型对象的元素列表。 List 适用于按数值索引访问元素的情形。 Map 提供了一个更通用的元素存储方法。 Map 集合类用于存储元素对（称作“键”和“值”）其中每个键映射到一个值。 List、Map、Set接口，存取元素时各自特点List 以特定次序来持有元素，可有重复元素。Set 无法拥有重复元素,内部排序。Map 保存key-value值，value可多值。 List的遍历： List接口有size()和get()方法，用这两个方法可以实现对List的遍历。size()方法得到List中的元素个数。get()方法取得某个位置上的元素 HashMap与HashTable的区别1、HashMap 是非线程安全的，HashTable 是线程安全的。 2、HashMap 的键和值都允许有 null 值存在，而 HashTable 则不行。 3、因为线程安全的问题，HashMap 效率比 HashTable 的要高。HashMap 的实现机制：维护一个每个元素是一个链表的数组，而且链表中的每个节点是一个 Entry[] 键值对的数据结构。实现了 数组+链表 的特性，查找快，插入删除也快。对于每个 key , 他对应的数组索引下标是 int i = hash(key.hashcode)&amp;(len-1);每个新加入的节点放在链表首，然后该新加入的节点指向原链表首 Hashcode的作用Java中的集合有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。 equals方法可用于保证元素不重复，但如果每增加一个元素就检查一次，若集合中现在已经有1000个元素，那么第1001个元素加入集合时，就要调用1000次equals方法。这显然会大大降低效率。?于是，Java采用了哈希表的原理。 哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。 这样一来，当集合要添加新的元素时，先调用这个元素的HashCode方法，就一下子能定位到它应该放置的物理位置上。 （1）如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了。 （2）如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了。 （3）不相同的话，也就是发生了Hash key相同导致冲突的情况，那么就在这个Hash key的地方产生一个链表，将所有产生相同HashCode的对象放到这个单链表上去，串在一起（很少出现）。 这样一来实际调用equals方法的次数就大大降低了，几乎只需要一两次。 如何理解HashCode的作用： 从Object角度看，JVM每new一个Object，它都会将这个Object丢到一个Hash表中去，这样的话，下次做Object的比较或者取这个对象的时候（读取过程），它会根据对象的HashCode再从Hash表中取这个对象。这样做的目的是提高取对象的效率。若HashCode相同再去调用equal。 HashMap，ConcurrentHashMap与LinkedHashMap的区别ConcurrentHashMap是使用了锁分段技术技术来保证线程安全的，锁分段技术：首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问ConcurrentHashMap 是在每个段（segment）中线程安全的LinkedHashMap维护一个双链表，可以将里面的数据按写入的顺序读出 ConcurrentHashMap应用场景1：ConcurrentHashMap 的应用场景是高并发，但是并不能保证线程安全，而同步的 HashMap 和 HashMap 的是锁住整个容器，而加锁之后 ConcurrentHashMap 不需要锁住整个容器，只需要锁住对应的 Segment 就好了，所以可以保证高并发同步访问，提升了效率。2：可以多线程写。ConcurrentHashMap把HashMap分成若干个Segmenet1.get时，不加锁，先定位到segment然后在找到头结点进行读取操作。而value是volatile变量，所以可以保证在竞争条件时保证读取最新的值，如果读到的value是null，则可能正在修改，那么久调用ReadValueUnderLock函数，加锁保证读到的数据是正确的。 2.Put时会加锁，一律添加到hash链的头部。 3.Remove时也会加锁，由于next是final类型不可改变，所以必须把删除的节点之前的节点都复制一遍。 4.ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对Hash表的不同Segment进行的修改。ConcurrentHashMap的应用场景是高并发，但是并不能保证线程安全，而同步的HashMap和HashTable的是锁住整个容器，而加锁之后ConcurrentHashMap不需要锁住整个容器，只需要锁住对应的segment就好了，所以可以保证高并发同步访问，提升了效率。 HashMap的hashcode的作用hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的。 如果两个对象相同，就是适用于equals(java.lang.Object) 方法，那么这两个对象的hashCode一定要相同。 如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点。 两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。 什么时候需要重写？ 一般的地方不需要重载hashCode，只有当类需要放在HashTable、HashMap、HashSet等等hash结构的集合时才会重载hashCode，那么为什么要重载hashCode呢？ 要比较两个类的内容属性值，是否相同时候，根据hashCode 重写规则，重写类的 指定字段的hashCode()，equals()方法。 Vector和ArrayList的区别 首先看这两类都实现List接口，而List接口一共有三个实现类，分别是 ArrayList、Vector 和 LinkedList 。List 用于存放多个元素，能够维护元素的次序，并且允许元素的重复。3个具体实现类的相关区别如下： 1.ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要将已经有数组的数据复制到新的存储空间中。当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。2.Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢。3.LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用。 ArrayList 与 LinkedList 的区别最明显的区别是 ArrrayList 底层的数据结构是数组，支持随机访问，而 LinkedList 的底层数据结构是链表，不支持随机访问。使用下标访问一个元素，ArrayList 的时间复杂度是 O(1)，而 LinkedList 是 O(n)。1.LinkedList内部存储的是Node，不仅要维护数据域，还要维护prev和next，如果LinkedList中的结点特别多，则LinkedList比ArrayList更占内存。插入删除操作效率：2.LinkedList在做插入和删除操作时，插入或删除头部或尾部时是高效的，操作越靠近中间位置的元素时，需要遍历查找，速度相对慢一些，如果在数据量较大时，每次插入或删除时遍历查找比较费时。所以LinkedList插入与删除，慢在遍历查找，快在只需要更改相关结点的引用地址。ArrayList在做插入和删除操作时，插入或删除尾部时也一样是高效的，操作其他位置，则需要批量移动元素，所以ArrayList插入与删除，快在遍历查找，慢在需要批量移动元素。3.循环遍历效率：由于ArrayList实现了RandomAccess随机访问接口，所以使用for(int i = 0; i &lt; size; i++)遍历会比使用Iterator迭代器来遍历快而由于LinkedList未实现RandomAccess接口，所以推荐使用Iterator迭代器来遍历数据。因此，如果我们需要频繁在列表的中部改变插入或删除元素时，建议使用LinkedList，否则，建议使用ArrayList，因为ArrayList遍历查找元素较快，并且只需存储元素的数据域，不需要额外记录其他数据的位置信息，可以节省内存空间。 Java 中的 LinkedList 是单向链表还是双向链表是双向链表。 String、StringBuffer、StringBuilder之间区别1.三者在执行速度方面的比较：StringBuilder &gt; StringBuffer &gt; String2.在线程方面：StringBuilder是线程非安全的;StringBuffer是线程安全的 3.对于三者的使用：如果要操作少量的数据用 = String；单线程操作字符串缓冲区 下操作大量数据 = StringBuilder；多线程操作字符串缓冲区 下操作大量数据 = StringBuffer； Object 的常用方有哪些clone()、equals()、hashCode()、notify()、notifyAll()、toString()、wait()、finalize() Java序列化的方式(1).Java原生以流的方法进行的序列化 (2).Json序列化 (3).FastJson序列化 (4).Protobuff序列化 传值和传引用的区别，Java是怎么样的，有没有传值引用定义： 传值：传递的是值的副本。方法中对副本的修改，不会影响到调用方 传引用：传递的是引用的副本，共用一个内存，会影响到调用方。此时，形参和实参指向同一个内存地址。对引用副本本身（对象地址）的修改，如设置为null，重新指向其他对象，不会影响到调用方。 总结： 1.基本类型（byte,short,int,long,double,float,char,boolean）为传值 2.对象类型（Object,数组，容器）为传引用 3.String、Integer、Double等immutable类型因为类的变量设为final属性，无法被修改，只能重新赋值或生成对象。当Integer作为方法参数传递时，对其赋值会导致原有的引用被指向了方法内的栈地址，失去原有的的地址指向，所以对赋值后的Integer做任何操作都不会影响原有值。 补充： 值传递和引用传递，属于函数调用时参数的求值策略(Evaluation Strategy)，这是对调用函数时，求值和传值的方式的描述，而非传递的内容的类型（内容指：是值类型还是引用类型，是值还是指针）。值类型/引用类型，是用于区分两种内存分配方式，值类型在调用栈上分配，引用类型在堆上分配。（不要问我引用类型里定义个值类型成员或反之会发生什么，这不在这个本文的讨论范畴内，而且你看完之后，你应该可以自己想明白）。一个描述内存分配方式，一个描述参数求值策略，两者之间无任何依赖或约束关系。 一个ArrayList在循环过程中删除，会不会出问题会，发报出并发修改异常Java.util.ConcurrentModificationException。 错误原因都是ArrayList集合中remove方法底层的源码中有一个fastRemove(index)方法，然后会有一个modCount++的操作，然后在ArratList内部的迭代器中有一个checkForComodification操作，也就是检查modCount是否改变，如果改变了，就抛出并发修改错误。同样的在For each增强for循环中，也是利用了ArrayList自身的Iterator迭代器，也是会出现这样的错误。 对于一般的for遍历，可能并没有删除要修改的数，可以采用倒序删除的写法改正这个错误。对于增强for循环中的遍历，会抛出并发修改异常，使用Iterator自己的remove方法。 要避免这种情况的出现，则在使用迭代器迭代时(显式或for each的隐式)不要使用ArrayList的remove，改用Iterator的remove即可。 @transactional注解在什么情况下会失效1.@Transactional 注解只能应用到 public 可见度的方法上。 如果应用在protected、private或者 package可见度的方法上，也不会报错，不过事务设置不会起作用。 2.默认情况下，Spring会对unchecked异常进行事务回滚；如果是checked异常则不回滚。辣么什么是checked异常，什么是unchecked异常。 3.只读事务：@Transactional(propagation=Propagation.NOT_SUPPORTED,readOnly=true)只读标志只在事务启动时应用，否则即使配置也会被忽略。启动事务会增加线程开销，数据库因共享读取而锁定(具体跟数据库类型和事务隔离级别有关)。通常情况下，仅是读取数据时，不必设置只读事务而增加额外的系统开销。 JVM的内存结构主要分为6个区域： 程序计数器：可看做是当前线程执行的字节码的行号指示器，字节码解释器就是通过改变这个计数器的值来获取下一条需要执行的字节码指令，完成分支、循环、跳转和异常处理等功能。 虚拟机栈：每创建一个线程时，JVM就会为这个线程创建一个对应的栈，所以栈是线程私有的。方法执行的时候还会创建一个栈帧在虚拟机栈上，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。局部变量表所需的空间在编译期间就完成了分配。 本地方法栈：基本同虚拟机栈，只不过本地方法栈是为本地方法服务。 java堆：JVM管理的内存最大的部分，线程共享，用于存放对象实例。java堆可以处于物理上不连续的内存空间上。用-Xms表示堆起始内存大小，-Xmx表示堆最大内存大小。当堆内存大小大于-Xmx时抛出OutOfMemoryError异常。 方法区：存储已被JVM加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。在Hotspot实现中，它位于java堆上。可称为永久代(PermGen)，使用-XX:MaxPermGen参数配置永久代最大内存。 运行时常量池：方法区的一部分。在class文件被JVM加载后，其常量池中的字面量和符号引用将被保存到这里。 补充了解：逃逸分析 常用的对象堆外存储技术需要基于逃逸分析(Escape Analysis)技术实现。其目标就是分析出对象的作用域。比如当一个对象定义在方法体内部时，它的受访范围就在方法体内，jvm会在栈帧中为其分配内存空间。但一旦被外部成员引用后，这个对象就发生了逃逸。 在JDK 6u23后，HotSpot就默认开启了逃逸分析，早期版本可用-XX:+DoEscapeAnalysis参数开启，-XX:+PrintEscapeAnalysis查看。 Mysql 的分页 SQL 语句select * from tablename limit m,n(n是指从第m+1条开始，取n条) Hibernate与MyBatis的异同相同点：Hibernate与MyBatis都可以是通过SessionFactoryBuider由XML配置文件生成SessionFactory，然后由SessionFactory 生成Session，最后由Session来开启执行事务和SQL语句。其中SessionFactoryBuider，SessionFactory，Session的生命周期都是差不多的。Hibernate和MyBatis都支持JDBC和JTA事务处理。Mybatis优势：MyBatis可以进行更为细致的SQL优化，可以减少查询字段。MyBatis容易掌握，而Hibernate门槛较高。Hibernate优势：Hibernate的DAO层开发比MyBatis简单，Mybatis需要维护SQL和结果映射。Hibernate对对象的维护和缓存要比MyBatis好，对增删改查的对象的维护要方便。Hibernate数据库移植性很好，MyBatis的数据库移植性不好，不同的数据库需要写不同SQL。Hibernate有更好的二级缓存机制，可以使用第三方缓存。MyBatis本身提供的缓存机制不佳。 Hibernate与MyBatis在sql优化方面异同Hibernate的查询会将表中的所有字段查询出来，这一点会有性能消耗。Hibernate也可以自己写SQL来指定需要查询的字段，但这样就破坏了Hibernate开发的简洁性。而Mybatis的SQL是手动编写的，所以可以按需求指定查询的字段。Hibernate HQL语句的调优需要将SQL打印出来，而Hibernate的SQL被很多人嫌弃因为太丑了。MyBatis的SQL是自己手动写的所以调整方便。但Hibernate具有自己的日志统计。Mybatis本身不带日志统计，使用Log4j进行日志记录。 Hibernate与MyBatis对象管理对比Hibernate 是完整的对象/关系映射解决方案，它提供了对象状态管理（state management）的功能，使开发者不再需要理会底层数据库系统的细节。也就是说，相对于常见的 JDBC/SQL 持久层方案中需要管理 SQL 语句，Hibernate采用了更自然的面向对象的视角来持久化 Java 应用中的数据。换句话说，使用 Hibernate 的开发者应该总是关注对象的状态（state），不必考虑 SQL 语句的执行。这部分细节已经由 Hibernate 掌管妥当，只有开发者在进行系统性能调优的时候才需要进行了解。而MyBatis在这一块没有文档说明，用户需要对对象自己进行详细的管理。 Jsp九大内置对象1.Request: request对象主要用于客户端请求处理2.Response: response对象提供了多个方法用来处理HTTP响应，可以调用response中的方法修改ContentType中的MIME类型以及实现页面的跳转等等，3.Page: page对象有点类似于Java编程中的this指针，就是指当前JSP页面本身。page是java.lang.Object类的对象。4.Session: session是与请求有关的会话期，它是java.servlet.http.HttpSession类的对象，用来表示和存储当前页面的请求信息。5.Application: application是javax.servlet.ServletContext类对象的一个实例，用于实现用户之间的数据共享6.Out:7.Exception: exception内置对象是用来处理页面出现的异常错误8.Config: config内置对象是ServletConfig类的一个实例。在Servlet初始化的时候，JSP引擎通过config向它传递信息。这种信息可以是属性名/值匹配的参数，也可以是通过ServletContext对象传递的服务器的有关信息。9.pageContext: pageContext对象是一个比较特殊的对象。它相当于页面中所有其他对象功能的最大集成者，即使用它可以访问到本页面中所有其他对象 Comparator 与 Comparable 有什么不同Comparable 接口用于定义对象的自然顺序，而 comparator 通常用于定义用户定制的顺序。Comparable 总是只有一个，但是可以有多个 comparator 来定义对象的顺序。 Collection 和 Collections的区别Collection是集合类的上级接口，继承与他的接口主要有Set 和List.Collections是针对集合类的一个帮助类，他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。 String s = new String(“xyz”);创建了几个String Object两个对象，一个是“xyx”,一个是指向“xyx”的引用对象s。 线程同步的方法wait():使一个线程处于等待状态，并且释放所持有的对象的lock。sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。Allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。 Volatile和Synchronized四个不同点 粒度不同，前者锁对象和类，后者针对变量 syn阻塞，volatile线程不阻塞 syn保证三大特性，volatile不保证原子性 syn编译器优化，volatile不优化volatile具备两种特性：保证此变量对所有线程的可见性，指一条线程修改了这个变量的值，新值对于其他线程来说是可见的，但并不是多线程安全的。禁止指令重排序优化。Volatile如何保证内存可见性:1.当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。2.当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。同步：就是一个任务的完成需要依赖另外一个任务，只有等待被依赖的任务完成后，依赖任务才能完成。异步：不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，只要自己任务完成了就算完成了，被依赖的任务是否完成会通知回来。（异步的特点就是通知）。打电话和发短信来比喻同步和异步操作。阻塞：CPU停下来等一个慢的操作完成以后，才会接着完成其他的工作。非阻塞：非阻塞就是在这个慢的执行时，CPU去做其他工作，等这个慢的完成后，CPU才会接着完成后续的操作。非阻塞会造成线程切换增加，增加CPU的使用时间能不能补偿系统的切换成本需要考虑。 SpringMVC运行原理 客户端请求提交到DispatcherServlet 由DispatcherServlet控制器查询HandlerMapping，找到并分发到指定的Controller中。 Controller调用业务逻辑处理后，返回ModelAndView DispatcherServlet查询一个或多个ViewResoler视图解析器，找到ModelAndView指定的视图 视图负责将结果显示到客户端 SpringMVC与Struts2区别与比较总结1、Struts2是类级别的拦截， 一个类对应一个request上下文，SpringMVC是方法级别的拦截，一个方法对应一个request上下文，而方法同时又跟一个url对应,所以说从架构本身上SpringMVC就容易实现restful url,而struts2的架构实现起来要费劲，因为Struts2中Action的一个方法可以对应一个url，而其类属性却被所有方法共享，这也就无法用注解或其他方式标识其所属方法了。 2、由上边原因，SpringMVC的方法之间基本上独立的，独享request response数据，请求数据通过参数获取，处理结果通过ModelMap交回给框架，方法之间不共享变量，而Struts2搞的就比较乱，虽然方法之间也是独立的，但其所有Action变量是共享的，这不会影响程序运行，却给我们编码 读程序时带来麻烦，每次来了请求就创建一个Action，一个Action对象对应一个request上下文。3、由于Struts2需要针对每个request进行封装，把request，session等servlet生命周期的变量封装成一个一个Map，供给每个Action使用，并保证线程安全，所以在原则上，是比较耗费内存的。 4、 拦截器实现机制上，Struts2有以自己的interceptor机制，SpringMVC用的是独立的AOP方式，这样导致Struts2的配置文件量还是比SpringMVC大。 5、SpringMVC的入口是servlet，而Struts2是filter（这里要指出，filter和servlet是不同的。以前认为filter是servlet的一种特殊），这就导致了二者的机制不同，这里就牵涉到servlet和filter的区别了。 6、SpringMVC集成了Ajax，使用非常方便，只需一个注解@ResponseBody就可以实现，然后直接返回响应文本即可，而Struts2拦截器集成了Ajax，在Action中处理时一般必须安装插件或者自己写代码集成进去，使用起来也相对不方便。 7、SpringMVC验证支持JSR303，处理起来相对更加灵活方便，而Struts2验证比较繁琐，感觉太烦乱。 8、Spring MVC和Spring是无缝的。从这个项目的管理和安全上也比Struts2高（当然Struts2也可以通过不同的目录结构和相关配置做到SpringMVC一样的效果，但是需要xml配置的地方不少）。 9、 设计思想上，Struts2更加符合OOP的编程思想， SpringMVC就比较谨慎，在servlet上扩展。 10、SpringMVC开发效率和性能高于Struts2。11、SpringMVC可以认为已经100%零配置。 简单总结springMVC和struts2的区别 springmvc的入口是一个servlet即前端控制器，而struts2入口是一个filter过虑器。 springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，可以设计为单例或多例(建议单例)，struts2是基于类开发，传递参数是通过类的属性，只能设计为多例。 Struts采用值栈存储请求和响应的数据，通过OGNL存取数据， springmvc通过参数解析器是将request请求内容解析，并给方法形参赋值，将数据和视图封装成ModelAndView对象，最后又将ModelAndView中的模型数据通过reques域传输到页面。Jsp视图解析器默认使用jstl。 SpringMvc怎么和AJAX相互调用的通过Jackson框架就可以把Java里面的对象直接转化成Js可以识别的Json对象具体步骤如下1.加入Jackson.jar2.在配置文件中配置json的映射3.在接受Ajax方法里面可以直接返回Object,List等,但方法前面要加上@ResponseBody注解 Spring有哪些优点1.轻量级：Spring在大小和透明性方面绝对属于轻量级的，基础版本的Spring框架大约只有2MB。2.控制反转(IOC)：Spring使用控制反转技术实现了松耦合。依赖被注入到对象，而不是创建或寻找依赖对象。3.面向切面编程(AOP)： Spring支持面向切面编程，同时把应用的业务逻辑与系统的服务分离开来。4.容器：Spring包含并管理应用程序对象的配置及生命周期。5.MVC框架：Spring的web框架是一个设计优良的web MVC框架，很好的取代了一些web框架。6.事务管理：Spring对下至本地业务上至全局业务(JAT)提供了统一的事务管理接口。7.异常处理：Spring提供一个方便的API将特定技术的异常(由JDBC, Hibernate, 或JDO抛出)转化为一致的、Unchecked异常。 spring 主要使用了哪些 ，IOC和AOP实现原理是什么spring主要功能有IOC，AOP，MVC等，IOC实现原理：先反射生成实例，然后调用时主动注入。AOP原理：主要使用java动态代理。 解释AOP模块AOP(Aspect Oriented Programming) 面向切面编程，是目前软件开发中的一个热点，是Spring框架内容，利用AOP可以对业务逻辑的各个部分隔离，从而使的业务逻辑各部分的耦合性降低，提高程序的可重用性，踢开开发效率，主要功能：日志记录，性能统计，安全控制，事务处理，异常处理等。 AOP实现原理是java动态代理，但是jdk的动态代理必须实现接口，所以spring的aop是用cglib这个库实现的，cglis使用里asm这个直接操纵字节码的框架，所以可以做到不使用接口的情况下实现动态代理。 AOP与OOP的区别OOP面向对象编程，针对业务处理过程的实体及其属性和行为进行抽象封装，以获得更加清晰高效的逻辑单元划分。而AOP则是针对业务处理过程中的切面进行提取，它所面对的是处理过程的某个步骤或阶段，以获得逻辑过程的中各部分之间低耦合的隔离效果。这两种设计思想在目标上有着本质的差异。 举例： 对于“雇员”这样一个业务实体进行封装，自然是OOP的任务，我们可以建立一个“Employee”类，并将“雇员”相关的属性和行为封装其中。而用AOP 设计思想对“雇员”进行封装则无从谈起。 同样，对于“权限检查”这一动作片段进行划分，则是AOP的目标领域。 OOP面向名次领域，AOP面向动词领域。 总之AOP可以通过预编译方式和运行期动态代理实现在不修改源码的情况下，给程序动态同意添加功能的一项技术。 IoC容器是什么其优点Spring IOC负责创建对象、管理对象(通过依赖注入)、整合对象、配置对象以及管理这些对象的生命周期。优点:IOC或依赖注入减少了应用程序的代码量。它使得应用程序的测试很简单，因为在单元测试中不再需要单例或JNDI查找机制。简单的实现以及较少的干扰机制使得松耦合得以实现。IOC容器支持勤性单例及延迟加载服务。 Spring 的依赖注入方式有哪一些Spring 的依赖注入可以有两种方式来完成:setter 方法注入和构造方法注入。构造器依赖注入：构造器依赖注入在容器触发构造器的时候完成，该构造器有一系列的参数，每个参数代表注入的对象。Setter方法依赖注入：首先容器会触发一个无参构造函数或无参静态工厂方法实例化对象，之后容器调用bean中的setter方法完成Setter方法依赖注入。 Spring支持的事务管理类型Spring支持如下两种方式的事务管理：编程式事务管理：这意味着你可以通过编程的方式管理事务，这种方式带来了很大的灵活性，但很难维护。声明式事务管理：这种方式意味着你可以将事务管理和业务代码分离。你只需要通过注解或者XML配置管理事务。 ThreadLocal(线程变量副本)Synchronized实现内存共享，ThreadLocal为每个线程维护一个本地变量。 采用空间换时间，它用于线程间的数据隔离，为每一个使用该变量的线程提供一个副本，每个线程都可以独立地改变自己的副本，而不会和其他线程的副本冲突。 ThreadLocal类中维护一个Map，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值为对应线程的变量副本。 ThreadLocal在Spring中发挥着巨大的作用，在管理Request作用域中的Bean、事务管理、任务调度、AOP等模块都出现了它的身影。 Spring中绝大部分Bean都可以声明成Singleton作用域，采用ThreadLocal进行封装，因此有状态的Bean就能够以singleton的方式在多线程中正常工作了。 throw 和 throws 的区别throw 用于抛出 java.lang.Throwable 类的一个实例化对象，意思是说你可以通过关键字 throw 抛出一个 Error 或者 一个Exception，如： throw new IllegalArgumentException(“size must be multiple of 2″) 而throws 的作用是作为方法声明和签名的一部分，方法被抛出相应的异常以便调用者能处理。Java 中，任何未处理的受检查异常强制在 throws 子句中声明。 final关键字的作用final class 表示此类不允许有子类。final virable 表示一个常量。final method 表示一个方法不能被重写 static关键字有哪些作用static 修饰变量、修饰方法;静态块;静态内部类;静态导包; String是最基本的数据类型吗基本数据类型包括byte、int、char、long、float、double、boolean和short。java.lang.String类是final类型的，因此不可以继承这个类、不能修改这个类。为了提高效率节省空间，我们应该用StringBuffer类。 synchronized和java.util.concurrent.locks.Lock的异同主要相同点:Lock 能完成 synchronized 所实现的所有功能.主要不同点:Lock 有比 synchronized 更精确的线程语义和更好的性能(在相同点中回答此点也行)synchronized 会自动释放锁. 而 Lock 一定要求程序员手工释放.并且必须在 finally 从句中释放,如果没有答出在 finally 中释放不得分.就如 Connection 没有在 finally 中关闭一样.连最基本的资源释放都做不好,还谈什么多线程编程. spring的事务有几种它的隔离级别和传播行为声明式事务和编程式事务隔离级别： DEFAULT使用数据库默认的隔离级别 READ_UNCOMMITTED会出现脏读，不可重复读和幻影读问题 READ_COMMITTED会出现重复读和幻影读 REPEATABLE_READ会出现幻影读 SERIALIZABLE最安全，但是代价最大，性能影响极其严重和传播行： REQUIRED存在事务就融入该事务，不存在就创建事务 SUPPORTS存在事务就融入事务，不存在则不创建事务 MANDATORY存在事务则融入该事务，不存在，抛异常 REQUIRES_NEW总是创建新事务 NOT_SUPPORTED存在事务则挂起，一直执行非事务操作 NEVER总是执行非事务，如果当前存在事务则抛异常 NESTED嵌入式事务 sleep() 和 wait() 有什么区别最大区别是等待时wait会释放锁，而sleep会一直持有锁，wait通常用于线程时交互，sleep通常被用于暂停执行。 sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，给执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 多线程和同步有几种实现方法多线程有两种实现方法，分别是继承Thread类与实现Runnable接口同步的实现方面有两种，分别是synchronized,wait与notify 启动一个线程是用run()还是start()启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM调度并执行。这并不意味着线程就会立即运行。run()方法可以产生必须退出的标志来停止一个线程。 final,finally,finalize的区别final—修饰符（关键字）如果一个类被声明为final，意味着它不能再派生出新的子类，不能作为父类被继承。因此一个类不能既被声明为 abstract的，又被声明为final的。将变量或方法声明为final，可以保证它们在使用中不被改变。被声明为final的变量必须在声明时给定初值，而在以后的引用中只能读取，不可修改。被声明为final的方法也同样只能使用，不能重载。 finally—再异常处理时提供 finally 块来执行任何清除操作。如果抛出一个异常，那么相匹配的 catch 子句就会执行，然后控制就会进入 finally 块（如果有的话）。 finalize—方法名。Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的。它是在 Object 类中定义的，因此所有的类都继承了它。子类覆盖 finalize() 方法以整理系统资源或者执行其他清理工作。finalize() 方法是在垃圾收集器删除对象之前对这个对象调用的。 abstract class和interface有什么区别抽象类与接口的区别：1.接口可以多重继承 ，抽象类不可以2.接口定义方法，不给实现；而抽象类可以实现部分方法3.接口中基本数据类型的数据成员，都默认为static和final，抽象类则不是如果事先知道某种东西会成为基础类，那么第一个选择就是把它变成一个接口。只有在必须使用方法定义或者成员变量的时候，才应考虑采用抽象类。 Set里的元素不能重复，用==还是equals ()判断Set里的元素是不能重复的，那么用iterator()方法来区分重复与否。equals()是判读两个Set是否相等。equals()和==方法决定引用值是否指向同一对象equals()在类中被覆盖，为的是当两个分离的对象的内容和类型相配的话，返回真值。 struts 框架是如何体现MVC模式struts 框架为开发者提供了MVC 的3个逻辑组成部分，主要由ActionServlet、Action和strust-config.xml配置文件组成控制层，由ActionForm 来承担模型层的功能，而struts 下的视图由JSP来完成。处理请求：由ActionServlet接收请求，然后根据 struts-config.xml 中的配置，类判断由于哪个Action来处理请求和由哪个ActionForm来保存数据，在通过Action的返回值来判断应该由哪个JSP来负责页面的展示，最后由 JSP 来完成结果响应。 Hibernate 的实体存在哪几种状态Hibernate 中的实体在它的生命周期里面，存在 3 中状态。瞬时：new语句创建的实体类对象是就是瞬时状态，它一般没有id。持久：存放在 Session 中的实体对象就属于持久状态，一般通过 save() 或 saveOrUpdate()等等，方法转换而来。托管：实体中Session中脱离出来的时候，它的状态就属于托管状态了，尽管它具有 id 值，但已经不存在Session 中了，即使 实体中的数据发生变化也不能同步到数据库中。通过 close()、evict()等方法转化而来。 Hibernate 的get()和load()的区别Hibernate 对于 load() 方法该方法认为数据一定存在于数据，可以放心的代理来延迟加载，如果在使用过程中发现了问题，只能抛出异常，而get()方法可以不存在。 为什么wait和notify方法要在同步块中调用主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。 线程有几种状态在Java当中，线程通常都有五种状态，创建、就绪、运行、阻塞和死亡。 第一是创建状态。在生成线程对象，并没有调用该对象的start方法，这是线程处于创建状态； 第二是就绪状态。当调用了线程对象的start方法之后，该线程就进入了就绪状态，但是此时线程调度程序还没有把该线程设置为当前线程，此时处于就绪状态。在线程运行之后，从等待或者睡眠中回来之后，也会处于就绪状态 第三是运行状态。线程调度程序将处于就绪状态的线程设置为当前线程，此时线程就进入了运行状态，开始运行run函数当中的代码。 第四是阻塞状态。线程正在运行的时候，被暂停，通常是为了等待某个时间的发生（比如说某项资源就绪）之后再继续运行。sleep,suspend等方法都可以导致线程阻塞。 第五是死亡状态。如果一个线程的run方法执行结束，该线程就会死亡。对于已经死亡的线程，无法再使用start方法令其进入就绪状态。 有A、B、C线程，A线程输出A, B线程输出B, C线程输出C要求, 同时启动线程, 按顺序输出ABC主要通过join方法来实现顺序输出ABC。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package thread; public class TestThread1 &#123; public static void main(String[] args) &#123; // 线程A final Thread a = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("A"); &#125; &#125;); // 线程B final Thread b = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; // 执行b线程之前，加入a线程,让a线程执行 a.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("B"); &#125; &#125;); // 线程C final Thread c = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; // 执行c线程之前，加入b线程,让b线程执行 b.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("C"); &#125; &#125;); // 线程D Thread d = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; // 执行d线程之前，加入c线程,让c线程执行 c.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("D"); &#125; &#125;); // 启动四个线程 a.start(); b.start(); c.start(); d.start(); &#125; &#125; 什么是ThreadLocal变量ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。线程局部变量的另一个不错的例子是ThreadLocalRandom类，它在多线程环境中减少了创建代价高昂的Random对象的个数。 从使用场景的角度出发来介绍对ReentrantLock的使用，相对来说容易理解一些。 可重入锁的用处及实现原理场景1：如果已加锁，则不再重复加锁 a、忽略重复加锁。b、用在界面交互时点击执行较长时间请求操作时，防止多次点击导致后台重复执行（忽略重复触发）。 以上两种情况多用于进行非重要任务防止重复执行，（如：清除无用临时文件，检查某些资源的可用性，数据备份操作等） 1234567if (lock.tryLock()) &#123; //如果已经被lock，则立即返回false不会等待，达到忽略操作的效果 try &#123; //操作 &#125; finally &#123; lock.unlock(); &#125;&#125; 场景2：如果发现该操作已经在执行，则尝试等待一段时间，等待超时则不执行（尝试等待执行） 这种其实属于场景2的改进，等待获得锁的操作有一个时间的限制，如果超时则放弃执行。用来防止由于资源处理不当长时间占用导致死锁情况（大家都在等待资源，导致线程队列溢出）。 1234567891011try &#123; if (lock.tryLock(5, TimeUnit.SECONDS)) &#123; //如果已经被lock，尝试等待5s，看是否可以获得锁，如果5s后仍然无法获得锁则返回false继续执行 try &#123; //操作 &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; catch (InterruptedException e) &#123; e.printStackTrace(); //当前线程被中断时(interrupt)，会抛InterruptedException &#125; 场景3：如果发现该操作已经加锁，则等待一个一个加锁（同步执行，类似synchronized） 这种比较常见大家也都在用，主要是防止资源使用冲突，保证同一时间内只有一个操作可以使用该资源。但与synchronized的明显区别是性能优势（伴随jvm的优化这个差距在减小）。同时Lock有更灵活的锁定方式，公平锁与不公平锁，而synchronized永远是公平的。 这种情况主要用于对资源的争抢（如：文件操作，同步消息发送，有状态的操作等） ReentrantLock默认情况下为不公平锁 12private ReentrantLock lock = new ReentrantLock(); //参数默认false，不公平锁private ReentrantLock lock = new ReentrantLock(true); //公平锁 123456try &#123; lock.lock(); //如果被其它资源锁定，会在此等待锁释放，达到暂停的效果 //操作&#125; finally &#123; lock.unlock();&#125; 不公平锁与公平锁的区别： 公平情况下，操作会排一个队按顺序执行，来保证执行顺序。（会消耗更多的时间来排队）不公平情况下，是无序状态允许插队，jvm会自动计算如何处理更快速来调度插队。（如果不关心顺序，这个速度会更快） 场景4：可中断锁 synchronized与Lock在默认情况下是不会响应中断(interrupt)操作，会继续执行完。lockInterruptibly()提供了可中断锁来解决此问题。（场景3的另一种改进，没有超时，只能等待中断或执行完毕） 这种情况主要用于取消某些操作对资源的占用。如：（取消正在同步运行的操作，来防止不正常操作长时间占用造成的阻塞） 12345678try &#123; lock.lockInterruptibly(); //操作&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; finally &#123; lock.unlock();&#125; 可重入概念:若一个程序或子程序可以“安全的被并行执行(Parallel computing)”，则称其为可重入（reentrant或re-entrant）的。即当该子程序正在运行时，可以再次进入并执行它（并行执行时，个别的执行结果，都符合设计时的预期）。可重入概念是在单线程操作系统的时代提出的。 如何避免死锁Java多线程中的死锁死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件：互斥条件：一个资源每次只能被一个进程使用。请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。 Java中活锁和死锁有什么区别这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主要区别是前者进程的状态可以改变但是却不能继续执行。 怎么检测一个线程是否拥有锁我一直不知道我们竟然可以检测一个线程是否拥有锁，直到我参加了一次电话面试。在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。 Maven有哪些优点优点如下：简化了项目依赖管理：易于上手，对于新手可能一个”mvn clean package”命令就可能满足他的工作便于与持续集成工具（jenkins）整合便于项目升级，无论是项目本身升级还是项目使用的依赖升级。有助于多模块项目的开发，一个模块开发好后，发布到仓库，依赖该模块时可以直接从仓库更新，而不用自己去编译。maven有很多插件，便于功能扩展，比如生产站点，自动发布版本等 Maven常见的依赖范围有哪些1.compile:编译依赖，默认的依赖方式，在编译（编译项目和编译测试用例），运行测试用例，运行（项目实际运行）三个阶段都有效，典型地有spring-core等jar。2.test:测试依赖，只在编译测试用例和运行测试用例有效，典型地有JUnit。provided:对于编译和测试有效，不会打包进发布包中，典型的例子为servlet-api,一般的web工程运行时都使用容器的servlet-api。3.runtime:只在运行测试用例和实际运行时有效，典型地是jdbc驱动jar包。4.system: 不从maven仓库获取该jar,而是通过systemPath指定该jar的路径。5.import: 用于一个dependencyManagement对另一个dependencyManagement的继承。 使用“Mvn Clean Package”进行项目打包,其过程执行了哪些动作在这个命令中我们调用了maven的clean周期的clean阶段绑定的插件任务，以及default周期的package阶段绑定的插件任务默认执行的任务有（maven的术语叫goal, 也有人翻译成目标，我这里用任务啦）： maven-clean-plugin:clean-&gt;maven-resources-plugin:resources-&gt;maven-compile-plugin:compile-&gt;mavne-resources-plugin:testResources-&gt;maven-compile-plugin:testCompile-&gt;maven-jar-plugin:jar Maven 多模块如何聚合配置一个打包类型为pom的聚合模块，然后在该pom中使用元素声明要聚合的模块 缓存框架memcache和redis的区别？项目中，怎么去选择？ehcache,memcache和redis等。 区别： Redis和Memcache都是将数据存放在内存中，都是内存数据库。不过memcache还可用于缓存其他东西，例如图片、视频等等。 Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，hash等数据结构的存储。 虚拟内存–Redis当物理内存用完时，可以将一些很久没用到的value 交换到磁盘。 过期策略–memcache在set时就指定，例如set key1 0 0 8,即永不过期。Redis可以通 过例如expire 设定，例如expire name 10。 分布式–设定memcache集群，利用magent做一主多从;redis可以做一主多从。都 可以一主一从。 存储数据安全–memcache挂掉后，数据没了；redis可以定期保存到磁盘（持久化）。 灾难恢复–memcache挂掉后，数据不可恢复; redis数据丢失后可以通过aof恢复。 Redis支持数据的备份，即master-slave模式的数据备份。 java的原子类，实现原理是什么采用硬件提供原子操作指令实现的，即CAS。每次调用都会先判断预期的值是否符合，才进行写操作，保证数据安全。 数据库性能优化有哪些方法使用explain进行优化，查看sql是否充分使用索引。避免使用in,用exist替代，字段值尽可能使用更小的值，任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。使用连接查询(join)代替子查询。 在表的多列字段上建立一个索引，但只有在查询这些字段的第一个字段时，索引才会被使用。 HTTP请求方法get和post有什么区别 Post传输数据时，不需要在URL中显示出来，而Get方法要在URL中显示。 Post传输的数据量大，可以达到2M，而Get方法由于受到URL长度限制,只能传递大约1024字节. Post就是为了将数据传送到服务器段,Get就是为了从服务器段取得数据.而Get之所以也能传送数据,只是用来设计告诉服务器,你到底需要什么样的数据.Post的信息作为http请求的内容，而Get是在Http头部传输的。 其他 HTTP 请求方法 HEAD 与 GET 相同，但只返回 HTTP 报头，不返回文档主体。 PUT上传指定的 URI 表示。 DELETE 删除指定资源。 OPTIONS 返回服务器支持的 HTTP 方法 CONNECT 把请求连接转换到透明的 TCP/IP 通道。 linux命令，查看某个线程，整个机器负载和文件内容快速查找的命令查看线程：ps -ef|greptomcat 查看负载：top 文件内容查找：vi /aa test.txt 或者先打开文件，再查找: vi test.txt /aa JVM内存的模型，垃圾回收的机制，如何对JVM进行调优由栈和堆组成，栈是运行时单位，堆内存则分为年轻代、年老代、持久代等，年轻代中的对象经过几次的回收，仍然存在则被移到年老代；持久代主要是保存class,method,filed等对象。 sun回收机制：主要对年轻代和年老代中的存活对象进行回收，分为以下： 年轻代串行（Serial Copying）、年轻代并行（ParNew）、年老代串行（SerialMSC），年老代并行（Parallel Mark Sweep），年老代并发（Concurrent Mark-Sweep GC，即CMS）等等,目前CMS回收算法使用最广泛。 JVM调优主要是对堆内容和回收算法进行配置，需要对jdk产生的回收日志进行观察，同时通过工具（Jconsole，jProfile，VisualVM）对堆内存不断分析，这些优化是一个过程，需要不断地进行观察和维护。 高并发时，又如何保证性能和数据正确如果是单机内完成这些操作，那使用数据库的事务，即可轻松实现。 分布式事务如何实现分布式事务可以采用分布式锁进行实现，目前zookeeper就提供此锁；分布式锁需要牺牲一定性能去实现，若业务支付最终一致性，那此方法是最佳方案。如在京东下订单，过一会才会告诉你订单审核通过，而不是马上响应订单结果。 抽象类和接口的区别，项目中如何使用它们 相同点： 两者都是抽象类，都不能实例化。 interface实现类及abstractclass的子类都必须要实现已经声明的抽象方法。 不同点： interface需要实现，要用implements，而abstractclass需要继承，要用extends。 一个类可以实现多个interface，但一个类只能继承一个abstractclass。 interface强调特定功能的实现，而abstractclass强调所属关系。 尽管interface实现类及abstrctclass的子类都必须要实现相应的抽象方法，但实现的形式不同。interface中的每一个方法都是抽象方法，都只是声明的 (declaration, 没有方法体)，实现类必须要实现。而abstractclass的子类可以有选择地实现。 使用： abstract：在既需要统一的接口，又需要实例变量或缺省的方法的情况下，使用abstract; ​ interface：类与类之前需要特定的接口进行协调，而不在乎其如何实现。 作为能够实现特定功能的标识存在，也可以是什么接口方法都没有的纯粹标识。需要将一组类视为单一的类，而调用者只通过接口来与这组类发生联系。需要实现特定的多项功能，而这些功能之间可能完全没有任何联系。 TCP通讯有几次握手，有使用过哪些socket框架​ 3次握手，客户端–&gt;服务端，服务端–&gt;客户端，客户端–&gt;服务端，当这些过程完成之后，才真正建立起通信。java中比较有名的socket框架有：mina,netty,都是韩国小棒子写的。 反射的作用与原理反射概念：Java 反射是可以让我们在运行时，通过一个类的Class对象来获取它获取类的方法、属性、父类、接口等类的内部信息的机制。这种动态获取信息以及动态调用对象的方法的功能称为JAVA的反射。 作用：在任意一个方法里， 1.如果我知道一个类的名称/或者它的一个实例对象， 我就能把这个类的所有方法和变量的信息找出来(方法名，变量名，方法，修饰符，类型，方法参数等等所有信息) 2.如果我还明确知道这个类里某个变量的名称，我还能得到这个变量当前的值。 3.当然，如果我明确知道这个类里的某个方法名+参数个数类型，我还能通过传递参数来运行那个类里的那个方法。 反射机制主要提供了以下功能： 在运行时判断任意一个对象所属的类。 在运行时构造任意一个类的对象。 在运行时判断任意一个类所具有的成员变量和方法。 在运行时调用任意一个对象的方法。 生成动态代理。 反射的原理：JAVA语言编译之后会生成一个.class文件，反射就是通过字节码文件找到某一个类、类中的方法以及属性等。 反射的实现API：反射的实现主要借助以下四个类： 1234Class：类的对象Constructor：类的构造方法Field：类中的属性对象Method：类中的方法对象 java反射机制，反射生成类，可否访问私有变量即动态生成java的实例，可以。 Java反射机制是一个非常强大的功能，在很多的项目比如Spring，Mybatis都都可以看到反射的身影。通过反射机制，我们可以在运行期间获取对象的类型信息。利用这一点我们可以实现工厂模式和代理模式等设计模式，同时也可以解决java泛型擦除等令人苦恼的问题。 获取一个对象对应的反射类，在Java中有三种方法可以获取一个对象的反射类， 通过getClass()方法 通过Class.forName()方法 使用类.class 通过类加载器实现，getClassLoader() RPC是什么，有使用过哪些RPC框架​ 远程进程调用，本地机器调用远程的服务，在项目规模大到一定程度，需要使用RPC相关框架进行服务化部署。如：hessian 、webservice等 jquery如何绑定页面某元素的点击事件​ $(“#btn”).click(function(){ …. }) volatile实现原理volatile如何保证可见性和禁止指令重排序的： 观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令，lock前缀指令实际上相当于一个 内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它 确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会 强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。 session 与 cookie 区别 cookie数据存放在客户的浏览器上，session数据放在服务器上。 cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗考虑到安全应当使用session。 session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能考虑到减轻服务器性能方面，应当使用COOKIE。 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 所以个人建议： 将登陆信息等重要信息存放为SESSION 其他信息如果需要保留，可以放在COOKIE中 session 分布式处理第一种：粘性session 粘性Session是指将用户锁定到某一个服务器上，比如上面说的例子，用户第一次请求时，负载均衡器将用户的请求转发到了A服务器上，如果负载均衡器设置了粘性Session的话，那么用户以后的每次请求都会转发到A服务器上，相当于把用户和A服务器粘到了一块，这就是粘性Session机制。 第二种：服务器session复制 原理：任何一个服务器上的session发生改变（增删改），该节点会把这个 session的所有内容序列化，然后广播给所有其它节点，不管其他服务器需不需要session，以此来保证Session同步。 第三种：session共享机制 使用分布式缓存方案比如memcached、Redis，但是要求Memcached或Redis必须是集群。 原理：不同的 tomcat指定访问不同的主memcached。多个Memcached之间信息是同步的，能主从备份和高可用。用户访问时首先在tomcat中创建session，然后将session复制一份放到它对应的memcahed上 第四种：session持久化到数据库 原理：就不用多说了吧，拿出一个数据库，专门用来存储session信息。保证session的持久化。 优点：服务器出现问题，session不会丢失 缺点：如果网站的访问量很大，把session存储到数据库中，会对数据库造成很大压力，还需要增加额外的开销维护数据库。 第五种terracotta实现session复制 原理：就不用多说了吧，拿出一个数据库，专门用来存储session信息。保证session的持久化。 优点：服务器出现问题，session不会丢失 缺点：如果网站的访问量很大，把session存储到数据库中，会对数据库造成很大压力，还需要增加额外的开销维护数据库。 说说自定义注解的场景及实现跟踪代码的依赖性，实现代替配置文件的功能。比较常见的是Spring等框架中的基于注解配置。 还可以生成文档常见的@See@param@return等。如@override放在方法签名，如果这个方法 并不是覆盖了超类方法，则编译时就能检查出。 使用@interface自定义注解时，自动继承了java.lang.annotation.Annotation接口，由编译程序自动完成其他细节，在定义注解时，不能继承其他注解或接口。 HashSet 和 HashMap 区别 HashSet： HashSet实现了Set接口，它不允许集合中出现重复元素。当我们提到HashSet时，第一件事就是在将对象存储在 HashSet之前，要确保重写hashCode（）方法和equals（）方法，这样才能比较对象的值是否相等，确保集合中没有储存相同的对象。如果不重写上述两个方法，那么将使用下面方法默认实现： public boolean add(Object obj)方法用在Set添加元素时，如果元素值重复时返回 “false”，如果添加成功则返回”true” HashMap： HashMap实现了Map接口，Map接口对键值对进行映射。Map中不允许出现重复的键（Key）。Map接口有两个基本的实现TreeMap和HashMap。TreeMap保存了对象的排列次序，而HashMap不能。HashMap可以有空的键值对（Key（null）-Value（null））HashMap是非线程安全的（非Synchronize），要想实现线程安全，那么需要调用collections类的静态方法synchronizeMap（）实现。 public Object put(Object Key,Object value)方法用来将元素添加到map中。 总结： HashMap 实现了 Map 接口；存储键值对；调用put（）向map中添加元素；HashMap使用键（Key）计算Hashcode；HashMap相对于HashSet较快，因为它是使用唯一的键获取对象。 HashSet 实现了 Set 接口；仅存储对象；调用add（）方法向Set中添加元素；HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false；HashSet较HashMap来说比较慢。 HashMap 的工作原理及代码实现 HashMap是基于哈希表的Map接口的非同步实现，允许使用null值和null键，但不保证映射的顺序。 底层使用数组实现，数组中每一项是个单向链表，即数组和链表的结合体；当链表长度大于一定阈值时，链表转换为红黑树，这样减少链表查询时间。 HashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Node对象。HashMap底层采用一个Node[]数组来保存所有的key-value对，当需要存储一个Node对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Node时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Node。 HashMap进行数组扩容需要重新计算扩容后每个元素在数组中的位置，很耗性能 采用了Fail-Fast机制，通过一个modCount值记录修改次数，对HashMap内容的修改都将增加这个值。迭代器初始化过程中会将这个值赋给迭代器的expectedModCount，在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map，马上抛出异常 ConcurrentHashMap 的工作原理及代码实现 ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。 它使用了多个锁来控制对hash表的不同段进行的修改，每个段其实就是一个小的hashtable，它们有自己的锁。只要多个并发发生在不同的段上，它们就可以并发进行。 ConcurrentHashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 与HashMap不同的是，ConcurrentHashMap使用多个子Hash表，也就是段(Segment) ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。如果使用传统的技术，如HashMap中的实现，如果允许可以在hash链的中间添加或删除元素，读操作不加锁将得到不一致的数据。ConcurrentHashMap实现技术是保证HashEntry几乎是不可变的。 ConcurrentHashMap能完全替代HashTable吗HashTable虽然性能上不如ConcurrentHashMap，但并不能完全被取代，两者的迭代器的一致性不同的，HashTable的迭代器是强一致性的，而ConcurrentHashMap是弱一致的。ConcurrentHashMap的get，clear，iterator 都是弱一致性的。 Doug Lea 也将这个判断留给用户自己决定是否使用ConcurrentHashMap。 什么是强一致性和弱一致性get方法是弱一致的，是什么含义？可能你期望往ConcurrentHashMap底层数据结构中加入一个元素后，立马能对get可见，但ConcurrentHashMap并不能如你所愿。换句话说，put操作将一个元素加入到底层数据结构后，get可能在某段时间内还看不到这个元素，若不考虑内存模型，单从代码逻辑上来看，却是应该可以看得到的。 下面将结合代码和java内存模型相关内容来分析下put/get方法。put方法我们只需关注Segment#put，get方法只需关注Segment#get，在继续之前，先要说明一下Segment里有两个volatile变量：count和table；HashEntry里有一个volatile变量：value。 总结：ConcurrentHashMap的弱一致性主要是为了提升效率，是一致性与效率之间的一种权衡。要成为强一致性，就得到处使用锁，甚至是全局锁，这就与Hashtable和同步的HashMap一样了。 ThreadLocal 原理分析ThreadLocal 为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。当使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。 每个线程中都保有一个 ThreadLocalMap 的成员变量，ThreadLocalMap 内部采用 WeakReference 数组保存，数组的key即为 ThreadLocal 内部的Hash值。 创建线程的方式及实现Java使用Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。Java可以用三种方式来创建线程，如下所示： 继承Thread类创建线程 实现Runnable接口创建线程 使用Callable和Future创建线程 继承Thread类创建线程 通过继承Thread类来创建并启动多线程的一般步骤如下 1】d定义Thread类的子类，并重写该类的run()方法，该方法的方法体就是线程需要完成的任务，run()方法也称为线程执行体。 2】创建Thread子类的实例，也就是创建了线程对象 3】启动线程，即调用线程的start()方法 代码实例 1234567891011public class MyThread extends Thread&#123;//继承Thread类 public void run()&#123; //重写run方法 &#125;&#125;public class Main &#123; public static void main(String[] args)&#123; new MyThread().start();//创建并启动线程 &#125;&#125; 实现Runnable接口创建线程 通过实现Runnable接口创建并启动线程一般步骤如下： 1】定义Runnable接口的实现类，一样要重写run()方法，这个run（）方法和Thread中的run()方法一样是线程的执行体 2】创建Runnable实现类的实例，并用这个实例作为Thread的target来创建Thread对象，这个Thread对象才是真正的线程对象 3】第三部依然是通过调用线程对象的start()方法来启动线程 代码实例： 123456789101112131415public class MyThread2 implements Runnable &#123;//实现Runnable接口 public void run()&#123; //重写run方法 &#125;&#125;public class Main &#123; public static void main(String[] args)&#123; //创建并启动线程 MyThread2 myThread=new MyThread2(); Thread thread=new Thread(myThread); thread().start(); //或者 new Thread(new MyThread2()).start(); &#125;&#125; 使用Callable和Future创建线程 和Runnable接口不一样，Callable接口提供了一个call（）方法作为线程执行体，call()方法比run()方法**功能要强大。 》call()方法可以有返回值 》call()方法可以声明抛出异常 Java5提供了Future接口来代表Callable接口里call()方法的返回值，并且为Future接口提供了一个实现类FutureTask，这个实现类既实现了Future接口，还实现了Runnable接口，因此可以作为Thread类的target。在Future接口里定义了几个公共方法来控制它关联的Callable任务。 >boolean cancel(boolean mayInterruptIfRunning)：视图取消该Future里面关联的Callable任务 >V get()：返回Callable里call（）方法的返回值，调用这个方法会导致程序阻塞，必须等到子线程结束后才会得到返回值 >V get(long timeout,TimeUnit unit)：返回Callable里call（）方法的返回值，最多阻塞timeout时间，经过指定时间没有返回抛出TimeoutException >boolean isDone()：若Callable任务完成，返回True >boolean isCancelled()：如果在Callable任务正常完成前被取消，返回True 介绍了相关的概念之后，创建并启动有返回值的线程的步骤如下： 1】创建Callable接口的实现类，并实现call()方法，然后创建该实现类的实例（从java8开始可以直接使用Lambda表达式创建Callable对象）。 2】使用FutureTask类来包装Callable对象，该FutureTask对象封装了Callable对象的call()方法的返回值 3】使用FutureTask对象作为Thread对象的target创建并启动线程（因为FutureTask实现了Runnable接口） 4】调用FutureTask对象的get()方法来获得子线程执行结束后的返回值 代码实例： 123456789101112131415161718192021222324252627282930313233public class Main &#123; public static void main(String[] args)&#123; MyThread3 th=new MyThread3(); //使用Lambda表达式创建Callable对象 //使用FutureTask类来包装Callable对象 FutureTask&lt;Integer&gt; future=new FutureTask&lt;Integer&gt;( (Callable&lt;Integer&gt;)()-&gt;&#123; return 5; &#125; ); new Thread(task,"有返回值的线程").start();//实质上还是以Callable对象来创建并启动线程 try&#123; System.out.println("子线程的返回值："+future.get()); //get()方法会阻塞，直到子线程执行结束才返回 &#125;catch(Exception e)&#123; ex.printStackTrace(); &#125; &#125;&#125; ————————————–三种创建线程方法对比————————————– 实现Runnable和实现Callable接口的方式基本相同，不过是后者执行call()方法有返回值，后者线程执行体run()方法无返回值，因此可以把这两种方式归为一种这种方式与继承Thread类的方法之间的差别如下： 1、线程只是实现Runnable或实现Callable接口，还可以继承其他类。 2、这种方式下，多个线程可以共享一个target对象，非常适合多线程处理同一份资源的情形。 3、但是编程稍微复杂，如果需要访问当前线程，必须调用Thread.currentThread()方法。 4、继承Thread类的线程类不能再继承其他父类（Java单继承决定）。 注：一般推荐采用实现接口的方式来创建多线程 sleep() 、join（）、yield（）有什么区别sleep():方法导致了程序暂停执行指定的时间，让出cpu给其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态，但不会释放“锁标志”，不推荐使用。 wait():在其他线程调用对象的notify或notifyAll方法前，导致当前线程等待。线程会释放掉它所占有的“锁标志”，从而使别的线程有机会抢占该锁。 yield():暂停当前正在执行的线程对象。yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。yield()只能使同优先级或更高优先级的线程有执行的机会。 join():等待调用join方法的线程结束，再继续执行。 sleep是针对于thread对象，wait是针对于Object对象。 ConcurrentHashMap如何保证线程安全JDK 1.7及以前： ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同部分进行的修改。ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。 JDK 1.8： Segment虽保留，但已经简化属性，仅仅是为了兼容旧版本。 插入时使用CAS算法：unsafe.compareAndSwapInt(this, valueOffset, expect, update)。 CAS(Compare And Swap)意思是如果valueOffset位置包含的值与expect值相同，则更新valueOffset位置的值为update，并返回true，否则不更新，返回false。插入时不允许key或value为null 与Java8的HashMap有相通之处，底层依然由“数组”+链表+红黑树； 底层结构存放的是TreeBin对象，而不是TreeNode对象； CAS作为知名无锁算法，那ConcurrentHashMap就没用锁了么？当然不是，当hash值与链表的头结点相同还是会synchronized上锁，锁链表。 new与newInstance()的区别 new是一个关键字，它是调用new指令创建一个对象，然后调用构造方法来初始化这个对象，可以使用带参数的构造器 newInstance()是Class的一个方法，在这个过程中，是先取了这个类的不带参数的构造器Constructor，然后调用构造器的newInstance方法来创建对象。 Class.newInstance不能带参数，如果要带参数需要取得对应的构造器，然后调用该构造器的Constructor.newInstance(Object … initargs)方法 JDK中用到的设计模式 装饰模式：java.io 单例模式：Runtime类 简单工厂模式：Integer.valueOf方法 享元模式：String常量池、Integer.valueOf(int i)、Character.valueOf(char c) 迭代器模式：Iterator 职责链模式：ClassLoader的双亲委派模型 解释器模式：正则表达式java.util.regex.Pattern hashCode() &amp;&amp; equals()hashcode() 返回该对象的哈希码值，支持该方法是为哈希表提供一些优点，例如，java.util.Hashtable 提供的哈希表。 在 Java 应用程序执行期间，在同一对象上多次调用 hashCode 方法时，必须一致地返回相同的整数，前提是对象上 equals 比较中所用的信息没有被修改（equals默认返回对象地址是否相等）。如果根据 equals(Object)方法，两个对象是相等的，那么在两个对象中的每个对象上调用 hashCode 方法都必须生成相同的整数结果。 以下情况不是必需的：如果根据 equals(java.lang.Object) 方法，两个对象不相等，那么在两个对象中的任一对象上调用 hashCode 方法必定会生成不同的整数结果。但是，程序员应该知道，为不相等的对象生成不同整数结果可以提高哈希表的性能。 实际上，由 Object 类定义的 hashCode 方法确实会针对不同的对象返回不同的整数。（这一般是通过将该对象的内部地址转换成一个整数来实现的，但是 JavaTM 编程语言不需要这种实现技巧I。） hashCode的存在主要是用于查找的快捷性，如 Hashtable，HashMap等，hashCode 是用来在散列存储结构中确定对象的存储地址的； 如果两个对象相同，就是适用于 equals(java.lang.Object) 方法，那么这两个对象的 hashCode 一定要相同； 如果对象的 equals 方法被重写，那么对象的 hashCode 也尽量重写，并且产生 hashCode使用的对象，一定要和 equals 方法中使用的一致，否则就会违反上面提到的第2点； 两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。 Object类的finalize方法的实现原理Object 类提供的实现不Finalize方法和垃圾回收器将派生的类型不标记Object终止除非它们将覆盖Finalize方法。 如果类型未重写Finalize方法，则垃圾回收器会将类型的每个实例的条目添加到调用终止队列中的内部结构。 终止队列中包含垃圾回收器才能回收其内存之前，必须运行其终止代码托管堆中的所有对象的条目。 然后，垃圾回收器调用Finalize在以下情况下自动的方法︰ 垃圾回收器发现，一个对象不可访问，除非您通过调用从终止豁免已对象后 GC.SuppressFinalize 方法。 在关闭应用程序域中，除非该对象是免于终止的对象。 在关闭期间，终止甚至仍是可访问的对象。 Finalize将自动调用一次在给定实例中，除非的对象重新注册通过使用一种机制，如GC.ReRegisterForFinalize和GC.SuppressFinalize尚未随后调用方法。 Finalize操作具有以下限制︰ 终结器执行时的确切时间不确定。 若要确保确定性释放资源，对你的类的实例实现Close方法，或者提供IDisposable.Dispose实现。 两个对象的终结器不保证任何特定顺序运行即使另一个对象引用。 也就是说，如果对象 A 具有对对象 B 的引用，并且二者的终结器，对象 B 可能已经被终结的对象 A 终结器启动时。 终结器运行的线程未指定。 Finalize方法可能无法运行完成，或可能根本不运行下列异常情况下︰ 如果另一个终结器会无限期阻止 （进入无限循环，尝试获取的锁，它可以永远不会获取，等等）。 运行时尝试运行终结器来完成，因为其他终结器可能不会调用终结器块如果无限期。 如果不提供机会清理的运行时，进程将终止。 在这种情况下，运行时的第一个通知的进程是终止的一个 DLL_PROCESS_DETACH 通知。 运行时将继续完成在关闭过程的对象，仅当可终结对象数目继续减少。 如果Finalize或的重写Finalize引发异常，并且运行时不承载的应用程序将替代默认策略，运行时终止进程，且无活动try/finally执行块或终结器。如果终结器无法释放或销毁资源，则此行为确保处理完整性。 实施者注意事项 应重写Finalize类使用非托管的资源，如文件句柄或数据库必须在垃圾回收期间放弃使用它们的托管的对象时释放的连接。 Lock是Java 5以后引入的新的API，和关键字synchronized相比主要相同点：Lock 能完成synchronized所实现的所有功能；主要不同点：Lock有比synchronized更精确的线程语义和更好的性能，而且不强制性的要求一定要获得锁。synchronized会自动释放锁，而Lock一定要求程序员手工释放，并且最好在finally 块中释放（这是释放外部资源的最好的地方）。 CAS 乐观锁CAS是通过unsafe类的compareAndSwap方法实现的；方法参数作用，第一个参数是要修改的对象，第二个参数是对象中要修改变量的偏移量，第三个参数是修改之前的值，第四个参数是预想修改后的值；CAS指令有缺点，存在ABA问题。 ABA 问题就是一个变量V，如果变量V初次读取的时候是A，并且在准备赋值的时候检查到它仍然是A，那能说明它的值没有被其他线程修改过了吗？如果在这段期间它的值曾经被改成了B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。解决：针对这种情况，java并发包中提供了一个带有标记的原子引类”AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。 CAS有什么缺陷，该如何解决CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作 ABA问题。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。 乐观锁的业务场景及实现方式1.我们经常会在访问数据库的时候用到锁，怎么实现乐观锁和悲观锁呢？以Hibernate为例，可以通过为记录添加版本或时间戳字段来实现乐观锁。可以用session.Lock()锁定对象来实现悲观锁（本质上就是执行了SELECT * FROM t FOR UPDATE语句）。 2.如果把乐观锁看作是关于冲突检测的，那么悲观锁就是关于冲突避免的。在实际应用的源代码控制系统中， 这两种策略都可以被使用，但是现在大多数源代码开发者更倾向于使用乐观锁策略。（有一种很有道理的说法：乐观锁并不是真正的锁定，但是这种叫法很方便并且广泛流传，以至于不容忽略。） 在乐观锁和悲观锁之间进行选择的标准是：冲突的频率与严重性。如果冲突很少，或者冲突的后果不会很严重，那么通常情况下应该选择乐观锁，因为它能得到更好的并发性，而且更容易实现。但是，如果冲突的结果对于用户来说痛苦的，那么就需要使用悲观策略。 访问修饰符public,private,protected,以及不写时的区别 修饰符 当前类 同 包 子 类 其他包 public √ √ √ √ protected √ √ √ × default √ √ × × private √ × × × 类的成员不写访问修饰时默认为default。默认对于同一个包中的其他类相当于公开（public），对于不是同一个包中的其他类相当于私有（private）。受保护（protected）对子类相当于公开，对不是同一包中的没有父子关系的类相当于私有。Java中，外部类的修饰符只能是public或默认，类的成员（包括内部类）的修饰符可以是以上四种。 String 是不是最基本的数据类型不是。Java中的基本数据类型只有8个：byte、short、int、long、float、double、char、boolean；除了基本类型（primitive type），剩下的都是引用类型（reference type），Java 5以后引入的枚举类型也算是一种比较特殊的引用类型。 short s1 = 1; s1 = s1 + 1;有错吗?short s1 = 1; s1 += 1;有错吗对于short s1 = 1; s1 = s1 + 1;由于1是int类型，因此s1+1运算结果也是int 型，需要强制转换类型才能赋值给short型可修改为s1 =(short)(s1 + 1)。而short s1 = 1; s1 += 1;可以正确编译，因为s1+= 1;相当于s1 = (short)(s1 + 1);其中有隐含的强制类型转换。 是否可以继承String类String 类是final类，不可以被继承。 补充：继承String本身就是一个错误的行为，对String类型最好的重用方式是关联关系（Has-A）和依赖关系（Use-A）而不是继承关系（Is-A） JVM加载class文件的原理机制JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。加载完成后，Class对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证、准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。最后JVM对类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap）、扩展加载器（Extension）、系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader的子类）。从Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM更好的保证了Java平台的安全性，在该机制中，JVM自带的Bootstrap是根加载器，其他的加载器都有且仅有一个父类加载器。类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM不会向Java程序提供对Bootstrap的引用。下面是关于几个类加载器的说明： Bootstrap：一般用本地代码实现，负责加载JVM基础核心类库（rt.jar）； Extension：从java.ext.dirs系统属性所指定的目录中加载类库，它的父加载器是Bootstrap； System：又叫应用类加载器，其父类是Extension。它是应用最广泛的类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类，是用户自定义加载器的默认父加载器。 静态嵌套类(Static Nested Class)和内部类（Inner Class）的不同Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化后才能实例化，其语法看起来挺诡异的，如下所示。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * 扑克类（一副扑克） * @author 骆昊 * */public class Poker &#123; private static String[] suites = &#123;"黑桃", "红桃", "草花", "方块"&#125;; private static int[] faces = &#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13&#125;; private Card[] cards; /** * 构造器 * */ public Poker() &#123; cards = new Card[52]; for(int i = 0; i &lt; suites.length; i++) &#123; for(int j = 0; j &lt; faces.length; j++) &#123; cards[i * 13 + j] = new Card(suites[i], faces[j]); &#125; &#125; &#125; /** * 洗牌 （随机乱序） * */ public void shuffle() &#123; for(int i = 0, len = cards.length; i &lt; len; i++) &#123; int index = (int) (Math.random() * len); Card temp = cards[index]; cards[index] = cards[i]; cards[i] = temp; &#125; &#125; /** * 发牌 * @param index 发牌的位置 * */ public Card deal(int index) &#123; return cards[index]; &#125; /** * 卡片类（一张扑克） * [内部类] * @author 骆昊 * */ public class Card &#123; private String suite; // 花色 private int face; // 点数 public Card(String suite, int face) &#123; this.suite = suite; this.face = face; &#125; @Override public String toString() &#123; String faceStr = ""; switch(face) &#123; case 1: faceStr = "A"; break; case 11: faceStr = "J"; break; case 12: faceStr = "Q"; break; case 13: faceStr = "K"; break; default: faceStr = String.valueOf(face); &#125; return suite + faceStr; &#125; &#125;&#125; ​ 测试代码： 1234567891011121314class PokerTest &#123; public static void main(String[] args) &#123; Poker poker = new Poker(); poker.shuffle(); // 洗牌 Poker.Card c1 = poker.deal(0); // 发第一张牌 // 对于非静态内部类Card // 只有通过其外部类Poker对象才能创建Card对象 Poker.Card c2 = poker.new Card("红心", 1); // 自己创建一张牌 System.out.println(c1); // 洗牌后的第一张 System.out.println(c2); // 打印: 红心A &#125;&#125; GC是什么？为什么要有GC？GC是垃圾收集的意思，内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。Java程序员不用担心内存管理，因为垃圾收集器会自动进行管理。要请求垃圾收集，可以调用下面的方法之一：System.gc() 或Runtime.getRuntime().gc() ，但JVM可以屏蔽掉显示的垃圾回收调用。垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低优先级的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。在Java诞生初期，垃圾回收是Java最大的亮点之一，因为服务器端的编程需要有效的防止内存泄露问题，然而时过境迁，如今Java的垃圾回收机制已经成为被诟病的东西。移动智能终端用户通常觉得iOS的系统比Android系统有更好的用户体验，其中一个深层次的原因就在于Android系统中垃圾回收的不可预知性。 补充：垃圾回收机制有很多种，包括：分代复制垃圾回收、标记垃圾回收、增量垃圾回收等方式。标准的Java进程既有栈又有堆。栈保存了原始型局部变量，堆保存了要创建的对象。Java平台对堆内存回收和再利用的基本算法被称为标记和清除，但是Java对其进行了改进，采用“分代式垃圾收集”。这种方法会跟Java对象的生命周期将堆内存划分为不同的区域，在垃圾收集过程中，可能会将对象移动到不同区域： 伊甸园（Eden）：这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。 幸存者乐园（Survivor）：从伊甸园幸存下来的对象会被挪到这里。 终身颐养园（Tenured）：这是足够老的幸存对象的归宿。年轻代收集（Minor-GC）过程是不会触及这个地方的。当年轻代收集不能把对象放进终身颐养园时，就会触发一次完全收集（Major-GC），这里可能还会牵扯到压缩，以便为大对象腾出足够的空间。 String s = new String(“xyz”);创建了几个字符串对象两个对象，一个是静态区的”xyz”，一个是用new创建在堆上的对象。 如何实现字符串的反转及替换方法很多，可以自己写实现也可以使用String或StringBuffer/StringBuilder中的方法。有一道很常见的面试题是用递归实现字符串反转，代码如下所示： public static String reverse(String originStr) {​ if(originStr == null || originStr.length() &lt;= 1)​ return originStr;​ return reverse(originStr.substring(1)) + originStr.charAt(0);​ } List、Set、Map是否继承自Collection接口List、Set 是，Map 不是。Map是键值对映射容器，与List和Set有明显的区别，而Set存储的零散的元素且不允许有重复元素（数学中的集合也是如此），List是线性结构的容器，适用于按数值索引访问元素的情形。 List、Map、Set三个接口存取元素时，各有什么特点List以特定索引来存取元素，可以有重复元素。Set不能存放重复元素（用对象的equals()方法来区分元素是否重复）。Map保存键值对（key-value pair）映射，映射关系可以是一对一或多对一。Set和Map容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。 当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的synchronized修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。 线程同步以及线程调度相关的方法 wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁； sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常； notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关； notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态； 启动一个线程是调用run()还是start()方法启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM 调度并执行，这并不意味着线程就会立即运行。run()方法是线程启动后要进行回调（callback）的方法。 Java中有几种类型的流字节流和字符流。字节流继承于InputStream、OutputStream，字符流继承于Reader、Writer。在java.io 包中还有许多其他的流，主要是为了提高性能和使用方便。关于Java的I/O需要注意的有两点：一是两种对称性（输入和输出的对称性，字节和字符的对称性）；二是两种设计模式（适配器模式和装潢模式）。另外Java中的流不同于C#的是它只有一个维度一个方向。 在项目中哪些地方用到了XMLXML的主要作用有两个方面：数据交换和信息配置。在做数据交换时，XML将数据用标签组装成起来，然后压缩打包加密后通过网络传送给接收者，接收解密与解压缩后再从XML文件中还原相关信息进行处理，XML曾经是异构系统间交换数据的事实标准，但此项功能几乎已经被JSON（JavaScript Object Notation）取而代之。当然，目前很多软件仍然使用XML来存储配置信息，我们在很多项目中通常也会将作为配置信息的硬代码写在XML文件中，Java的很多框架也是这么做的，而且这些框架都选择了dom4j作为处理XML的工具，因为Sun公司的官方API实在不怎么好用。 vector、ArrayList、LinkedList 的区别是什么vector是同步的，arraylist和linkedlist不是同步的。底层方面，vector与arraylist都是基于object[]array实现的，但考虑vector线程安全，所以arraylist效率上回比vector较快。元素随机访问上，vector与arraylist是基本相同的，时间复杂度是O(1)，linkedlist的随机访问元素的复杂度为O(n)。但在插入删除数据上，linkedlist则比arraylist要快很多。linkedlist比arraylist更占内存，因为linkedlist每个节点上还要存储对前后两个节点的引用。 NIO和传统的IO有什么区别IO是面向流的，NIO是面向块（缓冲区）的。 IO面向流的操作一次一个字节地处理数据。一个输入流产生一个字节的数据，一个输出流消费一个字节的数据。，导致了数据的读取和写入效率不佳。 NIO面向块的操作在一步中产生或者消费一个数据块。按块处理数据比按(流式的)字节处理数据要快得多，同时数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。通俗来说，NIO采取了“预读”的方式，当你读取某一部分数据时，他就会猜测你下一步可能会读取的数据而预先缓冲下来。 IO是阻塞的，NIO是非阻塞的 对于传统的IO，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 而对于NIO，使用一个线程发送读取数据请求，没有得到响应之前，线程是空闲的，此时线程可以去执行别的任务，而不是像IO中那样只能等待响应完成。 NIO和IO适用场景 NIO是为弥补传统IO的不足而诞生的，但是尺有所短寸有所长，NIO也有缺点，因为NIO是面向缓冲区的操作，每一次的数据处理都是对缓冲区进行的，那么就会有一个问题，在数据处理之前必须要判断缓冲区的数据是否完整或者已经读取完毕，如果没有，假设数据只读取了一部分，那么对不完整的数据处理没有任何意义。所以每次数据处理之前都要检测缓冲区数据。 那么NIO和IO各适用的场景是什么呢？ 如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，这时候用NIO处理数据可能是个很好的选择。 而如果只有少量的连接，而这些连接每次要发送大量的数据，这时候传统的IO更合适。使用哪种处理数据，需要在数据的响应等待时间和检查缓冲区数据的时间上作比较来权衡选择。 通俗解释，最后，对于NIO和传统IO 有一个网友讲的生动的例子： 以前的流总是堵塞的，一个线程只要对它进行操作，其它操作就会被堵塞，也就相当于水管没有阀门，你伸手接水的时候，不管水到了没有，你就都只能耗在接水（流）上。 nio的Channel的加入，相当于增加了水龙头（有阀门），虽然一个时刻也只能接一个水管的水，但依赖轮换策略，在水量不大的时候，各个水管里流出来的水，都可以得到妥 善接纳，这个关键之处就是增加了一个接水工，也就是Selector，他负责协调，也就是看哪根水管有水了的话，在当前水管的水接到一定程度的时候，就切换一下：临时关上当 前水龙头，试着打开另一个水龙头（看看有没有水）。 当其他人需要用水的时候，不是直接去接水，而是事前提了一个水桶给接水工，这个水桶就是Buffer。也就是，其他人虽然也可能要等，但不会在现场等，而是回家等，可以做 其它事去，水接满了，接水工会通知他们。 这其实也是非常接近当前社会分工细化的现实，也是统分利用现有资源达到并发效果的一种很经济的手段，而不是动不动就来个并行处理，虽然那样是最简单的，但也是最浪费资源的方式 如何通过反射创建对象 方法1：通过类对象调用newInstance()方法，例如：String.class.newInstance() 方法2：通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器（Constructor）对象并调用其newInstance()方法创建对象，例如：String.class.getConstructor(String.class).newInstance(“Hello”); Statement与PreparedStatement的区别,什么是SQL注入，如何防止SQL注入使用PreparedStatement可以提升代码的可读性和可维护性，可以尽最大可能提高性能。因为Statement每次执行一个SQL命令都会对其编译，但PreparedStatement则只编译一次。PreparedStatement就类似于流水线生产。另一方面PreparedStatement可以极大提高安全性：它对传递过来的参数进行了强制参数类型转换，确保插入或查询数据时，与底层数据库格式匹配。SQL注入：就是通过将sql命令插入到web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意SQL命令。如sql命令：select id from test where name=’1’ or 1=1; drop table test,但用PreparedStatement就可以避免这种问题。 用Java写一个单例类饿汉式单例: public class Singleton {​ private Singleton(){}​ private static Singleton instance = new Singleton();​ public static Singleton getInstance(){​ return instance;​ }} 懒汉式单例: public class Singleton {​ private static Singleton instance = null;​ private Singleton() {}​ public static synchronized Singleton getInstance(){​ if (instance == null) instance ＝ new Singleton();​ return instance;​ }} 用Java写一个冒泡排序冒泡排序几乎是个程序员都写得出来，但是面试的时候如何写一个逼格高的冒泡排序却不是每个人都能做到 12345678910111213141516171819202122import java.util.Comparator;/** * 排序器接口(策略模式: 将算法封装到具有共同接口的独立的类中使得它们可以相互替换) * @author骆昊 * */public interface Sorter &#123; /** * 排序 * @param list 待排序的数组 */ public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] list); /** * 排序 * @param list 待排序的数组 * @param comp 比较两个对象的比较器 */ public &lt;T&gt; void sort(T[] list, Comparator&lt;T&gt; comp);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.Comparator;/** * 冒泡排序 * * @author骆昊 * */public class BubbleSorter implements Sorter &#123; @Override public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] list) &#123; boolean swapped = true; for (int i = 1, len = list.length; i &lt; len &amp;&amp; swapped; ++i) &#123; swapped = false; for (int j = 0; j &lt; len - i; ++j) &#123; if (list[j].compareTo(list[j + 1]) &gt; 0) &#123; T temp = list[j]; list[j] = list[j + 1]; list[j + 1] = temp; swapped = true; &#125; &#125; &#125; &#125; @Override public &lt;T&gt; void sort(T[] list, Comparator&lt;T&gt; comp) &#123; boolean swapped = true; for (int i = 1, len = list.length; i &lt; len &amp;&amp; swapped; ++i) &#123; swapped = false; for (int j = 0; j &lt; len - i; ++j) &#123; if (comp.compare(list[j], list[j + 1]) &gt; 0) &#123; T temp = list[j]; list[j] = list[j + 1]; list[j + 1] = temp; swapped = true; &#125; &#125; &#125; &#125;&#125; char型变量中能不能存贮一个中文汉字char型变量是用来存储Unicode编码的字符的，unicode编码字符集中包含了汉字，所以，char型变量中当然可以存储汉字啦。不过，如果某个特殊的汉字没有被包含在unicode编码字符集中，那么，这个char型变量中就不能存储这个特殊汉字。补充说明：unicode编码占用两个字节，所以，char类型的变量也是占用两个字节。 用最有效率的方法算出2乘以8等于几2&lt;&lt; 3，(左移三位)因为将一个数左移n位，就相当于乘以了2的n次方，那么，一个数乘以8只要将其左移3位即可，而位运算cpu直接支持的，效率最高，所以，2乘以8等於几的最效率的方法是2&lt;&lt; 3。 静态变量和实例变量的区别在语法定义上的区别：静态变量前要加 static 关键字，而实例变量前则不加。 在程序运行时的区别：实例变量属于某个对象的属性，必须创建了实例对象，其中的实例变量才会被分配空间，才能使用这个实例变量。静态变量不属于某个实例对象，而是属于类，所以也称为类变量，只要程序加载了类的字节码，不用创建任何实例对象，静态变量就会被分配空间，静态变量就可以被使用了。总之，实例变量必须创建对象后才可以通过这个对象来使用，静态变量则可以直接使用类名来引用。 例如，对于下面的程序，无论创建多少个实例对象，永远都只分配了一个staticVar变量，并且每创建一个实例对象，这个staticVar就会加1；但是，每创建一个实例对象，就会分配一个instanceVar，即可能分配多个instanceVar，并且每个instanceVar的值都只自加了1次。 1234567891011121314151617public class VariantTest&#123; publicstatic int staticVar = 0; publicint instanceVar = 0; publicVariantTest()&#123; staticVar++; instanceVar++; System.out.println(staticVar +instanceVar); &#125;&#125; switch语句能否作用在 byte 、 long 和String 上在switch（e）中，e只能是一个整数表达式或者枚举常量（更大字体），整数表达式可以是int基本类型或Integer包装类型，由于byte,short,char都可以隐含转换为int，所以，这些类型以及这些类型的包装类型也是可以的。显然，long和String类型都不符合switch的语法规定，并且不能被隐式转换成int类型，所以，它们不能作用于swtich语句中。 switch语句能否作用在String上说错了，Java1.7之后已经支持这种写法了！ 如何跳出当前的多重嵌套循环在Java中，要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号的break语句，即可跳出外层循环。 例如： 123456for(int i=0;i&lt;10;i++)&#123; for(intj=0;j&lt;10;j++)&#123; System.out.println(“i=” + i + “,j=” + j); if(j == 5) break ok; &#125;&#125; 另外，我个人通常并不使用标号这种方式，而是让外层的循环条件表达式的结果可以受到里层循环体代码的控制，例如，要在二维数组中查找到某个数字。 123456789101112131415161718192021int arr[][] =&#123;&#123;1,2,3&#125;,&#123;4,5,6,7&#125;,&#123;9&#125;&#125;;boolean found = false;for(int i=0;i&lt;arr.length&amp;&amp;!found;i++) &#123; for(intj=0;j&lt;arr[i].length;j++)&#123; System.out.println(“i=” + i + “,j=” + j); if(arr[i][j] ==5) &#123; found =true; break; &#125; &#125;&#125; 说说&amp;和&amp;&amp;的区别 &amp;和&amp;&amp;都可以用作逻辑与的运算符，表示逻辑与（and），当运算符两边的表达式的结果都为true时，整个运算结果才为true，否则，只要有一方为false，则结果为false。 ​ &amp;&amp;还具有短路的功能，即如果第一个表达式为false，则不再计算第二个表达式，例如，对于if(str!= null&amp;&amp; !str.equals(s))表达式，当str为null时，后面的表达式不会执行，所以不会出现NullPointerException如果将&amp;&amp;改为&amp;，则会抛出NullPointerException异常。If(x==33 &amp;++y&gt;0) y会增长，If(x==33 &amp;&amp; ++y&gt;0)不会增长 ​ &amp;还可以用作位运算符，当&amp;操作符两边的表达式不是boolean类型时，&amp;表示按位与操作，我们通常使用0x0f来与一个整数进行&amp;运算，来获取该整数的最低4个bit位，例如，0x31 &amp; 0x0f的结果为0x01。 一个”.java”源文件中是否可以包括多个类（不是内部类）有什么限制 可以有多个类，但只能有一个public的类，并且public的类名必须与文件名相一致。 可以从一个static方法内部发出对非static方法的调用吗不可以。因为非static方法是要与对象关联在一起的，必须创建一个对象后，才可以在该对象上进行方法调用，而static方法调用时不需要创建对象，可以直接调用。也就是说，当一个static方法被调用时，可能还没有创建任何实例对象，如果从一个static方法中发出对非static方法的调用，那个非static方法是关联到哪个对象上的呢？这个逻辑无法成立，所以，一个static方法内部发出对非static方法的调用。 Hibernate中怎样实现类之间的关系 类与类之间的关系主要体现在表与表之间的关系进行操作，它们都是对对象进行操作，我们在程序中把所有的表与类都映射在一起，它们通过配置文件中的many-to-one、one-to-many、many-to-many进行操作。 Hibernate中的update()和saveOrUpdate()的区别saveOrUpdate()： ​ 1、如果对象已经在本session中持久化了，不做任何事 ​ 2、如果另一个与本session关联的对象拥有相同的持久化标识(identifier)，抛出一个异常 ​ 3、如果对象没有持久化标识(identifier)属性，对其调用save() ​ 4、如果对象的持久标识(identifier)表明其是一个新实例化的对象，对其调用save() ​ 5、如果对象是附带版本信息的（通过或 ）并且版本属性的值表明其是一个新实例化的 对象，调用save()。否则update() 这个对象。 update() ：是将一个游离状态的实体对象直接更新。 Hibernate的缓存机制 一级缓存：内部缓存存在Hibernate中，属于应用事物级缓存。 二级缓存：应用级缓存、 分布式缓存。使用场景：数据不会被第三方修改、数据大小在可接受范围、数据更新频率低、同一数据被系统频繁使用、非关键数据 引入第三方缓存（如ehcache等）。 如何优化Hibernate1.使用双向一对多关联，不使用单向一对多 2.灵活使用单向一对多关联 3.不用一对一，用多对一取代 4.配置对象缓存，不使用集合缓存 5.一对多集合使用Bag,多对多集合使用Set 6.继承类使用显式多态 7.表字段要少，表关联不要怕多，有二级缓存撑腰 hibernate的延迟加载和openSessionInView延迟加载要在session范围内，用到的时候再加载； opensessioninview是在web层写了一个filter来打开和关闭session，这样就表示在一次request过程中session一直开着，保证了延迟加载在session中的这个前提。 Mysql 优化1.如果明确知道只有一条结果返回，limit1能够提高效率 2.把计算放在业务层而不是数据库层，除了节省数据的 CPU ,还有意想不到的查询缓存优化效果。 3.强制类型转换会全表扫描 4.在属性上进行计算不能命中索引 5.使用 ENUM 而不是字符串 6.数据分区度不大的字段不宜使用索引 7.负向查询和前导模糊查询不能使用索引 8.用TRUNCATE替代DELETE 9.删除重复记录 10.用Where子句替换HAVING子句 11.用EXISTS替代IN、用NOT EXISTS替代NOT IN 12.用索引提高效率 13.用EXISTS替换DISTINCT 14.用&gt;=替代&gt; 15.用IN来替换OR Mysql 的交集、差集、并集只有并集没有交集差集的关键字。 1.并集 1234-- UNION 不包含重复数据-- UNION ALL 包含重复数据SELECT NAME FROM a UNIONSELECT NAME FROM b; 2.差集 找出在a表中存在的id 但是在b表中不存在的id 1234567-- 利用 unionSELECT ID FROM (-- 并集SELECT DISTINCT a.id AS ID FROM a UNION ALLSELECT DISTINCT B.ID AS ID FROM b)TEMP GROUP BY ID HAVING COUNT(ID) = 1; 12-- 子查询 not inSELECT id FROM a WHERE id NOT IN (SELECT id FROM b); 12-- 子查询 not existsSELECT id FROM a WHERE NOT EXISTS (SELECT id FROM b WHERE a.id = b.id); 12-- 左连接判断右表IS NULLSELECT a.id FROM a LEFT JOIN b ON a.id = b.id WHERE b.id IS NULL ORDER BY a.id 3.交集 INTERSECT 123456SELECT ID FROM (-- 并集 SELECT DISTINCT a.id AS ID FROM a UNION ALLSELECT DISTINCT B.ID AS ID FROM b)TEMP GROUP BY ID HAVING COUNT(ID) != 1; Java内存模型是什么 Java内存模型规定和指引Java程序在不同的内存架构、CPU和操作系统间有确定性地行为。它在多线程的情况下尤其重要。Java内存模型对一个线程所做的变动能被其它线程可见提供了保证，它们之间是先行发生关系。这个关系定义了一些规则让程序员在并发编程时思路更清晰。比如，先行发生关系确保了： ​ 线程内的代码能够按先后顺序执行，这被称为程序次序规则。 ​ 对于同一个锁，一个解锁操作一定要发生在时间上后发生的另一个锁定操作之前，也叫做管程锁定规则。 ​ 前一个对volatile的写操作在后一个volatile的读操作之前，也叫volatile变量规则。 ​ 一个线程内的任何操作必需在这个线程的start()调用之后，也叫作线程启动规则。 ​ 一个线程的所有操作都会在线程终止之前，线程终止规则。 ​ 一个对象的终结操作必需在这个对象构造完成之后，也叫对象终结规则。 可传递性 Thread接口和Runnable接口的区别 可以避免由于Java的单继承特性而带来的局限. 使用Runnable实现多线程可以达到资源共享目的。 Runnable接口和Callable接口的区别Runnable应该是比较熟悉的接口，它只有一个run()函数，用于将耗时操作写在其中，该函数没有返回值，不能将结果返回给客户程序。然后使用某个线程去执行runnable即可实现多线程，Thread类在调用start()函数后就是执行的是Runnable的run()函数。Runnable的声明如下 : 123public interface Runnable &#123; public abstract void run(); &#125; Callable与Runnable的功能大致相似，Callable中有一个call()函数，但是call()函数有返回值。 Callable的声明如下 : 123public interface Callable&lt;V&gt; &#123; V call() throws Exception; &#125; 可以看到，这是一个泛型接口，call()函数返回的类型就是客户程序传递进来的V类型。不同之处：1.Callable可以返回一个类型V，而Runnable不可以；2.Callable能够抛出checked exception,而Runnable不可以；3.Runnable是自从java1.1就有了，而Callable是1.5之后才加上去的；4.Callable和Runnable都可以应用于executors。而Thread类只支持Runnable；Callable与executors联合在一起，在任务完成时可立刻获得一个更新了的Future；而Runable却要自己处理。 5.加入线程池运行，Runnable使用ExecutorService的execute方法，Callable使用submit方法。 线程池的实现原理先启动若干数量的线程，并让这些线程都处于睡眠状态，当客户端有一个新请求时，就会唤醒线程池中的某一个睡眠线程，让它来处理客户端的这个请求，当处理完这个请求后，线程又处于睡眠状态。 节约大量的的系统资源，使得更多的CPU时间和内存用来处理实际的商业应用，而不是频繁的线程创建与销毁。 线程池的几种方式Java通过Executors提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 (1).newCacheThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。示例代码如下： 123456789101112131415161718ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;cachedThreadPool.execute(new Runnable() &#123;@Overridepublic void run() &#123; System.out.println(index);&#125;&#125;);&#125; 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 (2). newFixedThreadPool： 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。示例代码如下： 123456789101112131415161718ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; fixedThreadPool.execute(new Runnable() &#123;@Overridepublic void run() &#123;try &#123; System.out.println(index); Thread.sleep(2000);&#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125;&#125;&#125;);&#125; 因为线程池大小为3，每个任务输出index后sleep 2秒，所以每两秒打印3个数字。 定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors()。可参考PreloadDataCache。 (3).newScheduledThreadPool: 创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下： 12345678ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.schedule(new Runnable() &#123;@Overridepublic void run() &#123; System.out.println("delay 3 seconds");&#125;&#125;, 3, TimeUnit.SECONDS); 表示延迟3秒执行。 定期执行示例代码如下： 1234567scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123;@Overridepublic void run() &#123; System.out.println("delay 1 seconds, and excute every 3 seconds");&#125;&#125;, 1, 3, TimeUnit.SECONDS); 表示延迟1秒后每3秒执行一次。 ScheduledExecutorService比Timer更安全，功能更强大 (4).newSingleThreadExecutor: 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。示例代码如下： 1234567891011121314151617ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();for (int i = 0; i &lt; 10; i++) &#123;final int index = i;singleThreadExecutor.execute(new Runnable() &#123;@Overridepublic void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000);&#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125;&#125; &#125;);&#125; 结果依次输出，相当于顺序执行各个任务。 现行大多数GUI程序都是单线程的。Android中单线程可用于数据库操作，文件操作，应用批量安装，应用批量删除等不适合并发但可能IO阻塞性及影响UI线程响应的操作。 线程池的作用线程池作用就是限制系统中执行线程的数量。根 据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排 队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池 中有等待的工作线程，就可以开始运行了；否则进入等待队列。 为什么要使用线程池1.减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 2.可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。 Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。 比较重要的几个类： ExecutorService： 真正的线程池接口。 ScheduledExecutorService： 能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。 ThreadPoolExecutor： ExecutorService的默认实现。 ScheduledThreadPoolExecutor： 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现。 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。 newSingleThreadExecutor 创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 newFixedThreadPool 创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 newCachedThreadPool 创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 newScheduledThreadPool 创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 synchronized关键字的用法，优缺点用法： 指定对象加锁:对给定的对象进行加锁,进入同步代码块要获得给定对象的锁 直接作用于实例方法:相当于对当前实例加锁,进入同步代码块要获得当前实例的锁(这要求创建Thread的时候,要用同一个Runnable的实例才可以) 直接作用于静态方法:相当于给当前类加锁,进入同步代码块前要获得当前类的锁 优缺点： 使用synchronized，当多个线程尝试获取锁时，未获取到锁的线程会不断的尝试获取锁，而不会发生中断，这样会造成性能消耗。而ReentranLock的lockInterruptibly()可以优先相应中断。举例：两个线程A，B，A获得了锁（A.lockInterruptibly（）），B在请求锁的时候发生阻塞，如果调用 B.interrupt()，会中断B的阻塞。 多线程的作用（1）发挥多核CPU的优势，提高CPU的利用率（2）防止阻塞，提高效率 什么是线程安全当多个线程访问某一个类（对象或方法）时，这个对象始终都能表现出正确的行为，那么这个类（对象或方法）就是线程安全的。 线程安全级别（1）不可变（2）绝对线程安全（3）相对线程安全（4）线程非安全 如何在两个线程之间共享数据线程之间数据共享，其实可以理解为线程之间的通信，可以用wait/notify/notifyAll 进行等待和唤醒。 Java中提供了对象的那些级别引用在Java中提供了对象的4个级别引用, 分别是强引用、软引用、弱引用以及虚引用。这四个类型的引用中, 只有强类型的引用是包内可见的, 其他级别的引用都是Public, 可以直接被应用程序开发者使用的。 强引用 我们在Java中创建的对象引用, 一般都是强类型引用. 这同样意味着当该对象如果有引用存在的情况下, 同时在JVM整个环境中该对象是路径可达的, 那么该对象永远不会被垃圾回收机制回收的。 例如我们创建一个对象Object object = new Object(); 该object就是一个强引用. 当强引用的对象占用内存过多, 而又没有释放的时候, 就会出现OOM问题; 软引用 软引用使用的时候需要通过一个软引用对象来进行声明, 软引用对象比强引用稍微弱一点, 通过软引用的对象当出现内存不足的情况的时候, 垃圾回收机制会将该类型的对象进行回收 弱引用 弱引用使用的时候需要通过一个弱引用对象进行声明。弱引用可以维持对对象的引用, 但是一旦垃圾回收线程工作的时候, 发现一个对象只有弱引用保持的时候, 那么就会对该对象进行垃圾回收.引用类型是一种比软引用弱的易用类型, 在系统GC时, 只要发现一个对象只有弱引用时不管系统堆空间是否足够, 都会将对象回收。但是由于垃圾回收器的线程通常优先级很低, 因此并不一定能够很快发现只有弱引用持有的对象, 在这种情况下, 弱引用对象可以存在很长的时间。一旦弱引用对象被垃圾回收器回收, 那么有一种机制能够保证该弱引用添加到一个注册引用的队列中。 虚引用 虚引用与其他的引用都不相同, 虚引用并不会决定引用对象的生命周期, 所以虚引用又成为”幽灵引用”。如果一个对象只持有虚引用, 那么该对象就跟没有任何引用一样, 在任何时候都有可能被垃圾回收器回收. 所以没办法在程序中调用它的任何相关函数, 因为存在太多的不确定性。而虚引用主要是用来提供当对象被GC的时候的通知机制. 通过该通知机制我们可以做一些资源回收等方面的工作. 因为对象只存在虚引用完全没有意义, 即在程序中声明一个对象的虚引用完全没有意义, 所以虚引用一定要与Reference队列一起使用, 才能起到对象回收通知机制. Finalizer对象什么时候会在引用队列中对于Java而言： 调用时机：当垃圾回收器要宣告一个对象死亡时，至少要经过两次标记过程：如果对象在进行可达性分析后发现没有和GC Roots相连接的引用链，就会被第一次标记，并且判断是否执行finalizer( )方法，如果对象覆盖finalizer( )方法且未被虚拟机调用过，那么这个对象会被放置在F-Queue队列中，并在稍后由一个虚拟机自动建立的低优先级的Finalizer线程区执行触发finalizer( )方法，但不承诺等待其运行结束。 finalization的目的：对象逃脱死亡的最后一次机会。（只要重新与引用链上的任何一个对象建立关联即可。）但是不建议使用，运行代价高昂，不确定性大，且无法保证各个对象的调用顺序。可用try-finally或其他替代。 CountDownLatch 原理实现原理：计数器的值由构造函数传入，并用它初始化AQS的state值。当线程调用await方法时会检查state的值是否为0，如果是就直接返回（即不会阻塞）；如果不是，将表示该节点的线程入列，然后将自身阻塞。当其它线程调用countDown方法会将计数器减1，然后判断计数器的值是否为0，当它为0时，会唤醒队列中的第一个节点，由于CountDownLatch使用了AQS的共享模式，所以第一个节点被唤醒后又会唤醒第二个节点，以此类推，使得所有因await方法阻塞的线程都能被唤醒而继续执行。 从源代码和实现原理中可以看出一个CountDownLatch对象，只能使用一次，不能重复使用。 CyclicBarrier 原理实现原理：在CyclicBarrier的内部定义了一个Lock对象，每当一个线程调用CyclicBarrier的await方法时，将剩余拦截的线程数减1，然后判断剩余拦截数是否为0，如果不是，进入Lock对象的条件队列等待。如果是，执行barrierAction对象的Runnable方法，然后将锁的条件队列中的所有线程放入锁等待队列中，这些线程会依次的获取锁、释放锁，接着先从await方法返回，再从CyclicBarrier的await方法中返回。 Semaphore 原理信号量主要用于两个目的，一个是用于多个共享资源的互斥使用，另一个用于并发线程数的控制。 Semaphore的流程的一些特性： • 管理一系列许可证，即state共享资源值；• 每acquire一次则state就减1一次，直到许可证数量小于0则阻塞等待；• 释放许可的时候要保证唤醒后继结点，以此来保证线程释放他们所持有的信号量；• 是Synchronized的升级版，因为Synchronized是只有一个许可，而Semaphore就像开了挂一样，可以有多个许可； Exchanger 原理作用：Exchanger类用于两个线程之间交换数据。 换句话说Exchanger提供的是一个交换服务，允许原子性的交换两个（多个）对象，但同时只有一对才会成功。先看一个简单的实例模型。 在上面的模型中，我们假定一个空的栈（Stack），栈顶（Top）当然是没有元素的。同时我们假定一个数据结构Node，包含一个要交换的元素E和一个要填充的“洞”Node。这时线程T1携带节点node1进入栈（cas_push)，当然这是CAS操作，这样栈顶就不为空了。线程T2携带节点node2进入栈，发现栈里面已经有元素了node1，同时发现node1的hold（Node）为空，于是将自己（node2）填充到node1的hold中（cas_fill）。然后将元素node1从栈中弹出（cas_take）。这样线程T1就得到了node1.hold.item也就是node2的元素e2，线程T2就得到了node1.item也就是e1，从而达到了交换的目的。 算法描述就是下图展示的内容。 JDK 5就是采用类似的思想实现的Exchanger。JDK 6以后为了支持多线程多对象同时Exchanger了就进行了改造（为了支持更好的并发），采用ConcurrentHashMap的思想，将Stack分割成很多的片段（或者说插槽Slot），线程Id（Thread.getId()）hash相同的落在同一个Slot上，这样在默认32个Slot上就有很好的吞吐量。当然会根据机器CPU内核的数量有一定的优化，有兴趣的可以去了解下Exchanger的源码。 CountDownLatch 与 CyclicBarrier 区别 CountDownLatch：一个或者多个线程，等待其他多个线程完成某件事情之后才能执行； CyclicBarrier：多个线程互相等待，直到到达同一个同步点，再继续一起执行。 对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。 CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。 线程池中的coreNum和maxNum有什么不同在不同的业务场景中，线程池参数如何设置线程的生命周期 上图是一个线程的生命周期状态流转图，很清楚的描绘了一个线程从创建到终止的过程。 这些状态的枚举值都定义在java.lang.Thread.State下 12345678public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; NEW：毫无疑问表示的是刚创建的线程，还没有开始启动。 RUNNABLE: 表示线程已经触发start()方式调用，线程正式启动，线程处于运行中状态。 BLOCKED：表示线程阻塞，等待获取锁，如碰到synchronized、lock等关键字等占用临界区的情况，一旦获取到锁就进行RUNNABLE状态继续运行。 WAITING：表示线程处于无限制等待状态，等待一个特殊的事件来重新唤醒，如通过wait()方法进行等待的线程等待一个notify()或者notifyAll()方法，通过join()方法进行等待的线程等待目标线程运行结束而唤醒，一旦通过相关事件唤醒线程，线程就进入了RUNNABLE状态继续运行。 TIMED_WAITING：表示线程进入了一个有时限的等待，如sleep(3000)，等待3秒后线程重新进行RUNNABLE状态继续运行。 TERMINATED：表示线程执行完毕后，进行终止状态。 需要注意的是，一旦线程通过start方法启动后就再也不能回到初始NEW状态，线程终止后也不能再回到RUNNABLE状态。 synchronize 实现原理synchronized可以保证方法或者代码块在运行时，同一时刻只有一个方法可以进入到临界区，同时它还可以保证共享变量的内存可见性 Java中每一个对象都可以作为锁，这是synchronized实现同步的基础： 普通同步方法，锁是当前实例对象 静态同步方法，锁是当前类的class对象 同步方法块，锁是括号里面的对象 Lock接口有哪些实现类，使用场景是什么Lock接口有三个实现类，一个是ReentrantLock,另两个是ReentrantReadWriteLock类中的两个静态内部类ReadLock和WriteLock。与互斥锁定相比，读-写锁定允许对共享数据进行更高级别的并发访问。虽然一次只有一个线程（writer 线程）可以修改共享数据，但在许多情况下，任何数量的线程可以同时读取共享数据（reader 线程）。从理论上讲，与互斥锁定相比，使用读-写锁定所允许的并发性增强将带来更大的性能提高。在实践中，只有在多处理器上并且只在访问模式适用于共享数据时，才能完全实现并发性增强。——例如，某个最初用数据填充并且之后不经常对其进行修改的 collection，因为经常对其进行搜索（比如搜索某种目录），所以这样的 collection 是使用读-写锁定的理想候选者。 ReentrantLock 的原理原理：可重入锁的原理是在锁内部维护了一个线程标示，标示该锁目前被那个线程占用，然后关联一个计数器，一开始计数器值为0，说明该锁没有被任何线程占用，当一个线程获取了该锁，计数器会变成1，其他线程在获取该锁时候发现锁的所有者不是自己所以被阻塞，但是当获取该锁的线程再次获取锁时候发现锁拥有者是自己会把计数器值+1， 当释放锁后计数器会-1，当计数器为0时候，锁里面的线程标示重置为null,这时候阻塞的线程会获取被唤醒来获取该锁. ReentrantLock 类实现了Lock ，它拥有与synchronized 相同的并发性和内存语义，但是添加了类似锁投票、定时锁等候和可中断锁等候的一些特性。 此外，它还提供了在激烈争用情况下更佳的性能。（换句话说，当许多线程都想访问共享资源时，JVM 可以花更少的时候来调度线程，把更多时间用在执行线程上。） ReentrantLock扩展的功能1.实现可轮询的锁请求： –在内部锁中，死锁是致命的——唯一的恢复方法是重新启动程序，唯一的预防方法是在构建程序时不要出错。而可轮询的锁获取模式具有更完善的错误 恢复机制，可以规避死锁的发生。 –如果你不能获得所有需要的锁，那么使用可轮询的获取方式使你能够重新拿到控制权，它会释放你已经获得的这些锁，然后再重新尝试。 可轮询的锁获取模式，由tryLock()方法实现。此方法仅在调用时锁为空闲状态才获取该锁。如果锁可用，则获取锁，并立即返回值true。 如果锁不可用，则此方法将立即返回值false。此方法的典型使用语句如下： 12345678910111213141516171819Lock lock = ...; if (lock.tryLock()) &#123; try &#123; // manipulate protected state &#125; finally &#123; lock.unlock(); &#125; &#125; else &#123; // perform alternative actions &#125; 2.实现可定时的锁请求 –当使用内部锁时，一旦开始请求，锁就不能停止了，所以内部锁给实现具有时限的活动带来了风险。为了解决这一问题，可以使用定时锁。 当具有时限的活动调用了阻塞方法，定时锁能够在时间预算内设定相应的超时。如果活动在期待的时间内没能获得结果，定时锁能使程序提前返回。 可定时的锁获取模式，由tryLock(long, TimeUnit)方法实现。 3.实现可中断的锁获取请求 –可中断的锁获取操作允许在可取消的活动中使用。lockInterruptibly()方法能够使你获得锁的时候响应中断。 ReentrantLock不好与需要注意的地方–lock 必须在 finally 块中释放。否则，如果受保护的代码将抛出异常，锁就有可能永远得不到释放！这一点区别看起来可能没什么，但是实际上， 它极为重要。忘记在 finally 块中释放锁，可能会在程序中留下一个定时炸弹，当有一天炸弹爆炸时，您要花费很大力气才有找到源头在哪。 而使用同步，JVM 将确保锁会获得自动释放. –当 JVM 用 synchronized 管理锁定请求和释放时，JVM 在生成线程转储时能够包括锁定信息。这些对调试非常有价值，因为它们能标识死锁或者 其他异常行为的来源。 Lock 类只是普通的类，JVM 不知道具体哪个线程拥有 Lock 对象。 synchronized 和java.util.concurrent.locks.Lock的异同主要相同点：Lock能完成synchronized所实现的所有功能 主要不同点：Lock有比synchronized更精确的线程语义和更好的性能。synchronized会自动释放锁，而Lock一定要求程序员手工释放，并且必须在finally从句中释放。Lock还有更强大的功能，例如，它的tryLock方法可以非阻塞方式去拿锁。 介绍下栈和队列栈和队列都是动态集合，且在其上进行DELETE操作所移除的元素是预先设定的。在栈（stack）中，被删除的是最近插入的元素：栈实现的是一种后进先出（last-in, first-out, LIFO)策略。类似地，在队列（queue）中，被删去的总是在集合中存在时间最长的那个元素：队列实现的是一种先进先出（first-in, first-out, FIFO)策略。 synchronized、Lock、ReentrantLock、ReadWriteLockLock和synchronized有以下几点不同： Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 Lock可以提高多个线程进行读操作的效率。在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。 ReentrantReadWriteLock相比ReentrantLock的最大区别是： ReentrantReadWriteLock的读锁是共享锁，任何线程都可以获取，而写锁是独占锁。ReentrantLock不论读写，是独占锁。 介绍下CAS(无锁技术)CAS: java.util.concurrent包中借助CAS实现了区别于synchronouse同步锁的一种乐观锁。 CAS应用：CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 CAS原理:CAS通过调用JNI的代码实现的。JNI:Java Native Interface为JAVA本地调用，允许java调用其他语言。 CAS缺点: CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作 ThreadPoolExecutor的内部工作原理 如果线程池大小poolSize小于corePoolSize，则创建新线程执行任务。 如果线程池大小poolSize大于corePoolSize，且等待队列未满，则进入等待队列。 如果线程池大小poolSize大于corePoolSize且小于maximumPoolSize，且等待队列已满，则创建新线程执行任务。 如果线程池大小poolSize大于corePoolSize且大于maximumPoolSize，且等待队列已满，则调用拒绝策略来处理该任务。 线程池里的每个线程执行完任务后不会立刻退出，而是会去检查下等待队列里是否还有线程任务需要执行，如果在keepAliveTime里等不到新的任务了，那么线程就会退出。 ThreadPoolExecutor线程池中拒绝策略： AbortPolicy：为java线程池默认的阻塞策略，不执行此任务，而且会直接抛出一个执行时异常，切记TreadPoolExecutor.execute需要try catch，否则程序会直接退出。 DiscardPolicy：直接抛弃，任务不执行，空方法 DiscardOldestPolicy：从队列里面抛弃head的一个任务，并再次execute 此任务（task） CallerRunsPolicy：在调用execute的线程里面执行此command，会阻塞入口。 用户自定义拒绝策略：实现RejectdExecutionHandler，并自己定义策略模式。 分布式环境下，怎么保证线程安全有哪些类加载器能不能自己写一个类叫java.lang.String可以，但在应用的时候，需要用自己的类加载器去加载，否则，系统的类加载器永远只是去加载jre.jar包中的那个java.lang.String。由于在tomcat的web应用程序中，都是由webapp自己的类加载器先自己加载WEB-INF/classess目录中的类，然后才委托上级的类加载器加载，如果我们在tomcat的web应用程序中写一个java.lang.String，这时候Servlet程序加载的就是我们自己写的java.lang.String，但是这么干就会出很多潜在的问题，原来所有用了java.lang.String类的都将出现问题。 虽然java提供了endorsed技术，可以覆盖jdk中的某些类，具体做法是….。但是，能够被覆盖的类是有限制范围，反正不包括java.lang这样的包中的类。 例如，运行下面的程序： 1234567891011package java.lang;public class String &#123;public static void main(String[] args) &#123;System.out.println("string");&#125;&#125; 报告的错误如下： java.lang.NoSuchMethodError: main Exception in thread “main” 这是因为加载了jre自带的java.lang.String，而该类中没有main方法。 介绍下B树、二叉树B树： B树（英语：B-tree）是一种自平衡的树)，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一个一般化的二叉查找树（binary search tree），可以拥有多于2个子节点。与自平衡二叉查找树不同，B树为系统大块数据的读写操作做了优化。B树减少定位记录时所经历的中间过程，从而加快存取速度。B树这种数据结构可以用来描述外部存储。这种数据结构常被应用在数据库和文件系统的实现上。 概括关键词：自平衡，可以拥有多于2个子节点，适用于数据库和文件系统。 二叉树： 二叉树是一种特殊的有序树：每个节点至多有两个分支（子节点），分支具有左右次序，不能颠倒。两种特殊的二叉树：完全二叉树：除最后一层外，若其余层都是满的，并且最后一层或者是满的，或者是在右边缺少连续若干节点（注意是右边，而不能是左边缺少）。满二叉树：每一层都是满的（除了最后一层，这里的最后一层是指叶节点）。 红黑树： 红黑树（英语：Red–black tree）是一种自平衡二叉查找树。它的操作有着良好的最坏情况运行时间，并且在实践中是高效的：它可以在O(log n)时间内做查找，插入和删除，这里的n是树中元素的数目。 红黑树的性质 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径)都包含相同数目的黑色节点。 分布式锁的实现针对分布式锁的实现，目前比较常用的有以下几种方案： (1).基于数据库实现分布式锁 (2).基于缓存（redis，memcached，tair）实现分布式锁 (3).基于Zookeeper实现分布式锁 实现方式 优点 缺点 数据库实现 直接借助数据库，容易理解。 1. 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。 2.操作数据库需要一定的开销，性能问题需要考虑。 使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。 缓存实现 性能好，实现起来较为方便。 1.通过超时时间来控制锁的失效时间并不是十分的靠谱。 Zookeeper实现 有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。 1.性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。 三种方法比较： 上面几种方式，哪种方式都无法做到完美。就像CAP一样，在复杂性、可靠性、性能等方面无法同时满足，所以，根据不同的应用场景选择最适合自己的才是王道。 从理解的难易程度角度（从低到高） 数据库 &gt; 缓存 &gt; Zookeeper 从实现的复杂程度角度（从低到高） Zookeeper &gt;= 缓存 &gt; 数据库 从性能角度（从高到低） 缓存 &gt; Zookeeper &gt;= 数据库 从可靠性角度（从高到低） Zookeeper &gt; 缓存 &gt; 数据库 分布式session存储解决方案1. Session Stick Session Stick 方案即将客户端的每次请求都转发至同一台服务器，这就需要负载均衡器能够根据每次请求的会话标识（SessionId）来进行请求转发，如下图所示。 这种方案实现比较简单，对于Web服务器来说和单机的情况一样。但是可能会带来如下问题： 如果有一台服务器宕机或者重启，那么这台机器上的会话数据会全部丢失。 会话标识是应用层信息，那么负载均衡要将同一个会话的请求都保存到同一个Web服务器上的话，就需要进行应用层（第7层）的解析，这个开销比第4层大。 负载均衡器将变成一个有状态的节点，要将会话保存到具体Web服务器的映射。和无状态节点相比，内存消耗更大，容灾方面也会更麻烦。 2. Session Replication Session Replication 的方案则不对负载均衡器做更改，而是在Web服务器之间增加了会话数据同步的功能，各个服务器之间通过同步保证不同Web服务器之间的Session数据的一致性，如下图所示。 Session Replication 方案对负载均衡器不再有要求，但是同样会带来以下问题： 同步Session数据会造成额外的网络带宽的开销，只要Session数据有变化，就需要将新产生的Session数据同步到其他服务器上，服务器数量越多，同步带来的网络带宽开销也就越大。 每台Web服务器都需要保存全部的Session数据，如果整个集群的Session数量太多的话，则对于每台机器用于保存Session数据的占用会很严重。 3. Session 数据集中存储 Session 数据集中存储方案则是将集群中的所有Session集中存储起来，Web服务器本身则并不存储Session数据，不同的Web服务器从同样的地方来获取Session，如下图所示。 相对于Session Replication方案，此方案的Session数据将不保存在本机，并且Web服务器之间也没有了Session数据的复制，但是该方案存在的问题在于： 读写Session数据引入了网络操作，这相对于本机的数据读取来说，问题就在于存在时延和不稳定性，但是通信发生在内网，则问题不大。 如果集中存储Session的机器或集群出现问题，则会影响应用。 4. Cookie Based Cookie Based 方案是将Session数据放在Cookie里，访问Web服务器的时候，再由Web服务器生成对应的Session数据，如下图所示。 但是Cookie Based 方案依然存在不足： Cookie长度的限制。这会导致Session长度的限制。 安全性。Seesion数据本来是服务端数据，却被保存在了客户端，即使可以加密，但是依然存在不安全性。 带宽消耗。这里不是指内部Web服务器之间的宽带消耗，而是数据中心的整体外部带宽的消耗。 性能影响。每次HTTP请求和响应都带有Seesion数据，对Web服务器来说，在同样的处理情况下，响应的结果输出越少，支持的并发就会越高。 总结前面四个方案都是可行的，但是对于大型网站来说，Session Sticky和Session数据集中存储是比较好的方案。 常用的linux命令mkdir: 用于新建一个新目录 pwd: 显示当前工作目录 rmdir: 删除给定的目录。 rm: 会删除给定的文件 mv: 命令对文件或文件夹进行移动，如果文件或文件夹存在于当前工作目录，还可以对文件或文件夹进行重命名。 cat: 用于在标准输出（监控器或屏幕）上查看文件内容 tail: 默认在标准输出上显示给定文件的最后10行内容，可以使用tail -n N 指定在标准输出上显示文件的最后N行内容。 less: 按页或按窗口打印文件内容。在查看包含大量文本数据的大文件时是非常有用和高效的。你可以使用Ctrl+F向前翻页，Ctrl+B向后翻页。 grep: 在给定的文件中搜寻指定的字符串。grep -i “” 在搜寻时会忽略字符串的大小写，而grep -r “” 则会在当前工作目录的文件中递归搜寻指定的字符串。 find: 这个命令会在给定位置搜寻与条件匹配的文件。你可以使用find -name 的-name选项来进行区分大小写的搜寻，find -iname 来进行不区分大小写的搜寻。 tar: 命令能创建、查看和提取tar压缩文件。tar -cvf 是创建对应压缩文件，tar -tvf 来查看对应压缩文件，tar -xvf 来提取对应压缩文件。 gzip: 命令创建和提取gzip压缩文件，还可以用gzip -d 来提取压缩文件。 unzip: 对gzip文档进行解压。在解压之前，可以使用unzip -l 命令查看文件内容。 whatis: 会用单行来描述给定的命令，就是解释当前命令。 exit: 用于结束当前的终端会话。 who: 能列出当前登录的用户名。 su: 用于切换不同的用户。即使没有使用密码，超级用户也能切换到其它用户。 uname: 会显示出关于系统的重要信息，如内核名称、主机名、内核版本、处理机类型等等，使用uname -a可以查看所有信息。 df: 查看文件系统中磁盘的使用情况–硬盘已用和可用的存储空间以及其它存储设备。你可以使用df -h将结果以人类可读的方式显示。 ps: 显示系统的运行进程。 top: 命令会默认按照CPU的占用情况，显示占用量较大的进程,可以使用top -u 查看某个用户的CPU使用排名情况。 文章地址：https://www.jianshu.com/p/0056d671ea6d https://juejin.im/post/5a9f5ce86fb9a028de443ed9]]></content>
      <categories>
        <category>基础面试题</category>
      </categories>
      <tags>
        <tag>基础面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的基本要素]]></title>
    <url>%2F2018%2F01%2F15%2FPython%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%A6%81%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[Python 的基本要素 基本数据类型 对象引用 组合数据类型 逻辑操作符 控制流语句 算数操作符 输入/输出 函数的创建与调用 要素1：基本数据类型 任何数据语言都必须能够表示基本数据项目 Python 中的基本数据类型有 【1】Integral 类型 ​ （1）.整型：不可变类型 1num = 1 #被保存在内存中，是不可变的 ​ 注意：对象和变量都是不可变的 ​ （2）.布尔型 (Ture、False) ​ 注意：加引号 【2】浮点类型 ​ （1）. 浮点数字 ​ （2）. 复数 【3】字符串 ​ 注意：在这里字符串表示的序列。 1type(放任意的类型) # 输出变量的类型 ​ 要素2：对象引用（变量） Python 将所有数据存为内存对象 Python 中，对象事实上是只想内存对象的引用 动态类型：在任何时刻，只要需要，某个对象都可以重新引用一个不同的对象（可以是不同的数据类型） 内建函数type()用于返回给定数据项的数据类型 “=” 用于将变量名与内存中的某个对象进行绑定：如果对象事先存在，就直接绑定；否则用 “=” 创建引用的对象。 变量的命名规则 只能包含字母下、数字和下划线，且不能以数字开头。 区分数字大小写 禁止使用保留字段（Python2和Python3有所不同） 命名惯例 一单个下划线开头的变量名称 (_x) 不会被 from model import * 语句导入 前后都有下滑线的变量名(x ) 是系统定义的变量名称，对 Python 解释器有特殊的意义 以两个下划线开头但结尾没有下划线的变量名称(__x)是类的本地变量 交互模式下，变量名 “—” 用于保存最后表达式的结果 1234&gt;&gt;&gt; 1+12&gt;&gt;&gt; print(_)2 ​ 注意： 变量名没有类型，对象才有 变量可以指定任何类型（这是 Python 和其他语言不同的） 要素3：组合数据类型 数据结构：通过某种方式（例如对元素进行编码）组织在一起的数据元素的集合 Python 常用的组合数据类型 序列类型 列表：使用[]创建，如[‘Call’,’me’,’Ishmell’,’_’] 12345&gt;&gt;&gt; l1 = ['Call','me','Ishmell','_']&gt;&gt;&gt; l1[0]'Call'&gt;&gt;&gt; l1[0][0]'C' 注意：列表是可变的，可以在原处进行修改，且内容改变，id 不会改变 1234567891011121314&gt;&gt;&gt; print(l1)['Call', 'me', 'Ishmell', '_']&gt;&gt;&gt; print(l1[1])me&gt;&gt;&gt; l1[1] = 'your'&gt;&gt;&gt; print(l1)['Call', 'your', 'Ishmell', '_']&gt;&gt;&gt; id(l1)1543556324360&gt;&gt;&gt; l1[2]= 'Xshell'&gt;&gt;&gt; print(l1)['Call', 'your', 'Xshell', '_']&gt;&gt;&gt; id(l1)1543556324360 ​ 元组：使用 () 创建，如(‘one’,’two’) 12345&gt;&gt;&gt; t1 = ('This','is')&gt;&gt;&gt; t1[1]'is'&gt;&gt;&gt; t1[0]'This' 注意: 元组是不能做原处修改的，一旦修改就会引发异常 ​ 字符串也属于序列类型 优点：可以做字符串的切块操作 123456789101112131415&gt;&gt;&gt; name = 'jerry'&gt;&gt;&gt; name[0]'j'&gt;&gt;&gt; name[0:1]'j'&gt;&gt;&gt; name[0:2]'je'&gt;&gt;&gt; name[:2]'je'&gt;&gt;&gt; name[2:]'rry'&gt;&gt;&gt; name[0:4]'jerr'&gt;&gt;&gt; name[0:4:2]'jr' 注意：切块本身会创建新的对象（因为字符串本身是不可用的） 集合类型 集合（杂乱的数据） 映射类型 字典 列表是可变序列，元组是不可变序列 Python 中，组合数据类型也是对象，因此其可以嵌套 [‘hello’,’worle’,[1,2,3]] 实质上，列表和元组并不是真正存储数据，而是存放对象引用 Python 对象可以具有其可以被调用的特定 “方法（函数）” 元组、列表以及字符串等数据类型是“有大小的”，也即，其长度可用内置函数 len() 测量 要素4：逻辑操作符 逻辑运算是任何程序设计语言的基本共能 Python 提供了4 组逻辑运算符 身份操作符 is:判断左端对象引用是否等于右端对象引用；也可以与Node进行； 对象引用可以不同，但是对象 所属的类型有可能是相同 1234&gt;&gt;&gt; name="swfswf"&gt;&gt;&gt; test="swfswf"&gt;&gt;&gt; type(name) is type(test)True 比较操作符号 &lt;,&gt;,&lt;=,&gt;=,!=,== 成员操作符 in 或 not in :测试成员关系 逻辑运算符 and、or、not 要素5：控制流语句 控制流语句是过程式编程语言的基本控制机制 Python 的常见控制流语句 if 1234567if boolean_expression1: suite1else if boolean_expression2: suite2.....else: else_suite 注意：冒号是代码块起始的标志 while 12while boolean_expression: suite for…in 12for variable in iterable: suite try 要素6：算数操作符 Python 提供了完整的算数操作符集 很多的 Python 数据类型也可以使用增强的赋值操作符，如+=、-= 等 同样的功能使用增强型赋值操作符的性能较好。 Python 的 int 类型是不可变的，因此，增强型赋值的实际过程是创建了一个新的对象来存储结果后将变量名执行了重新绑定 要素7：输入/输出 现实中，具有实际共能的程序必须能够读取输入（如从键盘或文件中），以及产生输出，并写到终端或文件中 Python 的输入/输出 输出 Python3：print() 函数 Python2: print 语句 输入 input() 12345678910&gt;&gt;&gt; input("plz input a num:")plz input a num:a'a'&gt;&gt;&gt; input("plz input a num:")plz input a num:3'3'&gt;&gt;&gt; a = input("plz input a num:")plz input a num:Hello&gt;&gt;&gt; print(a)Hello row_input() Python 解释器提供了 3 中标准的文件对象，分别为标准输入、标准输出和标准错误，它们 sys 模块中分别以 sys.stdin、sys.stdout 和 sys.stderr 形式提供 Python 的 print 语句实现打印 从技术角度来讲，print 是把一个或多个对象转化为其文本表达形式，然后发送给标准输出或另一个类似文件的流 在 Python 中，打印与文件和流的概念联系紧密 文件写入方法是把字符串写入到任意文件 print 默认把对象打印到 stdout 流，并添加一些自动的格式化 实质上，print 语句只是 Python 的人性化特性的具体实现，它提供了 sys.stdout.write() 的简单接口，再加上一些默认的格式设置 print 接受一个逗号分隔的对象列表，并为行尾自动添加一个换行符，如果不需要，则在最后个元素后面添加逗号 实现格式化输出，print “String %format1%format2…”%(varialbe1,varialbe2,…….) | 字符 | 输出格式 || —- | ————————– || d,i | 十进制整数或长整型 || u | 无符号整数或长整型 || o | 八进制整数或长整型 || x | 十六进制整数或长整型 || X | 十六进制整数 || f | 浮点数 || e | 浮点数 || E | 浮点数 || g,G | 指数小于-4或更高精度时使用%e或%E,否则使用%f || s | 字符串火任意对象，格式化代码使用str()生成字符串 || r | 同 repr() 生成的字符串 || c | 单个字符 || % | 字面量% | ​ 1234567891011121314151617&gt;&gt;&gt; num = 7.9&gt;&gt;&gt; print("The num is %f" %num)The num is 7.900000&gt;&gt;&gt; print("The num is %d" %num)The num is 7&gt;&gt;&gt; num2 = 9.13&gt;&gt;&gt; print("The nums are %d and %f" %(num,num2))The nums are 7 and 9.130000&gt;&gt;&gt; print("The nums are %e and %f"%(num,3.1))The nums are 7.900000e+00 and 3.100000&gt;&gt;&gt; print("The nums are %d and %f"%(num,3.1))The nums are 7 and 3.100000&gt;&gt;&gt; name = "Jerry"&gt;&gt;&gt; print("The name is %s."%name)The name is Jerry.&gt;&gt;&gt; print("The name is %s."%num)The name is 7.9. 注意：Python 的输出是需要转换的。 数据转换类型： 显示转换 123456&gt;&gt;&gt; num = 7.9&gt;&gt;&gt; test3 = str(num)&gt;&gt;&gt; type(test3)&lt;class 'str'&gt;&gt;&gt;&gt; type(num)&lt;class 'float'&gt; 隐式转换 想知道内置有多少种类型 python3 123&gt;&gt;&gt; dir()['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'name', 'num', 'num2', 'test3']&gt;&gt;&gt; dir(__builtins__) python2 123&gt;&gt;&gt;dir(builtins)['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'name', 'num', 'num2', 'test3']&gt;&gt;&gt; dir(__builtins__) 想明确一个工具怎么使用 1234567891011&gt;&gt;&gt; help(str)Help on class str in module builtins:class str(object) | str(object='') -&gt; str | str(bytes_or_buffer[, encoding[, errors]]) -&gt; str | | Create a new string object from the given object. If encoding or | errors is specified, then the object must expose a data buffer | that will be decoded using the given encoding and error handler. .... % 后面可以使用的修饰符，（如果有只能按如下的顺序） 1%[(name)][flags][width][.precision]typecode 位于括号中的一个属性后面的字典的键名，用于选出一个具体项 下面标志中的一个或多个 减号（-）:表示左对齐，默认为右对齐 1234&gt;&gt;&gt; print("The name are %+10f and %+f"%(num,-3.1))The name are +7.900000 and -3.100000&gt;&gt;&gt; print("The name are %-20f and %+f"%(num,-3.1))The name are 7.900000 and -3.100000 ​ 加号（+）:表示包含数字符号，整数也会带 “+” 1234567891011&gt;&gt;&gt;num=7.9&gt;&gt;&gt; print("The name are %+e and %f"%(num,3.1))The name are +7.900000e+00 and 3.100000&gt;&gt;&gt; print("The name are %+e and %+f"%(num,3.1))The name are +7.900000e+00 and +3.100000&gt;&gt;&gt; print("The name are %+e and %f"%(num,-3.1))The name are +7.900000e+00 and -3.100000&gt;&gt;&gt; print("The name are %+e and %+f"%(num,-3.1))The name are +7.900000e+00 and -3.100000&gt;&gt;&gt; print("The name are %f and %f"%(num,-3.1))The name are 7.900000 and -3.100000 零（0）:表示一个零填充 一个指定最小宽度的数 一个小数,用于按照精度分割字段的宽度(如下例子：15指小数占15位数) 12&gt;&gt;&gt; print("The name are %-20.15f and %+f"%(num,-3.1))The name are 7.900000000000000 and -3.100000 一个数字,指定要打印字符串中的最大字符个数，浮点数中小数点之后的位数，或者整数最小位数。 字典：kv集合（键值对集合） 123456&gt;&gt;&gt; d1=&#123;'a':33,'b':66&#125;&gt;&gt;&gt; d1['a']33&gt;&gt;&gt; d1=&#123;0:33,1:66&#125; &gt;&gt;&gt; d1[0]33 注意字典也是可变对象;键可以是字符也可以是数字 12345&gt;&gt;&gt; d=&#123;'x':32,'y':27.490325,'z':65&#125; &gt;&gt;&gt; print("%(x)-10d %(y)0.3g"%d) 32 27.5 ​ 要素8：函数的创建与调用 函数实现模块化编程的组件 Python 使用 def 语句定义函数 12def functionName(arguments): suite 函数可以参数化，通过传递不同的参数来调用。 1234&gt;&gt;&gt; def printName(name): print(name)&gt;&gt;&gt; printName('Tony')Tony 注意：函数也是对象 每个 Python 函数都有一个返回值，默认为None,也可以使用 “return value” 明确定义返回值 def 会创建一个函数对象，并同时创建一个函数的对象引用 函数也是对象，可以存储在组合数据类型中，也可以作为参数传递给其他函数 callable() 可用于测试函数是否可调用 1234&gt;&gt;&gt; callable(name)False&gt;&gt;&gt; callable(printName)True Python 有众多内置函数 dir()、id()、type() 、str()、help()、len()、callable() 等等 Python 标准库拥有众多内置模块，这些模块拥有大量的函数 Python 模块实际上是包含 Python 代码的 .py 文件，其拥有自定义的函数与类及变量等 导入代码块使用 import 语句进行，后跟模块名称（不能指定模块文件的后缀.py） 导入一个模块后，可以访问其内部的任意函数、类及变量]]></content>
      <categories>
        <category>Python 基础</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 常用的内置（BIF）函数]]></title>
    <url>%2F2018%2F01%2F01%2F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python 常用的内置函数如果你遇到一个需求，且你认为这个需求很普遍，先想想有没有什么内置函数可以使用（BIF）。另外要记住：Python 3 包含 70 多个 BIF ，所以有大量现成的功能等着你来发现。 list()这是一个工厂函数，创建一个新的空列表。 1234import os;aTuole = (123,'xyz','zare','abc');aList = list(aTuole);print("列表元素：",aList); range()range() BIF 迭代固定次数。 可以提供你需要的控制来迭代指定的次数，而且可以用来生成一个从 0 直到（但不包含）某个数的数字列表。 一下是这个 BIF 的用法： 1234import os;# num 是目标标识符，会琢个赋值为 "range()" 生成的各个数字for num in range(4); print(num); F5 运行程序 enumerate()创建成对数据的一个编码列表，从 0 开始 先来做一个对比: 法1: 使用 range() 和 len() 来实现 123import os;aTuole = ('xyz','zare','abc'); print(i,aTuole[i]); 法2:使用enumerate () 来实现 1234import os;aTuole = ('xyz','zare','abc');for index,text in enumerate(aTuole): print(index,text); enumerate会将数组或列表组成一个索引序列。使我们再获取索引和索引内容的时候更加方便。 int()int()函数的作用是将一个数字或base类型的字符串转换成整数。 函数原型 int(x, base=10)，base缺省值为10，也就是说不指定base的值时，函数将x按十进制处理。 注意： x 可以是数字或字符串，但是base被赋值后 x 只能是字符串 x 作为字符串时必须是 base 类型，也就是说 x 变成数字时必须能用 base 进制表示 【1】 x 是数字的情况： 123int(2.345) # 2int(2e2) # 200int(23, 2) # 出错，base 被赋值后函数只接收字符串 【2】x 是字符串的情况： 12int('23', 16) # 35int('HI', 16) # 出错，HI不是个16进制数 【3】 base 可取值范围是 2~36，囊括了所有的英文字母(不区分大小写)，十六进制中F表示15，那么G将在二十进制中表示16，依此类推….Z在三十六进制中表示35 12int('FZ', 16) # 出错，FZ不能用十六进制表示int('FZ', 36) # 575 【4】字符串 0x 可以出现在十六进制中，视作十六进制的符号，同理 0b 可以出现在二进制中，除此之外视作数字 0 和字母 x 123int('0x10', 16) # 16，0x是十六进制的符号int('0x10', 17) # 出错，'0x10'中的 x 被视作英文字母 xint('0x10', 36) # 42804，36进制包含字母 x id()id(object)函数是返回对象object在其生命周期内位于内存中的地址，id函数的参数类型是一个对象。 注意： 我们需要明确一点就是在Python中一切皆对象，变量中存放的是对象的引用。这个确实有点难以理解，“一切皆对象”？对，在Python中确实是这样，包括我们之前经常用到的字符串常量，整型常量都是对象。 1234567import os;print(id(5));print( id('python'));x=2print(id(x));y='hello'print(id(y)); 这段代码的运行结果: 1234567import os;x=2print(id(2));print(id(x)); y='hello'print(id('hello')); print(id(y)); 运行结果: 结果说明:对于这个语句id(2)没有报错，就可以知道2在这里是一个对象。id(x)和id(2)的值是一样的，id(y)和id(‘hello’)的值也是一样的。 12345678x=2;print(id(x));y=2;print(id(y));s='hello';print(id(s));t=s;print(id(t)); 运行结果: 结果说明:id(x)和id(y)的结果是相同的，id(s)和id(t)的结果也是相同的。这说明x和y指向的是同一对象，而t和s也是指向的同一对象。x=2这句让变量x指向了int类型的对象2，而y=2这句执行时，并不重新为2分配空间，而是让y直接指向了已经存在的int类型的对象2.这个很好理解，因为本身只是想给y赋一个值2，而在内存中已经存在了这样一个int类型对象2，所以就直接让y指向了已经存在的对象。这样一来不仅能达到目的，还能节约内存空间。t=s这句变量互相赋值，也相当于是让t指向了已经存在的字符串类型的对象’hello’。 看这幅图就理解了： 1234567891011121314x=2;print(id(2)); print(id(x)); x=3;print(id(3)); print(id(x)); L=[1,2,3];M=L;print(id(L));print(id(M)); print(id(L[2])); L[0]=2;print(id(L)); print(M); 运行结果: 结果分析:两次的id(x)的值不同，这个可能让人有点难以理解。注意，在Python中，单一元素的对象是不允许更改的，比如整型数据、字符串、浮点数等。x=3这句的执行过程并不是先获取x原来指向的对象的地址，再把内存中的值更改为3，而是新申请一段内存来存储对象3，再让x去指向对象3，所以两次id(x)的值不同。然而为何改变了L中的某个子元素的值后，id(L)的值没有发生改变？在Python中，复杂元素的对象是允许更改的，比如列表、字典、元组等。Python中变量存储的是对象的引用，对于列表，其id()值返回的是列表第一个子元素L[0]的存储地址。就像上面的例子，L=[1,2,3]，这里的L有三个子元素L[0]，L[1]，L[2]，L[0]、L[1]、L[2]分别指向对象1、2、3，id(L)值和对象3的存储地址相同. 看下面这个图就明白了: 因为L和M指向的是同一对象，所以在更改了L中子元素的值后，M也相应改变了，但是id(L)值并没有改变，因为这句L[0]=2只是让L[0]重新指向了对象2，而L[0]本身的存储地址并没有发生改变，所以id(L)的值没有改变（ id(L)的值实际等于L[0]本身的存储地址）。 next()next()函数返回迭代器的下一个元素 1234567it = iter([10, 20, 30, 40])while True: try: x = next(it) print(x); # 或者 x = it.next() except StopIteration: break 运行结果:]]></content>
      <categories>
        <category>常用的内置（BIF）函数</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python发布包到pypi]]></title>
    <url>%2F2018%2F01%2F01%2Fpython%E5%8F%91%E5%B8%83%E5%8C%85%E5%88%B0pypi%2F</url>
    <content type="text"><![CDATA[python发布包到pypipython更新太快了，甚至连这种发布上传机制都在不断的更新，这导致网上的一些关于python发布上传到pypi的教程都过时了，按着博文操作可能会失败。 pypi相关概念介绍关于pypi本身 pypi是专门用于存放第三方python包的地方，你可以在这里找别人分享的模块，也可以自己分享模块给别人。可以通过easy_install或者pip进行安装。pypi针对分享提供了两个平台，一个是测试发布平台，一个是正式发布平台，我们正式发布前可以先用测试发布平台发布，看是否正确，然后再采用正式发布平台． 关于python打包发布工具 python的打包安装工具也经历了很多次变化，由最早的distutils到setuptools到distribute又回到setuptools，后来还有disutils2以及distlib等，其中distutils是python标准库的一部分，它提出了采用setup.py机制安装和打包发布上传机制．setuptools(操作系统发布版本可能没有自带安装,需要自己额外安装)基于它扩展了很多功能，也是采用setup.py机制，针对安装额外提供了easy_install命令．distribute是setuptools的一个分之，后来又合并到setuptools了，所以姑且就把它看做是最新的setuptools吧！和我们打包最相关的貌似就是distutils或者setuptools，两者都可以用来打包发布并上传到pypi，后面介绍采用distutils，如果想更多的功能，比如想通过entry points扩展的一些功能，那么就要使用setuptools了．另外，还有一个工具可以用来发布到pypi，叫twine，需要额外安装．最后,需要确保自己的工具都是尽量新的,官方给出的版本参考:twine v1.8.0+ (recommended tool), setuptools 27+, or the distutils included with Python 3.4.6+,Python 3.5.3+, Python 3.6+, and 2.7.13+,升级的参考命令: sudo -H pip install -U pip setuptools twine 写一个 setup.py123456789from distutils.core import setup # 从 Python 发布工具导入 setup 函数setup( name='swfswf', # 要打包的模块名称 version='1.0', description='Python Distribution Utilities', author='shenwenfang', author_email='1978626782@qq.com', url='https://swenfang.github.io/', ) 也可参阅官方文档： https://docs.python.org/2/dis… 注意： 这里只是最基本的参考例子，执行打包会报警告，说缺少一些需要的文件，比如MANIFEST.in、readme.txt等等，暂时忽略即可。正式的项目中会复杂很多，甚至需要用到setuptools来扩展。这部分可以参考其他文档 为了保证效果，在打包之前我们可以验证setup.py的正确性。执行代码python setup.py check，输出一般是running check，如果有错误或者警告，就会在此之后显示.没有任何显示表示Distutils认可你这个setup.py文件 执行 python setup.py sdist upload -r pypi 创建发布并上传,如果想先上传到测试平台，可以执行 python setup.py sdist upload -r pypitest，成功后再执行上面命令上传到正式平台。注意，这一步的配置文件里面由于pypi的发布机制更新导致有一些问题的出现。 410错误：这个是pypi上传机制变更导致的,我虽然参考的是最新的blog，但是还是过时了！！！（.pypirc的repository过时了，很多博客说的repository: https://pypi.python.org/pypi会导致后面步骤操作出现410错误） ​ 打包发布到pypi基本流程： 注册 pypi 账号，如果期望测试发布，同时需要注册pypitest账号（可以采用相同的用户名和密码） 直接通过官网注册 https://pypi.python.org/pypi?…，填写用户名、密码、确认密码、邮箱， 但是需要验证邮件并确认激活。 创建配置文件, 该配置文件里面记录了你的账号信息以及要发布的平台信息，参考如下配置文件创建即可 在自己的用户目录下新建一个空白文件命名为.pypirc，内容如下： 123456789101112[distutils]index-servers=pypi[pypi]repository = https://upload.pypi.org/legacy/username = shenwenfangpassword = **************# 如果期望测试发布，同时需要#repository: https://test.pypi.org/legacy/#username= your_username#password= your_password 相关命令： 1python setup.py check #验证setup.py的正确性 1python setup.py sdist upload -r pypi #打包发布到pypi，返回 "Server response (200) : OK" 说明上传成功 查看上传记录： 如果你的包已经上传成功，那么当你登录PyPI网站后应该能在右侧导航栏看到管理入口。 测试代码块12import swfswf;swfswf.print_lol(参数1，参数2...) 管理你的包如果你的包已经上传成功，那么当你登录PyPI网站后应该能在右侧导航栏看到管理入口。 点击包名进去后你可以对你的包进行管理，当然你也可以从这里删除这个包。 让别人使用你的包包发布完成后，其他人只需要使用pip就可以安装你的包文件。比如： 1pip install package-name 如果你更新了包，别人可以可以通过--update参数来更新： 1pip install package-name --update 可能遇到的错误 410错误：.pypirc的repository过时了，很多博客说的repository: https://pypi.python.org/pypi会导致后面步骤操作出现410错误 403错误：是因为项目和已有 的项目重名了，可以先到 https://pypi.python.org/simple/ 上搜一下看看是否重名。解决的方法自然就是修改一下setup.py中setup函数中的name参数，删除之前生成的dist文件夹并重新生成，然后再upload 参考文章： https://www.xncoding.com/2015/10/26/python/setuptools.html https://segmentfault.com/a/1190000008663126 http://www.cnblogs.com/rongpmcu/p/7662821.html]]></content>
      <categories>
        <category>发布包到pypi</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 红黑树源码解读]]></title>
    <url>%2F2017%2F12%2F26%2FJava%20%E7%BA%A2%E9%BB%91%E6%A0%91%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[Java 红黑树源码解读目录红黑树的介绍红黑树(Red-Black Tree，简称R-B Tree)，它一种特殊的二叉查找树。红黑树是特殊的二叉查找树，意味着它满足二叉查找树的特征: 任意一个节点所包含的键值，大于等于左孩子的键值，小于等于右孩子的键值。除了具备该特性之外，红黑树还包括许多额外的信息。 红黑树的每个节点上都有存储位表示节点的颜色，颜色是红(Red)或黑(Black)。红黑树的特性:【1】 每个节点或者是黑色，或者是红色。【2】 根节点是黑色。【3】 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！]【4】 如果一个节点是红色的，则它的子节点必须是黑色的。【5】 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。 关于它的特性，需要注意的是：第一，特性(3)中的叶子节点，是只为空(NIL或null)的节点。第二，特性(5)，确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。 红黑树示意图如下： 红黑树的原理在研究红黑树原理，我们可以通过以下的实例进行 debug 调试，看它的整个执行过。接着再阅读以下内容，会比较容易理解红黑的原理，才能进一步深入研究清楚。 实例地址：https://github.com/KnIfER/RBTree-java 红黑树的实现(代码说明)红黑树的基本操作是添加、删除和旋转。在对红黑树进行添加或删除后，会用到旋转方法。为什么呢？道理很简单，添加或删除红黑树中的节点之后，红黑树就发生了变化，可能不满足红黑树的5条性质，也就不再是一颗红黑树了，而是一颗普通的树。而通过旋转，可以使这颗树重新成为红黑树。简单点说，旋转的目的是让树保持红黑树的特性。旋转包括两种：左旋 和 右旋。下面分别对红黑树的基本操作进行介绍。 1. 基本定义1234567891011121314151617181920212223242526public class RBTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private RBTNode&lt;T&gt; mRoot; // 根结点 private static final boolean RED = false; private static final boolean BLACK = true; public class RBTNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; boolean color; // 颜色 T key; // 关键字(键值) RBTNode&lt;T&gt; left; // 左孩子 RBTNode&lt;T&gt; right; // 右孩子 RBTNode&lt;T&gt; parent; // 父结点 public RBTNode(T key, boolean color, RBTNode&lt;T&gt; parent, RBTNode&lt;T&gt; left, RBTNode&lt;T&gt; right) &#123; this.key = key; this.color = color; this.parent = parent; this.left = left; this.right = right; &#125; &#125; ...&#125; RBTree是红黑树对应的类，RBTNode是红黑树的节点类。在RBTree中包含了根节点mRoot和红黑树的相关API。注意：在实现红黑树API的过程中，我重载了许多函数。重载的原因，一是因为有的API是内部接口，有的是外部接口；二是为了让结构更加清晰。 2. 左旋 对x进行左旋，意味着”将x变成一个左节点”。 左旋的实现代码(Java语言) 1234567891011121314151617181920212223242526272829303132333435363738394041/* * 对红黑树的节点(x)进行左旋转 * * 左旋示意图(对节点x进行左旋)： * px px * / / * x y * / \ --(左旋)-. / \ # * lx y x ry * / \ / \ * ly ry lx ly * * */private void leftRotate(RBTNode&lt;T&gt; x) &#123; // 设置x的右孩子为y RBTNode&lt;T&gt; y = x.right; // 将 “y的左孩子” 设为 “x的右孩子”； // 如果y的左孩子非空，将 “x” 设为 “y的左孩子的父亲” x.right = y.left; if (y.left != null) y.left.parent = x; // 将 “x的父亲” 设为 “y的父亲” y.parent = x.parent; if (x.parent == null) &#123; this.mRoot = y; // 如果 “x的父亲” 是空节点，则将y设为根节点 &#125; else &#123; if (x.parent.left == x) x.parent.left = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子” else x.parent.right = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子” &#125; // 将 “x” 设为 “y的左孩子” y.left = x; // 将 “x的父节点” 设为 “y” x.parent = y;&#125; 3. 右旋 对y进行左旋，意味着”将y变成一个右节点”。 右旋的实现代码(Java语言) 1234567891011121314151617181920212223242526272829303132333435363738394041/* * 对红黑树的节点(y)进行右旋转 * * 右旋示意图(对节点y进行左旋)： * py py * / / * y x * / \ --(右旋)-. / \ # * x ry lx y * / \ / \ # * lx rx rx ry * */private void rightRotate(RBTNode&lt;T&gt; y) &#123; // 设置x是当前节点的左孩子。 RBTNode&lt;T&gt; x = y.left; // 将 “x的右孩子” 设为 “y的左孩子”； // 如果"x的右孩子"不为空的话，将 “y” 设为 “x的右孩子的父亲” y.left = x.right; if (x.right != null) x.right.parent = y; // 将 “y的父亲” 设为 “x的父亲” x.parent = y.parent; if (y.parent == null) &#123; this.mRoot = x; // 如果 “y的父亲” 是空节点，则将x设为根节点 &#125; else &#123; if (y == y.parent.right) y.parent.right = x; // 如果 y是它父节点的右孩子，则将x设为“y的父节点的右孩子” else y.parent.left = x; // (y是它父节点的左孩子) 将x设为“x的父节点的左孩子” &#125; // 将 “y” 设为 “x的右孩子” x.right = y; // 将 “y的父节点” 设为 “x” y.parent = x;&#125; 4. 添加将一个节点插入到红黑树中，需要执行哪些步骤呢？首先，将红黑树当作一颗二叉查找树，将节点插入；然后，将节点着色为红色；最后，通过”旋转和重新着色”等一系列操作来修正该树，使之重新成为一颗红黑树。详细描述如下：第一步: 将红黑树当作一颗二叉查找树，将节点插入。​ 红黑树本身就是一颗二叉查找树，将节点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。此外，无论是左旋还是右旋，若旋转之前这棵树是二叉查找树，旋转之后它一定还是二叉查找树。这也就意味着，任何的旋转和重新着色操作，都不会改变它仍然是一颗二叉查找树的事实。好吧？那接下来，我们就来想方设法的旋转以及重新着色，使这颗树重新成为红黑树！ 第二步：将插入的节点着色为”红色”。​ 为什么着色成红色，而不是黑色呢？为什么呢？在回答之前，我们需要重新温习一下红黑树的特性：(1) 每个节点或者是黑色，或者是红色。(2) 根节点是黑色。(3) 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！](4) 如果一个节点是红色的，则它的子节点必须是黑色的。(5) 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。​ 将插入的节点着色为红色，不会违背”特性(5)”！少违背一条特性，就意味着我们需要处理的情况越少。接下来，就要努力的让这棵树满足其它性质即可；满足了的话，它就又是一颗红黑树了。o(∩∩)o…哈哈 第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。​ 第二步中，将插入节点着色为”红色”之后，不会违背”特性(5)”。那它到底会违背哪些特性呢？​ 对于”特性(1)”，显然不会违背了。因为我们已经将它涂成红色了。​ 对于”特性(2)”，显然也不会违背。在第一步中，我们是将红黑树当作二叉查找树，然后执行的插入操作。而根据二叉查找数的特点，插入操作不会改变根节点。所以，根节点仍然是黑色。​ 对于”特性(3)”，显然不会违背了。这里的叶子节点是指的空叶子节点，插入非空节点并不会对它们造成影响。​ 对于”特性(4)”，是有可能违背的！​ 那接下来，想办法使之”满足特性(4)”，就可以将树重新构造成红黑树了。 添加操作的实现代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * 将结点插入到红黑树中 * * 参数说明： * node 插入的结点 // 对应《算法导论》中的node */private void insert(RBTNode&lt;T&gt; node) &#123; int cmp; RBTNode&lt;T&gt; y = null; RBTNode&lt;T&gt; x = this.mRoot; // 1. 将红黑树当作一颗二叉查找树，将节点添加到二叉查找树中。 while (x != null) &#123; y = x; cmp = node.key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else x = x.right; &#125; node.parent = y; if (y!=null) &#123; cmp = node.key.compareTo(y.key); if (cmp &lt; 0) y.left = node; else y.right = node; &#125; else &#123; this.mRoot = node; &#125; // 2. 设置节点的颜色为红色 node.color = RED; // 3. 将它重新修正为一颗二叉查找树 insertFixUp(node);&#125;/* * 新建结点(key)，并将其插入到红黑树中 * * 参数说明： * key 插入结点的键值 */public void insert(T key) &#123; RBTNode&lt;T&gt; node=new RBTNode&lt;T&gt;(key,BLACK,null,null,null); // 如果新建结点失败，则返回。 if (node != null) insert(node);&#125; 内部接口 – insert(node)的作用是将”node”节点插入到红黑树中。外部接口 – insert(key)的作用是将”key”添加到红黑树中。 添加修正操作的实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/* * 红黑树插入修正函数 * * 在向红黑树中插入节点之后(失去平衡)，再调用该函数； * 目的是将它重新塑造成一颗红黑树。 * * 参数说明： * node 插入的结点 // 对应《算法导论》中的z */private void insertFixUp(RBTNode&lt;T&gt; node) &#123; RBTNode&lt;T&gt; parent, gparent; // 若“父节点存在，并且父节点的颜色是红色” while (((parent = parentOf(node))!=null) &amp;&amp; isRed(parent)) &#123; // 获得祖父节点 gparent = parentOf(parent); //若“父节点”是“祖父节点的左孩子” if (parent == gparent.left) &#123; // Case 1条件：叔叔节点是红色 RBTNode&lt;T&gt; uncle = gparent.right; if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123; setBlack(uncle); setBlack(parent); setRed(gparent); node = gparent; continue; &#125; // Case 2条件：叔叔是黑色，且当前节点是右孩子 if (parent.right == node) &#123; RBTNode&lt;T&gt; tmp; leftRotate(parent); tmp = parent; parent = node; node = tmp; &#125; // Case 3条件：叔叔是黑色，且当前节点是左孩子。 setBlack(parent); setRed(gparent); rightRotate(gparent); &#125; else &#123; //若“z的父节点”是“z的祖父节点的右孩子” // Case 1条件：叔叔节点是红色 RBTNode&lt;T&gt; uncle = gparent.left; if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123; setBlack(uncle); setBlack(parent); setRed(gparent); node = gparent; continue; &#125; // Case 2条件：叔叔是黑色，且当前节点是左孩子 if (parent.left == node) &#123; RBTNode&lt;T&gt; tmp; rightRotate(parent); tmp = parent; parent = node; node = tmp; &#125; // Case 3条件：叔叔是黑色，且当前节点是右孩子。 setBlack(parent); setRed(gparent); leftRotate(gparent); &#125; &#125; // 将根节点设为黑色 setBlack(this.mRoot);&#125; insertFixUp(node)的作用是对应”上面所讲的第三步”。它是一个内部接口。 5. 删除操作将红黑树内的某一个节点删除。需要执行的操作依次是：首先，将红黑树当作一颗二叉查找树，将该节点从二叉查找树中删除；然后，通过”旋转和重新着色”等一系列来修正该树，使之重新成为一棵红黑树。详细描述如下：第一步：将红黑树当作一颗二叉查找树，将节点删除。​ 这和”删除常规二叉查找树中删除节点的方法是一样的”。分3种情况：① 被删除节点没有儿子，即为叶节点。那么，直接将该节点删除就OK了。② 被删除节点只有一个儿子。那么，直接删除该节点，并用该节点的唯一子节点顶替它的位置。③ 被删除节点有两个儿子。那么，先找出它的后继节点；然后把“它的后继节点的内容”复制给“该节点的内容”；之后，删除“它的后继节点”。在这里，后继节点相当于替身，在将后继节点的内容复制给”被删除节点”之后，再将后继节点删除。这样就巧妙的将问题转换为”删除后继节点”的情况了，下面就考虑后继节点。 在”被删除节点”有两个非空子节点的情况下，它的后继节点不可能是双子非空。既然”的后继节点”不可能双子都非空，就意味着”该节点的后继节点”要么没有儿子，要么只有一个儿子。若没有儿子，则按”情况① “进行处理；若只有一个儿子，则按”情况② “进行处理。 第二步：通过”旋转和重新着色”等一系列来修正该树，使之重新成为一棵红黑树。​ 因为”第一步”中删除节点之后，可能会违背红黑树的特性。所以需要通过”旋转和重新着色”来修正该树，使之重新成为一棵红黑树。 删除操作的实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/* * 删除结点(node)，并返回被删除的结点 * * 参数说明： * node 删除的结点 */private void remove(RBTNode&lt;T&gt; node) &#123; RBTNode&lt;T&gt; child, parent; boolean color; // 被删除节点的"左右孩子都不为空"的情况。 if ( (node.left!=null) &amp;&amp; (node.right!=null) ) &#123; // 被删节点的后继节点。(称为"取代节点") // 用它来取代"被删节点"的位置，然后再将"被删节点"去掉。 RBTNode&lt;T&gt; replace = node; // 获取后继节点 replace = replace.right; while (replace.left != null) replace = replace.left; // "node节点"不是根节点(只有根节点不存在父节点) if (parentOf(node)!=null) &#123; if (parentOf(node).left == node) parentOf(node).left = replace; else parentOf(node).right = replace; &#125; else &#123; // "node节点"是根节点，更新根节点。 this.mRoot = replace; &#125; // child是"取代节点"的右孩子，也是需要"调整的节点"。 // "取代节点"肯定不存在左孩子！因为它是一个后继节点。 child = replace.right; parent = parentOf(replace); // 保存"取代节点"的颜色 color = colorOf(replace); // "被删除节点"是"它的后继节点的父节点" if (parent == node) &#123; parent = replace; &#125; else &#123; // child不为空 if (child!=null) setParent(child, parent); parent.left = child; replace.right = node.right; setParent(node.right, replace); &#125; replace.parent = node.parent; replace.color = node.color; replace.left = node.left; node.left.parent = replace; if (color == BLACK) removeFixUp(child, parent); node = null; return ; &#125; if (node.left !=null) &#123; child = node.left; &#125; else &#123; child = node.right; &#125; parent = node.parent; // 保存"取代节点"的颜色 color = node.color; if (child!=null) child.parent = parent; // "node节点"不是根节点 if (parent!=null) &#123; if (parent.left == node) parent.left = child; else parent.right = child; &#125; else &#123; this.mRoot = child; &#125; if (color == BLACK) removeFixUp(child, parent); node = null;&#125;/* * 删除结点(z)，并返回被删除的结点 * * 参数说明： * tree 红黑树的根结点 * z 删除的结点 */public void remove(T key) &#123; RBTNode&lt;T&gt; node; if ((node = search(mRoot, key)) != null) remove(node);&#125; 内部接口 – remove(node)的作用是将”node”节点插入到红黑树中。外部接口 – remove(key)删除红黑树中键值为key的节点。 删除修正操作的实现代码(Java语言) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/* * 红黑树删除修正函数 * * 在从红黑树中删除插入节点之后(红黑树失去平衡)，再调用该函数； * 目的是将它重新塑造成一颗红黑树。 * * 参数说明： * node 待修正的节点 */private void removeFixUp(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123; RBTNode&lt;T&gt; other; while ((node==null || isBlack(node)) &amp;&amp; (node != this.mRoot)) &#123; if (parent.left == node) &#123; other = parent.right; if (isRed(other)) &#123; // Case 1: x的兄弟w是红色的 setBlack(other); setRed(parent); leftRotate(parent); other = parent.right; &#125; if ((other.left==null || isBlack(other.left)) &amp;&amp; (other.right==null || isBlack(other.right))) &#123; // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 setRed(other); node = parent; parent = parentOf(node); &#125; else &#123; if (other.right==null || isBlack(other.right)) &#123; // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 setBlack(other.left); setRed(other); rightRotate(other); other = parent.right; &#125; // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。 setColor(other, colorOf(parent)); setBlack(parent); setBlack(other.right); leftRotate(parent); node = this.mRoot; break; &#125; &#125; else &#123; other = parent.left; if (isRed(other)) &#123; // Case 1: x的兄弟w是红色的 setBlack(other); setRed(parent); rightRotate(parent); other = parent.left; &#125; if ((other.left==null || isBlack(other.left)) &amp;&amp; (other.right==null || isBlack(other.right))) &#123; // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 setRed(other); node = parent; parent = parentOf(node); &#125; else &#123; if (other.left==null || isBlack(other.left)) &#123; // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 setBlack(other.right); setRed(other); leftRotate(other); other = parent.left; &#125; // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。 setColor(other, colorOf(parent)); setBlack(parent); setBlack(other.left); rightRotate(parent); node = this.mRoot; break; &#125; &#125; &#125; if (node!=null) setBlack(node);&#125; removeFixup(node, parent)是对应”上面所讲的第三步”。它是一个内部接口。 红黑树的Java实现(完整源码)下面是红黑树实现的完整代码和相应的测试程序。(1) 除了上面所说的”左旋”、”右旋”、”添加”、”删除”等基本操作之后，还实现了”遍历”、”查找”、”打印”、”最小值”、”最大值”、”创建”、”销毁”等接口。(2) 函数接口大多分为内部接口和外部接口。内部接口是private函数，外部接口则是public函数。(3) 测试代码中提供了”插入”和”删除”动作的检测开关。默认是关闭的，打开方法可以参考”代码中的说明”。建议在打开开关后，在草稿上自己动手绘制一下红黑树。 红黑树的实现文件(RBTree.java) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692 1 /** 2 * Java 语言: 红黑树 3 * 4 * @author skywang 5 * @date 2013/11/07 6 */ 7 8 public class RBTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; 9 10 private RBTNode&lt;T&gt; mRoot; // 根结点 11 12 private static final boolean RED = false; 13 private static final boolean BLACK = true; 14 15 public class RBTNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; 16 boolean color; // 颜色 17 T key; // 关键字(键值) 18 RBTNode&lt;T&gt; left; // 左孩子 19 RBTNode&lt;T&gt; right; // 右孩子 20 RBTNode&lt;T&gt; parent; // 父结点 21 22 public RBTNode(T key, boolean color, RBTNode&lt;T&gt; parent, RBTNode&lt;T&gt; left, RBTNode&lt;T&gt; right) &#123; 23 this.key = key; 24 this.color = color; 25 this.parent = parent; 26 this.left = left; 27 this.right = right; 28 &#125; 29 30 public T getKey() &#123; 31 return key; 32 &#125; 33 34 public String toString() &#123; 35 return ""+key+(this.color==RED?"(R)":"B"); 36 &#125; 37 &#125; 38 39 public RBTree() &#123; 40 mRoot=null; 41 &#125; 42 43 private RBTNode&lt;T&gt; parentOf(RBTNode&lt;T&gt; node) &#123; 44 return node!=null ? node.parent : null; 45 &#125; 46 private boolean colorOf(RBTNode&lt;T&gt; node) &#123; 47 return node!=null ? node.color : BLACK; 48 &#125; 49 private boolean isRed(RBTNode&lt;T&gt; node) &#123; 50 return ((node!=null)&amp;&amp;(node.color==RED)) ? true : false; 51 &#125; 52 private boolean isBlack(RBTNode&lt;T&gt; node) &#123; 53 return !isRed(node); 54 &#125; 55 private void setBlack(RBTNode&lt;T&gt; node) &#123; 56 if (node!=null) 57 node.color = BLACK; 58 &#125; 59 private void setRed(RBTNode&lt;T&gt; node) &#123; 60 if (node!=null) 61 node.color = RED; 62 &#125; 63 private void setParent(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123; 64 if (node!=null) 65 node.parent = parent; 66 &#125; 67 private void setColor(RBTNode&lt;T&gt; node, boolean color) &#123; 68 if (node!=null) 69 node.color = color; 70 &#125; 71 72 /* 73 * 前序遍历"红黑树" 74 */ 75 private void preOrder(RBTNode&lt;T&gt; tree) &#123; 76 if(tree != null) &#123; 77 System.out.print(tree.key+" "); 78 preOrder(tree.left); 79 preOrder(tree.right); 80 &#125; 81 &#125; 82 83 public void preOrder() &#123; 84 preOrder(mRoot); 85 &#125; 86 87 /* 88 * 中序遍历"红黑树" 89 */ 90 private void inOrder(RBTNode&lt;T&gt; tree) &#123; 91 if(tree != null) &#123; 92 inOrder(tree.left); 93 System.out.print(tree.key+" "); 94 inOrder(tree.right); 95 &#125; 96 &#125; 97 98 public void inOrder() &#123; 99 inOrder(mRoot);100 &#125;101 102 103 /*104 * 后序遍历"红黑树"105 */106 private void postOrder(RBTNode&lt;T&gt; tree) &#123;107 if(tree != null)108 &#123;109 postOrder(tree.left);110 postOrder(tree.right);111 System.out.print(tree.key+" ");112 &#125;113 &#125;114 115 public void postOrder() &#123;116 postOrder(mRoot);117 &#125;118 119 120 /*121 * (递归实现)查找"红黑树x"中键值为key的节点122 */123 private RBTNode&lt;T&gt; search(RBTNode&lt;T&gt; x, T key) &#123;124 if (x==null)125 return x;126 127 int cmp = key.compareTo(x.key);128 if (cmp &lt; 0)129 return search(x.left, key);130 else if (cmp &gt; 0)131 return search(x.right, key);132 else133 return x;134 &#125;135 136 public RBTNode&lt;T&gt; search(T key) &#123;137 return search(mRoot, key);138 &#125;139 140 /*141 * (非递归实现)查找"红黑树x"中键值为key的节点142 */143 private RBTNode&lt;T&gt; iterativeSearch(RBTNode&lt;T&gt; x, T key) &#123;144 while (x!=null) &#123;145 int cmp = key.compareTo(x.key);146 147 if (cmp &lt; 0) 148 x = x.left;149 else if (cmp &gt; 0) 150 x = x.right;151 else152 return x;153 &#125;154 155 return x;156 &#125;157 158 public RBTNode&lt;T&gt; iterativeSearch(T key) &#123;159 return iterativeSearch(mRoot, key);160 &#125;161 162 /* 163 * 查找最小结点：返回tree为根结点的红黑树的最小结点。164 */165 private RBTNode&lt;T&gt; minimum(RBTNode&lt;T&gt; tree) &#123;166 if (tree == null)167 return null;168 169 while(tree.left != null)170 tree = tree.left;171 return tree;172 &#125;173 174 public T minimum() &#123;175 RBTNode&lt;T&gt; p = minimum(mRoot);176 if (p != null)177 return p.key;178 179 return null;180 &#125;181 182 /* 183 * 查找最大结点：返回tree为根结点的红黑树的最大结点。184 */185 private RBTNode&lt;T&gt; maximum(RBTNode&lt;T&gt; tree) &#123;186 if (tree == null)187 return null;188 189 while(tree.right != null)190 tree = tree.right;191 return tree;192 &#125;193 194 public T maximum() &#123;195 RBTNode&lt;T&gt; p = maximum(mRoot);196 if (p != null)197 return p.key;198 199 return null;200 &#125;201 202 /* 203 * 找结点(x)的后继结点。即，查找"红黑树中数据值大于该结点"的"最小结点"。204 */205 public RBTNode&lt;T&gt; successor(RBTNode&lt;T&gt; x) &#123;206 // 如果x存在右孩子，则"x的后继结点"为 "以其右孩子为根的子树的最小结点"。207 if (x.right != null)208 return minimum(x.right);209 210 // 如果x没有右孩子。则x有以下两种可能：211 // (01) x是"一个左孩子"，则"x的后继结点"为 "它的父结点"。212 // (02) x是"一个右孩子"，则查找"x的最低的父结点，并且该父结点要具有左孩子"，找到的这个"最低的父结点"就是"x的后继结点"。213 RBTNode&lt;T&gt; y = x.parent;214 while ((y!=null) &amp;&amp; (x==y.right)) &#123;215 x = y;216 y = y.parent;217 &#125;218 219 return y;220 &#125;221 222 /* 223 * 找结点(x)的前驱结点。即，查找"红黑树中数据值小于该结点"的"最大结点"。224 */225 public RBTNode&lt;T&gt; predecessor(RBTNode&lt;T&gt; x) &#123;226 // 如果x存在左孩子，则"x的前驱结点"为 "以其左孩子为根的子树的最大结点"。227 if (x.left != null)228 return maximum(x.left);229 230 // 如果x没有左孩子。则x有以下两种可能：231 // (01) x是"一个右孩子"，则"x的前驱结点"为 "它的父结点"。232 // (01) x是"一个左孩子"，则查找"x的最低的父结点，并且该父结点要具有右孩子"，找到的这个"最低的父结点"就是"x的前驱结点"。233 RBTNode&lt;T&gt; y = x.parent;234 while ((y!=null) &amp;&amp; (x==y.left)) &#123;235 x = y;236 y = y.parent;237 &#125;238 239 return y;240 &#125;241 242 /* 243 * 对红黑树的节点(x)进行左旋转244 *245 * 左旋示意图(对节点x进行左旋)：246 * px px247 * / /248 * x y 249 * / \ --(左旋)-. / \ #250 * lx y x ry 251 * / \ / \252 * ly ry lx ly 253 *254 *255 */256 private void leftRotate(RBTNode&lt;T&gt; x) &#123;257 // 设置x的右孩子为y258 RBTNode&lt;T&gt; y = x.right;259 260 // 将 “y的左孩子” 设为 “x的右孩子”；261 // 如果y的左孩子非空，将 “x” 设为 “y的左孩子的父亲”262 x.right = y.left;263 if (y.left != null)264 y.left.parent = x;265 266 // 将 “x的父亲” 设为 “y的父亲”267 y.parent = x.parent;268 269 if (x.parent == null) &#123;270 this.mRoot = y; // 如果 “x的父亲” 是空节点，则将y设为根节点271 &#125; else &#123;272 if (x.parent.left == x)273 x.parent.left = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子”274 else275 x.parent.right = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子”276 &#125;277 278 // 将 “x” 设为 “y的左孩子”279 y.left = x;280 // 将 “x的父节点” 设为 “y”281 x.parent = y;282 &#125;283 284 /* 285 * 对红黑树的节点(y)进行右旋转286 *287 * 右旋示意图(对节点y进行左旋)：288 * py py289 * / /290 * y x 291 * / \ --(右旋)-. / \ #292 * x ry lx y 293 * / \ / \ #294 * lx rx rx ry295 * 296 */297 private void rightRotate(RBTNode&lt;T&gt; y) &#123;298 // 设置x是当前节点的左孩子。299 RBTNode&lt;T&gt; x = y.left;300 301 // 将 “x的右孩子” 设为 “y的左孩子”；302 // 如果"x的右孩子"不为空的话，将 “y” 设为 “x的右孩子的父亲”303 y.left = x.right;304 if (x.right != null)305 x.right.parent = y;306 307 // 将 “y的父亲” 设为 “x的父亲”308 x.parent = y.parent;309 310 if (y.parent == null) &#123;311 this.mRoot = x; // 如果 “y的父亲” 是空节点，则将x设为根节点312 &#125; else &#123;313 if (y == y.parent.right)314 y.parent.right = x; // 如果 y是它父节点的右孩子，则将x设为“y的父节点的右孩子”315 else316 y.parent.left = x; // (y是它父节点的左孩子) 将x设为“x的父节点的左孩子”317 &#125;318 319 // 将 “y” 设为 “x的右孩子”320 x.right = y;321 322 // 将 “y的父节点” 设为 “x”323 y.parent = x;324 &#125;325 326 /*327 * 红黑树插入修正函数328 *329 * 在向红黑树中插入节点之后(失去平衡)，再调用该函数；330 * 目的是将它重新塑造成一颗红黑树。331 *332 * 参数说明：333 * node 插入的结点 // 对应《算法导论》中的z334 */335 private void insertFixUp(RBTNode&lt;T&gt; node) &#123;336 RBTNode&lt;T&gt; parent, gparent;337 338 // 若“父节点存在，并且父节点的颜色是红色”339 while (((parent = parentOf(node))!=null) &amp;&amp; isRed(parent)) &#123;340 gparent = parentOf(parent);341 342 //若“父节点”是“祖父节点的左孩子”343 if (parent == gparent.left) &#123;344 // Case 1条件：叔叔节点是红色345 RBTNode&lt;T&gt; uncle = gparent.right;346 if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123;347 setBlack(uncle);348 setBlack(parent);349 setRed(gparent);350 node = gparent;351 continue;352 &#125;353 354 // Case 2条件：叔叔是黑色，且当前节点是右孩子355 if (parent.right == node) &#123;356 RBTNode&lt;T&gt; tmp;357 leftRotate(parent);358 tmp = parent;359 parent = node;360 node = tmp;361 &#125;362 363 // Case 3条件：叔叔是黑色，且当前节点是左孩子。364 setBlack(parent);365 setRed(gparent);366 rightRotate(gparent);367 &#125; else &#123; //若“z的父节点”是“z的祖父节点的右孩子”368 // Case 1条件：叔叔节点是红色369 RBTNode&lt;T&gt; uncle = gparent.left;370 if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123;371 setBlack(uncle);372 setBlack(parent);373 setRed(gparent);374 node = gparent;375 continue;376 &#125;377 378 // Case 2条件：叔叔是黑色，且当前节点是左孩子379 if (parent.left == node) &#123;380 RBTNode&lt;T&gt; tmp;381 rightRotate(parent);382 tmp = parent;383 parent = node;384 node = tmp;385 &#125;386 387 // Case 3条件：叔叔是黑色，且当前节点是右孩子。388 setBlack(parent);389 setRed(gparent);390 leftRotate(gparent);391 &#125;392 &#125;393 394 // 将根节点设为黑色395 setBlack(this.mRoot);396 &#125;397 398 /* 399 * 将结点插入到红黑树中400 *401 * 参数说明：402 * node 插入的结点 // 对应《算法导论》中的node403 */404 private void insert(RBTNode&lt;T&gt; node) &#123;405 int cmp;406 RBTNode&lt;T&gt; y = null;407 RBTNode&lt;T&gt; x = this.mRoot;408 409 // 1. 将红黑树当作一颗二叉查找树，将节点添加到二叉查找树中。410 while (x != null) &#123;411 y = x;412 cmp = node.key.compareTo(x.key);413 if (cmp &lt; 0)414 x = x.left;415 else416 x = x.right;417 &#125;418 419 node.parent = y;420 if (y!=null) &#123;421 cmp = node.key.compareTo(y.key);422 if (cmp &lt; 0)423 y.left = node;424 else425 y.right = node;426 &#125; else &#123;427 this.mRoot = node;428 &#125;429 430 // 2. 设置节点的颜色为红色431 node.color = RED;432 433 // 3. 将它重新修正为一颗二叉查找树434 insertFixUp(node);435 &#125;436 437 /* 438 * 新建结点(key)，并将其插入到红黑树中439 *440 * 参数说明：441 * key 插入结点的键值442 */443 public void insert(T key) &#123;444 RBTNode&lt;T&gt; node=new RBTNode&lt;T&gt;(key,BLACK,null,null,null);445 446 // 如果新建结点失败，则返回。447 if (node != null)448 insert(node);449 &#125;450 451 452 /*453 * 红黑树删除修正函数454 *455 * 在从红黑树中删除插入节点之后(红黑树失去平衡)，再调用该函数；456 * 目的是将它重新塑造成一颗红黑树。457 *458 * 参数说明：459 * node 待修正的节点460 */461 private void removeFixUp(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123;462 RBTNode&lt;T&gt; other;463 464 while ((node==null || isBlack(node)) &amp;&amp; (node != this.mRoot)) &#123;465 if (parent.left == node) &#123;466 other = parent.right;467 if (isRed(other)) &#123;468 // Case 1: x的兄弟w是红色的 469 setBlack(other);470 setRed(parent);471 leftRotate(parent);472 other = parent.right;473 &#125;474 475 if ((other.left==null || isBlack(other.left)) &amp;&amp;476 (other.right==null || isBlack(other.right))) &#123;477 // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 478 setRed(other);479 node = parent;480 parent = parentOf(node);481 &#125; else &#123;482 483 if (other.right==null || isBlack(other.right)) &#123;484 // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 485 setBlack(other.left);486 setRed(other);487 rightRotate(other);488 other = parent.right;489 &#125;490 // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。491 setColor(other, colorOf(parent));492 setBlack(parent);493 setBlack(other.right);494 leftRotate(parent);495 node = this.mRoot;496 break;497 &#125;498 &#125; else &#123;499 500 other = parent.left;501 if (isRed(other)) &#123;502 // Case 1: x的兄弟w是红色的 503 setBlack(other);504 setRed(parent);505 rightRotate(parent);506 other = parent.left;507 &#125;508 509 if ((other.left==null || isBlack(other.left)) &amp;&amp;510 (other.right==null || isBlack(other.right))) &#123;511 // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 512 setRed(other);513 node = parent;514 parent = parentOf(node);515 &#125; else &#123;516 517 if (other.left==null || isBlack(other.left)) &#123;518 // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 519 setBlack(other.right);520 setRed(other);521 leftRotate(other);522 other = parent.left;523 &#125;524 525 // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。526 setColor(other, colorOf(parent));527 setBlack(parent);528 setBlack(other.left);529 rightRotate(parent);530 node = this.mRoot;531 break;532 &#125;533 &#125;534 &#125;535 536 if (node!=null)537 setBlack(node);538 &#125;539 540 /* 541 * 删除结点(node)，并返回被删除的结点542 *543 * 参数说明：544 * node 删除的结点545 */546 private void remove(RBTNode&lt;T&gt; node) &#123;547 RBTNode&lt;T&gt; child, parent;548 boolean color;549 550 // 被删除节点的"左右孩子都不为空"的情况。551 if ( (node.left!=null) &amp;&amp; (node.right!=null) ) &#123;552 // 被删节点的后继节点。(称为"取代节点")553 // 用它来取代"被删节点"的位置，然后再将"被删节点"去掉。554 RBTNode&lt;T&gt; replace = node;555 556 // 获取后继节点557 replace = replace.right;558 while (replace.left != null)559 replace = replace.left;560 561 // "node节点"不是根节点(只有根节点不存在父节点)562 if (parentOf(node)!=null) &#123;563 if (parentOf(node).left == node)564 parentOf(node).left = replace;565 else566 parentOf(node).right = replace;567 &#125; else &#123;568 // "node节点"是根节点，更新根节点。569 this.mRoot = replace;570 &#125;571 572 // child是"取代节点"的右孩子，也是需要"调整的节点"。573 // "取代节点"肯定不存在左孩子！因为它是一个后继节点。574 child = replace.right;575 parent = parentOf(replace);576 // 保存"取代节点"的颜色577 color = colorOf(replace);578 579 // "被删除节点"是"它的后继节点的父节点"580 if (parent == node) &#123;581 parent = replace;582 &#125; else &#123;583 // child不为空584 if (child!=null)585 setParent(child, parent);586 parent.left = child;587 588 replace.right = node.right;589 setParent(node.right, replace);590 &#125;591 592 replace.parent = node.parent;593 replace.color = node.color;594 replace.left = node.left;595 node.left.parent = replace;596 597 if (color == BLACK)598 removeFixUp(child, parent);599 600 node = null;601 return ;602 &#125;603 604 if (node.left !=null) &#123;605 child = node.left;606 &#125; else &#123;607 child = node.right;608 &#125;609 610 parent = node.parent;611 // 保存"取代节点"的颜色612 color = node.color;613 614 if (child!=null)615 child.parent = parent;616 617 // "node节点"不是根节点618 if (parent!=null) &#123;619 if (parent.left == node)620 parent.left = child;621 else622 parent.right = child;623 &#125; else &#123;624 this.mRoot = child;625 &#125;626 627 if (color == BLACK)628 removeFixUp(child, parent);629 node = null;630 &#125;631 632 /* 633 * 删除结点(z)，并返回被删除的结点634 *635 * 参数说明：636 * tree 红黑树的根结点637 * z 删除的结点638 */639 public void remove(T key) &#123;640 RBTNode&lt;T&gt; node; 641 642 if ((node = search(mRoot, key)) != null)643 remove(node);644 &#125;645 646 /*647 * 销毁红黑树648 */649 private void destroy(RBTNode&lt;T&gt; tree) &#123;650 if (tree==null)651 return ;652 653 if (tree.left != null)654 destroy(tree.left);655 if (tree.right != null)656 destroy(tree.right);657 658 tree=null;659 &#125;660 661 public void clear() &#123;662 destroy(mRoot);663 mRoot = null;664 &#125;665 666 /*667 * 打印"红黑树"668 *669 * key -- 节点的键值 670 * direction -- 0，表示该节点是根节点;671 * -1，表示该节点是它的父结点的左孩子;672 * 1，表示该节点是它的父结点的右孩子。673 */674 private void print(RBTNode&lt;T&gt; tree, T key, int direction) &#123;675 676 if(tree != null) &#123;677 678 if(direction==0) // tree是根节点679 System.out.printf("%2d(B) is root\n", tree.key);680 else // tree是分支节点681 System.out.printf("%2d(%s) is %2d's %6s child\n", tree.key, isRed(tree)?"R":"B", key, direction==1?"right" : "left");682 683 print(tree.left, tree.key, -1);684 print(tree.right,tree.key, 1);685 &#125;686 &#125;687 688 public void print() &#123;689 if (mRoot != null)690 print(mRoot, mRoot.key, 0);691 &#125;692 &#125; 红黑树的测试文件(RBTreeTest.java) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 1 /** 2 * Java 语言: 二叉查找树 3 * 4 * @author skywang 5 * @date 2013/11/07 6 */ 7 public class RBTreeTest &#123; 8 9 private static final int a[] = &#123;10, 40, 30, 60, 90, 70, 20, 50, 80&#125;;10 private static final boolean mDebugInsert = false; // "插入"动作的检测开关(false，关闭；true，打开)11 private static final boolean mDebugDelete = false; // "删除"动作的检测开关(false，关闭；true，打开)12 13 public static void main(String[] args) &#123;14 int i, ilen = a.length;15 RBTree&lt;Integer&gt; tree=new RBTree&lt;Integer&gt;();16 17 System.out.printf("== 原始数据: ");18 for(i=0; i&lt;ilen; i++)19 System.out.printf("%d ", a[i]);20 System.out.printf("\n");21 22 for(i=0; i&lt;ilen; i++) &#123;23 tree.insert(a[i]);24 // 设置mDebugInsert=true,测试"添加函数"25 if (mDebugInsert) &#123;26 System.out.printf("== 添加节点: %d\n", a[i]);27 System.out.printf("== 树的详细信息: \n");28 tree.print();29 System.out.printf("\n");30 &#125;31 &#125;32 33 System.out.printf("== 前序遍历: ");34 tree.preOrder();35 36 System.out.printf("\n== 中序遍历: ");37 tree.inOrder();38 39 System.out.printf("\n== 后序遍历: ");40 tree.postOrder();41 System.out.printf("\n");42 43 System.out.printf("== 最小值: %s\n", tree.minimum());44 System.out.printf("== 最大值: %s\n", tree.maximum());45 System.out.printf("== 树的详细信息: \n");46 tree.print();47 System.out.printf("\n");48 49 // 设置mDebugDelete=true,测试"删除函数"50 if (mDebugDelete) &#123;51 for(i=0; i&lt;ilen; i++)52 &#123;53 tree.remove(a[i]);54 55 System.out.printf("== 删除节点: %d\n", a[i]);56 System.out.printf("== 树的详细信息: \n");57 tree.print();58 System.out.printf("\n");59 &#125;60 &#125;61 62 // 销毁二叉树63 tree.clear();64 &#125;65 &#125; 红黑树的Java测试程序前面已经给出了红黑树的测试代码(RBTreeTest.java)，这里就不再重复说明。下面是测试程序的运行结果： 12345678910111213141516== 原始数据: 10 40 30 60 90 70 20 50 80 == 前序遍历: 30 10 20 60 40 50 80 70 90 == 中序遍历: 10 20 30 40 50 60 70 80 90 == 后序遍历: 20 10 50 40 70 90 80 60 30 == 最小值: 10== 最大值: 90== 树的详细信息: 30(B) is root10(B) is 30&apos;s left child20(R) is 10&apos;s right child60(R) is 30&apos;s right child40(B) is 60&apos;s left child50(R) is 40&apos;s right child80(B) is 60&apos;s right child70(R) is 80&apos;s left child90(R) is 80&apos;s right child]]></content>
      <categories>
        <category>红黑树</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap的使用]]></title>
    <url>%2F2017%2F12%2F26%2FConcurrentHashMap%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap的使用缓存的使用 高性能本地缓存：对系统中常用到的业务数据放到缓存中以提高系统性能，限制是单服务器模式 分布式缓存：常用分布式缓存技术memcached、redis等 ConcurrentHashMap就是常用的高并发下的缓存对象。接下来直接上例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class ConcurrentMapTest &#123; public static ConcurrentMap&lt;String, Future&lt;String&gt;&gt; cMap = new ConcurrentHashMap&lt;&gt;(); public static ConcurrentHashMap&lt;String, String&gt; cMap2 = new ConcurrentHashMap&lt;&gt;(); public static int index = 0; public static void main(String[] args) &#123; for (int i = 0; i &lt; 5; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; concurrentMap2("3"); try &#123; concurrentMap("123"); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125; /** * 解决并发写的线程安全问题。但是高并发可读取会造成重复写的问题... * 如果put的业务计算复杂将耗费不必要的资源 * 解决缓存读取问题，但可能会出现缓存重复写 */ private static void concurrentMap2(String key) &#123; System.out.println(Thread.currentThread().getName() + " start ...."); String f = cMap2.get(key); // ConcurrentMap读不加锁，写加锁。 // 当并发量高时会出现重复compute的操作，然后才put到map中 if (f == null) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cMap2.put(key, "dataTest" + index); System.out.println(Thread.currentThread().getName() + " compute , index================== " + index++); &#125; System.out.println(Thread.currentThread().getName() + " end .... " + cMap2.get(key)); &#125; /** * 解决并发写问题，同时避免了重复put计算的问题 解决缓存读写的问题 * * @param key * @throws InterruptedException * @throws ExecutionException * @throws TimeoutException */ private static void concurrentMap(String key) throws InterruptedException, ExecutionException, TimeoutException &#123; System.out.println(Thread.currentThread().getName() + " start ...."); Future&lt;String&gt; f = null; f = cMap.get(key); if (f == null) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; FutureTask&lt;String&gt; fTask = new FutureTask&lt;String&gt; (new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + " compute , index=============== " + index++); return "456789123"; &#125; &#125;); f = cMap.putIfAbsent(key, fTask); // 相当于get-if-absent-compute， //而且是原子执行，解决了并发读的问题。（FutureTask解决compute步骤） if (f == null) &#123; f = fTask; // f的值是FutureTask对象引用，解决了call的重复调用问题, // 只用一个线程会执行run()方法 fTask.run(); &#125; &#125; System.out.println("end ==========="); // get会等待FutureTask的计算结果，可以设置等待超时事件,超时会抛出超时异常 System.out.println(Thread.currentThread().getName() + " end ....====== " + f.get(3000, TimeUnit.MILLISECONDS)); // get会等待FutureTask的计算结果，永久等待 System.out.println(Thread.currentThread().getName() + " end .... " + f.get()); &#125;&#125; concurrentMap2的执行结果 Thread-0 start ….Thread-2 start ….Thread-4 start ….Thread-1 start ….Thread-3 start ….Thread-4 compute , index================== 0Thread-0 compute , index================== 2Thread-0 end …. dataTest0Thread-2 compute , index================== 1Thread-2 end …. dataTest0Thread-4 end …. dataTest0Thread-3 compute , index================== 3Thread-1 compute , index================== 4Thread-1 end …. dataTest3Thread-3 end …. dataTest3 可以看到put方法被重复执行…. concurrentMap的执行结果 Thread-1 start ….Thread-3 start ….Thread-0 start ….Thread-2 start ….Thread-4 start ….end ===========end ===========end ===========end ===========Thread-1 compute , index=============== 0Thread-3 end ….====== 456789123Thread-3 end …. 456789123end ===========Thread-1 end ….====== 456789123Thread-1 end …. 456789123Thread-0 end ….====== 456789123Thread-0 end …. 456789123Thread-2 end ….====== 456789123Thread-2 end …. 456789123Thread-4 end ….====== 456789123Thread-4 end …. 456789123 可以看到put运算只执行一次…. 总结： 如果缓存对象可以在系统启动时进行初始化加载，可以不使用ConcurrentHashMap 如果缓存在put时计算比较复杂，那么推荐直接使用concurrentMap写法 ConcurrentHashMap缺陷就是缓存无法回收，导致内存溢出问题。此问题在google发布Guava的Cache很好的进行了处理，可查看另一篇文章Guava Cache的使用]]></content>
      <categories>
        <category>ConcurrentHashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap 源码解读]]></title>
    <url>%2F2017%2F12%2F26%2FJava%208%20ConcurrentHashMap%20%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[Java 8 ConcurrentHashMap 源码解读 ConcurrentHashMap 当之无愧是支持并发最好的键值对（Map）集合。在日常编码中，出场率也相当之高。在jdk8中，集合类 ConcurrentHashMap 经 Doug Lea 大师之手，借助volatile语义以及CAS操作进行优化，使得该集合类更好地发挥出了并发的优势。与jdk7中相比，在原有段锁（Segment）的基础上，引入了数组＋链表＋红黑树的存储模型，在查询效率上花费了不少心思。 基础数据结构ConcurrentHashMap内存存储结构图大致如下： 概述1、设计首要目的：维护并发可读性（get、迭代相关）；次要目的：使空间消耗比HashMap相同或更好，且支持多线程高效率的初始插入（empty table）。 2、HashTable线程安全，但采用synchronized，多线程下效率低下。线程1put时，线程2无法put或get。 阅前了解在真正阅读 ConcurrentHashMap 源码之前，我们简单复习下关于volatile和CAS的概念，这样才能更好地帮助我们理解源码中的关键方法。 volatile语义java提供的关键字volatile是最轻量级的同步机制。当定义一个变量为volatile时，它就具备了三层语义： - 可见性（Visibility）：在多线程环境下，一个变量的写操作总是对其后的读取线程可见 - 原子性（Atomicity）：volatile的读/写操作具有原子性 - 有序性（Ordering）：禁止指令的重排序优化，JVM会通过插入内存屏障（Memory Barrier）指令来保证 就同步性能而言，大多数场景下volatile的总开销是要比锁低的。在ConcurrentHashMap的源码中，我们能看到频繁的volatile变量读取与写入。 CAS操作CAS一般被理解为原子操作。在java中，正是利用了处理器的CMPXCHG（intel）指令实现CAS操作。CAS需要接受原有期望值expected以及想要修改的新值x，只有在原有期望值与当前值相等时才会更新为x，否则为失败。在ConcurrentHashMap的方法中，大量使用CAS获取/修改互斥量，以达到多线程并发环境下的正确性。 ConcurrentHashMap 的常量12// maximum_capacity table的最大容量，必须为2次幂形式private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30 12// default_capacity table的默认初始容量，必须为2次幂形式private static final int DEFAULT_CAPACITY = 16 12// max_array_size MAX_VALUE=2^31-1=2147483647static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8 12// default_concurrency_leve 未被用到，用来兼容之前版本private static finalint DEFAULT_CONCURRENCY_LEVEL = 16 123// load_factor table的负载因子，当前节点数量超过 n * LOAD_FACTOR，执行扩容// 位操作表达式为 n - (n &gt;&gt;&gt; 2)private static final float LOAD_FACTOR = 0.75f 12// treeify_threshold 针对每个桶（bin），链表转换为红黑树的节点数阈值static final int TREEIFY_THRESHOLD = 8 12// 针对每个桶（bin），红黑树退化为链表的节点数阈值static final int UNTREEIFY_THRESHOLD = 6 12// min_treeify_capacity 最小的树的容量static final int MIN_TREEIFY_CAPACITY = 64 1234// 扩容线程每次最少要迁移16个hash桶// min_transfer_stride 在扩容中，参与的单个线程允许处理的最少table桶首节点个数// 虽然适当添加线程，会使得整个扩容过程变快，但需要考虑多线程内存同时分配的问题private static final int MIN_TRANSFER_STRIDE = 16 12// resize stamp bits sizeCtl 中记录 size 的 bit 数private static int RESIZE_STAMP_BITS = 16 12// max_resizers 2^15-1 参与扩容的最大线程数private static final int MAX_RESIZERS = (1&lt;&lt;(32-RESIZE_STAMP_BITS))-1 12// 32 - 16 = 16, sizeCtl 中记录 size 大小的偏移量private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS = 16 12// 转为 nodes的hash值、标示位static final int MOVED = -1 12// 树的根节点的 hash 值static final int TREEBIN = -2 12// ReservationNode 的 hash 值static final int RESERVED = -3 12345// 一些特定的哈希值代表不同含义static final int MOVED = -1; // hash for forwarding nodesstatic final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash 12// CPU数static final int NCPU = Runtime.getRuntime().availableProcessors() 123456789101112131415161718192021222324252627/** * 真正存储Node数据（桶首）节点的数组table * 所有Node节点根据hash分桶存储 * table数组中存储的是所有桶（bin）的首节点 * hash值相同的节点以链表形式分装在桶中 * 当一个桶中节点数达到8个时，转换为红黑树，提高查询效率 * 装载Node的数组，作为ConcurrentHashMap的数据容器，采用懒加载的方式 * 直到第一次插入数据的时候才会进行初始化操作，数组的大小总是为2的幂次方。 */transient volatile Node&lt;K,V&gt;[] table;// 扩容时候使用,平时为null，只有在扩容的时候才为非nullprivate transient volatile Node&lt;K,V&gt;[] nextTable;// 没有竞争条件时，使用private transient volatile long baseCount;// 扩容时，将table中的元素迁移至nextTable . 扩容时非空private transient volatile Node&lt;K,V&gt;[] nextTable;/** * 重要控制变量 * 根据变量的数值不同，类实例处于不同阶段 * 1. = -1 : 正在初始化 * 2. &lt; -1 : 正在扩容，数值为 -(1 + 参与扩容的线程数) * 3. = 0 : 创建时初始为0 * 4. &gt; 0 : 下一次扩容的大小 */private transient volatile int sizeCtl; ConcurrentHashMap 重要属性NodeKey-value entry, 继承自Map.Entry对象。 Node节点是ConcurrentHashMap存储数据的最基本结构。一个数据mapping节点中，存储4个变量：当前节点hash值、节点的key值、节点的value值、指向下一个节点的指针next。其中在子类中的hash可以为负数，具有特殊的并发处理意义，后文会解释。除了具有特殊意义的子类，Node中的key和val不允许为null。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; // Node节点的hash值和key的hash值相同 // TreeNode节点的hash值 final int hash; final K key; volatile V val; //带有同步锁的value(保证可见性) volatile Node&lt;K,V&gt; next;//带有同步锁的next指针 Node(inthash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; // HashMap调用Objects.hashCode()，最终也是调用Object.hashCode()；效果一样 public final int hashCode() &#123; returnkey.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; returnkey + "=" + val; &#125; //不允许直接改变value的值 public final V setValue(V value) &#123; // 不允许修改value值，HashMap允许 throw new UnsupportedOperationException(); &#125; // HashMap使用if (o == this)，且嵌套if；concurrent使用&amp;&amp; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((oinstanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; Node&lt;K,V&gt; find(inth, Object k) &#123; // 增加find方法辅助get方法 Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; /** * 以链表形式查找桶中下一个Node信息 * 当转换为subclass红黑树节点TreeNode * 则使用TreeNode中的find进行查询操作 */ &#125; while ((e = e.next) != null); &#125; returnnull; &#125; &#125; 另外可以看出很多属性都是用volatile进行修饰的，也就是为了保证内存可见性。 这个Node内部类与HashMap中定义的Node类很相似，但是有一些差别 它对value和next属性设置了volatile同步锁 它不允许调用setValue方法直接改变Node的value域 它增加了find方法辅助map.get()方法 TreeNodeNode的子类，红黑树节点，当Node链表过长时，会转换成红黑树。 位于 ConcurrentHashMap 类的 2653行 或 搜索 / —————- TreeNodes ————– / 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// Nodes for use in TreeBins，链表&gt;8，才可能转为TreeNode. // HashMap的TreeNode继承至LinkedHashMap.Entry；而这里继承至自己实现的Node，将带有next指针，便于treebin访问。 static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(inthash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; Node&lt;K,V&gt; find(inth, Object k) &#123; return findTreeNode(h, k, null); &#125; /** * Returns the TreeNode (or null if not found) for the given key * starting at given root. */ // 查找hash为h，key为k的节点 final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) &#123; if (k != null) &#123; // 比HMap增加判空 TreeNode&lt;K,V&gt; p = this; do &#123; intph, dir; K pk; TreeNode&lt;K,V&gt; q; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right; if ((ph = p.hash) &gt; h) p = pl; elseif (ph &lt; h) p = pr; elseif ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) returnp; elseif (pl == null) p = pr; elseif (pr == null) p = pl; elseif ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; elseif ((q = pr.findTreeNode(h, k, kc)) != null) returnq; else p = pl; &#125; while (p != null); &#125; return null; &#125; &#125; // 和HashMap相比，这里的TreeNode相当简洁；ConcurrentHashMap链表转树时，并不会直接转，// 正如注释（Nodes for use in TreeBins）所说，只是把这些节点包装成TreeNode放到TreeBin中，// 再由TreeBin来转化红黑树。 树节点，继承于承载数据的Node类。而红黑树的操作是针对TreeBin类的，从该类的注释也可以看出，也就是TreeBin会将TreeNode进行再一次封装 TreeBin位于 ConcurrentHashMap 类的 2709 行 或 搜索 / —————- TreeBins ————– / 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// TreeBin用于封装维护TreeNode，包含putTreeVal、lookRoot、UNlookRoot、remove、// balanceInsetion、balanceDeletion等方法，这里只分析其构造函数。当链表转树时，// 用于封装TreeNode，也就是说，ConcurrentHashMap的红黑树存放的是TreeBin，而不是treeNode。 TreeBin(TreeNode&lt;K,V&gt; b) &#123; super(TREEBIN, null, null, null);//hash值为常量TREEBIN=-2,表示roots of trees this.first = b; TreeNode&lt;K,V&gt; r = null; for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (r == null) &#123; x.parent = null; x.red = false; r = x; &#125; else &#123; K k = x.key; inth = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = r;;) &#123; intdir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; elseif (ph &lt; h) dir = 1; elseif ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; r = balanceInsertion(r, x); break; &#125; &#125; &#125; &#125; this.root = r; assert checkInvariants(root); &#125; 这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象。 threeifyBin位于 ConcurrentHashMap 类的 2611 行 或 搜索 “private final void treeifyBin” 1234567891011121314151617181920212223242526private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; intn, sc; if (tab != null) &#123; // 数组的大小还未超过64 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); // 容量&lt;64，则table两倍扩容，不转树了 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; // 读写锁 if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125; &#125; ForwardingNode位于 ConcurrentHashMap 类的 2163 行 或 搜索 “static final class ForwardingNode” 123456789101112131415161718192021222324252627282930313233343536// A node inserted at head of bins during transfer operations.连接两个table // 并不是我们传统的包含key-value的节点，只是一个标志节点，并且指向nextTable，提供find方法而已。// 生命周期：仅存活于扩容操作且bin不为null时，一定会出现在每个bin的首位。 static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); // 此节点hash=-1，key、value、next均为null this.nextTable = tab; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; // 查nextTable节点，outer避免深度递归 outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; intn; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) returnnull; for (;;) &#123; // CAS算法多和死循环搭配！直到查到或null int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) returne; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125; &#125; &#125; 在扩容时才会出现的特殊节点，其key,value,hash全部为null。并拥有nextTable指针引用新的table数组。 Traverser123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102static class Traverser&lt;K,V&gt; &#123; Node&lt;K,V&gt;[] tab; //下一个要访问的entry Node&lt;K,V&gt; next; //发现forwardingNode时，保存当前tab相关信息 TableStack&lt;K,V&gt; stack, spare; //下一个要访问的hash桶索引 int index; //当前正在访问的初始tab的hash桶索引 int baseIndex; //初始tab的hash桶索引边界 int baseLimit; //初始tab的长度 final int baseSize; Traverser(Node&lt;K,V&gt;[] tab, int size, int index, int limit) &#123; this.tab = tab; this.baseSize = size; this.baseIndex = this.index = index; this.baseLimit = limit; this.next = null; &#125; // 如果有可能，返回下一个有效节点，否则返回null。 final Node&lt;K,V&gt; advance() &#123; Node&lt;K,V&gt; e; //获取Node链表的下一个元素e if ((e = next) != null) e = e.next; for (;;) &#123; Node&lt;K,V&gt;[] t; int i, n; // e不为空，返回e if (e != null) return next = e; //e为空，说明此链表已经遍历完成，准备遍历下一个hash桶 if (baseIndex &gt;= baseLimit || (t = tab) == null || (n = t.length) &lt;= (i = index) || i &lt; 0) //到达边界，返回null return next = null; //获取下一个hash桶对应的node链表的头节点 if ((e = tabAt(t, i)) != null &amp;&amp; e.hash &lt; 0) &#123; //转发节点,说明此hash桶中的节点已经迁移到了nextTable if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; e = null; //保存当前tab的遍历状态 pushState(t, i, n); continue; &#125; //红黑树 else if (e instanceof TreeBin) e = ((TreeBin&lt;K,V&gt;)e).first; else e = null; &#125; if (stack != null) // 此时遍历的是迁移目标nextTable,尝试回退到源table， // 继续遍历源table中的节点 recoverState(n); else if ((index = i + baseSize) &gt;= n) //初始tab的hash桶索引+1 ，即遍历下一个hash桶 index = ++baseIndex; &#125; &#125; // 在遇到转发节点时保存遍历状态。 private void pushState(Node&lt;K,V&gt;[] t, int i, int n) &#123; TableStack&lt;K,V&gt; s = spare; // reuse if possible if (s != null) spare = s.next; else s = new TableStack&lt;K,V&gt;(); s.tab = t; s.length = n; s.index = i; s.next = stack; stack = s; &#125;// 可能会弹出遍历状态 private void recoverState(int n) &#123; TableStack&lt;K,V&gt; s; int len; // (s = stack) != null :stack不空，说明此时遍历的是nextTable // (index += (len = s.length)) &gt;= n: 确保了按照index, //index+tab.length的顺序遍历nextTable,条件成立表示nextTable已经遍历完毕 //nextTable中的桶遍历完毕 while ((s = stack) != null &amp;&amp; (index += (len = s.length)) &gt;= n) &#123; //弹出tab，获取tab的遍历状态，开始遍历tab中的桶 n = len; index = s.index; tab = s.tab; s.tab = null; TableStack&lt;K,V&gt; next = s.next; s.next = spare; // save for reuse stack = next; spare = s; &#125; if (s == null &amp;&amp; (index += baseSize) &gt;= n) index = ++baseIndex; &#125;&#125; tryPresize(扩容)协调多个线程如何调用transfer方法进行hash桶的迁移（addCount，helpTransfer 方法中也有类似的逻辑） tryPresize在putAll以及treeifyBin中调用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private final void tryPresize(int size) &#123; //计算扩容的目标size // 给定的容量若&gt;=MAXIMUM_CAPACITY的一半，直接扩容到允许的最大值，否则调用函数扩容 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; //没有正在初始化或扩容，或者说表还没有被初始化 Node&lt;K,V&gt;[] tab = table; int n; //tab没有初始化 if(tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; // 扩容阀值取较大者 // 期间没有其他线程对表操作，则CAS将SIZECTL状态置为-1，表示正在进行初始化 //初始化之前，CAS设置sizeCtl=-1 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; //sc=0.75n,相当于扩容阈值 sc = n - (n &gt;&gt;&gt; 2); //无符号右移2位，此即0.75*n &#125; &#125; finally &#123; // 此时并没有通过CAS赋值，因为其他想要执行初始化的线程， // 发现sizeCtl=-1，就直接返回，从而确保任何情况， // 只会有一个线程执行初始化操作。 sizeCtl = sc; &#125; &#125; &#125;// 若欲扩容值不大于原阀值，或现有容量&gt;=最值，什么都不用做了 //目标扩容size小于扩容阈值，或者容量超过最大限制时，不需要扩容 else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; //扩容 else if (tab == table) &#123; int rs = resizeStamp(n); // sc&lt;0表示，已经有其他线程正在扩容 if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt;//RESIZE_STAMP_SHIFT=16,MAX_RESIZERS=2^15-1 // 1. (sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs ：扩容线程数 &gt; MAX_RESIZERS-1 // 2. sc == rs + 1 和 sc == rs + MAX_RESIZERS ：表示什么？？？ // 3. (nt = nextTable) == null ：表示nextTable正在初始化 // transferIndex &lt;= 0 ：表示所有hash桶均分配出去 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) //如果不需要帮其扩容，直接返回 break; //CAS设置sizeCtl=sizeCtl+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) //帮其扩容 transfer(tab, nt); &#125; // 第一个执行扩容操作的线程，将sizeCtl设置为： // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125; &#125; 123456789private static final int tableSizeFor(int c)&#123;//和HashMap一样,返回&gt;=n的最小2的自然数幂 int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; spread 重新哈希spread()重哈希，以减小Hash冲突。我们知道对于一个hash表来说，hash值分散的不够均匀的话会大大增加哈希冲突的概率，从而影响到hash表的性能。因此通过spread方法进行了一次重hash从而大大减小哈希冲突的可能性。spread方法为： 123static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; 该方法主要是将key的hashCode的低16位于高16位进行异或运算，这样不仅能够使得hash值能够分散能够均匀减小hash冲突的概率，另外另外只用到了异或运算，在性能开销上也能兼顾，做到平衡的trade-off。 get(查找)1234567891011121314151617181920212223242526272829303132public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 1. 重hash int h = spread(key.hashCode()); // 2. table[i]桶节点的key与查找的key相同，则直接返回 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; // 唯一一处volatile读操作 (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 注意：因为容器大小为2的次方，所以 h mod n = h &amp; (n -1) if ((eh = e.hash) == h) &#123;// 如果hash值相等 // 检查第一个Node if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // hash为负表示是扩容中的ForwardingNode节点 // 直接调用ForwardingNode的find方法(可以是代理到扩容中的nextTable) // 3. 当前节点hash小于0说明为树节点，在红黑树中查找即可 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表，对比key值 // 通过next指针，逐一查找 while ((e = e.next) != null) &#123; //4. 从链表中查找，查找到则返回该节点的value，否则就返回null即可 if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; 代码的逻辑请看注释，首先先看当前的hash桶数组节点即table[i]是否为查找的节点，若是则直接返回；若不是，则继续再看当前是不是树节点？通过看节点的hash值是否为小于0，如果小于0则为树节点。如果是树节点在红黑树中查找节点；如果不是树节点，那就只剩下为链表的形式的一种可能性了，就向后遍历查找节点，若查找到则返回节点的value即可，若没有找到就返回null。 这个 get 请求，我们需要 cas 来保证变量的原子性。如果 tab[i] 正被锁住，那么 CAS 就会失败，失败之后就会不断的重试。这也保证了在高并发情况下不会出错。 我们来分析一下哪些情况会导致 get 在并发的情况下可能取不到值。 一个线程在 get 的时候，另一个线程在对同一个 key 的 node 进行 remove 操作 一个线程在 get 的时候，另一个线程正在重排 table 。可能导致旧 table 取不到值 那么本质是，我在get的时候，有其他线程在对同一桶的链表或树进行修改。那么get是怎么保证同步性的呢？我们看到e = tabAt(tab, (n - 1) &amp; h)) != null，在看下tablAt到底是干嘛的： 123static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; 它是对tab[i]进行原子性的读取，因为我们知道putVal等对table的桶操作是有加锁的，那么一般情况下我们对桶的读也是要加锁的，但是我们这边为什么不需要加锁呢？因为我们用了Unsafe的getObjectVolatile，因为table是volatile类型，所以对tab[i]的原子请求也是可见的。因为如果同步正确的情况下，根据happens-before原则，对volatile域的写入操作happens-before于每一个后续对同一域的读操作。所以不管其他线程对table链表或树的修改，都对get读取可见。用一张图说明，协调读-写线程可见示意图： jdk7是没有用到CAS操作和Unsafe类的，下面是jdk7的get方法： 12345678910111213141516V get(Object key, int hash) &#123; if(count != 0) &#123; // 首先读 count 变量 HashEntry&lt;K,V&gt; e = getFirst(hash); while(e != null) &#123; if(e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if(v != null) return v; // 如果读到 value 域为 null，说明发生了重排序，加锁后重新读取 return readValueUnderLock(e); &#125; e = e.next; &#125; &#125; return null; &#125; 为什么我们在get的时候需要判断count不等于0呢？如果是在HashMap的源码中是没有这个判断的，不用判断不是也是可以的吗？这个就是用到线程安全发布情况下happens-before原则之volatile变量法则：对volatile域的写入操作happens-before于每一个后续对同一域的读操作，看下面的示意图： tabAt以 volatile 读的方式读取 table 数组中的元素 12345// 这边为什么i要等于((long)i &lt;&lt; ASHIFT) + ABASE呢,计算偏移量static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; // Key对应的数组元素的可见性，由Unsafe的getObjectVolatile方法保证。 return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; tabAt 方法用来获取table数组中索引为i的Node元素。 put/putValputVal是将一个新key-value mapping插入到当前ConcurrentHashMap的关键方法。 此方法的具体流程如下图： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // 不允许 key 和 value 为空 if (key == null || value == null) throw new NullPointerException(); // 1.计算 key 的 hash 值(计算新节点的hash值) int hash = spread(key.hashCode()); // 返回 (h^(h&gt;&gt;&gt;16))&amp;HASH_BITS int binCount = 0; // 获取当前table，进入死循环,直到插入成功！ for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 2. 如果当前 table 还没初始化先调用 initTable 方法将 tab 进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 如果table为空，执行初始化，也即是延迟初始化 // 3. tab中索引为i的位置的元素为null,则直接使用 CAS 将值插入即可 // 如果bin为空，则采用cas算法赋值，无需加锁 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null,new Node&lt;K,V&gt;(hash, key, value, null))) // 直接设置为桶首节点成功，退出死循环（出口之一） break; &#125; // 4. 当前正在扩容 // 当前桶首节点正在特殊的扩容状态下，当前线程尝试参与扩容 // 然后重新进入死循环 //f.hash == MOVED 表示为：ForwardingNode，说明其他线程正在扩容 else if ((fh = f.hash) == MOVED) // MOVED = -1 tab = helpTransfer(tab, f); // 当发现其他线程扩容时，帮其扩容 // 通过桶首节点，将新节点加入table else &#123; V oldVal = null; // 获取桶首节点实例对象锁，进入临界区进行添加操作 synchronized (f) &#123; // 再判断以此f是否仍是第一个Node，如果不是，退出临界区，重复添加操作 if (tabAt(tab, i) == f) &#123; //5. 当前为链表，在链表中插入新的键值对 if (fh &gt;= 0) &#123; // 桶首节点hash值&gt;0，表示为链表 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 找到hash值相同的key,覆盖旧值即可 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; // 仅 putIfAbsent() 方法中的 onlyIfAbsend 为 true; if (!onlyIfAbsent) // putIfAbsend() 包含 key 则返回 get ,否则 put 并返回 e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果到链表末尾仍未找到，则直接将新值插入到链表末尾即可 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 桶首节点为Node子类型TreeBin，表示为红黑树 // 6.当前为红黑树，将新的键值对插入到红黑树中 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; // 调用putTreeVal方法，插入新值 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; // key已经存在，则替换 oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // 7.插入完键值对后再根据实际大小看是否需要转换成红黑树 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) // 插入新节点后，达到链表转换红黑树阈值，则执行转换操作 // 此函数内部会判断是树化，还是扩容：tryPresize treeifyBin(tab, i); // 退出死循环（出口之二） if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 更新计算count时的base和counterCells数组 //8.对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容 addCount(1L, binCount); return null;&#125; 当table[i]为链表的头结点，在链表中插入新值在table[i]不为null并且不为forwardingNode时，并且当前Node f的hash值大于0（fh &gt;= 0）的话说明当前节点f为当前桶的所有的节点组成的链表的头结点。那么接下来，要想向ConcurrentHashMap插入新值的话就是向这个链表插入新值。通过synchronized (f)的方式进行加锁以实现线程安全性。往链表中插入节点的部分代码为： 12345678910111213141516171819202122if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 找到hash值相同的key,覆盖旧值即可 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; //如果到链表末尾仍未找到，则直接将新值插入到链表末尾即可 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125;&#125; 这部分代码很好理解，就是两种情况：1. 在链表中如果找到了与待插入的键值对的key相同的节点，就直接覆盖即可；2. 如果直到找到了链表的末尾都没有找到的话，就直接将待插入的键值对追加到链表的末尾即可。 当table[i]为红黑树的根节点，在红黑树中插入新值按照之前的数组+链表的设计方案，这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，甚至在极端情况下，查找一个节点会出现时间复杂度为O(n)的情况，则会严重影响ConcurrentHashMap的性能，于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高ConcurrentHashMap的性能，其中会用到红黑树的插入、删除、查找等算法。当table[i]为红黑树的树节点时的操作为： 12345678910if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125;&#125; 首先在if中通过f instanceof TreeBin判断当前table[i]是否是树节点，这下也正好验证了我们在最上面介绍时说的TreeBin会对TreeNode做进一步封装，对红黑树进行操作的时候针对的是TreeBin而不是TreeNode。这段代码很简单，调用putTreeVal方法完成向红黑树插入新节点，同样的逻辑，如果在红黑树中存在于待插入键值对的Key相同（hash值相等并且equals方法判断为true）的节点的话，就覆盖旧值，否则就向红黑树追加新节点。 当table[i]为红黑树的根节点，在红黑树中插入新值。按照之前的数组+链表的设计方案，这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，甚至在极端情况下，查找一个节点会出现时间复杂度为O(n)的情况，则会严重影响ConcurrentHashMap的性能，于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高ConcurrentHashMap的性能，其中会用到红黑树的插入、删除、查找等算法。当table[i]为红黑树的树节点时的操作为： 123456789if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125;&#125; 首先在if中通过f instanceof TreeBin判断当前table[i]是否是树节点，这下也正好验证了我们在最上面介绍时说的TreeBin会对TreeNode做进一步封装，对红黑树进行操作的时候针对的是TreeBin而不是TreeNode。这段代码很简单，调用putTreeVal方法完成向红黑树插入新节点，同样的逻辑，如果在红黑树中存在于待插入键值对的Key相同（hash值相等并且equals方法判断为true）的节点的话，就覆盖旧值，否则就向红黑树追加新节点。 根据当前节点个数进行调整当完成数据新节点插入之后，会进一步对当前链表大小进行调整，这部分代码为： 1234567if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break;&#125; 很容易理解，如果当前链表节点个数大于等于8（TREEIFY_THRESHOLD）的时候，就会调用treeifyBin方法将tabel[i]（第i个散列桶）拉链转换成红黑树。 关于Put方法的逻辑就基本说的差不多了，现在来做一些总结： 整体流程： 首先对于每一个放入的值，首先利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在 table中的位置； 如果当前table数组还未初始化，先将table数组进行初始化操作； 如果这个位置是null的，那么使用CAS操作直接放入； 如果这个位置存在结点，说明发生了hash碰撞，首先判断这个节点的类型。如果该节点fh==MOVED(代表forwardingNode,数组正在进行扩容)的话，说明正在进行扩容； 如果是链表节点（fh&gt;0）,则得到的结点就是hash值相同的节点组成的链表的头节点。需要依次向后遍历确定这个新加入的值所在位置。如果遇到hash值与key值都与新加入节点是一致的情况，则只需要更新value值即可。否则依次向后遍历，直到链表尾插入这个结点； 如果这个节点的类型是TreeBin的话，直接调用红黑树的插入方法进行插入新的节点； 插入完节点之后再次检查链表长度，如果长度大于8，就把这个链表转换成红黑树； 对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容。 该流程中，可以细细品味的环节有： - 初始化方法 initTable - 扩容方法 transfer (在多线程扩容方法 helpTransfer 中被调用) initTableinitTable方法允许多线程同时进入，但只有一个线程可以完成table的初始化，其他线程都会通过yield方法让出cpu。 12345678910111213141516171819202122232425262728293031323334353637private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; // 前文提及sizeCtl是重要的控制变量 // sizeCtl = -1 表示正在初始化 if ((sc = sizeCtl) &lt; 0) // 已经有其他线程在执行初始化，则主动让出cpu // 1. 保证只有一个线程正在进行初始化操作 Thread.yield(); // 利用CAS操作设置sizeCtl为-1 // 设置成功表示当前线程为执行初始化的唯一线程 // 此处进入临界区 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; // 由于让出cpu的线程也会后续进入该临界区 // 需要进行再次确认table是否为null if ((tab = table) == null || tab.length == 0) &#123; // 2. 得出数组的大小 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") // 3. 这里才真正的初始化数组，即分配Node数组 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 默认负载为0.75 // 4. 计算数组中可用的大小：实际大小n*0.75（加载因子） sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; // 退出死循环的唯一出口 break; &#125; &#125; return tab;&#125; 代码的逻辑请见注释，有可能存在一个情况是多个线程同时走到这个方法中，为了保证能够正确初始化，在第1步中会先通过if进行判断，若当前已经有一个线程正在初始化即sizeCtl值变为-1，这个时候其他线程在If判断为true从而调用Thread.yield()让出CPU时间片。正在进行初始化的线程会调用U.compareAndSwapInt方法将sizeCtl改为-1即正在初始化的状态。另外还需要注意的事情是，在第四步中会进一步计算数组中可用的大小即为数组实际大小n乘以加载因子0.75.可以看看这里乘以0.75是怎么算的，0.75为四分之三，这里n - (n &gt;&gt;&gt; 2)是不是刚好是n-(1/4)n=(3/4)n，挺有意思的吧:)。如果选择是无参的构造器的话，这里在new Node数组的时候会使用默认大小为DEFAULT_CAPACITY（16），然后乘以加载因子0.75为12，也就是说数组的可用大小为12。 casTabAt(原子操作方法)以 CAS 的方式，将元素插入到 table 数组 123456789101112/* *这边为什么i要等于((long)i &lt;&lt; ASHIFT) + ABASE呢,计算偏移量 *ASHIFT是指tab[i]中第i个元素在相对于数组第一个元素的偏移量，而ABASE就算第一数组的内存素的偏移地址 *所以呢，((long)i &lt;&lt; ASHIFT) + ABASE就算i最后的地址 * 那么compareAndSwapObject的作用就算tab[i]和c比较，如果相等就tab[i]=v否则tab[i]=c; */ // 利用CAS算法设置i位置上的Node节点（将c和table[i]比较，相同则插入v）。 static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; //原子的执行如下逻辑：如果tab[i]==c,则设置tab[i]=v，并返回ture.否则返回false return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v); &#125; 利用CAS操作设置table数组中索引为i的元素 setTabAt以 valatile 写的方式，将元素插入 table 数组 123static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; 该方法用来设置table数组中索引为i的元素 实例构造器方法在使用ConcurrentHashMap第一件事自然而然就是new 出来一个ConcurrentHashMap对象，一共提供了如下几个构造器方法： 12345678910// 1. 构造一个空的map，即table数组还未初始化，初始化放在第一次插入数据时，默认大小为16ConcurrentHashMap()// 2. 给定map的大小ConcurrentHashMap(int initialCapacity) // 3. 给定一个mapConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m)// 4. 给定map的大小以及加载因子ConcurrentHashMap(int initialCapacity, float loadFactor)// 5. 给定map大小，加载因子以及并发度（预计同时操作数据的线程）ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) ConcurrentHashMap一共给我们提供了5中构造器方法，具体使用请看注释，我们来看看第2种构造器，传入指定大小时的情况，该构造器源码为： 1234567891011public ConcurrentHashMap(int initialCapacity) &#123; //1. 小于0直接抛异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(); //2. 判断是否超过了允许的最大值，超过了话则取最大值，否则再对该值进一步处理 int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); //3. 赋值给sizeCtl this.sizeCtl = cap;&#125; 这段代码的逻辑请看注释，很容易理解，如果小于0就直接抛出异常，如果指定值大于了所允许的最大值的话就取最大值，否则，在对指定值做进一步处理。最后将cap赋值给sizeCtl,关于sizeCtl的说明请看上面的说明，当调用构造器方法之后，sizeCtl的大小应该就代表了ConcurrentHashMap的大小，即table数组长度。tableSizeFor做了哪些事情了？源码为： tableSizeFor12345678910private static final int tableSizeFor(int c) &#123; int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 通过注释就很清楚了，该方法会将调用构造器方法时指定的大小转换成一个2的幂次方数，也就是说ConcurrentHashMap的大小一定是2的幂次方，比如，当指定大小为18时，为了满足2的幂次方特性，实际上concurrentHashMapd的大小为2的5次方（32）。另外，需要注意的是，调用构造器方法的时候并未构造出table数组（可以理解为ConcurrentHashMap的数据容器），只是算出table数组的长度，当第一次向ConcurrentHashMap插入数据的时候才真正的完成初始化创建table数组的工作。 helpTransfer(协助扩容)123456789101112131415161718192021// 协助扩容方法。多线程下，当前线程检测到其他线程正进行扩容操作，则协助其一起扩容；（只有这种情况会被调用）从某种程度上说，其“优先级”很高，只要检测到扩容，就会放下其他工作，先扩容。 // 调用之前，nextTable一定已存在。 final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; intsc; if (tab != null &amp;&amp; (finstanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; intrs = resizeStamp(tab.length); //标志位 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab);//调用扩容方法，直接进入复制阶段 break; &#125; &#125; return nextTab; &#125; return table; &#125; addCount在put方法结尾处调用了addCount方法，把当前ConcurrentHashMap的元素个数+1这个方法一共做了两件事,更新baseCount的值，检测是否进行扩容。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //利用CAS方法更新baseCount的值 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123;// 1 CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; // 多线程 CAS 发生失败的时候执行 fullAddCount(x, uncontended); // 2 return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; //如果check值大于等于0 则需要检验是否需要进行扩容操作 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; // 当条件满足的时候开始扩容 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); // 如果小于0 说明已经有线程在进行扩容了 if (sc &lt; 0) &#123; // 一下的情况说明已经有在扩容或者多线程进行了扩容，其他线程直接 break 不要进入扩容 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 如果已经有其他线程在执行扩容操作 // 如果相等说明已经完成，可以继续扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 当前线程是唯一的或是第一个发起扩容的线程 此时nextTable=null // 这个时候 sizeCtl 已经等于(rs&lt;&lt;RESIZE_STAMP_SHIFT)+2 等于一个大的负数，这边 // 加上2很巧，因为 transfer 后面对 sizeCtl-- 操作的时候，最多只能减两个就结束 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125; &#125; 看上面的注释1,每次都会对 baseCount 加1,如果并发竞争太大，那么可能导致 U.compareAndSwapLong(this,BASECOUNT,b=baseCount,s = b + x) 失败,那么为了提高高并发的时候 baseCount 可见性的失败的问题,又避免一直重试，这样性能会有很大的影响,那么在 jdk 8的时候是有引入一个类 Striped64 ,其中 LongAdder 和 DoubleAdder 就是对这个类的实现。这两个方法都是为了解决高并发场景而生的，是 AtomicLong 的加强版,AtomicLong 在高并发场景性能会比 LongAdder 差。但是 LongAdder 的空间复杂度会高点。 fullAddCount123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293private final void fullAddCount(long x, boolean wasUncontended) &#123; int h; // 获取当前线程的 probe 值作为 hash 值,如果0则强制初始化当前线程的 Probe 值， // 初始化 probe 值不为 0 if ((h = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); // force initialization h = ThreadLocalRandom.getProbe(); // 设置未竞争标记为true wasUncontended = true; &#125; boolean collide = false; // True if last slot nonempty for (;;) &#123; CounterCell[] as; CounterCell a; int n; long v; if ((as = counterCells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; if ((a = as[(n - 1) &amp; h]) == null) &#123; // Try to attach new Cell 如果当前没有 CounterCell 就创建一个 if (cellsBusy == 0) &#123; CounterCell r = new CounterCell(x); // Optimistic create if (cellsBusy == 0 &amp;&amp; // 这边加上 cellsBusy 锁 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean created = false; try &#123; // Recheck under lock CounterCell[] rs; int m, j; if ((rs = counterCells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; rs[j] = r; created = true; &#125; &#125; finally &#123; // 释放 cellsBusy 锁定，让其他线程可以进来 cellsBusy = 0; &#125; if (created) break; continue; // Slot is now non-empty &#125; &#125; collide = false; &#125; // wasUncontended 为 false 说明已经发生了竞争，重置为true重新执行上面代码 else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash // 对 cell 的值进行累计x(1) else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; // 表明 as 已经过时，说明 cells 已经初始化完成，看下面， // 重置 collide 为 false 表明已经存在竞争 else if (counterCells != as || n &gt;= NCPU) collide = false; // At max size or stale else if (!collide) collide = true; else if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; try &#123; // 下面的方法主要是给 counterCells 扩容，尽可能避免冲突 if (counterCells == as) &#123;// Expand table unless stale CounterCell[] rs = new CounterCell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; counterCells = rs; &#125; &#125; finally &#123; cellsBusy = 0; &#125; collide = false; continue; // Retry with expanded table &#125; h = ThreadLocalRandom.advanceProbe(h); &#125; // 表明 counterCells 还没初始化，则初始化，这边用 cellsBusy 加锁 else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean init = false; try &#123; // Initialize table if (counterCells == as) &#123; CounterCell[] rs = new CounterCell[2]; rs[h &amp; 1] = new CounterCell(x); counterCells = rs; init = true; &#125; &#125; finally &#123; cellsBusy = 0; &#125; if (init) break; &#125; // 最终如果上面的都失败就把 x 累计到 baseCount else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; // Fall back on using base &#125; &#125; 回到 addCount 来,我们每次竞争都对 baseCount 进行加 1 当达到一定的容量时，就需要对 table 进行扩容。 使用 transfer 方法。 transfer负责迁移node节点 扩容transfer方法是一个设计极为精巧的方法。通过互斥读写ForwardingNode，多线程可以协同完成扩容任务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //计算每次迁移的node个数（MIN_TRANSFER_STRIDE该值作为下限，以避免扩容线程过多） if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) // 确保每次迁移的node个数不少于16个 stride = MIN_TRANSFER_STRIDE; // nextTab为扩容中的临时table if (nextTab == null) &#123; try &#123; //扩容一倍 @SuppressWarnings("unchecked") // 1. 新建一个 node 数组，容量为之前的两倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; // transferIndex为扩容复制过程中的桶首节点遍历索引 // 所以从n开始，表示从后向前遍历 transferIndex = n; &#125; int nextn = nextTab.length; // ForwardingNode是Node节点的直接子类，是扩容过程中的特殊桶首节点 // 该类中没有key,value,next // hash值为特定的-1 // 附加Node&lt;K,V&gt;[] nextTable变量指向扩容中的nextTab // 在find方法中，将扩容中的查询操作导入到nextTab上 //2. 新建forwardingNode引用，在之后会用到 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; // 循环的关键变量，判断是否已经扩容完成，完成就 return , 退出循环 boolean finishing = false; //【1】逆序迁移已经获取到的hash桶集合，如果迁移完毕，则更新transferIndex， // 获取下一批待迁移的hash桶 //【2】如果transferIndex=0，表示所以hash桶均被分配，将i置为-1， // 准备退出transfer方法 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // 3. 确定遍历中的索引i（更新待迁移的hash桶索引） // 循环的关键 i , i-- 操作保证了倒叙遍历数组 while (advance) &#123; int nextIndex, nextBound; // 更新迁移索引i if (--i &gt;= bound || finishing) advance = false; // transferIndex = 0表示table中所有数组元素都已经有其他线程负责扩容 // nextIndex=transferIndex=n=tab.length(默认16) else if ((nextIndex = transferIndex) &lt;= 0) &#123; // transferIndex&lt;=0表示已经没有需要迁移的hash桶， // 将i置为-1，线程准备退出 i = -1; advance = false; &#125; //cas无锁算法设置 transferIndex = transferIndex - stride // 尝试更新transferIndex，获取当前线程执行扩容复制的索引区间 // 更新成功，则当前线程负责完成索引为(nextBound，nextIndex)之间的桶首节点扩容 //当迁移完bound这个桶后，尝试更新transferIndex，获取下一批待迁移的hash桶 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //退出transfer //4.将原数组中的元素复制到新数组中去 //4.5 for循环退出，扩容结束修改sizeCtl属性// i&lt;0 说明已经遍历完旧的数组tab;i&gt;=n什么时候有可能呢？在下面看到i=n,所以目前i最大应该是n吧// i+n&gt;=nextn,nextn=nextTab.length,所以如果满足i+n&gt;=nextn说明已经扩容完成 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; // a //最后一个迁移的线程，recheck后，做收尾工作，然后退出 nextTable = null; table = nextTab; // 扩容成功，设置新sizeCtl，仍然为总大小的0.75 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; // 第一个扩容的线程，执行transfer方法之前，会设置 sizeCtl = // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 后续帮其扩容的线程，执行transfer方法之前，会设置 sizeCtl = sizeCtl+1 // 每一个退出transfer的方法的线程，退出之前，会设置 sizeCtl = sizeCtl-1 // 那么最后一个线程退出时： // 必然有sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2)， // 即 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 如果有多个线程进行扩容，那么这个值在第二个线程以后就不会相等，因为 // sizeCtl 已经被减1了，所以后面的线程只能直接返回， // 始终保证只有一个线程执行了a(上面的注释a) if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // finishing 和 advance 保证线程已经扩容完成了可以退出循环 finishing = advance = true; //最后退出的线程要重新check下是否全部迁移完毕 i = n; &#125; &#125; // 当前table节点为空，不需要复制，直接放入ForwardingNode //4.1 当前数组中第i个元素为null，用CAS设置成特殊节点forwardingNode(可以理解成占位符) // 如果 tab[i] 为 null,那么就把 fwd 插入到 tab[i],表明这个节点已经处理过了 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 当前table节点已经是ForwardingNode // 表示已经被其他线程处理了，则直接往前遍历 // 通过CAS读写ForwardingNode节点状态，达到多线程互斥处理 // 4.2 如果遍历到ForwardingNode节点说明这个点已经被处理过了直接跳过 // 这里是控制并发扩容的核心 // 如果 f.hash=-1 的话说明该节点为 ForwardingNode,说明该节点已经处理过了 else if ((fh = f.hash) == MOVED) advance = true; //迁移node节点 else &#123; // 锁住当前桶首节点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // 链表节点复制(链表迁移) if (fh &gt;= 0) &#123; // 4.3 处理当前节点为链表的头结点的情况，构造两个链表，一个是原链表 // 另一个是原链表的反序排列 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; //将node链表，分成2个新的node链表 // 这边还对链表进行遍历，这边的算法和hashMap的算法又不一样了，对半拆分 // 把链表拆分为，hash&amp;n 等于0和不等于0的，然后分别放在新表的i和i+n位置 // 此方法同 HashMap 的 resize for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //将新node链表赋给nextTab //在nextTable的i位置上插入一个链表 setTabAt(nextTab, i, ln); //在nextTable的i+n的位置上插入另一个链表 setTabAt(nextTab, i + n, hn); // 扩容成功后，设置ForwardingNode节点 //在table的i位置上插入forwardNode节点表示已经处理过该节点 // 把已经替换的节点的旧tab的i的位置用fwd替换，fwd包含nextTab setTabAt(tab, i, fwd); //设置advance为true 返回到上面的while循环中 就可以执行i--操作 advance = true; &#125; // 红黑树节点复制(红黑树迁移) //4.4 处理当前节点是TreeBin时的情况，操作和上面的类似 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 判断扩容后是否还需要红黑树 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); // 扩容成功后，设置ForwardingNode节点 setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125; &#125; 代码逻辑请看注释,整个扩容操作分为两个部分： 第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。新建table数组的代码为:Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1],在原容量大小的基础上右移一位。 第二个部分就是将原来table中的元素复制到nextTable中，主要是遍历复制的过程。根据运算得到当前遍历的数组的位置i，然后利用tabAt方法获得i位置的元素再进行判断： 如果这个位置为空，就在原table中的i位置放入forwardNode节点，这个也是触发并发扩容的关键点； 如果这个位置是Node节点（fh&gt;=0），如果它是一个链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上 如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要untreefi，把处理的结果分别放在nextTable的i和i+n的位置上 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。设置为新容量的0.75倍代码为 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1)，仔细体会下是不是很巧妙，n&lt;&gt;&gt;1左右一位相当于n除以2即0.5n,然后两者相减为2n-0.5n=1.5n,是不是刚好等于新容量的0.75倍即2n*0.75=1.5n。最后用一个示意图来进行总结（图片摘自网络）： mappingCount 与 sizemappingCount与size方法的类似 从给出的注释来看，应该使用mappingCount代替size方法 两个方法都没有直接返回basecount 而是统计一次这个值，而这个值其实也是一个大概的数值，因此可能在统计的时候有其他线程正在执行插入或删除操作。 1234567891011121314151617181920212223242526272829303132public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125; /** * Returns the number of mappings. This method should be used * instead of &#123;@link #size&#125; because a ConcurrentHashMap may * contain more mappings than can be represented as an int. The * value returned is an estimate; the actual count may differ if * there are concurrent insertions or removals. * * @return the number of mappings * @since 1.8 */public long mappingCount() &#123; long n = sumCount(); return (n &lt; 0L) ? 0L : n; // ignore transient negative values&#125; final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value;//所有counter的值求和 &#125; &#125; return sum;&#125; remove和put方法一样，多个remove线程请求不同的hash桶时，可以并发执行 如图所示：删除的node节点的next依然指着下一个元素。此时若有一个遍历线程正在遍历这个已经删除的节点，这个遍历线程依然可以通过next属性访问下一个元素。从遍历线程的角度看，他并没有感知到此节点已经删除了，这说明了ConcurrentHashMap提供了弱一致性的迭代器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public V remove(Object key) &#123; return replaceNode(key, null, null); &#125; // 当参数 value == null 时，删除节点。否则更新节点的值为value // cv 是个期望值，当 map[key].value 等于期望值 cv 或 cv == null 时， // 删除节点，或者更新节点的值 final V replaceNode(Object key, V value, Object cv) &#123; int hash = spread(key.hashCode()); for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // table 还没初始化或key对应的 hash 桶为空 if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; // 正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; boolean validated = false; synchronized (f) &#123; // CAS 获取 tab[i] ,如果此时 tab[i] != f,说明其他线程修改了 tab[i] // 回到 for 循环开始处，重新执行 if (tabAt(tab, i) == f) &#123; // node 链表 if (fh &gt;= 0) &#123; validated = true; for (Node&lt;K,V&gt; e = f, pred = null;;) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; V ev = e.val; // ev 代表参数期望值 // cv == null:直接更新value/删除节点 // cv 不为空，则只有在 key 的 oldVal 等于 // 期望值的时候，才更新 value/删除节点 if (cv == null || cv == ev || (ev != null &amp;&amp; cv.equals(ev))) &#123; oldVal = ev; //更新value if (value != null) e.val = value; //删除非头节点 else if (pred != null) pred.next = e.next; //删除头节点 else // 因为已经获取了头结点锁，所以此时 // 不需要使用casTabAt setTabAt(tab, i, e.next); &#125; break; &#125; //当前节点不是目标节点，继续遍历下一个节点 pred = e; if ((e = e.next) == null) //到达链表尾部，依旧没有找到，跳出循环 break; &#125; &#125; //红黑树 else if (f instanceof TreeBin) &#123; validated = true; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; r, p; if ((r = t.root) != null &amp;&amp; (p = r.findTreeNode(hash, key, null)) != null) &#123; V pv = p.val; if (cv == null || cv == pv || (pv != null &amp;&amp; cv.equals(pv))) &#123; oldVal = pv; if (value != null) p.val = value; else if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); &#125; &#125; &#125; &#125; &#125; if (validated) &#123; if (oldVal != null) &#123; //如果删除了节点，更新size if (value == null) addCount(-1L, -1); return oldVal; &#125; break; &#125; &#125; &#125; return null; &#125; ForwardingNode1234567891011121314151617181920212223242526272829303132333435static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; //hash值为MOVED（-1）的节点就是ForwardingNode super(MOVED, null, null, null); this.nextTable = tab; &#125; //通过此方法，访问被迁移到nextTable中的数据 Node&lt;K,V&gt; find(int h, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; int n; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) return null; for (;;) &#123; int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125; &#125;&#125; 总结JDK6,7中的ConcurrentHashmap主要使用Segment来实现减小锁粒度，分割成若干个Segment，在put的时候需要锁住Segment，get时候不加锁，使用volatile来保证可见性，当要统计全局时（比如size），首先会尝试多次计算modcount来确定，这几次尝试中，是否有其他线程进行了修改操作，如果没有，则直接返回size。如果有，则需要依次锁住所有的Segment来计算。 而在1.8的时候摒弃了segment臃肿的设计，这种设计在定位到具体的桶时，要先定位到具体的segment，然后再在segment中定位到具体的桶。而到了1.8的时候是针对的是Node[] tale数组中的每一个桶，进一步减小了锁粒度。并且防止拉链过长导致性能下降，当链表长度大于8的时候采用红黑树的设计。 主要设计上的变化有以下几点: 不采用segment而采用node，锁住node来实现减小锁粒度。 设计了MOVED状态 当resize的中过程中 线程2还在put数据，线程2会帮助resize。 使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。 sizeCtl的不同值来代表不同含义，起到了控制的作用。 采用synchronized而不是ReentrantLock volatile语义提供更细颗粒度的轻量级锁，使得多线程可以(几乎)同时读写实例中的关键量，正确理解当前类所处的状态，进入对应if语句中执行相关逻辑。 采用更加细粒度的hash桶级别锁，扩容期间，依然可以保证写操作的并发度。 多线程无锁扩容的关键就是通过CAS设置sizeCtl与transferIndex变量，协调多个线程对table数组中的node进行迁移。 参考文章：http://www.cnblogs.com/huaizuo/p/5413069.html 参考文章：http://www.bijishequ.com/detail/560964?p= 参考文章：https://bentang.me/tech/2016/12/01/jdk8-concurrenthashmap-1/ 参考文章: http://www.jianshu.com/p/5bc70d9e5410 扩容原理: http://www.jianshu.com/p/487d00afe6ca 遍历操作：http://www.jianshu.com/p/3e85ac8f8662 改进说明带例子:http://www.voidcn.com/article/p-gdbewnlb-qh.html http://nannan408.iteye.com/blog/2217042]]></content>
      <categories>
        <category>ConcurrentHashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 款最好的 Python IDE]]></title>
    <url>%2F2017%2F12%2F21%2F10%E6%AC%BE%E6%9C%80%E5%A5%BD%E7%9A%84Python%20IDE%2F</url>
    <content type="text"><![CDATA[10 款最好的 Python IDE Vim Eclipse PyDev Sublime Text Emacs Komodo PyCharm Wing PyScripter The Eric Python IDE Interactive Editor for Python]]></content>
      <categories>
        <category>Python IDE</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime Text 3 搭建Python开发环境]]></title>
    <url>%2F2017%2F12%2F21%2FSublime%20Text%203%20%E6%90%AD%E5%BB%BAPython%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[Sublime Text 3 搭建Python开发环境前言 Sublime Text：一款具有代码高亮、语法提示、自动完成且反应快速的编辑器软件，不仅具有华丽的界面，还支持插件扩展机制，用她来写代码，绝对是一种享受。相比于难于上手的 Vim ，浮肿沉重的 Eclipse ， VS ，即便体积轻巧迅速启动的 Editplus 、 Notepad++ ，在 Sublime Text 面前也略显失色，无疑这款性感无比的编辑器是 Coding 和 Writing 最佳的选择，没有之一。 Sublime Text 3 的功能实在是太强大了，搭配各种 package ，码代码、美如画。对于 Sublime Text 3 的介绍网上一大堆，博主就不再这里赘述了。本篇博文主要是记录一下博主如何在 Sublime Text 3 下优雅的编写、编译、运行 python 代码。 安装 我使用的版本是 Sublime Text Build 3143 ，大家自行下载后直接安装即可，安装完之后需要 License 来激活我们的软件。 ​ Sublime Text Build 3143的下载路径： ​ https://code.aliyun.com/shenwenfang106/SublimeTextBuild3143.git 直接将下面的 License 复制过去就好，亲测可用： 12345678910111213—– BEGIN LICENSE —– TwitterInc 200 User License EA7E-890007 1D77F72E 390CDD93 4DCBA022 FAF60790 61AA12C0 A37081C5 D0316412 4584D136 94D7F7D4 95BC8C1C 527DA828 560BB037 D1EDDD8C AE7B379F 50C9D69D B35179EF 2FE898C4 8E4277A8 555CE714 E1FB0E43 D5D52613 C3D12E98 BC49967F 7652EED2 9D2D2E61 67610860 6D338B72 5CF95C69 E36B85CC 84991F19 7575D828 470A92AB —— END LICENSE ——12345678910111213 配置Package Control 按 Ctrl+` 调出 console ，粘贴以下代码到底部命令行并回车： 1import urllib.request,os,hashlib; h = '6f4c264a24d933ce70df5dedcf1dcaee' + 'ebe013ee18cced0ef93d5f746d80ef60'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)1 重启 Sublime Text 3。如果在 Perferences-&gt;package settings 中看到 package control 这一项，则安装成功。按下 Ctrl+Shift+P 调出命令面板输入 install 调出 Install Package 选项并回车，然后在列表中选中要安装的插件。 下面介绍几个比较实用的 package 。 SideBarEnhancements SideBarEnhancements 扩展了侧边栏中菜单选项的数量，从而提升你的工作效率。诸如 “New file” 和 “Duplicate” 这样的选项对于 ST3 来说实在是太重要了，而且仅凭 “Delete” 这一个功能就让这个插件值得下载。这个功能将你会在你删除文件的时候把它放入回收站。虽然这个功能乍一看没什么用，但是当你没有使用这样的功能而彻底删除了一个文件的时候，除非你用了版本管理软件，否则你将很难恢复这个文件。 Anaconda Anaconda 是一个终极 Python 插件。它为 ST3 增添了多项 IDE 类似的功能，例如： Autocompletion 自动完成，该选项默认开启，同时提供多种配置选项。 Code linting 使用支持 pep8 标准的 PyLint 或者 PyFlakes。 McCabe code complexity checker 让你可以在特定的文件中使用 McCabe complexity checker. Goto Definitions 能够在你的整个工程中查找并且显示任意一个变量，函数，或者类的定义。 Find Usage 能够快速的查找某个变量，函数或者类在某个特定文件中的什么地方被使用了。 Show Documentation： 能够显示一个函数或者类的说明性字符串(当然，是在定义了字符串的情况下) 但是，刚安装完之后，打开一个 python 文档，所有代码都会被白色细线框中，如图所示； ​ 强迫症的我看着好难受，决心要搞一搞这东西。后来发现在 Sublime &gt; Preferences &gt; Package Settings &gt; Anaconda &gt; Settings – Default 下修改 linting behaviour 选项即可，我这里改成了只有在保存的时候linting工作。 12345678/* Sets the linting behaviour for anaconda: "always" - Linting works always even while you are writing (in the background) "load-save" - Linting works in file load and save only "save-only" - Linting works in file save only*/"anaconda_linting_behaviour": "save-only", SublimeREPL 这可能是对程序员来说最有用的插件。SublimeREPL 允许你在 Sublime Text 中运行各种语言（NodeJS ，Python，Ruby， Scala 和 Haskell 等等）。 在 Sublime &gt; Tools &gt; SublimeREPL 下我们可以看到 SublimeREPL 支持运行的所有语言。 下面的代码是在 AppData\Roaming\Sublime Text 3\Packages\SublimeREPL\config\Python 下的 Default.sublime-commands 文件，从中我们可以看到 SublimeREPL 所支持的 python 的各种运行方式。 1234567891011121314151617181920212223242526272829303132333435363738[ &#123; "caption": "SublimeREPL: Python", "command": "run_existing_window_command", "args": &#123; "id": "repl_python", "file": "config/Python/Main.sublime-menu" &#125; &#125;, &#123; "caption": "SublimeREPL: Python - PDB current file", "command": "run_existing_window_command", "args": &#123; "id": "repl_python_pdb", "file": "config/Python/Main.sublime-menu" &#125; &#125;, &#123; "caption": "SublimeREPL: Python - RUN current file", "command": "run_existing_window_command", "args": &#123; "id": "repl_python_run", "file": "config/Python/Main.sublime-menu" &#125; &#125;, &#123; "command": "python_virtualenv_repl", "caption": "SublimeREPL: Python - virtualenv" &#125;, &#123; "caption": "SublimeREPL: Python - IPython", "command": "run_existing_window_command", "args": &#123; "id": "repl_python_ipython", "file": "config/Python/Main.sublime-menu" &#125; &#125;] 接下来配置快捷键，打开 Sublime &gt; Preferences &gt; Key Building ，在右侧栏（ User 部分）添加下面的代码。下面的代码用 F5 来执行当前 Python 脚本，用 F4 来实现切换至 Python 命令行窗口。 12345678910111213[ &#123;"keys":["f5"], "caption": "SublimeREPL: Python - RUN current file", "command": "run_existing_window_command", "args": &#123;"id": "repl_python_run", "file": "config/Python/Main.sublime-menu"&#125;&#125; , &#123;"keys":["f4"], "caption": "SublimeREPL: Python", "command": "run_existing_window_command", "args": &#123;"id": "repl_python", "file": "config/Python/Main.sublime-menu"&#125;&#125;] 【1】Shift+Ctrl+Alt+p 创建 python 文件 先保存再执行。 【2】F5 执行代码 （如果你没有设置快捷键就 win+b） 【3】 看 Python 命令行窗口 ​ 当然，如果你电脑里面安装了两个版本的 Python ，而你想指定使用某个版本，则需要修改下面的代码。下面的代码是在 AppData\Roaming\Sublime Text 3\Packages\SublimeREPL\config\Python 下的 Main.sublime-menu 文件，主要修改 “cmd” 后面跟着的 python 命令。比如我电脑里 python2.7 的执行程序命名是 python.exe ，而 python3.6 的执行程序命名为 python3.exe ，我想要使用 python3 ，所以把所有 “cmd” 后面跟着的命令都改为 “python3” 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[ &#123; "id": "tools", "children": [&#123; "caption": "SublimeREPL", "mnemonic": "R", "id": "SublimeREPL", "children": [ &#123;"caption": "Python", "id": "Python", "children":[ &#123;"command": "repl_open", "caption": "Python", "id": "repl_python", "mnemonic": "P", "args": &#123; "type": "subprocess", "encoding": "utf8", "cmd": ["python3", "-i", "-u"], "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123;"PYTHONIOENCODING": "utf-8"&#125; &#125; &#125;, &#123;"command": "python_virtualenv_repl", "id": "python_virtualenv_repl", "caption": "Python - virtualenv"&#125;, &#123;"command": "repl_open", "caption": "Python - PDB current file", "id": "repl_python_pdb", "mnemonic": "D", "args": &#123; "type": "subprocess", "encoding": "utf8", "cmd": ["python3", "-i", "-u", "-m", "pdb", "$file_basename"], "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123;"PYTHONIOENCODING": "utf-8"&#125; &#125; &#125;, &#123;"command": "repl_open", "caption": "Python - RUN current file", "id": "repl_python_run", "mnemonic": "R", "args": &#123; "type": "subprocess", "encoding": "utf8", "cmd": ["python3", "-u", "$file_basename"], "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123;"PYTHONIOENCODING": "utf-8"&#125; &#125; &#125;, &#123;"command": "repl_open", "caption": "Python - IPython", "id": "repl_python_ipython", "mnemonic": "I", "args": &#123; "type": "subprocess", "encoding": "utf8", "autocomplete_server": true, "cmd": &#123; "osx": ["python3", "-u", "$&#123;packages&#125;/SublimeREPL/config/Python/ipy_repl.py"], "linux": ["python3", "-u", "$&#123;packages&#125;/SublimeREPL/config/Python/ipy_repl.py"], "windows": ["python3", "-u", "$&#123;packages&#125;/SublimeREPL/config/Python/ipy_repl.py"] &#125;, "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123; "PYTHONIOENCODING": "utf-8", "SUBLIMEREPL_EDITOR": "$editor" &#125; &#125; &#125; ]&#125; ] &#125;] &#125;] 别忘了， Sublime Text 3 也有自己的 build 功能，即也支持 python 等语言的代码构建（ ctrl + b ）。同样的，我们如何添加不同的 python 版本到我们的构建系统呢？很简单，Sublime &gt; Tools &gt; Build System &gt; New Build System，分别添加如下代码之后，再分别保存为 python2.sublime-build 和 python3.sublime-build ，这样，当我们再次打开 Sublime &gt; Tools &gt; Build System 之后，就会发现我们新添加的 python2 和 python3 构建系统了。 12345&#123; "cmd": ["D:/Program Files/Python/Python27/python.exe", "-u", "$file"], "file_regex": "^[ ]*File \"(...*?)\", line([0-9]*)", "selector": "source.python"&#125; 12345&#123; "cmd": ["D:/Program Files/Python/Python36/python3.exe", "-u", "$file"], "file_regex": "^[ ]*File \"(...*?)\", line([0-9]*)", "selector": "source.python"&#125; SublimeTmpl 快速生成文件模板 ，SublimeTmpl能新建html、css、javascript、php、python、ruby六种类型的文件模板，所有的文件模板都在插件目录的templates文件夹里，可以自定义编辑文件模板。 SublimeTmpl默认的快捷键: 123456ctrl+alt+h htmlctrl+alt+j javascriptctrl+alt+c cssctrl+alt+p phpctrl+alt+r rubyctrl+alt+shift+p python 这里我想修改一下python模板，所以就需要进行如下操作：Sublime &gt; Preferences &gt; Package Settings &gt; SublimeTmpl &gt; Settings – User 添加如下代码。然后 ctrl+alt+shift+p 来新建一个模板试试看。 123456789&#123; "disable_keymap_actions": false, // "all"; "html,css" "date_format" : "%Y-%m-%d %H:%M:%S", "attr": &#123; "author": "WordZzzz", "email": "wordzzzz@foxmail.com", "link": "http://blog.csdn.net/u011475210" &#125; &#125; 快捷键也是可以更改的，全部在 Sublime &gt; Preferences &gt; Package Settings &gt; SublimeTmpl 的设置中。 如果想要新建其他类型的文件模板的话，先自定义文件模板方在templates文件夹里，再分别打开Default (Windows).sublime-keymap、Default.sublime-commands、Main.sublime-menu、SublimeTmpl.sublime-settings这四个文件照着里面的格式自定义想要新建的类型，这里就不详细介绍了，请各位自己折腾哈~ 快捷键 跳转到任意内容 (“cmd+p”) 用来快速查找和打开文件。你仅仅只需要工程中文件的一部分路径或者文件名你就可以很容易的打开这个文件。这在一个大型的 Django 工程中显得非常方便。 跳转到指定行 (“ctrl+g”) 让你在当前文件中跳转到指定行数。 跳转到标志 (“cmd+r”) 可以列出当前文件中所有的函数或者类，让你更方便查找。你可以通过输入关键字来查找你所需要的函数或者类。 跳转到行首 (cmd+left-arrow-key) 与 跳转到行尾 (cmd+right-arrow-key) 删除当前行(ctrl+shift+k) 多重编辑 是我迄今为止最喜欢的快捷键选定一个单词，点击 “cmd+d”来选择同样的单词，再次点击 “cmd+d”*继续选择下一个单词…或者 “cmd+单击”来指定多个你想要同时修改的地方。 块编辑 (option+left-mouse-click) 用于选择一整块的内容。通常在整理 CSV 文件的时候用于删除空白内容。 自定义命令 你可以很容易地使用 Python 来编辑你自己的自定义命令和快捷键组合。例如： 拷贝当前文件路径到剪贴板 – 链接 关闭除当前活动标签页以外的所有其他标签页 – 链接 通过文件选项打开你的 Package 文件夹(Sublime &gt; Preferences &gt; Browse Packages)，然后打开 User 文件夹，接下来将上述的 Python 文件添加到 “/Sublime Text 3/Packages/User” 文件夹中。 最后请在 Key Bindings – User file (Sublime Text &gt; Preferences &gt; Package Settings &gt; AdvancedNewFile &gt; Key Bindings – User) 文件中完成快捷键绑定。 1234567891011[ // Copy file name &#123; "keys": ["cmd+shift+c"], "command": "copy_path_to_clipboard" &#125;, // Close all other tabs &#123; "keys": ["cmd+alt+w"], "command": "close_tabs" &#125; 参看文章：http://blog.csdn.net/u011475210/article/details/78168341]]></content>
      <categories>
        <category>搭建Python开发环境</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据迭代的基本用法]]></title>
    <url>%2F2017%2F12%2F20%2Fpython%E5%88%97%E8%A1%A8%E8%BF%AD%E4%BB%A3%2F</url>
    <content type="text"><![CDATA[数据迭代的基本用法：for 循环的使用12345&gt;&gt;&gt;fav_movies = ["The Holy Crail","The Life of Brian"]&gt;&gt;&gt;for each_flick in fav_movies:print(each_flick)The Holy CrailThe Life of Brian while 循环的使用1234567&gt;&gt;&gt;count=2&gt;&gt;&gt;while count&gt;0: 【注意加冒号了再回车】 print("aaaa") 【如果正确会自动缩进】 count = count-1 aaaa 【输出结果】aaaa enumerate，dict，zip 使用通过一个练习，看看这三个函数怎么用的哈。小丽，你也跟着敲一下代码，看看运行效果 题目：现有: 123list1=[&apos;neil&apos;,&apos;mike&apos;,&apos;lucy&apos;]list2=[&apos;123456&apos;,&apos;xuiasj==&apos;,&apos;passWD123&apos;]list3=[&apos;www.abc.com&apos;,&apos;www.mike.org&apos;,&apos;www.lucy.gov&apos;] 需要形成列表： 1fin_list = [&#123;&apos;name&apos;:&apos;neil&apos;,&apos;passwd&apos;:&apos;123456&apos;,&apos;url&apos;:&apos;www.abc.com&apos;&#125;,&#123;&apos;name&apos;:&apos;mike&apos;,&apos;passwd&apos;:&apos;xuiasj==&apos;,&apos;url&apos;:&apos;www.mike.org&apos;&#125;,&#123;&apos;name&apos;:&apos;lucy&apos;,&apos;passwd&apos;:&apos;passWD123&apos;,&apos;url&apos;:&apos;www.lucy.gov&apos;&#125;] python新手的小丽啊，这要如何实现呢？你先自己好好想想怎么实现，动手敲敲代码哈。 在这里我提供两种方法： 方法1: 使用 enumerate 函数来实现 123456789101112131415【按题目定义3个列表】&gt;&gt;&gt;list1 = ['neil','mike','lucy']&gt;&gt;&gt;list2 = ['123456','xuiasj==','passWD123']&gt;&gt;&gt;list3 = ['www.abc.com','www.mike.org','www.lucy.gov']&gt;&gt;&gt;fin_list = []&gt;&gt;&gt;for i , name in enumerate(list1): d = &#123;&#125; d['name'] = name d['password'] = list2[i] d['url'] = list3[i] fin_list.append(d) 【小丽你回车,会空格一行】&gt;&gt;&gt;fin_list 【再输入要输出的这个列表名】【这是输出的结果】[&#123;'name': 'neil', 'password': '123456', 'url': 'www.abc.com'&#125;, &#123;'name': 'mike', 'password': 'xuiasj==', 'url': 'www.mike.org'&#125;, &#123;'name': 'lucy', 'password': 'passWD123', 'url': 'www.lucy.gov'&#125;] 之前你问我:python 中 in 的使用 和 enumerate 函数，在这里我来回答你，你要认真看哈！ enumerate 函数一般情况下我们对一个列表或数组既要遍历索引又要遍历元素时，会这样写： 12&gt;&gt;&gt;for i in range (0,len(list)): 【其实，在 ypthon 中 for... in .. 它就是一个语法】&gt;&gt;&gt;print i ,list[i] 【range 是取一个范围的值】 但是这种方法有些累赘，使用内置enumerrate函数会有更加直接，优美的做法，先看看enumerate的定义： 1234567&gt;&gt;&gt;def enumerate(collection): 【def 函数我在下面会跟你讲】&gt;&gt;&gt; 'Generates an indexed series: (0,coll[0]), (1,coll[1])'&gt;&gt;&gt; i = 0 &gt;&gt;&gt; it = iter(collection) &gt;&gt;&gt; while 1: &gt;&gt;&gt; yield (i, it.next()) &gt;&gt;&gt; i += 1 enumerate会将数组或列表组成一个索引序列。使我们再获取索引和索引内容的时候更加方便如下： 12&gt;&gt;&gt;for index，text in enumerate(list)):&gt;&gt;&gt; print index ,text 如果你要计算文件的行数，可以这样写： 1&gt;&gt;&gt;count = len(open(thefilepath,‘rU’).readlines()) 前面这种方法简单，但是可能比较慢，当文件比较大时甚至不能工作，下面这种循环读取的方法更合适些。 1234&gt;&gt;&gt;Count = -1 &gt;&gt;&gt;For count,line in enumerate(open(thefilepath,‘rU’))：&gt;&gt;&gt; Pass&gt;&gt;&gt;Count += 1 小丽，计算文件的行数的这两种方法，看不懂没关系，你只要知道就可以了。 看到这里你必须掌握的是：for 的迭代 和 enumerate 行数的使用 在来看看 def 函数 def 函数对于某些需要重复调用的程序，可以使用函数进行定义，基本形式为： def 函数名(参数1, 参数2, ……, 参数N): 执行语句函数名为调用的表示名，参数则是传入的参数。 1234567891011# 例1：简单的函数使用# coding=gb2312 # 定义函数def hello(): print 'hello python!' # 调用函数 hello() &gt;&gt;&gt; hello python! 函数可以带参数和返回值，参数将按从左到右的匹配，参数可设置默认值，当使用函数时没给相应的参数时，会按照默认值进行赋值。 1234567891011121314151617181920# 例2：累加计算值# coding=gb2312 # 定义函数def myadd(a=1,b=100): result = 0 i = a while i &lt;= b: # 默认值为1+2+3+……+100 result += i i += 1 return result # 打印1+2+……+10 print myadd(1,10)print myadd() # 使用默认参数1，100print myadd(50) # a赋值50，b使用默认值 &gt;&gt;&gt; 55&gt;&gt;&gt; 5050&gt;&gt;&gt; 3825 Python 函数的参数传递时，值得注意的是参数传入时若为变量会被当作临时赋值给参数变量，如果是对象则会被引用。 12345678910111213141516# 例3：# coding=gb2312 def testpara(p1,p2): p1 = 10 p2.append('hello') l = [] # 定义一数组对像a = 20 # 给变量a赋值testpara(a,l) # 变量a与对象数组l作为参数传入print a # 打印运行参数后的值for v in l: # 打印数组对象的成员 print v &gt;&gt;&gt; 20 # 调用函数后a变量并未被复值&gt;&gt;&gt; hello # 而对象l数组则增加成员hello 方法2: 使用 dict 和 zip 函数来实现** 1234567891011121314【按题目定义3个列表】&gt;&gt;&gt;list1 = ['neil','mike','lucy']&gt;&gt;&gt;list2 = ['123456','xuiasj==','passWD123']&gt;&gt;&gt;list3 = ['www.abc.com','www.mike.org','www.lucy.gov']&gt;&gt;&gt;fin_list = []&gt;&gt;&gt;style = ['name','passwd','url']&gt;&gt;&gt;fin_list.append(dict(zip(style,list1)))&gt;&gt;&gt;fin_list.append(dict(zip(style,list2)))&gt;&gt;&gt;fin_list.append(dict(zip(style,list3)))&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;print(fin_list)【这是输出的结果】[&#123;'name': 'neil', 'password': '123456', 'url': 'www.abc.com'&#125;, &#123;'name': 'mike', 'password': 'xuiasj==', 'url': 'www.mike.org'&#125;, &#123;'name': 'lucy', 'password': 'passWD123', 'url': 'www.lucy.gov'&#125;]]]></content>
      <categories>
        <category>数据迭代</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3 安装]]></title>
    <url>%2F2017%2F12%2F20%2FPython3%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Python3 安装Linux下默认安装的是Python2.7，要使用Python3，需要自行安装。Python3最新的版本是Python3.6。 在这里介绍在CentOS，Debian和Windows上安装Python3.6。 小丽，你跳过前面的，只看Windows上安装Python3.6哈。 CentOS安装Python3.6更详细的安装过程查看：CentOS7安装Python3.6 IUS软件源中包含了Python3.6，可以使用IUS软件源安装Python3.6，查看如何安装使用IUS软件源 1）安装IUS软件源 12345复制#安装EPEL依赖sudo yum install epel-release#安装IUS软件源sudo yum install https://centos7.iuscommunity.org/ius-release.rpm 2）安装Python3.6 1复制sudo yum install python36u 安装Python3完成后的shell命令为python3.6，为了使用方便，创建一个到python3的符号链接 1复制sudo ln -s /bin/python3.6 /bin/python3 3）安装pip3 安装完成python36u并没有安装pip，安装pip 1复制sudo yum install python36u-pip 安装pip完成后的shell命令为pip3.6，为了使用方便，创建一个到pip3的符号链接 1复制sudo ln -s /bin/pip3.6 /bin/pip3 Debian安装Python3.6Debian8的软件源中包含了Python3.4，要安装Python3.6，需要下载源文件安装： 1）安装编译，安装Python源文件的依赖包，GCC编译器，Make编译程序，Zlib压缩库： 1复制sudo aptitude -y install gcc make zlib1g-dev 2）运行如下命令安装Python3.6，以下命令依次为获取Python3.6源文件，解压，配置环境，编译，安装Python3.6 123456复制wget https://www.python.org/ftp/python/3.6.0/Python-3.6.0.tar.xztar xJf Python-3.6.0.tar.xzcd Python-3.6.0sudo ./configuresudo makesudo make install 安装完成后，Python安装在了/usr/local文件夹中，可运行文件/usr/local/bin，库文件/usr/local/lib，可以使用如下命令查看安装位置和版本 3）查看安装位置： 123复制anxin@bogon:~$ which python3/usr/local/bin/python3 4）验证Python3.6版本 123复制anxin@bogon:~$ python3 -VPython 3.6.0 Windows安装Python3.61）进入Python下载页面下载对应版本的Python安装包，本例下载Python3.6 64位Windows安装包 python-3.6.2-amd64.exe 如果你的电脑系统是32 位的,你就直接点击箭头的按钮下载就好了! 如果你的电脑系统是64 位的,就按下面流程下载哈 下载下来： 2）双击Python3.6安装包，开始安装Python3.6。 1. 选择 Install Now 安装方式方式 其实你也可以一步就完成 Python3.6 的安装，如果选择 Install Now 安装方式，以后下的步骤你可以全部不用做。 查看安装是否成功，打开cmd 输入 python 即可 2. 选择选择自定义安装（Customize installation）方式，可以选择安装的内容和目录： 注：安装Python3.6时，可以选中 Add Python 3.6 to PATH ，这样Python会自动把Python3.6的路径加入当前用户的PATH路径下，而不是系统的PATH路径下。 3）选择要安装的内容（如果你清除它们是什么），一般可以选择默认，即：所有内容，点击Next 4）选择一些安装选择，一般选择默认，在这一步可以选择安装目录，也可以直接输入目录地址，点击“浏览（Browse）”按钮： 5）选择安装的目录，最好先创建好目录如 python36 ，点击“确定”按钮： 6）如图所示选择好Python3.6的安装目录，点击“Install”按钮，开始安装Python3.6 7）如不出什么以外，会提示你安装完成 恭喜你，成功的在Windows安装了Python 3.6！ 配置Python3.6环境变量你也可以在安装完成Python3.6后，自己手动配置Python3.6的环境变量。 Win7进入控制面板–&gt;系统和安全–&gt;系统–&gt;高级系统设置–&gt;环境变量–&gt;系统变量，选中Path，双击编辑Path环境变量，添加路径\和\Scripts\： 在本例中我们添加的Python3.6环境变量的路径为：;C:\python36\Scripts\;C:\python36\，注意：Windows的环境变量已 ; 分隔。 我们敲代码的地方 打开箭头指向的 IDLE ，就是我们的编辑器。]]></content>
      <categories>
        <category>Python3 安装</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2017%2F12%2F14%2FConcurrentHashMap%E6%89%A9%E5%AE%B9%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap扩容实现机制jdk8中，采用多线程扩容。整个扩容过程，通过CAS设置sizeCtl，transferIndex等变量协调多个线程进行并发扩容。 扩容相关的属性nextTable扩容期间，将table数组中的元素 迁移到 nextTable。 12345/** * The next table to use; non-null only while resizing. 扩容时，将table中的元素迁移至nextTable . 扩容时非空 */private transient volatile Node&lt;K,V&gt;[] nextTable; sizeCtl属性1private transient volatile int sizeCtl; 多线程之间，以volatile的方式读取sizeCtl属性，来判断ConcurrentHashMap当前所处的状态。通过cas设置sizeCtl属性，告知其他线程ConcurrentHashMap的状态变更。 不同状态，sizeCtl所代表的含义也有所不同。 未初始化： sizeCtl=0：表示没有指定初始容量。 sizeCtl&gt;0：表示初始容量。 初始化中： sizeCtl=-1,标记作用，告知其他线程，正在初始化 正常状态： sizeCtl=0.75n ,扩容阈值 扩容中: sizeCtl &lt; 0 : 表示有其他线程正在执行扩容 sizeCtl = (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2 :表示此时只有一个线程在执行扩容 ConcurrentHashMap的状态图如下： transferIndex属性1234567private transient volatile int transferIndex; /** 扩容线程每次最少要迁移16个hash桶 */private static final int MIN_TRANSFER_STRIDE = 16; 扩容索引，表示已经分配给扩容线程的table数组索引位置。主要用来协调多个线程，并发安全地获取迁移任务（hash桶）。 1 在扩容之前，transferIndex 在数组的最右边 。此时有一个线程发现已经到达扩容阈值，准备开始扩容。 2 扩容线程，在迁移数据之前，首先要将transferIndex右移（以cas的方式修改 transferIndex=transferIndex-stride(要迁移hash桶的个数)），获取迁移任务。每个扩容线程都会通过for循环+CAS的方式设置transferIndex，因此可以确保多线程扩容的并发安全。 换个角度，我们可以将待迁移的table数组，看成一个任务队列，transferIndex看成任务队列的头指针。而扩容线程，就是这个队列的消费者。扩容线程通过CAS设置transferIndex索引的过程，就是消费者从任务队列中获取任务的过程。为了性能考虑，我们当然不会每次只获取一个任务（hash桶），因此ConcurrentHashMap规定，每次至少要获取16个迁移任务（迁移16个hash桶，MIN_TRANSFER_STRIDE = 16） cas设置transferIndex的源码如下： 123456789101112131415161718private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; //计算每次迁移的node个数 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // 确保每次迁移的node个数不少于16个 ... for (int i = 0, bound = 0;;) &#123; ... //cas无锁算法设置 transferIndex = transferIndex - stride if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; ... ... &#125; ...//省略迁移逻辑 &#125; &#125; ForwardingNode节点 标记作用，表示其他线程正在扩容，并且此节点已经扩容完毕 关联了nextTable,扩容期间可以通过find方法，访问已经迁移到了nextTable中的数据 123456789101112 static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; //hash值为MOVED（-1）的节点就是ForwardingNode super(MOVED, null, null, null); this.nextTable = tab; &#125; //通过此方法，访问被迁移到nextTable中的数据 Node&lt;K,V&gt; find(int h, Object k) &#123; ... &#125;&#125; 何时扩容1 当前容量超过阈值12345final V putVal(K key, V value, boolean onlyIfAbsent) &#123; ... addCount(1L, binCount); ...&#125; 123456789101112private final void addCount(long x, int check) &#123; ... if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //s&gt;=sizeCtl 即容量达到扩容阈值，需要扩容 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; //调用transfer()扩容 ... &#125; &#125; &#125; 2 当链表中元素个数超过默认设定（8个），当数组的大小还未超过64的时候，此时进行数组的扩容，如果超过则将链表转化成红黑树123456789101112final V putVal(K key, V value, boolean onlyIfAbsent) &#123; ... if (binCount != 0) &#123; //链表中元素个数超过默认设定（8个） if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; ...&#125; 12345678910111213private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; //数组的大小还未超过64 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) //扩容 tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; //转换成红黑树 ... &#125; &#125;&#125; 3 当发现其他线程扩容时，帮其扩容1234567final V putVal(K key, V value, boolean onlyIfAbsent) &#123; ... //f.hash == MOVED 表示为：ForwardingNode，说明其他线程正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); ...&#125; 扩容过程分析 线程执行put操作，发现容量已经达到扩容阈值，需要进行扩容操作，此时transferindex=tab.length=32 扩容线程A 以cas的方式修改transferindex=32-16=16 ,然后按照降序迁移table[32]–table[16]这个区间的hash桶 迁移hash桶时，会将桶内的链表或者红黑树，按照一定算法，拆分成2份，将其插入nextTable[i]和nextTable[i+n]（n是table数组的长度）。 迁移完毕的hash桶,会被设置成ForwardingNode节点，以此告知访问此桶的其他线程，此节点已经迁移完毕。 相关代码如下： 123456789101112131415161718private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; ...//省略无关代码 synchronized (f) &#123; //将node链表，分成2个新的node链表 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //将新node链表赋给nextTab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); &#125; ...//省略无关代码&#125; 此时线程2访问到了ForwardingNode节点，如果线程2执行的put或remove等写操作，那么就会先帮其扩容。如果线程2执行的是get等读方法，则会调用ForwardingNode的find方法，去nextTable里面查找相关元素。 线程2加入扩容操作 如果准备加入扩容的线程，发现以下情况，放弃扩容，直接返回。 发现transferIndex=0,即所有node均已分配 发现扩容线程已经达到最大扩容线程数 部分源码分析tryPresize方法协调多个线程如何调用transfer方法进行hash桶的迁移（addCount，helpTransfer 方法中也有类似的逻辑） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960private final void tryPresize(int size) &#123; //计算扩容的目标size int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; //tab没有初始化 if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; //初始化之前，CAS设置sizeCtl=-1 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; //sc=0.75n,相当于扩容阈值 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // 此时并没有通过CAS赋值，因为其他想要执行初始化的线程， // 发现sizeCtl=-1，就直接返回，从而确保任何情况， // 只会有一个线程执行初始化操作。 sizeCtl = sc; &#125; &#125; &#125; //目标扩容size小于扩容阈值，或者容量超过最大限制时，不需要扩容 else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; //扩容 else if (tab == table) &#123; int rs = resizeStamp(n); //sc&lt;0表示，已经有其他线程正在扩容 if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt; //1 (sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs ：扩容线程数 &gt; MAX_RESIZERS-1 //2 sc == rs + 1 和 sc == rs + MAX_RESIZERS ：表示什么？？？ //3 (nt = nextTable) == null ：表示nextTable正在初始化 //4 transferIndex &lt;= 0 ：表示所有hash桶均分配出去 //如果不需要帮其扩容，直接返回 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //CAS设置sizeCtl=sizeCtl+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) //帮其扩容 transfer(tab, nt); &#125; // 第一个执行扩容操作的线程，将sizeCtl设置为： // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125;&#125; transfer方法负责迁移node节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //计算需要迁移多少个hash桶（MIN_TRANSFER_STRIDE该值作为下限，以避免扩容线程过多） if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; //扩容一倍 @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // 1.逆序迁移已经获取到的hash桶集合，如果迁移完毕， // 则更新transferIndex，获取下一批待迁移的hash桶 // 2.如果transferIndex=0，表示所以hash桶均被分配， // 将i置为-1，准备退出transfer方法 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; //更新待迁移的hash桶索引 while (advance) &#123; int nextIndex, nextBound; //更新迁移索引i。 if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; // transferIndex&lt;=0表示已经没有需要迁移的hash桶， // 将i置为-1，线程准备退出 i = -1; advance = false; &#125; // 当迁移完bound这个桶后，尝试更新transferIndex， // 获取下一批待迁移的hash桶 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //退出transfer if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; //最后一个迁移的线程，recheck后，做收尾工作，然后退出 nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 第一个扩容的线程，执行transfer方法之前，会设置 sizeCtl = // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 后续帮其扩容的线程，执行transfer方法之前，会设置 sizeCtl = sizeCtl+1 // 每一个退出transfer的方法的线程，退出之前，会设置 sizeCtl = sizeCtl-1 // 那么最后一个线程退出时： // 必然有sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2)， // 即 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT //不相等，说明不到最后一个线程，直接退出transfer方法 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; //最后退出的线程要重新check下是否全部迁移完毕 i = n; // recheck before commit &#125; &#125; else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) advance = true; // already processed //迁移node节点 else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; //链表迁移 if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; //将node链表，分成2个新的node链表 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //将新node链表赋给nextTab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; //红黑树迁移 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 总结多线程无锁扩容的关键就是通过CAS设置sizeCtl与transferIndex变量，协调多个线程对table数组中的node进行迁移。 勘误：tab.length为32，扩容阈值是32*0.75=24]]></content>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 版本控制的使用]]></title>
    <url>%2F2017%2F12%2F13%2FIDEA%20%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[版本控制的使用IntelliJ IDEA 下的版本控制介绍这一章节放在这么靠前位置来讲是因为版本控制在我心目中的地位比后面的实战知识点都来得重要。不管是个人开发或是团队开发，版本控制都是可以很好地被使用的，目前我找不到任何开发者不使用版本控制的理由。而且对于 IDE 来讲，集成版本控制的本身就是它最大的亮点之一，很多开发者也是为此而使用它。 在本章节中也会对 IntelliJ IDEA 的相关版本控制进行了介绍，会开始涉及到一些 IntelliJ IDEA 人性化设置，也希望你能从这一讲开始认识到 IntelliJ IDEA 的优雅。 很多人认为 IntelliJ IDEA 自带了 SVN 或是 Git 等版本控制工具，认为只要安装了 IntelliJ IDEA 就可以完全使用版本控制应有的功能。这完全是一种错误的解读，IntelliJ IDEA 是自带对这些版本控制工具的支持插件，但是该装什么版本控制客户端还是要照样装的。 如上图标注 1 所示，IntelliJ IDEA 对版本控制的支持是以插件化的方式来实现的。旗舰版默认支持目前主流的版本控制软件：CVS、Subversion（SVN）、Git、ClearCase、Mercurial、Perforce、TFS。又因为目前太多人使用 Github 进行协同或是项目版本管理，所以 IntelliJ IDEA 同时自带了 Github 插件，方便 Checkout 和管理你的 Github 项目。 SVN 的配置要在 IntelliJ IDEA 中使用 SVN，需要先安装 SVN 客户端或是 TortoiseSVN 这类图形化工具，Windows 系统这里推荐安装 TortoiseSVN，即使在不使用 IntelliJ IDEA 也可以方便管理我们的项目。 SVN 主要使用的版本有 1.6、1.7、1.8，最新的是 1.9。推荐大家使用 1.8 的。如果你的项目使用的是 1.6 的版本，在安装 1.8 之后是可以直接对项目文件进行升级的，所以无需担心，也因此更加推荐大家使用 1.8。 Subversion 官网下载：https://subversion.apache.org/download/#recommended-release TortoiseSVN 官网下载：http://tortoisesvn.net/downloads.zh.html 如上图箭头所示，在安装 TortoiseSVN 的时候，默认 command line client tools，是不安装的，这里建议勾选上。 如上图标注 1 所示，勾选 Use command line client 如上图标注 2 所示，建议 svn 的路径自己根据安装后的路径进行选择，不然有时候 IntelliJ IDEA 无法识别到会报：Cannot run program &quot;svn&quot; 这类错误。 如上图标注 3 所示，当使用一段时间 SVN 以后，发现各种 SVN 相关问题无法解决，可以考虑点击此按钮进行清除一下缓存。 根据目前的使用经验来看，IntelliJ IDEA 下 SVN 的使用经历并不算愉快，至少比 Git 不好用很多，经常遇到很多问题，所以这里也算是先给大家提个醒。如果紧急情况下 IntelliJ IDEA 无法更新、提交的时候，要记得使用 TortoiseSVN 来操作。 Git 的配置要在 IntelliJ IDEA 中使用 Git，需要先安装 Git 客户端，这里推荐安装官网版本。 Git 主要的版本有 1.X、2.X，最新的是 2.X，使用版本随意，但是不要太新了，不然可能 IntelliJ IDEA 小旧版本会无法支持可能。 Git 官网下载：http://git-scm.com/ TortoiseGit 官网下载：http://download.tortoisegit.org/tgit/ 如上图标注 1 所示，确定好该路径下是否有对应的可执行文件。 Github 的配置和使用 如上图标注 1 所示，填写你的 Github 登录账号和密码，点击 Test 可以进行测试是否可以正确连上。 如上图标注 1 所示，支持直接从你当前登录的 Github 账号上 Checkout 项目。 如上图标注 1 所示，支持把当前本地项目分享到你的 Github 账号上。 如上图标注 1 所示，支持创建 Gist。Github 的 Gist 官网地址：https://gist.github.com/ 版本控制主要操作按钮 如上图标注 1 所示，对目录进行右键弹出的菜单选项。 如上图标注 1 所示，对文件进行右键弹出的菜单选项。 如上图标注红圈所示，为工具栏上版本控制操作按钮，基本上大家也都是使用这里进行操作。 第一个按钮：Update Project 更新项目。 第二个按钮：Commit changes 提交项目上所有变化文件。点击这个按钮不会立马提交所有文件，而是先弹出一个被修改文件的一个汇总框，具体操作下面会有图片进行专门介绍。 第三个按钮：Compare with the Same Repository Version 当前文件与服务器上该文件通版本的内容进行比较。如果当前编辑的文件没有修改，则是灰色不可点击。 第四个按钮：Show history 显示当前文件的历史记录。 第五个按钮：Revert 还原当前被修改的文件到未被修改的版本状态下。如果当前编辑的文件没有修改，则是灰色不可点击。 如上图标注 1 所示，菜单栏上的版本控制操作区。 版本控制相关的常用设置说明 如上图标注 1 所示，当前项目使用的版本控制是 Git。如果你不愿意这个项目继续使用版本控制可以点击旁边的减号按钮，如果你要切换版本控制，可以点击 Git，会出现 IntelliJ IDEA 支持的各种版本控制选择列表，但是我们一般情况下一个项目不会有多个版本控制的。 如上图标注 2 所示，Show directories with changed descendants 表示子目录有文件被修改了，则该文件的所有上层目录都显示版本控制被概念的颜色。默认是不勾选的，我一般建议勾选此功能。 如上图标注 1 所示，When files are created 表示当有新文件放进项目中的时候 IntelliJ IDEA 做如何处理，默认是 Show options before adding to version control 表示弹出提示选项，让开发者决定这些新文件是加入到版本控制中还是不加入。如果不想弹出提示，则选择下面两个选项进行默认操作。 如上图标注 2 所示，When files are deleted 表示当有新文件在项目中被删除的时候 IntelliJ IDEA 做如何处理，默认是 Show options before removing from version control 表示弹出提示选项，让开发者决定这些被删除的是否从版本控制中删除。如果不想弹出提示，则选择下面两个选项进行默认操作。 如上图标注 1 所示，对于不想加入到版本控制的文件，可以添加要此忽略的列表中。但是如果已经加入到版本控制的文件使用此功能，则表示该文件 或 目录无法再使用版本控制相关的操作，比如提交、更新等。我个人使用过程中发现在 SVN 上此功能不太好用，Git 上是可以用的。 上图所示的弹出层就是本文上面说的 Commit Changes 点击后弹出的变动文件汇总弹出层。 如上图标注 1 所示，可以在文件上右键进行操作。 Show Diff 当前文件与服务器上该文件通版本的内容进行比较。 Move to Another Changelist 将选中的文件转移到其他的 Change list 中。Change list 是一个重要的概念，这里需要进行重点说明。很多时候，我们开发一个项目同时并发的任务可能有很多，每个任务涉及到的文件可能都是基于业务来讲的。所以就会存在一个这样的情况：我改了 30 个文件，其中 15 个文件是属于订单问题，剩下 15 个是会员问题，那我希望提交代码的时候是根据业务区分这些文件的，这样我填写 Commit Message 是好描述的，同时在文件多的情况下，我也好区分这些要提交的文件业务模块。所以我一般会把属于订单的 15 个文件转移到其他的 Change list中，先把专注点集中在 15 个会员问题的文件，先提交会员问题的 Change list，然后在提交订单会员的 Change list。我个人还有一种用法是把一些文件暂时不提交的文件转移到一个我指定的 Change list，等后面我觉得有必要提交了，再做提交操作，这样这些文件就不会干扰我当前修改的文件提交。总结下 Change list 的功能就是为了让你更好地管理你的版本控制文件，让你的专注点得到更好的集中，从而提供效率。 Jump to Source 打开并跳转到被选中。 如上图标注 2 所示，可以根据工具栏按钮进行操作，操作的对象会鼠标选中的文件，多选可以按 Ctrl后不放，需要注意的是这个更前面的复选框是没有多大关系的。 如上图标注 3 所示，可以在提交前自动对被提交的文件进行一些操作事件（该项目使用的 Git，使用其他版本控制可能有些按钮有差异。）： Reformat code 格式化代码，如果是 Web 开发建议不要勾选，因为格式化 JSP 类文件，格式化效果不好。如果都是 Java 类则可以安心格式化。 Rearrange code 重新编排代码，IntelliJ IDEA 支持各种复杂的编排设置选项，这个会在后面说。设置好了编码功能之后，这里就可以尝试勾选这个进行自动编排。 Optimize imports 优化导入包，会在自动去掉没有使用的包。这个建议都勾选，这个只对 Java 类有作用，所以不用担心有副作用。 Perform code analysis 进行代码分析，这个建议不用在提交的时候处理，而是在开发完之后，要专门养成对代码进行分析的习惯。IntelliJ IDEA 集成了代码分析功能。 Check TODO 检查代码中的 TODO。TODO 功能后面也会有章节进行讲解，这里简单介绍：这是一个记录待办事项的功能。 Cleanup 清除下版本控制系统，去掉一些版本控制系统的错误信息，建议勾选（主要针对 SVN，Git 不适用）。 如上图标注 4 所示，填写提交的信息。 如上图标注 5 所示，Change list 改变列表，这是一个下拉选项，说明我们可以切换不同的 Change list，提交不同的 Change list 文件。 如上图标注箭头所示，我们可以查看我们提交历史中使用的 Commit Message，有些时候，我们做得是同一个任务，但是需要提交多次，为了更好管理项目，建议是提交的 Message 是保持一致的。 如上图标注箭头所示，如果你使用的 Git，点击此位置可以切换分支和创建分支，以及合并、删除分支等操作。 SVN 的使用SVN 的这个窗口有的 IntelliJ IDEA 上叫 Changes，有的叫 Version Control，具体是什么原因引起这样的差异，我暂时还不清楚。但是不管叫法如何里面的结构是一样的，所以对使用者来讲没多大影响，但是你需要知道他们其实是一样的功能即可。 上图 Local Changes 这个 Tab 表示当前项目的 SVN 中各个文件的总的情况预览。这里的 Default 是 IntelliJ IDEA 的默认 change list 名称，no commit 是我自己创建的一个change list，我个人有一个习惯是把一些暂时不需要提交的先放这个 list 里面。change list 很常用而且重要，本文前面也有强调过了，所以一定好认真对待。unversioned Files表示项目中未加到版本控制系统中的文件，你可以点击 Click to browse，会弹出一个弹出框列表显示这些未被加入的文件。 上图 Repository 这个 Tab 表示项目的 SVN 信息汇总，内容非常的详细，也是我平时用最多的地方。如果你点击这个 Tab 没看到数据，是因为你需要点击上图红圈这个刷新按钮。初次使用下默认的过滤条件不是我上图这样的，我习惯根据 User 进行过滤筛选，所以上图箭头中的 Filter 我是选择 User。选择之后，如上图标注 1 所示，显示了这个项目中参与提交的各个用户名，选择一个用户之后，上图标注 2 所以会显示出该用户提交了哪些记录。选择标注 2 区域中的某个提交记录后，标注 3 显示对应的具体提交细节，我们可以对这些文件进行右键操作，具体操作内容跟本文上面提到的那些提交时的操作按钮差不多，这里不多讲。 总的来说，SVN 这个功能用来管理和审查开发团队中人员的代码是非常好用的，所以非常非常建议你一定要学会该功能。 Git 常见问题 更新的时候报： 1Can&apos;t update: no tracked branch 解决办法：打开 git-bash（路径：C:\Program Files\Git\git-bash.exe），切换到这个更新不下来的项目的根目录，然后输入：git branch --set-upstream-to origin/master master，回车之后重新回到 IntelliJ IDEA 进行更新，正常就可以了。 输错密码后，弹出验证的登录框没有再出现： 解决办法如下图：选择 Do not save, forget passwords after restart 等你确定你的密码没错后再选择保存密码方案。 Git Flow 的介绍Git Flow 概念 Git Flow 是一个 git 扩展集，按 Vincent Driessen 的分支模型提供高层次的库操作。这里的重点是 Vincent Driessen 的分支模型思想，下面讲解的内容也是基于 Vincent Driessen 思想。 Vincent Driessen 的观点：http://nvie.com/posts/a-successful-git-branching-model/ Git Flow 是一个 git 扩展集 你可以理解 Git Flow 是一个基于 Git 的插件，这个插件简化了 Git 一些复杂的命令，比如 Git Flow 用一条命令，就可以代替 Git 原生 10 条命令。 Git Flow 对原生的 Git 不会有任何影响，你可以照旧用 Git 原生命令，也可以使用 Git Flow 命令。 还有其他的一些分支管理模型思想，具体可以看：http://www.ruanyifeng.com/blog/2015/12/git-workflow.html Git Flow 核心概念 必须有的两个核心分支（长期分支）： master，Git 代码仓库中默认的一条主分支。这条分支上的代码一般都建议为是正式版本的代码，并且这条分支不能进行代码修改，只能用来合并其他分支。 develop，一般用于存储开发过程的代码分支，并且这条分支也不能进行代码修改，只能用来合并其他辅助分支。 根据情况创建的辅助分支（临时分支） feature branches（功能分支） 基于 develop 分支上创建 开发完成后合并到 develop 分支上 当要开始一个新功能的开发时，我门可以创建一个 Feature branches 。等待这个新功能开发完成并确定应用到新版本中就合并回 develop 对于单人开发的 feature branches，start 之后，开发完成后可以直接 finish。 对于多人开发的 feature branches，start 之后，开发完成后先 publish 给其他开发人员进行合并，最后大家都开发完成后再 finish。这个思路也同样适用下面几个辅助分支场景。 feature branches 开发过程有 bug，直接在 feature branches 上修改、提交。 release branches（预发布分支） 基于 develop 分支上创建 测试确定新功能没有问题，合并到 develop 分支和 master 分支上 用来做新版本发布前的准备工作，在上面可以做一些小的 bug 修复、准备发布版本号等等和发布有关的小改动，其实已经是一个比较成熟的版本了。另外这样我们既可以在预发布分支上做一些发布前准备，也不会影响 “develop” 分支上下一版本的新功能开发。 hotfix branches（基于 master 基础上的生产环境 bug 的修复分支） 基于 master 分支上创建 修复测试无误后合并到 master 分支和 develop 分支上 主要用于处理线上版本出现的一些需要立刻修复的 bug 情况 Git Flow 安装 Windows：如果你安装 Git 用的是 Git for Windows，那它已经内置了。 Mac：brew install git-flow-avh Linux：wget --no-check-certificate -q https://raw.githubusercontent.com/petervanderdoes/gitflow-avh/develop/contrib/gitflow-installer.sh &amp;&amp; sudo bash gitflow-installer.sh install stable; rm gitflow-installer.sh 更多版本：https://github.com/petervanderdoes/gitflow-avh/wiki/Installation 在系统环境上支持之后，再安装 IntelliJ IDEA 对 Git Flow 支持的插件：https://plugins.jetbrains.com/plugin/7315-git-flow-integration Git Flow 基础命令资料 https://danielkummer.github.io/git-flow-cheatsheet/index.zh_CN.html http://www.jianshu.com/p/9e4291078853 http://stormzhang.com/git/2014/01/29/git-flow/ Hotfix/Release/Develop/Feature/ Git Flow Integration 插件的使用· 如果你已经理解了上面的理论，再看下面这些截图你能理解对应的是什么意思。]]></content>
      <categories>
        <category>IntelliJ IDEA</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 调试教程]]></title>
    <url>%2F2017%2F12%2F12%2FIntelliJ%20IDEA%20%20%E8%B0%83%E8%AF%95%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[IntelliJ IDEA 调试教程在调试代码的时候，你的项目得debug模式启动，也就是点那个绿色的甲虫启动服务器，然后，就可以在代码里面断点调试啦。下面不要在意，这个快捷键具体是啥，因为，这个keymap是可以自己配置的，有的人keymap是mac版的，有的是Windows版的。我的就是Windows，而且修改keymap为eclipse的keymap，因为我算是eclipse转过来的吧。 看图，每一个按钮（按钮对应图中的数字）都是什么功能 rerun XXX，这个就是直接重新跑某个程序。 这个相当于eclipse里面的f8，直接跑完，到下一个断点停下，没有就直接跑完程序。 停止项目或者程序。要是自己的main呢，点一下就停下了，要是Java web项目，则点2下，就把服务器给停了。 查看所有的断点设置情况。具体详情，下面有示意图，再细细解释。 直接取消所有断点，让所有断点无效。 要是你一不小心把这个下面的布局给弄乱了，你点这个，就把下面的布局给还原咯。 跳转到当前代码所执行的地方，也就是说你在看代码的时候，点到其他地方，一点这个按钮，就到了程序执行到当前哪行的代码的地方。 下一步，如果是方法，他是不会跳进去的。就是一行行的往下走。（eclipse里面的快捷键就是f6） 跳转到详情，如果下一行调试代码是可执行方法，就可以f7进去，查看这个方法的运行详细情况。重点就是点进去执行 从详情跳出去，和上面的9相反。 看字面意思就是跳转到下一个断点 这个点开之后，可以计算你想要看的代码段的值，后面详细上图。 看意思，同eclipse里面的watch，查看某个对象的值，自定义的对象。 把自定义的查看对象的值，分开到另一个tab页。 有时候当我们步入方法体之后，还想回退到方法体外，点这个按钮后，断点重新回到方法体之外。在继续还是可以再次进到方法内 查看断点处的某个对象的值，可以 如下几个方法：1，选中对象后，鼠标悬停在对象上 2 秒左右2，在watch里面添加这个对象，3，下面也许会自动列出来你代码里面有的4，使用上面图上标注的12的那个按钮 下面就再详细说下 4，12，13，144，查看所有的断点的详情，点开如下所示。在图中condition中可以设置断点的条件，当i==4的时候，才停下。查看具体断点内容。 关于设置断点条件，还可以，直接在代码断点处，右键设置，完啦之后，done，设置完成。 12，这个用的也比较多，这个就比较随意。可以根据你的输入，计算你要的结果，不局限代码里面的变量啥的。这个在debug的时候，使用起来是很方便的。 13，14，这2个点完之后，效果如下图，只是把自定义的变量和代码里面自带的变量分在两个tab页面展示。你可以点13号按钮，自行添加，你想查看的变量的值。 还有个需求，就是在调试代码的时候，实时的修改，运行状态的代码变量的值。 仔细看下图，就知道，怎么在实时调试代码的时候，怎么设置某些变量的值，可以看到，我上面在输入a之后，下面就有类似你写代码时候的提示，你就可以在这地方修改变量的值啦 关于调试的时候，设置运行时的参数，如下： 入口如下，2个地方都可以。 一般都是跑简单的main方法，跑main方法的时候，还带参数文件的，还是第一次，顺带做个记录吧。 更新：这个编辑器为了方便从eclipse编辑器转过来的同学们，他可以设置keymap的。具体看图。 因为我就是刚刚开始的时候，使用的就是eclipse，后来转过来的，所以，在使用的时候，就先设置了一下，这个键盘映射。使用的还是以前在eclipse上使用的快捷键。不需要再次去记一遍新的快捷键映射。这个也是极其方便的。 所以，在这个debug的快捷键上和使用eclipse时候，是一样的f5进去，f6是下一步。]]></content>
      <categories>
        <category>IntelliJ IDEA</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程面试题]]></title>
    <url>%2F2017%2F12%2F10%2FJava%E7%BA%BF%E7%A8%8B%E9%9D%A2%E8%AF%95%E9%A2%98%20Top%2050%2F</url>
    <content type="text"><![CDATA[Java线程面试题摘要： 不管你是新程序员还是老手，你一定在面试中遇到过有关线程的问题。Java语言一个重要的特点就是内置了对并发的支持，让Java大受企业和程序员的欢迎。大多数待遇丰厚的Java开发职位都要求开发者精通多线程技术并且有丰富的Java程序开发、调试、优化经验，所以线程相关的问题在面试中经常会被提到。 不管你是新程序员还是老手，你一定在面试中遇到过有关线程的问题。Java语言一个重要的特点就是内置了对并发的支持，让Java大受企业和程序员的欢迎。大多数待遇丰厚的Java开发职位都要求开发者精通多线程技术并且有丰富的Java程序开发、调试、优化经验，所以线程相关的问题在面试中经常会被提到。 在典型的Java面试中， 面试官会从线程的基本概念问起, 如：为什么你需要使用线程， 如何创建线程，用什么方式创建线程比较好（比如：继承thread类还是调用Runnable接口），然后逐渐问到并发问题像在Java并发编程的过程中遇到了什么挑战，Java内存模型，JDK1.5引入了哪些更高阶的并发工具，并发编程常用的设计模式，经典多线程问题如生产者消费者，哲学家就餐，读写器或者简单的有界缓冲区问题。仅仅知道线程的基本概念是远远不够的， 你必须知道如何处理死锁，竞态条件，内存冲突和线程安全等并发问题。掌握了这些技巧，你就可以轻松应对多线程和并发面试了。 许多Java程序员在面试前才会去看面试题，这很正常。因为收集面试题和练习很花时间，所以我从许多面试者那里收集了Java多线程和并发相关的50个热门问题。我只收集了比较新的面试题且没有提供全部答案。想必聪明的你对这些问题早就心中有数了， 如果遇到不懂的问题，你可以用Google找到答案。若你实在找不到答案，可以在文章的评论中向我求助。你也可以在这找到一些答案Java线程问答Top 12。 50道Java线程面试题 下面是Java线程相关的热门面试题，你可以用它来好好准备面试。 什么是线程？ 线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。程序员可以通过它进行多处理器编程，你可以使用多线程对运算密集型任务提速。比如，如果一个线程完成一个任务要100毫秒，那么用十个线程完成改任务只需10毫秒。Java在语言层面对多线程提供了卓越的支持，它也是一个很好的卖点。欲了解更多详细信息请点击这里。 线程和进程有什么区别？ 线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。别把它和栈内存搞混，每个线程都拥有单独的栈内存用来存储本地数据。更多详细信息请点击这里。 如何在Java中实现线程？ 在语言层面有两种方式。java.lang.Thread 类的实例就是一个线程但是它需要调用java.lang.Runnable接口来执行，由于线程类本身就是调用的Runnable接口所以你可以继承java.lang.Thread 类或者直接调用Runnable接口来重写run()方法实现线程。更多详细信息请点击这里. 用Runnable还是Thread？ 这个问题是上题的后续，大家都知道我们可以通过继承Thread类或者调用Runnable接口来实现线程，问题是，那个方法更好呢？什么情况下使用它？这个问题很容易回答，如果你知道Java不支持类的多重继承，但允许你调用多个接口。所以如果你要继承其他类，当然是调用Runnable接口好了。更多详细信息请点击这里。 Thread 类中的start() 和 run() 方法有什么区别？ 这个问题经常被问到，但还是能从此区分出面试者对Java线程模型的理解程度。start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。更多讨论请点击这里 Java中Runnable和Callable有什么不同？ Runnable和Callable都代表那些要在不同的线程中执行的任务。Runnable从JDK1.0开始就有了，Callable是在JDK1.5增加的。它们的主要区别是Callable的 call() 方法可以返回值和抛出异常，而Runnable的run()方法没有这些功能。Callable可以返回装载有计算结果的Future对象。我的博客有更详细的说明。 Java中CyclicBarrier 和 CountDownLatch有什么不同？ CyclicBarrier 和 CountDownLatch 都可以用来让一组线程等待其它线程。与 CyclicBarrier 不同的是，CountdownLatch 不能重新使用。点此查看更多信息和示例代码。 Java内存模型是什么？ Java内存模型规定和指引Java程序在不同的内存架构、CPU和操作系统间有确定性地行为。它在多线程的情况下尤其重要。Java内存模型对一个线程所做的变动能被其它线程可见提供了保证，它们之间是先行发生关系。这个关系定义了一些规则让程序员在并发编程时思路更清晰。比如，先行发生关系确保了： 线程内的代码能够按先后顺序执行，这被称为程序次序规则。对于同一个锁，一个解锁操作一定要发生在时间上后发生的另一个锁定操作之前，也叫做管程锁定规则。前一个对volatile的写操作在后一个volatile的读操作之前，也叫volatile变量规则。一个线程内的任何操作必需在这个线程的start()调用之后，也叫作线程启动规则。一个线程的所有操作都会在线程终止之前，线程终止规则。一个对象的终结操作必需在这个对象构造完成之后，也叫对象终结规则。可传递性 我强烈建议大家阅读《Java并发编程实践》第十六章来加深对Java内存模型的理解。 Java中的volatile 变量是什么？ volatile是一个特殊的修饰符，只有成员变量才能使用它。在Java并发程序缺少同步类的情况下，多线程对成员变量的操作对其它线程是透明的。volatile变量可以保证下一个读取操作会在前一个写操作之后发生，就是上一题的volatile变量规则。点击这里查看更多volatile的相关内容。 什么是线程安全？Vector是一个线程安全类吗？ （详见这里) 如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。 Java中什么是竞态条件？ 举个例子说明。 竞态条件会导致程序在并发情况下出现一些bugs。多线程对一些资源的竞争的时候就会产生竞态条件，如果首先要执行的程序竞争失败排到后面执行了，那么整个程序就会出现一些不确定的bugs。这种bugs很难发现而且会重复出现，因为线程间的随机竞争。一个例子就是无序处理，详见答案。 Java中如何停止一个线程？ Java提供了很丰富的API但没有为停止线程提供API。JDK 1.0本来有一些像stop(), suspend() 和 resume()的控制方法但是由于潜在的死锁威胁因此在后续的JDK版本中他们被弃用了，之后Java API的设计者就没有提供一个兼容且线程安全的方法来停止一个线程。当run() 或者 call() 方法执行完的时候线程会自动结束,如果要手动结束一个线程，你可以用volatile 布尔变量来退出run()方法的循环或者是取消任务来中断线程。点击这里查看示例代码。 一个线程运行时发生异常会怎样？ 这是我在一次面试中遇到的一个很刁钻的Java面试题, 简单的说，如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。 如何在两个线程间共享数据？ 你可以通过共享对象来实现这个目的，或者是使用像阻塞队列这样并发的数据结构。这篇教程《Java线程间通信》(涉及到在两个线程间共享对象)用wait和notify方法实现了生产者消费者模型。 Java中notify 和 notifyAll有什么区别？ 这又是一个刁钻的问题，因为多线程可以等待单监控锁，Java API 的设计人员提供了一些方法当等待条件改变的时候通知它们，但是这些方法没有完全实现。notify()方法不能唤醒某个具体的线程，所以只有一个线程在等待的时候它才有用武之地。而notifyAll()唤醒所有线程并允许他们争夺锁确保了至少有一个线程能继续运行。我的博客有更详细的资料和示例代码。 为什么wait, notify 和 notifyAll这些方法不在thread类里面？ 这是个设计相关的问题，它考察的是面试者对现有系统和一些普遍存在但看起来不合理的事物的看法。回答这些问题的时候，你要说明为什么把这些方法放在Object类里是有意义的，还有不把它放在Thread类里的原因。一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。你也可以查看这篇文章了解更多。 什么是ThreadLocal变量？ ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。线程局部变量的另一个不错的例子是ThreadLocalRandom类，它在多线程环境中减少了创建代价高昂的Random对象的个数。查看答案了解更多。 什么是FutureTask？ 在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。 Java中interrupted 和 isInterruptedd方法的区别？ interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。简单的说就是任何抛出InterruptedException异常的方法都会将中断状态清零。无论如何，一个线程的中断状态有有可能被其它线程调用中断来改变。 为什么wait和notify方法要在同步块中调用？ 主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。 为什么你应该在循环中检查等待条件? 处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。因此，当一个等待线程醒来时，不能认为它原来的等待状态仍然是有效的，在notify()方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用wait()方法效果更好的原因，你可以在Eclipse中创建模板调用wait和notify试一试。如果你想了解更多关于这个问题的内容，我推荐你阅读《Effective Java》这本书中的线程和同步章节。 Java中的同步集合与并发集合有什么区别？ 同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在Java1.5之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。更多内容详见答案。 Java中堆和栈有什么不同？ 为什么把这个问题归类在多线程和并发面试题里？因为栈是一块和线程紧密相关的内存区域。每个线程都有自己的栈内存，用于存储本地变量，方法参数和栈调用，一个线程中存储的变量对其它线程是不可见的。而堆是所有线程共享的一片公用内存区域。对象都在堆里创建，为了提升效率线程会从堆中弄一个缓存到自己的栈，如果多个线程使用该变量就可能引发问题，这时volatile 变量就可以发挥作用了，它要求线程从主存中读取变量的值。 更多内容详见答案。 什么是线程池？ 为什么要使用它？ 创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创建的线程数有限。为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。从JDK1.5开始，Java API提供了Executor框架让你可以创建不同的线程池。比如单线程池，每次处理一个任务；数目固定的线程池或者是缓存线程池（一个适合很多生存期短的任务的程序的可扩展线程池）。更多内容详见这篇文章。 如何写代码来解决生产者消费者问题？ 在现实中你解决的许多线程问题都属于生产者消费者模型，就是一个线程生产任务供其它线程进行消费，你必须知道怎么进行线程间通信来解决这个问题。比较低级的办法是用wait和notify来解决这个问题，比较赞的办法是用Semaphore 或者 BlockingQueue来实现生产者消费者模型，这篇教程有实现它。 如何避免死锁？http://www.cnblogs.com&amp;iframeId=iframe_0.21145907562000632“ frameborder=”0” scrolling=”no” height=”20”&gt; Java多线程中的死锁 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件： 互斥条件：一个资源每次只能被一个进程使用。请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。这篇教程有代码示例和避免死锁的讨论细节。 Java中活锁和死锁有什么区别？ 这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主要区别是前者进程的状态可以改变但是却不能继续执行。 怎么检测一个线程是否拥有锁？ 我一直不知道我们竟然可以检测一个线程是否拥有锁，直到我参加了一次电话面试。在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。你可以查看这篇文章了解更多。 你如何在Java中获取线程堆栈？ 对于不同的操作系统，有多种方法来获得Java进程的线程堆栈。当你获取线程堆栈时，JVM会把所有线程的状态存到日志文件或者输出到控制台。在Windows你可以使用Ctrl + Break组合键来获取线程堆栈，Linux下用kill -3命令。你也可以用jstack这个工具来获取，它对线程id进行操作，你可以用jps这个工具找到id。 JVM中哪个参数是用来控制线程的栈堆栈小的 这个问题很简单， -Xss参数用来控制线程的堆栈大小。你可以查看JVM配置列表来了解这个参数的更多信息。 Java中synchronized 和 ReentrantLock 有什么不同？ Java在过去很长一段时间只能通过synchronized关键字来实现互斥，它有一些缺点。比如你不能扩展锁之外的方法或者块边界，尝试获取锁时不能中途取消等。Java 5 通过Lock接口提供了更复杂的控制来解决这些问题。 ReentrantLock 类实现了 Lock，它拥有与 synchronized 相同的并发性和内存语义且它还具有可扩展性。你可以查看这篇文章了解更多 有三个线程T1，T2，T3，怎么确保它们按顺序执行？ 在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用T2，T2调用T1)，这样T1就会先完成而T3最后完成。你可以查看这篇文章了解更多。 Thread类中的yield方法有什么作用？ Yield方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行。点击这里查看更多yield方法的相关内容。 Java中ConcurrentHashMap的并发度是什么？ ConcurrentHashMap把实际map划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是ConcurrentHashMap类构造函数的一个可选参数，默认值为16，这样在多线程情况下就能避免争用。欲了解更多并发度和内部大小调整请阅读我的文章How ConcurrentHashMap works in Java。 Java中Semaphore是什么？ Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。更多详细信息请点击这里。 如果你提交任务时，线程池队列已满。会时发会生什么？ 这个问题问得很狡猾，许多程序员会认为该任务会阻塞直到线程池队列有空位。事实上如果一个任务不能被调度执行那么ThreadPoolExecutor’s submit()方法将会抛出一个RejectedExecutionException异常。 Java线程池中submit() 和 execute()方法有什么区别？ 两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中, 而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。更多详细信息请点击这里。 什么是阻塞式方法？ 阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。更多详细信息请点击这里。 Swing是线程安全的吗？ 为什么？ 你可以很肯定的给出回答，Swing不是线程安全的，但是你应该解释这么回答的原因即便面试官没有问你为什么。当我们说swing不是线程安全的常常提到它的组件，这些组件不能在多线程中进行修改，所有对GUI组件的更新都要在AWT线程中完成，而Swing提供了同步和异步两种回调方法来进行更新。点击这里查看更多swing和线程安全的相关内容。 Java中invokeAndWait 和 invokeLater有什么区别？ 这两个方法是Swing API 提供给Java开发者用来从当前线程而不是事件派发线程更新GUI组件用的。InvokeAndWait()同步更新GUI组件，比如一个进度条，一旦进度更新了，进度条也要做出相应改变。如果进度被多个线程跟踪，那么就调用invokeAndWait()方法请求事件派发线程对组件进行相应更新。而invokeLater()方法是异步调用更新组件的。更多详细信息请点击这里。 Swing API中那些方法是线程安全的？ 这个问题又提到了swing和线程安全，虽然组件不是线程安全的但是有一些方法是可以被多线程安全调用的，比如repaint(), revalidate()。 JTextComponent的setText()方法和JTextArea的insert() 和 append() 方法也是线程安全的。 如何在Java中创建Immutable对象？ 这个问题看起来和多线程没什么关系， 但不变性有助于简化已经很复杂的并发程序。Immutable对象可以在没有同步的情况下共享，降低了对该对象进行并发访问时的同步化开销。可是Java没有@Immutable这个注解符，要创建不可变类，要实现下面几个步骤：通过构造方法初始化所有成员、对变量不要提供setter方法、将所有的成员声明为私有的，这样就不允许直接访问这些成员、在getter方法中，不要直接返回对象本身，而是克隆对象，并返回对象的拷贝。我的文章how to make an object Immutable in Java有详细的教程，看完你可以充满自信。 Java中的ReadWriteLock是什么？ 一般而言，读写锁是用来提升并发程序性能的锁分离技术的成果。Java中的ReadWriteLock是Java 5 中新增的一个接口，一个ReadWriteLock维护一对关联的锁，一个用于只读操作一个用于写。在没有写线程的情况下一个读锁可能会同时被多个读线程持有。写锁是独占的，你可以使用JDK中的ReentrantReadWriteLock来实现这个规则，它最多支持65535个写锁和65535个读锁。 多线程中的忙循环是什么? 忙循环就是程序员用循环让一个线程等待，不像传统方法wait(), sleep() 或 yield() 它们都放弃了CPU控制，而忙循环不会放弃CPU，它就是在运行一个空循环。这么做的目的是为了保留CPU缓存，在多核系统中，一个等待线程醒来的时候可能会在另一个内核运行，这样会重建缓存。为了避免重建缓存和减少等待重建的时间就可以使用它了。你可以查看这篇文章获得更多信息。 volatile 变量和 atomic 变量有什么不同？ 这是个有趣的问题。首先，volatile 变量和 atomic 变量看起来很像，但功能却不一样。Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。 如果同步块内的线程抛出异常会发生什么？ 这个问题坑了很多Java程序员，若你能想到锁是否释放这条线索来回答还有点希望答对。无论你的同步块是正常还是异常退出的，里面的线程都会释放锁，所以对比锁接口我更喜欢同步块，因为它不用我花费精力去释放锁，该功能可以在finally block里释放锁实现。 单例模式的双检锁是什么？ 这个问题在Java面试中经常被问到，但是面试官对回答此问题的满意度仅为50%。一半的人写不出双检锁还有一半的人说不出它的隐患和Java1.5是如何对它修正的。它其实是一个用来创建线程安全的单例的老方法，当单例实例第一次被创建时它试图用单个锁进行性能优化，但是由于太过于复杂在JDK1.4中它是失败的，我个人也不喜欢它。无论如何，即便你也不喜欢它但是还是要了解一下，因为它经常被问到。你可以查看how double checked locking on Singleton works这篇文章获得更多信息。 如何在Java中创建线程安全的Singleton？ 这是上面那个问题的后续，如果你不喜欢双检锁而面试官问了创建Singleton类的替代方法，你可以利用JVM的类加载和静态变量初始化特征来创建Singleton实例，或者是利用枚举类型来创建Singleton，我很喜欢用这种方法。你可以查看这篇文章获得更多信息。 写出3条你遵循的多线程最佳实践 这种问题我最喜欢了，我相信你在写并发代码来提升性能的时候也会遵循某些最佳实践。以下三条最佳实践我觉得大多数Java程序员都应该遵循： 给你的线程起个有意义的名字。 这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比 Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要框架甚至JDK都遵循这个最佳实践。避免锁定和缩小同步的范围 锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。多用同步类少用wait 和 notify 首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。多用并发集合少用同步集合 这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程时使用并发集合效果更好。如果下一次你需要用到map，你应该首先想到用ConcurrentHashMap。我的文章Java并发集合有更详细的说明。 如何强制启动一个线程？ 这个问题就像是如何强制进行Java垃圾回收，目前还没有觉得方法，虽然你可以使用System.gc()来进行垃圾回收，但是不保证能成功。在Java里面没有办法强制启动一个线程，它是被线程调度器控制着且Java没有公布相关的API。 Java中的fork join框架是什么？ fork join框架是JDK7中出现的一款高效的工具，Java开发人员可以通过它充分利用现代服务器上的多处理器。它是专门为了那些可以递归划分成许多子模块设计的，目的是将所有可用的处理能力用来提升程序的性能。fork join框架一个巨大的优势是它使用了工作窃取算法，可以完成更多任务的工作线程可以从其它线程中窃取任务来执行。你可以查看这篇文章获得更多信息。 Java多线程中调用wait() 和 sleep()方法有什么不同？ Java程序中wait 和 sleep都会造成某种形式的暂停，它们可以满足不同的需要。wait()方法用于线程间通信，如果等待条件为真且其它线程被唤醒时它会释放锁，而sleep()方法仅仅释放CPU资源或者让当前线程停止执行一段时间，但不会释放锁。你可以查看这篇文章获得更多信息。 以上就是50道热门Java多线程和并发面试题啦。我没有分享所有题的答案但给未来的阅读者提供了足够的提示和线索来寻找答案。如果你真的找不到某题的答案，联系我吧，我会加上去的。这篇文章不仅可以用来准备面试，还能检查你对多线程、并发、设计模式和竞态条件、死锁和线程安全等线程问题的理解。我打算把这篇文章的问题弄成所有Java多线程问题的大合集，但是没有你的帮助恐怖是不能完成的，你也可以跟我分享其它任何问题，包括那些你被问到却还没有找到答案的问题。这篇文章对初学者或者是经验丰富的Java开发人员都很有用，过两三年甚至五六年你再读它也会受益匪浅。它可以扩展初学者尤其有用因为这个可以扩展他们的知识面，我会不断更新这些题，大家可以在文章后面的评论中提问，分享和回答问题一起把这篇面试题完善。]]></content>
      <categories>
        <category>Java线程</category>
      </categories>
      <tags>
        <tag>面试精髓</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(两到三年)Java 面试精髓]]></title>
    <url>%2F2017%2F12%2F10%2F(%E4%B8%A4%E5%88%B0%E4%B8%89%E5%B9%B4)Java%20%E9%9D%A2%E8%AF%95%E7%B2%BE%E9%AB%93%2F</url>
    <content type="text"><![CDATA[(两到三年)Java 面试精髓引言：工作两到三年。在面试的时候，其实会对我们平时所有用框架的源码和一些功能底层代码实现给出提问。 Struts2框架的执行流程 ?从客户端发送请求过来,先经过前端控制器（核心过滤器）过滤器中,执行一组拦截器（一组拦截器 就会完成部分功能代码）执行目标Action, 在Action中返回一个结果视图,根据Result的配置进行页面的跳转. Struts2和Struts1没有任何联系.Struts2内核是webwork的内核. hibernate框架的理解?定义: Hibernate是一个开放源代码的对象关系映射（ORM）框架，它对JDBC进行了非常轻量级的对象封装， 使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库.可以通过对象保存到关系型数据库中,仅提供sava/get方法即可 Hibernate是一个持久层的ORM框架. Spring框架的理解?Spring是一个开源框架,核心是控制反转（IOC编程思想）和面向切面（AOP）。简单来说，Spring是一个分层的JavaSE/EEfull-stack(一站式) 轻量级开源框架 Spring的AOP的理解:通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术,利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率.可以在不修改源代码的前提下，对程序进行增强. 例如:在以前配置事务的时候,进行事务的回滚,提交等操作,配置AOP 以后可以将事务的权限交给Spring框架去管理,自动管理 SpringMVC的理解?springMvc:是一个表现层框架,就是从请求中接收传入的参数, 将处理后的结果数据返回给页面展示 基本类型:string,double,float,integer,long.boolean Mybatis的理解?MyBatis是一个优秀的持久层框架，它对jdbc的操作数据库的过程进行封装，使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、结果集检索等jdbc繁杂的过程代码。 Mybatis通过xml或注解的方式将要执行的各种statement（statement、preparedStatement、CallableStatement）配置起来，并通过java对象和statement中的sql进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射成java对象并返回。 #{}可以有效防止sql注入 Servlet的理解?* GET和POST区别? * GET：请求参数会显示到地址栏.GET方式有大小的限制.GET方式没有请求体 * POST：请求参数不会显示到地址栏.在请求体中.POST没有大小限制.POST方式有请求体. * 只有表单设置为method=”post”才是post请求.其他的都是get请求 生命周期:客户端第一次访问该Servlet的时候才会创建一个Servlet的对象,那么Servlet中的init方法就会执行.任何一次从客户端发送的请求,那么服务器创建一个新的线程执行Servlet中service方法为这次请求服务. service方法的内部根据请求的方式的不同调用不同doXXX的方法.当Servlet从服务器中移除或者关闭服务器的时候Servlet对象就会被销毁.destroy的方法就会执行. Struts2与SpringMVC的区别?1)springmvc的入口是一个servlet即前端控制器，而struts2入口是一个filter过虑器。 2)springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，可以设计为单例或多例(建议单例)，struts2是基于类开发，传递参数是通过类的属性，只能设计为多例。 3)Struts采用值栈存储请求和响应的数据，通过OGNL存取数据， springmvc通过参数解析器是将request请求内容解析，并给方法形参赋值，将数据和视图封装成ModelAndView对象，最后又将ModelAndView中的模型数据通过reques域传输到页面。Jsp视图解析器默认使用jstl。 Jsp的核心及核心标签?a) Servlet b) Core XML Database Funcations Redis什么情况下使用，redis持久化方案?a) 处理大数据量的时候 b) Redis的所有数据都是保存在内存中， Rdb：快照形式，定期把内存中当前时刻的数据保存到磁盘，redis默认支持的持久化方案 aof形式：append only file。把所有对redis数据库操作的命令，增删改操作命令，保存到文件中，数据库恢复是把所有命令执行一遍即可。 Hibernate和Mybatis的区别和优劣?a) Sql优化方面：hibernate的查询会将表中所有的字段查询出来，这一点会有性能的消耗 Mybatis的sql是手动编写的，所以可以按需求指定查询的字段，sql会更灵活，可控性更好 b) Hibernate是在JDBC上进行了一次封装 Mybatis是基于原生的JDBC，运行速度有优势 c) Mybatis mapper xml支持动态sql；Hibernate不支持 d) Hibernate与具体数据库的关联只需在xml文件中配置即可，所有hql语句与具体的数据库无关，移植性好 Mybatis项目所有的sql语句都是依赖所用的数据库的，所以不同数据库类型的支持不好 StringBuffer、StringBuilder的区别?StringBuffer、StringBuilder是容器，是可变的字符串序列，存放于堆内存。 StringBuffer是JDK1.0版本的，线程是安全的，效率比较低。StringBuilder是JDK1.5出现的，线程不安全，效率高。 说一下SOLR?solr就是一个中文搜索引擎,做完分词之后会做热度排名,核心是中文分词器,全文搜索支持,索引值指向对应的文档,相当于是一个字典,默认为collection的一个域对象,查询快,效率高. 可以在Redis里做分词之后的缓存,每次搜索一次就次数加一,里面还有一个投票容错机制,主机挂掉还有备份机,一般配置都为奇数态配置. Solr与Lucene的区别?Lucene是一个开放源代码的全文检索引擎工具包，它不是一个完整的全文检索引擎，Lucene提供了完整的查询引擎和索引引擎，目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者以Lucene为基础构建全文检索引擎。 Solr的目标是打造一款企业级的搜索引擎系统，它是一个搜索引擎服务，可以独立运行，通过Solr可以非常快速的构建企业的搜索引擎，通过Solr也可以高效的完成站内搜索功能。 什么是Redis?1) Redis的高性能是由于其将所有数据都存储在了内存中，为了使Redis在重启之后仍能保证数据不丢失，需要将数据从内存中同步到硬盘中，这一过程就是持久化。 Redis支持两种方式的持久化，一种是RDB方式，一种是AOF方式。可以单独使用其中一种或将二者结合使用。 1.1RDB持久化 RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的数据进行快照并持久化到硬盘。 每次进行访问进行存储,如果服务器一旦崩溃,会导致数据丢失 RDB是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置： save 900 1 , save 300 10, save 60 10000 save 开头的一行就是持久化配置，可以配置多个条件（每行配置一个条件），每个条件之间是“或”的关系，“save 900 1”表示15分钟（900秒钟）内 至少 1个键被更改则进行快照，“save 300 10”表示5分钟（300秒）内至少10个键被更改则进行快照。 在redis.conf中： 配置dir指定 rdb快照文件的位置;配置dbfilenam指定rdb快照文件的名称 Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。 通常将记录一千万个字符串类型键、大小为1GB的快照文件载入到内存中需要花费20～30秒钟。 问题总结： 通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化。 1.2AOF持久化 默认情况下Redis没有开启AOF（append only file）方式的持久化，访问一段存储一段,效率高. 可以通过appendonly参数开启：appendonly yes开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件 AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：appendfilename appendonly.aof 2)主从复制（了解） 2.1什么是主从复制 持久化保证了即使redis服务重启也会丢失数据，因为redis服务重启后会将硬盘上持久化的数据恢复到内存中，但是当redis服务器的硬盘损坏了可能会导致数据丢失，如果通过redis的主从复制机制就可以避免这种单点故障，如下图： 说明： n主redis中的数据有两个副本（replication）即从redis1和从redis2，即使一台redis服务器宕机其它两台redis服务也可以继续提供服务。 n主redis中的数据和从redis上的数据保持实时同步，当主redis写入数据时通过主从复制机制会复制到两个从redis服务上。 n只有一个主redis，可以有多个从redis。 n主从复制不会阻塞master，在同步数据时，master 可以继续处理client 请求 n一个redis可以即是主又是从，如下图： 2.2主从配置 2.2.1主redis配置 无需特殊配置。 2.2.2从redis配置 修改从redis服务器上的redis.conf文件，添加slaveof主redisip主redis端口 上边的配置说明当前该从redis服务器所对应的主redis是192.168.101.3，端口是6379 2.3主从复制过程 2.3.1完整复制 在redis2.8版本之前主从复制过程如下图： 复制过程说明： 1、slave 服务启动，slave 会建立和master 的连接，发送sync 命令。 2、master启动一个后台进程将数据库快照保存到RDB文件中 注意：此时如果生成RDB文件过程中存在写数据操作会导致RDB文件和当前主redis数据不一致，所以此时master 主进程会开始收集写命令并缓存起来。 3、master 就发送RDB文件给slave 4、slave 将文件保存到磁盘上，然后加载到内存恢复 5、master把缓存的命令转发给slave 注意：后续master 收到的写命令都会通过开始建立的连接发送给slave。 当master 和slave 的连接断开时slave 可以自动重新建立连接。如果master 同时收到多个slave 发来的同步连接命令，只会启动一个进程来写数据库镜像，然后发送给所有slave。 完整复制的问题： 在redis2.8之前从redis每次同步都会从主redis中复制全部的数据，如果从redis是新创建的从主redis中复制全部的数据这是没有问题的，但是，如果当从redis停止运行，再启动时可能只有少部分数据和主redis不同步，此时启动redis仍然会从主redis复制全部数据，这样的性能肯定没有只复制那一小部分不同步的数据高。 2.3.2部分复制 部分复制说明： 从机连接主机后，会主动发起 PSYNC 命令，从机会提供 master的runid(机器标识，随机生成的一个串) 和 offset（数据偏移量，如果offset主从不一致则说明数据不同步），主机验证 runid 和 offset 是否有效， runid 相当于主机身份验证码，用来验证从机上一次连接的主机，如果runid验证未通过则，则进行全同步，如果验证通过则说明曾经同步过，根据offset同步部分数据。 2)redis是一个nosql(not only sql不仅仅只有sql)数据库.翻译成中文叫做非关系型型数据库. 关系型数据库:以二维表形式存储数据 非关系型数据库: 以键值对形式存储数据(key, value形式) Redis是用C语言开发的一个开源的高性能键值对（key-value）数据库。它通过提供多种键值数据类型来适应不同场景下的存储需求， 目前为止Redis支持的键值数据类型如下： 字符串类型 散列类型 列表类型 集合类型 有序集合类型。 3)redis的应用场景 缓存（数据查询、短连接、新闻内容、商品内容等等）。（最多使用） 分布式集群架构中的session分离。 聊天室的在线好友列表。 任务队列。（秒杀、抢购、12306等等） 应用排行榜。 网站访问统计。 数据过期处理（可以精确到毫秒） redis是将数据存放到内存中,由于内容存取速度快所以redis被广泛应用在互联网项目中, redis有点:存取速度快,官方称读取速度会达到30万次每秒,写速度在10万次每秒最有,具体限制于硬件. 缺点:对持久化支持不够良好, 所以redis一般不作为数据的主数据库存储,一般配合传统的关系型数据库使用. 4) redis应用领域 分布式缓存 分布式session 保存博客或者论坛的留言回复等. 总之是用在数据量大,并发量高的情况下 谈下DUBBO?Dubbo就是资源调度和治理中心的管理工具。 调用关系说明： \0. 服务容器负责启动，加载，运行服务提供者。 \1. 服务提供者在启动时，向注册中心注册自己提供的服务。 \2. 服务消费者在启动时，向注册中心订阅自己所需的服务。 \3. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 \4. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 \5. 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 解决跨域问题?JSONP–&gt;Script Tags 秒杀方案：1、把商品的数量放到redis中。 2、秒杀时使用decr命令对商品数量减一。如果不是负数说明抢到。 3、一旦返回数值变为0说明商品已售完。 ZOOKeeper?Zookeeper 作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，但是 Zookeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控你存储的数据的状态变化。 通过监控这些数据状态的变化，从而可以达到基于数据的集群管理 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力小。使用dubbo-2.3.3以上版本，建议使用zookeeper注册中心。 Zookeeper是Apacahe Hadoop的子项目，是一个树型的目录服务，支持变更推送，适合作为Dubbo服务的注册中心，工业强度较高，可用于生产环境，并推荐使用 ActiveMQ的消息形式一种是点对点的，即一个生产者和一个消费者一一对应；可进行缓存,只允许单人登录查看 另一种是发布/订阅模式，即一个生产者产生消息并进行发送后，可以由多个消费者进行接收。无法进行缓存,支持多人访问. JMS定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。 StreamMessage – Java原始值的数据流 MapMessage–一套名称-值对 TextMessage–一个字符串对象 ObjectMessage–一个序列化的 Java对象 BytesMessage–一个字节的数据流 1.订单系统 1.1.功能分析 1、在购物车页面点击“去结算”按钮跳转到订单确认页面。 a)展示商品列表 b)配送地址列表 c)选择支付方式 2、展示订单确认页面之前，应该确认用户身份。 a)使用拦截器实现。 b)Cookie中取token c)取不到token跳转到登录页面 d)取到token，根据token查询用户信息。 e)如果没有用户信息，登录过期跳转到登录页面 f)取到用户信息，放行。 3、提交订单 a)生成订单 b)展示订单提交成功页面。 订单系统系统：订单确认页面、订单提交成功页面。 订单服务系统 1.1.展示订单确认页面 1.1.1.功能分析 1、在购物车页面点击“去结算”按钮跳转到订单确认页面。 2、请求的url： /order/order-cart 3、参数：没有参数。 4、购物车商品数据从cookie中取出来的。可以在订单系统中取到cookie中的购物车数据。 5、配送地址列表，需要用户登录。需要根据用户id查询收货地址列表。静态数据。 6、支付方式。静态数据。 7、返回值：逻辑视图String，展示订单确认页面。 1.1.2.Dao层、Service层（没有） 需要根据用户id查询收货地址列表。没有此功能。 1.1.3.表现层 请求的url：/order/order-cart 参数：无 业务逻辑： 从cookie中取商品列表展示到页面。 返回值：逻辑视图。 1.1.用户身份认证 在展示订单确认页面之前，需要对用户身份进行认证，要求用户必须登录。 1.1.1.功能分析 1、使用springmvc的拦截器实现。需要实现一个接口HandlerInterceptor接口。 2、业务逻辑 a)从cookie中取token。 b)没有token，需要跳转到登录页面。 c)有token。调用sso系统的服务，根据token查询用户信息。 d)如果查不到用户信息。用户登录已经过期。需要跳转到登录页面。 e)查询到用户信息。放行。 3、在springmvc.xml中配置拦截器。 1.1.2.拦截器实现 1.1.1.功能分析 1、在订单确认页面点击“提交订单”按钮生成订单。 2、请求的url：/order/create 3、参数：提交的是表单的数据。保存的数据：订单、订单明细、配送地址。 a)向tb_order中插入记录。 i.订单号需要手动生成。 要求订单号不能重复。 订单号可读性号。 可以使用redis的incr命令生成订单号。订单号需要一个初始值。 ii.Payment：表单数据 iii.payment_type：表单数据 iv.user_id：用户信息 v.buyer_nick：用户名 vi.其他字段null b)向tb_order_item订单明细表插入数据。 i.Id：使用incr生成 ii.order_id：生成的订单号 iii.其他的都是表单中的数据。 c)tb_order_shipping，订单配送信息 i.order_id：生成的订单号 ii.其他字段都是表单中的数据。 d)使用pojo接收表单的数据。 可以扩展TbOrder，在子类中添加两个属性一个是商品明细列表，一个是配送信息。 把pojo放到taotao-order-interface工程中。 业务逻辑： 1、接收表单的数据 2、生成订单id 3、向订单表插入数据。 4、向订单明细表插入数据 5、向订单物流表插入数据。 6、返回TaotaoResult。 返回值：TaotaoResult 1.1.1.Dao层 可以使用逆向工程。 1.1.2.Service层 参数：OrderInfo 单点登录单点登录就是我们是做了分布式，tomcat集群之后会有session复制的问题，影响利群数量。所以把注册登录拿出来单独做了一个单点登录系统。做的时候是用的redis，key是用uuid生成的一个token,类似于session id,是用户的唯一标识，value是用户的信息。设置了有效期是7天。然后把redis放到了cookie中，实现了cookie的二级跨域。当我们进行操作时，首先要从cookie里面取出token如果取不到，就跳到单点登录系统进行登录操作如果取到了，再看看token有没有过期，如果过期了，也是跳到单点登录系统登录一下，没过期就继续用户的操作。密码进行了加密，用Md5 HashMap 和 HashTable 的区别1）容器整体结构： HashMap的key和value都允许为null，HashMap遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理。 Hashtable的key和value都不允许为null。Hashtable遇到null，直接返回NullPointerException。 2） 容量设定与扩容机制： HashMap默认初始化容量为 16，并且容器容量一定是2的n次方，扩容时，是以原容量 2倍 的方式 进行扩容。 Hashtable默认初始化容量为 11，扩容时，是以原容量 2倍 再加 1的方式进行扩容。即int newCapacity = (oldCapacity &lt;&lt; 1) + 1;。 3） 散列分布方式（计算存储位置）： HashMap是先将key键的hashCode经过扰动函数扰动后得到hash值，然后再利用 hash &amp; (length - 1)的方式代替取模，得到元素的存储位置。 Hashtable则是除留余数法进行计算存储位置的（因为其默认容量也不是2的n次方。所以也无法用位运算替代模运算），int index = (hash &amp; 0x7FFFFFFF) % tab.length;。 由于HashMap的容器容量一定是2的n次方，所以能使用hash &amp; (length - 1)的方式代替取模的方式计算元素的位置提高运算效率，但Hashtable的容器容量不一定是2的n次方，所以不能使用此运算方式代替。 4）线程安全（最重要）： HashMap 不是线程安全，如果想线程安全，可以通过调用synchronizedMap(Map&lt;K,V&gt; m)使其线程安全。但是使用时的运行效率会下降，所以建议使用ConcurrentHashMap容器以此达到线程安全。 Hashtable则是线程安全的，每个操作方法前都有synchronized修饰使其同步，但运行效率也不高，所以还是建议使用ConcurrentHashMap容器以此达到线程安全。 因此，Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 ArrayList和LinkedList 的区别 LinkedList内部存储的是Node&lt;E&gt;，不仅要维护数据域，还要维护prev和next，如果LinkedList中的结点特别多，则LinkedList比ArrayList更占内存。 插入删除操作效率：LinkedList在做插入和删除操作时，插入或删除头部或尾部时是高效的，操作越靠近中间位置的元素时，需要遍历查找，速度相对慢一些，如果在数据量较大时，每次插入或删除时遍历查找比较费时。所以LinkedList插入与删除，慢在遍历查找，快在只需要更改相关结点的引用地址。ArrayList在做插入和删除操作时，插入或删除尾部时也一样是高效的，操作其他位置，则需要批量移动元素，所以ArrayList插入与删除，快在遍历查找，慢在需要批量移动元素。 循环遍历效率： 由于ArrayList实现了RandomAccess随机访问接口，所以使用for(int i = 0; i &lt; size; i++)遍历会比使用Iterator迭代器来遍历快 而由于LinkedList未实现RandomAccess接口，所以推荐使用Iterator迭代器来遍历数据。 因此，如果我们需要频繁在列表的中部改变插入或删除元素时，建议使用LinkedList，否则，建议使用ArrayList，因为ArrayList遍历查找元素较快，并且只需存储元素的数据域，不需要额外记录其他数据的位置信息，可以节省内存空间。]]></content>
      <categories>
        <category>Java 面试精髓</category>
      </categories>
      <tags>
        <tag>基础面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试感悟：工作经验java程序员应有的技能]]></title>
    <url>%2F2017%2F12%2F10%2F%E9%9D%A2%E8%AF%95%E6%84%9F%E6%82%9F%EF%BC%9A%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8Cjava%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E6%9C%89%E7%9A%84%E6%8A%80%E8%83%BD%2F</url>
    <content type="text"><![CDATA[面试感悟：工作经验java程序员应有的技能前言因为和同事有约定再加上LZ自己也喜欢做完一件事之后进行总结，因此有了这篇文章。这篇文章大部分内容都是面向整个程序员群体的，当然因为LZ本身是做Java开发的，因此有一部分内容也是专门面向咱们Java程序员的。 简单先说一下，LZ坐标杭州，13届本科毕业，算上年前在阿里巴巴B2B事业部的面试，一共有面试了有6家公司（因为LZ不想请假，因此只是每个晚上去其他公司面试，所以面试的公司比较少），其中成功的有4家，另外两家失败的原因在于： 1、阿里巴巴B2B事业部的面试，两轮技术面试都过了，最后一轮面试是对方的主管，由于听说技术面试过了基本上90%都面试成功了，所以LZ在和主管的交谈中也是毫无顾忌，说得天花乱坠，很多自己介于知道和不知道的东西都直接脱口而出了，结果多次被对方一反问就问得哑口无言。事后想来，模棱两可的答案是面试中最忌讳的，这次的失败也让LZ认真地对待后面的每一次面试 2、另外一家失败的是一家小公司，也就20来个人吧，整个团队是支付宝出来创业的，非常厉害。面试完LZ多方了解了一下，对方认为我基本功什么的都不错，但是实际项目经验还是欠缺一些，因为对方是创业型公司，需要人上手就能干活，因此我在这个时候还不是特别适合他们团队 至于其他成功的四家公司，给LZ的面试评价都挺高的貌似，但LZ也不想记流水账，因此就不一一列举每家公司的面试过程了，下面LZ主要谈谈作为一名工作三年左右的Java程序员应该具备的一些技能以及个人的一些其他感悟。 关于程序员的几个阶段每个程序员、或者说每个工作者都应该有自己的职业规划，如果看到这里的朋友没有自己的职业规划，希望你可以思考一下自己的将来。 LZ常常思考自己的未来，也从自己的思考中总结出了一些东西，作为第一部分来谈谈。LZ认为一名程序员应该有几个阶段（以下时间都算上实习期）： 第一阶段：三年 我认为三年对于程序员来说是第一个门槛，这个阶段将会淘汰掉一批不适合写代码的人。这一阶段，我们走出校园，迈入社会，成为一名程序员，正式从书本上的内容迈向真正的企业级开发。我们知道如何团队协作、如何使用项目管理工具、项目版本如何控制、我们写的代码如何测试如何在线上运行等等，积累了一定的开发经验，也对代码有了一定深入的认识，是一个比较纯粹的Coder的阶段 第二阶段：五年 五年又是区分程序员的第二个门槛。有些人在三年里，除了完成工作，在空余时间基本不会研究别的东西，这些人永远就是个Coder，年纪大一些势必被更年轻的人给顶替；有些人在三年里，除了写代码之外，还热衷于研究各种技术实现细节、看了N多好书、写一些博客、在Github上分享技术，这些人在五年后必然具备在技术上独当一面的能力并且清楚自己未来的发展方向，从一个Coder逐步走向系统分析师或是架构师，成为项目组中不可或缺的人物 第三阶段：十年 十年又是另一个门槛了，转行或是继续做一名程序员就在这个节点上。如果在前几年就抱定不转行的思路并且为之努力的话，那么在十年的这个节点上，有些人必然成长为一名对行业有着深入认识、对技术有着深入认识、能从零开始对一个产品进行分析的程序员，这样的人在公司基本担任的都是CTO、技术专家、首席架构师等最关键的职位，这对于自己绝对是一件荣耀的事，当然老板在经济上也绝不会亏待你 第一部分总结一下，我认为，随着你工作年限的增长、对生活对生命认识的深入，应当不断思考三个问题： 1、我到底适不适合当一名程序员？ 2、我到底应不应该一辈子以程序员为职业？ 3、我对编程到底持有的是一种什么样的态度，是够用就好呢还是不断研究？ 最终，明确自己的职业规划，对自己的规划负责并为之努力。 关于项目经验LZ在网上经常看到一些别的朋友有提出项目经验的问题，依照LZ面试的感觉来说，面试主要看几点：项目经验+基本技术+个人潜力（也就是值不值得培养）。 关于项目经验，我认为并发编程网的创始人方腾飞老师讲的一段话非常好： 介绍产品时面试官会考察应聘者的沟通能力和思考能力，我们大部分情况都是做产品的一个功能或一个模块，但是即使是这样，自己有没有把整个系统架构或产品搞清楚，并能介绍清楚，为什么做这个系统？这个系统的价值是什么？这个系统有哪些功能？优缺点有哪些？如果让你重新设计这个系统你会如何设计？ 我觉得这就已经足以概括了。也许你仅仅工作一年，也许你做的是项目中微不足道的模块，当然这些一定是你的劣势且无法改变，但是如何弥补这个劣势，从方老师的话中我总结几点： 1、明确你的项目到底是做什么的，有哪些功能 2、明确你的项目的整体架构，在面试的时候能够清楚地画给面试官看并且清楚地指出从哪里调用到哪里、使用什么方式调用 3、明确你的模块在整个项目中所处的位置及作用 4、明确你的模块用到了哪些技术，更好一些的可以再了解一下整个项目用到了哪些技术 在你无法改变自己的工作年限、自己的不那么有说服力的项目经验的情况下（这一定是扣分项），可以通过这种方式来一定程度上地弥补并且增进面试官对你的好感度。 关于专业技能写完项目接着写写一名3年工作经验的Java程序员应该具备的技能，这可能是Java程序员们比较关心的内容。我这里要说明一下，以下列举的内容不是都要会的东西—-但是如果你掌握得越多，最终能得到的评价、拿到的薪水势必也越高。 1、基本语法 这包括static、final、transient等关键字的作用，foreach循环的原理等等。今天面试我问你static关键字有哪些作用，如果你答出static修饰变量、修饰方法我会认为你合格，答出静态块，我会认为你不错，答出静态内部类我会认为你很好，答出静态导包我会对你很满意，因为能看出你非常热衷研究技术。 最深入的一次，LZ记得面试官直接问到了我Volatile关键字的底层实现原理（顺便插一句，面试和被面试本身就是相对的，面试官能问这个问题同时也让面试者感觉到面试官也是一个喜爱研究技术的人，增加了面试者对公司的好感，LZ最终选择的就是问了这个问题的公司），不要觉得这太吹毛求疵了—-越简单的问题越能看出一个人的水平，别人对你技术的考量绝大多数都是以深度优先、广度次之为标准的，切记。 2、集合 非常重要，也是必问的内容。基本上就是List、Map、Set，问的是各种实现类的底层实现原理，实现类的优缺点。 集合要掌握的是ArrayList、LinkedList、Hashtable、HashMap、ConcurrentHashMap、HashSet的实现原理，能流利作答，当然能掌握CopyOnWrite容器和Queue是再好不过的了。另外多说一句，ConcurrentHashMap的问题在面试中问得特别多，大概是因为这个类可以衍生出非常多的问题，关于ConcurrentHashMap，我给网友朋友们提供三点回答或者是研究方向： （1）ConcurrentHashMap的锁分段技术 （2）ConcurrentHashMap的读是否要加锁，为什么 （3）ConcurrentHashMap的迭代器是强一致性的迭代器还是弱一致性的迭代器 3、设计模式 本来以为蛮重要的一块内容，结果只在阿里巴巴B2B事业部面试的时候被问了一次，当时问的是装饰器模式。 当然咱们不能这么功利，为了面试而学习，设计模式在工作中还是非常重要、非常有用的，23种设计模式中重点研究常用的十来种就可以了，面试中关于设计模式的问答主要是三个方向： （1）你的项目中用到了哪些设计模式，如何使用 （2）知道常用设计模式的优缺点 （3）能画出常用设计模式的UML图 4、多线程 这也是必问的一块了。因为三年工作经验，所以基本上不会再问你怎么实现多线程了，会问得深入一些比如说Thread和Runnable的区别和联系、多次start一个线程会怎么样、线程有哪些状态。当然这只是最基本的，出乎意料地，几次面试几乎都被同时问到了一个问题，问法不尽相同，总结起来是这么一个意思： 假如有Thread1、Thread2、ThreaD3、Thread4四条线程分别统计C、D、E、F四个盘的大小，所有线程都统计完毕交给Thread5线程去做汇总，应当如何实现？ 聪明的网友们对这个问题是否有答案呢？不难，java.util.concurrent下就有现成的类可以使用。 另外，线程池也是比较常问的一块，常用的线程池有几种？这几种线程池之间有什么区别和联系？线程池的实现原理是怎么样的？实际一些的，会给你一些具体的场景，让你回答这种场景该使用什么样的线程池比较合适。 最后，虽然这次面试问得不多，但是多线程同步、锁这块也是重点。synchronized和ReentrantLock的区别、synchronized锁普通方法和锁静态方法、死锁的原理及排查方法等等，关于多线程，我在之前有些过文章总结过多线程的40个问题，可以参看40个Java多线程问题总结。 5、JDK源码 要想拿高工资，JDK源码不可不读。上面的内容可能还和具体场景联系起来，JDK源码就是实打实地看你平时是不是爱钻研了。LZ面试过程中被问了不少JDK源码的问题，其中最刁钻的一个问了LZ，String的hashCode()方法是怎么实现的，幸好LZ平时String源代码看得多，答了个大概。JDK源码其实没什么好总结的，纯粹看个人，总结一下比较重要的源码： （1）List、Map、Set实现类的源代码 （2）ReentrantLock、AQS的源代码 （3）AtomicInteger的实现原理，主要能说清楚CAS机制并且AtomicInteger是如何利用CAS机制实现的 （4）线程池的实现原理 （5）Object类中的方法以及每个方法的作用 这些其实要求蛮高的，LZ去年一整年基本把JDK中重要类的源代码研究了个遍，真的花费时间、花费精力，当然回头看，是值得的—-不仅仅是为了应付面试。 6、框架 老生常谈，面试必问的东西。一般来说会问你一下你们项目中使用的框架，然后给你一些场景问你用框架怎么做，比如我想要在Spring初始化bean的时候做一些事情该怎么做、想要在bean销毁的时候做一些事情该怎么做、MyBatis中$和#的区别等等，这些都比较实际了，平时积累得好、有多学习框架的使用细节自然都不成问题。 如果上面你的问题答得好，面试官往往会深入地问一些框架的实现原理。问得最多的就是Spring AOP的实现原理，当然这个很简单啦，两句话就搞定的的事儿，即使你不会准备一下就好了。LZ遇到的最变态的是让LZ画一下Spring的Bean工厂实现的UML图，当然面对这样一个有深度的问题，LZ是绝对答不出来的/(ㄒoㄒ)/~~ 7、数据库 数据库十有八九也都会问到。一些基本的像union和union all的区别、left join、几种索引及其区别就不谈了，比较重要的就是数据库性能的优化，如果对于数据库的性能优化一窍不通，那么有时间，还是建议你在面试前花一两天专门把SQL基础和SQL优化的内容准备一下。 不过数据库倒是不用担心，一家公司往往有很多部门，如果你对数据库不熟悉而基本技术又非常好，九成都是会要你的，估计会先把你放到对数据库使用不是要求非常高的部门锻炼一下。 8、数据结构和算法分析 数据结构和算法分析，对于一名程序员来说，会比不会好而且在工作中绝对能派上用场。数组、链表是基础，栈和队列深入一些但也不难，树挺重要的，比较重要的树AVL树、红黑树，可以不了解它们的具体实现，但是要知道什么是二叉查找树、什么是平衡树，AVL树和红黑树的区别。记得某次面试，某个面试官和我聊到了数据库的索引，他问我： 你知道索引使用的是哪种数据结构实现吗？ LZ答到用的Hash表吧，答错。他又问，你知道为什么要使用树吗？LZ答到因为Hash表可能会出现比较多的冲突，在千万甚至是上亿级别的数据面前，会大大增加查找的时间复杂度。而树比较稳定，基本保证最多二三十次就能找到想要的数据，对方说不完全对，最后我们还是交流了一下这个问题，我也明白了为什么要使用树，这里不说，网友朋友们觉得索引为什么要使用树来实现呢？ 至于算法分析，不会、不想研究就算了，记得某次面试对方问我，Collections.sort方法使用的是哪种排序方法，额，吐血三升。当然为了显示LZ的博学，对算法分析也有一定的研究(⊙﹏⊙)b，LZ还是硬着头皮说了一句可能是冒泡排序吧。当然答案肯定不是，有兴趣的网友朋友们可以去看一下Collections.sort方法的源代码，用的是一种叫做TimSort的排序法，也就是增强型的归并排序法。 9、Java虚拟机 出乎LZ的意料，Java虚拟机应该是很重要的一块内容，结果在这几家公司中被问到的概率几乎为0。要知道，LZ去年可是花了大量的时间去研究Java虚拟机的，光周志明老师的《深入理解Java虚拟机：JVM高级特性与最佳实践》，LZ就读了不下五遍。 言归正传，虽然Java虚拟机没问到，但我觉得还是有必要研究的，LZ就简单地列一个提纲吧，谈谈Java虚拟机中比较重要的内容： （1）Java虚拟机的内存布局 （2）GC算法及几种垃圾收集器 （3）类加载机制，也就是双亲委派模型 （4）Java内存模型 （5）happens-before规则 （6）volatile关键字使用规则 也许面试无用，但在走向大牛的路上，不可不会。 10、Web方面的一些问题 Java主要面向Web端，因此Web的一些问题也是必问的。LZ碰到过问得最多的两个问题是： 谈谈分布式Session的几种实现方式 常用的四种能答出来自然是让面试官非常满意的，另外一个常问的问题是： 讲一下Session和Cookie的区别和联系以及Session的实现原理 这两个问题之外，web.xml里面的内容是重点，Filter、Servlet、Listener，不说对它们的实现原理一清二楚吧，至少能对它们的使用知根知底。另外，一些细节的方面比如get/post的区别、forward/重定向的区别、HTTPS的实现原理也都可能会被考察到。 噢，想起来了，一致性Hash算法貌似也被问到了几次，这个LZ以前专门深入研究过并且写了两篇博文，因此问到这个问题LZ自然是答得毫不费力。文章是MemCache超详细解读和对一致性Hash算法，Java代码实现的深入研究，特别说明，LZ真的不是在为自已以前写的文章打广告啊啊啊啊啊啊。 最后，如果有兴趣有时间，建议学习、研究一下SOA和RPC，面向服务体系，大型分布式架构必备，救命良方、包治百病、屡试不爽。 关于HR面试如果你过五关斩六将，成功地通过了所有的技术面，那么恭喜你，你离升职加薪、出任CEO、迎娶白富美、走向人生巅峰又进了一步。但是还没有到谈薪资待遇的时候，最后还有一个考验：HR面试。基本所有的大公司都有这一轮的面试，不要小看HR面试，很多公司的HR对于面试者都有一票否决权的—-即使前面的面试对你的评价再高。 所以，这轮的面试也必须重视起来，HR面试主要问的是几点： 1、简历中写的过去工作经历的离职原因 2、当前公司薪资待遇 3、期望能到怎样的一家公司 4、个人未来的发展方向 我专门提一下第2点。可能有人比较排斥也不想说这个，我个人倒是持开放状态，问了就说了，当然一些的夸大还是必要的，当前公司薪资待遇多报个一千块钱完全没问题（毕竟是一家互联网公司总多多少少有些补贴啊什么的嘛）。因为这和你在新公司能拿到的薪水关系不大，新公司能拿到的薪水的决定因素是整个公司的薪资情况以及根据你的面试情况在公司的定位，都是有固定的薪资范围的。HR问这个主要也就是心里有个数并且看你是否诚信—-有些公司入职时会要求你提供最近一家单位的银行流水号。 HR面试就说到这里了，总结起来其实就是四个字：滴水不漏。整个面试过程态度积极向上，不要有任何悲观消极的态度（尤其在谈到以前公司情况的时候，即使有再多的不满），就不会有问题。 关于面试心态这个嘛，LZ其实在公司也面试过几个人，一半以上的面试者回答问题的时候都属于那种双腿发抖、声音颤抖的类型。在LZ看来这大可不必并且这还是扣分项，回答问题的时候最最基本的两个要求： 1、不紧不慢，平心静气 2、条理清晰 表达能力绝对是面试的时候重要的考察项目。咱们做的是程序员这一行，讲究的是团队协作，不是写作、画画，一支笔、一个人就行了，一个表达能力不行的程序员，要来又有什么用呢？ 除此之外，就是保持良好的心态。古语说得好，只要功夫深，铁杵磨成针，面试的成功与否，在于平时的积累，临时抱抱佛脚，看两道面试题是没有用的，只要平时足够努力，成功是水到渠成的事情，平时不怎么研究技术的，那也就是个听天由命的事情，只要充分地展示平时自己的所学就可以了。 因此在我看来，不要把面试当作面试，当做一次技术交流，把面试的心态从我要找到一份工作转变为我要通过面试去发现不足、提升自己，这样就会平和多了，即使失败也不会有太多失望的感觉。 另外，如果平时自己热衷于研究技术的朋友，真的要有自信，不要觉得别人面试你别人就比你厉害。面试官未必比你优秀，他问的问题往往都是他平时研究得比较多的问题，你一样有很多自己的研究面试官未必知道。 关于Java网上常看到一种说法：Java比较简单。某种程度上这会打击Java程序员的信心—-原来咱们平时用的是这种小儿科的玩意儿啊，在我看来这种想法大可不必，这一部分我来讲讲对于这个话题的看法。 这种说法有些片面，得分开两部分来看，我用四个自总结一下就是：易学难精。 1、易学部分 Java易学我认为有两部分的原因： （1）很多培训公司包括大四的学生找工作都会学习Java，绝大多数是因为易学。Java从C/C++发展而来，感谢前人的智慧，它消除了C/C++中最复杂和让人困惑的语法、它消除了平台的差异性、它不需要用户手动释放内存空间、它避免了Java程序员和本地语言的交互，让程序员只需要专注于语法层面和应用层面。 （2）Java作为一门面向对象的语言，在企业级开发中体现出了它无与伦比的特性，整个开发流程比较固定化、模块化，需求分析起来也相对容易。我举个自己以前的例子吧，我在大一学习C语言的时候，用C语言写了一个图书管理系统写了2000+的代码，大四学了C++之后，用面向对象的语言C++取代面向过程的语言C语言重新写了一个功能相似的图书管理系统，只写了1100行的样子，这就是面向对象的优势。 2、难精部分 接着咱们聊聊难精的部分。 Java语言的设计者帮助Java程序员做了这么多事情，这有利也有弊。有利的部分前面已经说过了，让Java易学，不过有弊的部分同样明显。假如在应用运行过程中遇到了语法层面和应用层面之外的错误，应当如何处理？比如线上环境出现内存溢出怎么办？GC时间过长怎么办？IO长时间没反应怎么办？方法抛出莫名其妙的异常怎么办？ 凡此种种，绝不是一名只会写几个if…else…的Java程序员就可以解决的，这需要大量的经历、大量的实践、大量对Java底层实现细节的研究，而这往往是最难、最考验Java程序员的部分，一些人根本就不想往深去研究，另外一些人研究了一点点就研究不下去了。 Java为什么难精？就是这个原因。除非你水平特别高，否则五年工作经验以下的Java程序员在简历上写”精通Java”绝对是一件非常愚蠢的事情。 结语文章写到这里，感觉有点像鸡汤文了，那就以最后的鸡汤作为结尾吧。 在以前博客园的一篇文章中，讲到了奔三程序员的困惑，大致说的是三十岁之后程序员要转行之类的云云，LZ在博文中留下了如下的评论： 就以这段话自勉、共勉吧。越努力、越幸运，如果你不是官二代、富二代、红二代，那么请记住：勤奋才是改变你命运的唯一捷径。]]></content>
      <categories>
        <category>工作经验java程序员应有的技能</category>
      </categories>
      <tags>
        <tag>面试精髓</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList 源码分析]]></title>
    <url>%2F2017%2F12%2F09%2FLinkedList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LinkedList 源码分析前言有了ArrayList，自然少不了LinkedList了。 下面我就以面试问答的形式学习我们的常用的装载容器——LinkedList（源码分析基于JDK8） 问答内容LinkedList 用来做什么，怎么使用？问：请简单介绍一下您所了解的LinkedList，它可以用来做什么，怎么使用？ 答： LinkedList底层是双向链表，同时实现了List接口和Deque接口，所以它既可以看作是一个顺序容器，也可以看作是一个队列(Queue)，同时也可以看作是一个栈(Stack)，但如果想使用栈或队列等数据结构的话，推荐使用ArrayDeque，它作为栈或队列会比LinkedList有更好的使用性能。 示例代码： 12345678910111213141516171819// 创建一个LinkedList，链表的每个节点的内存空间都是实时分配的，所以无须事先指定容器大小LinkedList&lt;String&gt; linkedList = new LinkedList&lt;String&gt;();// 往容器里面添加元素linkedList.add("张三");linkedList.add("李四");// 在张三与李四之间插入一个王五linkedList.add(1, "王五");// 在头部插入一个小三linkedList.addFirst("小三");// 获取index下标为2的元素 王五String element = linkedList.get(2);// 修改index下标为2的元素 王五 为小四linkedList.set(2, "小四");// 删除index下标为1的元素 张三String removeElement = linkedList.remove(1);// 删除第一个元素String removeFirstElement = linkedList.removeFirst();// 删除最后一个元素String removeLastElement = linkedList.removeLast(); LinkedList底层实现是双向链表，核心组成元素有：int size = 0用于记录链表长度；Node&lt;E&gt; first;用于记录头（第一个）结点（储存的是头结点的引用）；Node&lt;E&gt; last;用于记录尾（最后一个）结点（储存的是尾结点的引用）。 示例代码： 123456789101112131415161718192021public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; // 记录链表长度 transient int size = 0; /** * Pointer to first node. 指向第一个结点 * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. 指向最后一个结点 * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last;&#125; 双向链表的核心组成元素还有一个最重要的Node&lt;E&gt;，Node&lt;E&gt;包含：E item; 用于存储元素数据，Node&lt;E&gt; next; 指向当前元素的后继结点，Node&lt;E&gt; prev; 指向当前元素的前驱结点。 示例代码： 1234567891011121314151617/** * 定义LinkedList底层的结点实现 */private static class Node&lt;E&gt; &#123; E item; // 存储元素数据 Node&lt;E&gt; next;// 指向当前元素的后继结点 Node&lt;E&gt; prev;// 指向当前元素的前驱结点 /** * Node结点构造方法 */ Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element;// 存储的元素 this.next = next;// 后继结点 this.prev = prev;// 前驱结点 &#125;&#125; 双向链表底层实现，图片来自网络 上图中的head即Node first; tail即Node last; LinkedList 的操作和对应的时间复杂度。问：请分别分析一下它是如何获取元素，修改元素，新增元素与删除元素，并分析这些操作对应的时间复杂度。 答： 获取元素：LinkedList提供了三种获取元素的方法，分别是： 获取第一个元素getFirst()，获取第一个元素，直接返回Node&lt;E&gt; first指向的结点即可，所以时间复杂度为O(1)。 获取最后一个元素getLast()，获取最后一个元素，直接返回Node&lt;E&gt; last指向的结点即可，所以时间复杂度也为O(1)。 获取指定索引index位置的元素get(int index)，由于Node&lt;E&gt;结点在内存中存储的空间不是连续存储的，所以查找某一位置的结点，只能通过遍历链表的方式查找结点，因此LinkedList会先通过判断index &lt; (size &gt;&gt; 1)，size&gt;&gt;1即为size/2当前链表长度的一半，判断index的位置是在链表的前半部分还是后半部分。决定是从头部遍历查找数据还是从尾部遍历查找数据。最坏情况下，获取中间元素，则需要遍历n/2次才能获取到对应元素，所以此方法的时间复杂度为O(n)。 综上所述，LinkedList获取元素的时间复杂度为O(n)。 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 返回列表中指定位置的元素 * * @param index 指定index位置 * @return 返回指定位置的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 遍历列表获取对应index位置的元素 return node(index).item;&#125;/** * 检查下标是否合法 */private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size;&#125;/** * 返回指定位置的结点元素（重点） */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 判断index位置是在链表的前半部分还是后半部分 if (index &lt; (size &gt;&gt; 1)) &#123; // 从头结点开始，从前往后遍历找到对应位置的结点元素 Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; // 从尾结点开始，从后往前遍历找到对应位置的结点元素 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 修改元素：LinkedList提供了一种修改元素数据的方法set(int index, E element)，修改元素数据的步骤是：1.检查index索引是否合法[0,size)。2.折半查询获取对应索引元素。3.将新元素赋值，返回旧元素。由获取元素的分析可知，折半查询的时间复杂度为O(n)，故修改元素数据的时间复杂度为O(n)。 示例代码： 123456789101112131415161718/** * 修改指定位置结点的存储数据 * * @param index 指定位置 * @param element 修改的存储数据 * @return 返回未修改前的存储数据 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 折半查询获取对应索引元素 Node&lt;E&gt; x = node(index); // 将新元素赋值，返回旧元素 E oldVal = x.item; x.item = element; return oldVal;&#125; 新增元素：LinkedList提供了四种新增元素的方法，分别是： 将指定元素插入到链表的第一个位置中addFirst(E e)，只需将头结点first指向新元素结点，将原第一结点的前驱指针指向新元素结点即可。不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度为O(1)。 将指定元素插入到链表的最后一个位置中addLast(E e)，只需将尾结点last指向新元素结点，将原最后一个结点的后继指针指向新元素结点即可。不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 添加元素方法add(E e) 等价于addLast(E e)。 将指定元素插入到链表的指定位置index中add(int index, E element)，需要先根据位置index调用node(index)遍历链表获取该位置的原结点，然后将新结点插入至原该位置结点的前面，不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 综上所述，LinkedList新增元素的时间复杂度为O(1)，单纯论插入新元素，操作是非常高效的，特别是插入至头部或插入到尾部。但如果是通过索引index的方式插入，插入的位置越靠近链表中间所费时间越长，因为需要对链表进行遍历查找。 添加元素结点示意图，图片来自《大话数据结构》 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/** * 将指定元素插入到链表的第一个位置中 * * @param e 要插入的元素 */public void addFirst(E e) &#123; linkFirst(e);&#125;/** * 将元素e作为第一个元素 */private void linkFirst(E e) &#123; // 获取原头结点 final Node&lt;E&gt; f = first; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); // 头指针指向新元素结点 first = newNode; // 如果是第一个元素（链表为空） if (f == null) // 将尾指针也指向新元素结点 last = newNode; else // 链表不会空 // 原头结点的前驱指针指向新结点 f.prev = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125;/** * 将指定元素插入到链表的最后一个位置中 * * &lt;p&gt;此方法等同与add(E e)方法 &#123;@link #add&#125;. * * @param e 要插入的元素 */public void addLast(E e) &#123; linkLast(e);&#125;/** * 将指定元素插入到链表的最后一个位置中 * * &lt;p&gt;此方法等同与addLast(E e)方法 &#123;@link #addLast&#125;. * * @param e 要插入的元素 * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** * 将元素e作为最后一个元素 */void linkLast(E e) &#123; // 获取原尾结点 final Node&lt;E&gt; l = last; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 位指针指向新元素结点 last = newNode; // 如果是第一个元素（链表为空） if (l == null) // 将头指针也指向新元素结点 first = newNode; else // 链表不会空 // 原尾结点的后继指针指向新结点 l.next = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125;/** * 将指定元素插入到链表的指定位置index中 * * @param index 元素要插入的位置index * @param element 要插入的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; // 检查插入位置是否合法[0,size] checkPositionIndex(index); // 如果插入的位置和当前链表长度相等，则直接将元素插入至链表的尾部 if (index == size) // 将元素插入至链表的尾部 linkLast(element); else //将元素插入至指定位置,node(index)先获取占有该index位置的原结点 linkBefore(element, node(index));&#125;/** * 检查位置是否合法 */private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;/** * 检查位置是否合法 */private boolean isPositionIndex(int index) &#123; //合法位置为[0,size] return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;/** * 将新元素e插入至旧元素succ前面 */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; // 记录旧元素结点succ的前驱指针 final Node&lt;E&gt; pred = succ.prev; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 旧元素结点的前驱指针指向新元素结点(即新元素结点放至在旧元素结点的前面，取代了原本旧元素的位置) succ.prev = newNode; // 如果旧元素结点的前驱指针为空，则证明旧元素结点是头结点， // 将新元素结点插入至旧元素结点前面，所以现时新的头结点是新元素结点 if (pred == null) first = newNode; else //不是插入至头部 // 旧元素的前驱结点的后继指针指向新元素结点 pred.next = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125; 删除元素：LinkedList提供了四种删除元素的方法，分别是： 删除链表中的第一个元素removeFirst()，只需将头结点first指向删除元素结点的后继结点并将其前驱结点指针信息prev清空即可。不需要移动原数据存储位置，只需操作相关结点的指针域信息即可。所以时间复杂度为O(1)。 删除链表中的最后一个元素removeLast()，只需将尾结点last指向删除元素结点的前驱结点并将其后继结点指针信息next清空即可。不需要移动原数据存储位置，只需操作相关结点的指针域信息即可，所以时间复杂度也为O(1)。 将指定位置index的元素删除remove(int index)，需要先根据位置index调用node(index)遍历链表获取该位置的原结点，然后将删除元素结点的前驱结点的next后继结点指针域指向删除元素结点的后继结点node.prev.next = node.next，删除元素结点的后继结点的prev前驱结点指针域指向删除元素结点的前驱结点即可node.next.prev = node.prev（此处可能有些绕，不太理解的同学自行学习一下双向链表的数据结构吧），不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 删除元素结点示意图，图片来自《大话数据结构》 删除传入的Object o指定对象，比较对象是否一致通过o.equals方法比较remove(Object o)，和3.的思路基本差不多，关键是比较对象是通过o.equals方法，记住这点即可。 综上所述，LinkedList删除元素的时间复杂度为O(1)，单纯论删除元素，操作是非常高效的，特别是删除第一个结点或删除最后一个结点。但如果是通过索引index的方式或者object对象的方式删除，则需要对链表进行遍历查找对应index索引的对象或者利用equals方法判断对象。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169/** * 删除链表中的第一个元素并返回 * * @return 链表中的第一个元素 * @throws NoSuchElementException if this list is empty */public E removeFirst() &#123; //根据头结点获取第一个元素结点 final Node&lt;E&gt; f = first; if (f == null) // 没有元素结点则抛出异常 throw new NoSuchElementException(); return unlinkFirst(f);&#125;/** * 移除第一个元素 */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; // 记录要移除元素结点的数据域 final E element = f.item; // 记录要移除元素结点的后继结点指针 final Node&lt;E&gt; next = f.next; // 清空要删除结点的数据域和next指针域信息，以帮助垃圾回收 f.item = null; f.next = null; // help GC // 头结点指向要移除元素结点的后继结点 first = next; // 如果要移除元素结点的后继结点为空，则证明链表只有一个元素 // 所以需要将尾结点的指针信息也要清空 if (next == null) last = null; else // 将新的第一个结点的前驱结点指针信息清空 next.prev = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125;/** * 删除链表中的最后一个元素并返回 * * @return 链表中的最后一个元素 * @throws NoSuchElementException if this list is empty */public E removeLast() &#123; // 根据尾结点获取最后一个元素结点 final Node&lt;E&gt; l = last; if (l == null)// 没有元素结点则抛出异常 throw new NoSuchElementException(); return unlinkLast(l);&#125;/** * 移除最后一个元素 */private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; // 记录要移除元素结点的数据域 final E element = l.item; // 记录要移除元素结点的前驱结点指针 final Node&lt;E&gt; prev = l.prev; // 清空要删除结点的数据域和prev指针域信息，以帮助垃圾回收 l.item = null; l.prev = null; // help GC // 头结点指向要移除元素结点的前驱结点 last = prev; // 如果要移除元素结点的前驱结点为空，则证明链表只有一个元素 // 所以需要将头结点的指针信息也要清空 if (prev == null) first = null; else // 将新的最后一个结点的后继结点指针信息清空 prev.next = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125;/** * 将指定位置index的元素删除 * * @param index 要删除的位置index * @return 要删除位置的原元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 根据index进行遍历链表获取要删除的结点，再调用unlink方法进行删除 return unlink(node(index));&#125;/** * 删除传入的Object o指定对象，比较对象是否一致通过o.equals方法比较 * @param o 要删除的Object o指定对象 * @return &#123;@code true&#125; 是否存在要删除对象o */public boolean remove(Object o) &#123; // 如果删除对象为null，则遍历链表查找node.item数据域为null的结点并移除 if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 从头开始遍历链表，并通过equals方法逐一比较node.item是否相等 // 相等则对象一致，删除此对象。 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;/** * 移除指定结点x */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; // 记录要移除元素结点的数据域 final E element = x.item; // 记录要移除元素结点的后继结点指针 final Node&lt;E&gt; next = x.next; // 记录要移除元素结点的前驱结点指针 final Node&lt;E&gt; prev = x.prev; // 如果要移除元素结点的前驱结点为空，则证明要删除结点为第一个结点 if (prev == null) &#123; // 头结点指向要删除元素结点的后继结点 first = next; &#125; else &#123; // 要删除元素结点的前驱结点的后继指针指向要删除元素结点的后继结点 prev.next = next; // 清空要删除结点的前驱结点指针信息，以帮助GC x.prev = null; &#125; // 如果要移除元素结点的后继结点为空，则证明要删除结点为最后一个结点 if (next == null) &#123; // 尾结点指向要删除元素结点的前驱结点 last = prev; &#125; else &#123; // 要删除元素结点的后继结点的前驱指针指向要删除元素结点的前驱结点 next.prev = prev; // 清空要删除结点的后继结点指针信息，以帮助GC x.next = null; &#125; // 清空要删除元素的数据域，以帮助GC x.item = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125; ArrayList和LinkedList 的区别问：那您可以比较一下ArrayList和LinkedList吗? 答： LinkedList内部存储的是Node&lt;E&gt;，不仅要维护数据域，还要维护prev和next，如果LinkedList中的结点特别多，则LinkedList比ArrayList更占内存。 插入删除操作效率：LinkedList在做插入和删除操作时，插入或删除头部或尾部时是高效的，操作越靠近中间位置的元素时，需要遍历查找，速度相对慢一些，如果在数据量较大时，每次插入或删除时遍历查找比较费时。所以LinkedList插入与删除，慢在遍历查找，快在只需要更改相关结点的引用地址。ArrayList在做插入和删除操作时，插入或删除尾部时也一样是高效的，操作其他位置，则需要批量移动元素，所以ArrayList插入与删除，快在遍历查找，慢在需要批量移动元素。 循环遍历效率： 由于ArrayList实现了RandomAccess随机访问接口，所以使用for(int i = 0; i &lt; size; i++)遍历会比使用Iterator迭代器来遍历快： 12345678for (int i=0, n=list.size(); i &lt; n; i++) &#123; list.get(i);&#125;runs faster than this loop:for (Iterator i=list.iterator(); i.hasNext(); ) &#123; i.next();&#125; 而由于LinkedList未实现RandomAccess接口，所以推荐使用Iterator迭代器来遍历数据。 因此，如果我们需要频繁在列表的中部改变插入或删除元素时，建议使用LinkedList，否则，建议使用ArrayList，因为ArrayList遍历查找元素较快，并且只需存储元素的数据域，不需要额外记录其他数据的位置信息，可以节省内存空间。 LinkedList是线程安全的吗？问：LinkedList是线程安全的吗？ 答：LinkedList不是线程安全的，如果多个线程同时对同一个LinkedList更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，LinkedList会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个LinkedList进行遍历时，在遍历期间，我们是不能对LinkedList进行添加，删除等更改数据结构的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在add,remove等更改LinkedList数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑调用Collections.synchronizedCollection(Collection&lt;T&gt; c)方法。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; public boolean hasPrevious() &#123; return nextIndex &gt; 0; &#125; public E previous() &#123; checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; &#125; public int nextIndex() &#123; return nextIndex; &#125; public int previousIndex() &#123; return nextIndex - 1; &#125; public void remove() &#123; checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; &#125; public void set(E e) &#123; if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; &#125; public void add(E e) &#123; checkForComodification(); lastReturned = null; if (next == null) linkLast(e); else linkBefore(e, next); nextIndex++; expectedModCount++; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &#123; action.accept(next.item); lastReturned = next; next = next.next; nextIndex++; &#125; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 总结LinkedList的结论已在第三个问题中展现了一部分了，所以不再重复说明了，我以面试问答的形式和大家一同学习了LinkedList，由于没有时间画图，可能此次没有ArrayList说的那么清楚，如果大家有看不懂的地方，请自行看一下关于链表的数据结构吧。如果此文对你有帮助，麻烦点个喜欢，谢谢各位。]]></content>
      <categories>
        <category>LinkedList</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 的详细分析]]></title>
    <url>%2F2017%2F12%2F09%2FHashMap%20%E7%9A%84%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap 的详细分析前言这次我和大家一起学习HashMap，HashMap我们在工作中经常会使用，而且面试中也很频繁会问到，因为它里面蕴含着很多知识点，可以很好的考察个人基础。但一个这么重要的东西，我为什么没有在一开始就去学习它呢，因为它是由多种基础的数据结构和一些代码设计思想组成的。我们要学习了这些基础，再学习HashMap，这样我们才能更好的去理解它。古人云：无欲速，无见小利。欲速则不达，见小利则大事不成。 HashMap其实就是ArrayList和LinkedList的数据结构加上hashCode和equals方法的思想设计出来的。没有理解上述说的知识点的同学可以翻开我过往的文章记录。 下面我就以面试问答的形式学习我们的——HashMap（源码分析基于JDK8，辅以JDK7），问答内容只是对HashMap的一个总结归纳，因为现时已经有大牛把HashMap通俗易懂的剖析了一遍，我学习HashMap也是主要通过这篇文章学习的，强烈推荐：美团点评技术团队的Java 8系列之重新认识HashMap 问答内容HashMap 的主要用途问：HashMap有用过吗？您能给我说说他的主要用途吗？ 答： 有用过，我在平常工作中经常会用到HashMap这种数据结构，HashMap是基于Map接口实现的一种键-值对&lt;key,value&gt;的存储结构，允许null值，同时非有序，非同步(即线程不安全)。HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分）。它存储和查找数据时，是根据键key的hashCode的值计算出具体的存储位置。HashMap最多只允许一条记录的键key为null，HashMap增删改查等常规操作都有不错的执行效率，是ArrayList和LinkedList等数据结构的一种折中实现。 示例代码： 12345678910111213141516171819202122232425262728293031323334// 创建一个HashMap，如果没有指定初始大小，默认底层hash表数组的大小为16HashMap&lt;String, String&gt; hashMap = new HashMap&lt;String, String&gt;();// 往容器里面添加元素hashMap.put("小明", "好帅");hashMap.put("老王", "坑爹货");hashMap.put("老铁", "没毛病");hashMap.put("掘金", "好地方");hashMap.put("王五", "别搞事");// 获取key为小明的元素 好帅String element = hashMap.get("小明");// value : 好帅System.out.println(element);// 移除key为王五的元素String removeElement = hashMap.remove("王五");// value : 别搞事System.out.println(removeElement);// 修改key为小明的元素的值value 为 其实有点丑hashMap.replace("小明", "其实有点丑");// &#123;老铁=没毛病, 小明=其实有点丑, 老王=坑爹货, 掘金=好地方&#125;System.out.println(hashMap);// 通过put方法也可以达到修改对应元素的值的效果hashMap.put("小明", "其实还可以啦,开玩笑的");// &#123;老铁=没毛病, 小明=其实还可以啦,开玩笑的, 老王=坑爹货, 掘金=好地方&#125;System.out.println(hashMap);// 判断key为老王的元素是否存在(捉奸老王)boolean isExist = hashMap.containsKey("老王");// true , 老王竟然来搞事System.out.println(isExist);// 判断是否有 value = "坑爹货" 的人boolean isHasSomeOne = hashMap.containsValue("坑爹货");// true 老王是坑爹货System.out.println(isHasSomeOne);// 查看这个容器里面还有几个家伙 value : 4System.out.println(hashMap.size()); HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分），核心组成元素有： int size;用于记录HashMap实际存储元素的个数； float loadFactor;负载因子（默认是0.75，此属性后面详细解释）。 int threshold;下一次扩容时的阈值，达到阈值便会触发扩容机制resize（阈值 threshold = 容器容量 capacity * 负载因子 load factor）。也就是说，在容器定义好容量之后，负载因子越大，所能容纳的键值对元素个数就越多。 Node&lt;K,V&gt;[] table; 底层数组，充当哈希表的作用，用于存储对应hash位置的元素Node&lt;K,V&gt;，此数组长度总是2的N次幂。（具体原因后面详细解释） 示例代码： 12345678910111213141516171819202122232425262728293031323334public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123;····· /* ---------------- Fields -------------- */ /** * 哈希表，在第一次使用到时进行初始化，重置大小是必要的操作， * 当分配容量时，长度总是2的N次幂。 */ transient Node&lt;K,V&gt;[] table; /** * 实际存储的key - value 键值对 个数 */ transient int size; /** * 下一次扩容时的阈值 * (阈值 threshold = 容器容量 capacity * 负载因子 load factor). * @serial */ int threshold; /** * 哈希表的负载因子 * * @serial */ final float loadFactor;·····&#125; 其中Node&lt;K,V&gt;[] table;哈希表存储的核心元素是Node&lt;K,V&gt;,Node&lt;K,V&gt;包含： final int hash;元素的哈希值，决定元素存储在Node&lt;K,V&gt;[] table;哈希表中的位置。由final修饰可知，当hash的值确定后，就不能再修改。 final K key; 键，由final修饰可知，当key的值确定后，就不能再修改。 V value; 值 Node&lt;K,V&gt; next; 记录下一个元素结点(单链表结构，用于解决hash冲突) 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 定义HashMap存储元素结点的底层实现 */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash;//元素的哈希值 由final修饰可知，当hash的值确定后，就不能再修改 final K key;// 键，由final修饰可知，当key的值确定后，就不能再修改 V value; // 值 Node&lt;K,V&gt; next; // 记录下一个元素结点(单链表结构，用于解决hash冲突) /** * Node结点构造方法 */ Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash;//元素的哈希值 this.key = key;// 键 this.value = value; // 值 this.next = next;// 记录下一个元素结点 &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; /** * 为Node重写hashCode方法，值为：key的hashCode 异或 value的hashCode * 运算作用就是将2个hashCode的二进制中，同一位置相同的值为0，不同的为1。 */ public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; /** * 修改某一元素的值 */ public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; /** * 为Node重写equals方法 */ public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; hashMap内存结构图 - 图片来自于《美团点评技术团队文章》 HashMap 常用操作的底层实现原理问：您能说说HashMap常用操作的底层实现原理吗？如存储put(K key, V value)，查找get(Object key)，删除remove(Object key)，修改replace(K key, V value)等操作。 答： 调用put(K key, V value)操作添加key-value键值对时，进行了如下操作： 判断哈希表Node&lt;K,V&gt;[] table是否为空或者null，是则执行resize()方法进行扩容。 根据插入的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]。如果存储位置没有元素存放，则将新增结点存储在此位置table[i]。 如果存储位置已经有键值对元素存在，则判断该位置元素的hash值和key值是否和当前操作元素一致，一致则证明是修改value操作，覆盖value即可。 当前存储位置即有元素，又不和当前操作元素一致，则证明此位置table[i]已经发生了hash冲突，则通过判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，已红黑树的方式新增结点。 如果不是红黑树，则证明是单链表，将新增结点插入至链表的最后位置，随后判断当前链表长度是否 大于等于 8，是则将当前存储位置的链表转化为红黑树。遍历过程中如果发现key已经存在，则直接覆盖value。 插入成功后，判断当前存储键值对的数量 大于 阈值threshold 是则扩容。 hashMap put方法执行流程图- 图片来自于《美团点评技术团队文章》 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * 添加key-value键值对 * * @param key 键 * @param value 值 * @return 如果原本存在此key，则返回旧的value值，如果是新增的key- * value，则返回nulll */public V put(K key, V value) &#123; //实际调用putVal方法进行添加 key-value 键值对操作 return putVal(hash(key), key, value, false, true);&#125;/** * 根据key 键 的 hashCode 通过 “扰动函数” 生成对应的 hash值 * 经过此操作后，使每一个key对应的hash值生成的更均匀， * 减少元素之间的碰撞几率（后面详细说明） */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;/** * 添加key-value键值对的实际调用方法（重点） * * @param hash key 键的hash值 * @param key 键 * @param value 值 * @param onlyIfAbsent 此值如果是true, 则如果此key已存在value，则不执 * 行修改操作 * @param evict 此值如果是false，哈希表是在初始化模式 * @return 返回原本的旧值, 如果是新增，则返回null */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // 用于记录当前的链表结点 Node&lt;K,V&gt; p; // n用于记录hash表的长度，i用于记录当前操作索引index int n, i; // 当前hash表为空 if ((tab = table) == null || (n = tab.length) == 0) // 初始化hash表，并把初始化后的hash表长度值赋值给n n = (tab = resize()).length; // 1）通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 2）确定当前元素的存储位置，此运算等价于 当前元素的hash值 % hash表的长度 // 3）计算出的存储位置没有元素存在 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 4) 则新建一个Node结点，在该位置存储此元素 tab[i] = newNode(hash, key, value, null); else &#123; // 当前存储位置已经有元素存在了(不考虑是修改的情况的话，就代表发生hash冲突了) // 用于存放新增结点 Node&lt;K,V&gt; e; // 用于临时存在某个key值 K k; // 1)如果当前位置已存在元素的hash值和新增元素的hash值相等 // 2)并且key也相等，则证明是同一个key元素，想执行修改value操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;// 将当前结点引用赋值给e else if (p instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构，则已红黑树结点结构新增元素 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123;// 排除上述情况，则证明已发生hash冲突，并hash冲突位置现时的结构是单链表结构 for (int binCount = 0; ; ++binCount) &#123; //遍历单链表，将新元素结点放置此链表的最后一位 if ((e = p.next) == null) &#123; // 将新元素结点放在此链表的最后一位 p.next = newNode(hash, key, value, null); // 新增结点后，当前结点数量是否大于等于 阈值 8 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 大于等于8则将链表转换成红黑树 treeifyBin(tab, hash); break; &#125; // 如果链表中已经存在对应的key，则覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // 已存在对应key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //如果允许修改，则修改value为新值 e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 当前存储键值对的数量 大于 阈值 是则扩容 if (++size &gt; threshold) // 重置hash大小，将旧hash表的数据逐一复制到新的hash表中（后面详细讲解） resize(); afterNodeInsertion(evict); // 返回null，则证明是新增操作，而不是修改操作 return null;&#125; 调用get(Object key)操作根据键key查找对应的key-value键值对时，进行了如下操作： 1.先调用 hash(key)方法计算出 key 的 hash值 2.根据查找的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]，判断存储位置是否有元素存在 。 如果存储位置有元素存放，则首先比较头结点元素，如果头结点的key的hash值 和 要获取的key的hash值相等，并且 头结点的key本身 和要获取的 key 相等，则返回该位置的头结点。 如果存储位置没有元素存放，则返回null。 3.如果存储位置有元素存放，但是头结点元素不是要查找的元素，则需要遍历该位置进行查找。 4.先判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，以红色树的方式遍历查找该结点，没有则返回null。 5.如果不是红黑树，则证明是单链表。遍历单链表，逐一比较链表结点，链表结点的key的hash值 和 要获取的key的hash值相等，并且 链表结点的key本身 和要获取的 key 相等，则返回该结点，遍历结束仍未找到对应key的结点，则返回null。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 返回指定 key 所映射的 value 值 * 或者 返回 null 如果容器里不存在对应的key * * 更确切地讲，如果此映射包含一个满足 (key==null ? k==null :key.equals(k)) * 的从 k 键到 v 值的映射关系， * 则此方法返回 v；否则返回 null。（最多只能有一个这样的映射关系。） * * 返回 null 值并不一定 表明该映射不包含该键的映射关系； * 也可能该映射将该键显示地映射为 null。可使用containsKey操作来区分这两种情况。 * * @see #put(Object, Object) */public V get(Object key) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用getNode方法获取对应key所映射的value值 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * 获取哈希表结点的方法实现 * * @param hash key 键的hash值 * @param key 键 * @return 返回对应的结点，如果结点不存在，则返回null */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // first用于记录对应hash位置的第一个结点，e充当工作结点的作用 Node&lt;K,V&gt; first, e; // n用于记录hash表的长度 int n; // 用于临时存放Key K k; // 通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 判断当前元素的存储位置是否有元素存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123;//元素存在的情况 // 如果头结点的key的hash值 和 要获取的key的hash值相等 // 并且 头结点的key本身 和要获取的 key 相等 if (first.hash == hash &amp;&amp; // always check first node 总是检查头结点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 返回该位置的头结点 return first; if ((e = first.next) != null) &#123;// 头结点不相等 if (first instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式获取对应key结点 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123;// 当前位置不是红黑树，则证明是单链表 // 遍历单链表，逐一比较链表结点 // 链表结点的key的hash值 和 要获取的key的hash值相等 // 并且 链表结点的key本身 和要获取的 key 相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 找到对应的结点则返回 return e; &#125; while ((e = e.next) != null); &#125; &#125; // 通过上述查找均无找到，则返回null return null;&#125; 调用remove(Object key)操作根据键key删除对应的key-value键值对时，进行了如下操作： 1.先调用 hash(key)方法计算出 key 的 hash值 2.根据查找的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]，判断存储位置是否有元素存在 。 如果存储位置有元素存放，则首先比较头结点元素，如果头结点的key的hash值 和 要获取的key的hash值相等，并且 头结点的key本身 和要获取的 key 相等，则该位置的头结点即为要删除的结点，记录此结点至变量node中。 如果存储位置没有元素存放，则没有找到对应要删除的结点，则返回null。 3.如果存储位置有元素存放，但是头结点元素不是要删除的元素，则需要遍历该位置进行查找。 4.先判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，以红色树的方式遍历查找并删除该结点，没有则返回null。 5.如果不是红黑树，则证明是单链表。遍历单链表，逐一比较链表结点，链表结点的key的hash值 和 要获取的key的hash值相等，并且 链表结点的key本身 和要获取的 key 相等，则此为要删除的结点，记录此结点至变量node中，遍历结束仍未找到对应key的结点，则返回null。 6.如果找到要删除的结点node，则判断是否需要比较value也是否一致，如果value值一致或者不需要比较value值，则执行删除结点操作，删除操作根据不同的情况与结构进行不同的处理。 如果当前结点是树结点，则证明当前位置的链表已变成红黑树结构，通过红黑树结点的方式删除对应结点。 如果不是红黑树，则证明是单链表。如果要删除的是头结点，则当前存储位置table[i]的头结点指向删除结点的下一个结点。 如果要删除的结点不是头结点，则将要删除的结点的后继结点node.next赋值给要删除结点的前驱结点的next域，即p.next = node.next;。 7.HashMap当前存储键值对的数量 - 1，并返回删除结点。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/** * 从此映射中移除指定键的映射关系（如果存在）。 * * @param key 其映射关系要从映射中移除的键 * @return 与 key 关联的旧值；如果 key 没有任何映射关系，则返回 null。 * （返回 null 还可能表示该映射之前将 null 与 key 关联。） */public V remove(Object key) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用removeNode方法删除对应key所映射的结点 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * 删除哈希表结点的方法实现 * * @param hash 键的hash值 * @param key 键 * @param value 用于比较的value值，当matchValue 是 true时才有效, 否则忽略 * @param matchValue 如果是 true 只有当value相等时才会移除 * @param movable 如果是 false当执行移除操作时，不删除其他结点 * @return 返回删除结点node，不存在则返回null */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // 用于记录当前的链表结点 Node&lt;K,V&gt; p; // n用于记录hash表的长度，index用于记录当前操作索引index int n, index; // 通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 判断当前元素的存储位置是否有元素存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123;// 元素存在的情况 // node 用于记录找到的结点，e为工作结点 Node&lt;K,V&gt; node = null, e; K k; V v; // 如果头结点的key的hash值 和 要获取的key的hash值相等 // 并且 头结点的key本身 和要获取的 key 相等 // 则证明此头结点就是要删除的结点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 记录要删除的结点的引用地址至node中 node = p; else if ((e = p.next) != null) &#123;// 头结点不相等 if (p instanceof TreeNode)// 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式获取对应key结点 // 记录要删除的结点的引用地址至node中 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123;// 当前位置不是红黑树，则证明是单链表 do &#123; // 遍历单链表，逐一比较链表结点 // 链表结点的key的hash值 和 要获取的key的hash值相等 // 并且 链表结点的key本身 和要获取的 key 相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; // 找到则记录要删除的结点的引用地址至node中，中断遍历 node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 如果找到要删除的结点，则判断是否需要比较value也是否一致 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; // value值一致或者不需要比较value值，则执行删除结点操作 if (node instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式删除对应结点 ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) // node 和 p相等，则证明删除的是头结点 // 当前存储位置的头结点指向删除结点的下一个结点 tab[index] = node.next; else // 删除的不是头结点 // p是删除结点node的前驱结点，p的next改为记录要删除结点node的后继结点 p.next = node.next; ++modCount; // 当前存储键值对的数量 - 1 --size; afterNodeRemoval(node); // 返回删除结点 return node; &#125; &#125; // 不存在要删除的结点，则返回null return null;&#125; 调用replace(K key, V value)操作根据键key查找对应的key-value键值对，随后替换对应的值value，进行了如下操作： 先调用 hash(key)方法计算出 key 的 hash值 随后调用getNode方法获取对应key所映射的value值 。 记录元素旧值，将新值赋值给元素，返回元素旧值，如果没有找到元素，则返回null。 示例代码： 123456789101112131415161718192021222324/** * 替换指定 key 所映射的 value 值 * * @param key 对应要替换value值元素的key键 * @param value 要替换对应元素的新value值 * @return 返回原本的旧值，如果没有找到key对应的元素，则返回null * @since 1.8 JDK1.8新增方法 */public V replace(K key, V value) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用getNode方法获取对应key所映射的value值 if ((e = getNode(hash(key), key)) != null) &#123;// 如果找到对应的元素 // 元素旧值 V oldValue = e.value; // 将新值赋值给元素 e.value = value; afterNodeAccess(e); // 返回元素旧值 return oldValue; &#125; // 没有找到元素，则返回null return null;&#125; HashMap 若要新增的这个元素存在了或hash冲突了怎么办问 1：您上面说，存放一个元素时，先计算它的hash值确定它的存储位置，然后再把这个元素放到对应的位置上，那万一这个位置上面已经有元素存在呢，新增的这个元素怎么办？ 问 2：hash冲突（或者叫hash碰撞）是什么？为什么会出现这种现象，如何解决hash冲突？ 答： hash冲突： 当我们调用put(K key, V value)操作添加key-value键值对，这个key-value键值对存放在的位置是通过扰动函数(key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16)计算键key的hash值。随后将 这个hash值 % 模上 哈希表Node&lt;K,V&gt;[] table的长度 得到具体的存放位置。所以put(K key, V value)多个元素，是有可能计算出相同的存放位置。此现象就是hash冲突或者叫hash碰撞。 例子如下：元素 A 的hash值 为 9，元素 B 的hash值 为 17。哈希表Node&lt;K,V&gt;[] table的长度为8。则元素 A 的存放位置为9 % 8 = 1，元素 B 的存放位置为17 % 8 = 1。两个元素的存放位置均为table[1]，发生了hash冲突。 hash冲突的避免：既然会发生hash冲突，我们就应该想办法避免此现象的发生，解决这个问题最关键就是如果生成元素的hash值。Java是使用“扰动函数”生成元素的hash值。 示例代码： 123456789101112131415161718/** * JDK 7 的 hash方法 */ final int hash(int h) &#123; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125;/** * JDK 8 的 hash方法 */ static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; Java7做了4次16位右位移异或混合，Java 8中这步已经简化了，只做一次16位右位移异或混合，而不是四次，但原理是不变的。例子如下： 扰动函数执行例子 - 图片来自于《知乎》 右位移16位，正好是32bit的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。 上述扰动函数的解释参考自：JDK 源码中 HashMap 的 hash 方法原理是什么？ hash冲突解决：解决hash冲突的方法有很多，常见的有：开发定址法，再散列法，链地址法，公共溢出区法（详细说明请查看我的文章JAVA基础-自问自答学hashCode和equals）。HashMap是使用链地址法解决hash冲突的，当有冲突元素放进来时，会将此元素插入至此位置链表的最后一位，形成单链表。但是由于是单链表的缘故，每当通过hash % length找到该位置的元素时，均需要从头遍历链表，通过逐一比较hash值，找到对应元素。如果此位置元素过多，造成链表过长，遍历时间会大大增加，最坏情况下的时间复杂度为O(N)，造成查找效率过低。所以当存在位置的链表长度 大于等于 8 时，HashMap会将链表 转变为 红黑树，红黑树最坏情况下的时间复杂度为O(logn)。以此提高查找效率。 HashMap 的容量为什么一定要是2的n次方问：HashMap的容量为什么一定要是2的n次方？ 答： 因为调用put(K key, V value)操作添加key-value键值对时，具体确定此元素的位置是通过 hash值 % 模上 哈希表Node&lt;K,V&gt;[] table的长度 hash % length 计算的。但是”模”运算的消耗相对较大，通过位运算h &amp; (length-1)也可以得到取模后的存放位置，而位运算的运行效率高，但只有length的长度是2的n次方时，h &amp; (length-1) 才等价于 h % length。 而且当数组长度为2的n次幂的时候，不同的key算出的index相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。 例子： hash &amp; (length-1)运算过程.jpg 上图中，左边两组的数组长度是16（2的4次方），右边两组的数组长度是15。两组的hash值均为8和9。 当数组长度是15时，当它们和1110进行&amp;与运算（相同为1，不同为0）时，计算的结果都是1000，所以他们都会存放在相同的位置table[8]中，这样就发生了hash冲突，那么查询时就要遍历链表，逐一比较hash值，降低了查询的效率。 同时，我们可以发现，当数组长度为15的时候，hash值均会与14（1110）进行&amp;与运算，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率。 所以，HashMap的容量是2的n次方，有利于提高计算元素存放位置时的效率，也降低了hash冲突的几率。因此，我们使用HashMap存储大量数据的时候，最好先预先指定容器的大小为2的n次方，即使我们不指定为2的n次方，HashMap也会把容器的大小设置成最接近设置数的2的n次方，如，设置HashMap的大小为 7 ，则HashMap会将容器大小设置成最接近7的一个2的n次方数，此值为 8 。 上述回答参考自：深入理解HashMap 示例代码： 12345678910111213/** * 返回一个比指定数cap大的，并且大小是2的n次方的数 * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; HashMap 的负载因子是什么，有什么作用问：HashMap的负载因子是什么，有什么作用？ 答：负载因子表示哈希表空间的使用程度（或者说是哈希表空间的利用率）。 例子如下：底层哈希表Node&lt;K,V&gt;[] table的容量大小capacity为 16，负载因子load factor为 0.75，则当存储的元素个数size = capacity 16 * load factor 0.75等于 12 时，则会触发HashMap的扩容机制，调用resize()方法进行扩容。 当负载因子越大，则HashMap的装载程度就越高。也就是能容纳更多的元素，元素多了，发生hash碰撞的几率就会加大，从而链表就会拉长，此时的查询效率就会降低。 当负载因子越小，则链表中的数据量就越稀疏，此时会对空间造成浪费，但是此时查询效率高。 我们可以在创建HashMap 时根据实际需要适当地调整load factor 的值；如果程序比较关心空间开销、内存比较紧张，可以适当地增加负载因子；如果程序比较关心时间开销，内存比较宽裕则可以适当的减少负载因子。通常情况下，默认负载因子 (0.75) 在时间和空间成本上寻求一种折衷，程序员无需改变负载因子的值。 因此，如果我们在初始化HashMap时，就预估知道需要装载key-value键值对的容量size，我们可以通过size / load factor 计算出我们需要初始化的容量大小initialCapacity，这样就可以避免HashMap因为存放的元素达到阈值threshold而频繁调用resize()方法进行扩容。从而保证了较好的性能。 HashMap 和 HashTable 的区别问：您能说说HashMap和HashTable的区别吗？ 答：HashMap和HashTable有如下区别： 1）容器整体结构： HashMap的key和value都允许为null，HashMap遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理。 Hashtable的key和value都不允许为null。Hashtable遇到null，直接返回NullPointerException。 2） 容量设定与扩容机制： HashMap默认初始化容量为 16，并且容器容量一定是2的n次方，扩容时，是以原容量 2倍 的方式 进行扩容。 Hashtable默认初始化容量为 11，扩容时，是以原容量 2倍 再加 1的方式进行扩容。即int newCapacity = (oldCapacity &lt;&lt; 1) + 1;。 3） 散列分布方式（计算存储位置）： HashMap是先将key键的hashCode经过扰动函数扰动后得到hash值，然后再利用 hash &amp; (length - 1)的方式代替取模，得到元素的存储位置。 Hashtable则是除留余数法进行计算存储位置的（因为其默认容量也不是2的n次方。所以也无法用位运算替代模运算），int index = (hash &amp; 0x7FFFFFFF) % tab.length;。 由于HashMap的容器容量一定是2的n次方，所以能使用hash &amp; (length - 1)的方式代替取模的方式计算元素的位置提高运算效率，但Hashtable的容器容量不一定是2的n次方，所以不能使用此运算方式代替。 4）线程安全（最重要）： HashMap 不是线程安全，如果想线程安全，可以通过调用synchronizedMap(Map&lt;K,V&gt; m)使其线程安全。但是使用时的运行效率会下降，所以建议使用ConcurrentHashMap容器以此达到线程安全。 Hashtable则是线程安全的，每个操作方法前都有synchronized修饰使其同步，但运行效率也不高，所以还是建议使用ConcurrentHashMap容器以此达到线程安全。 因此，Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 此处不再对Hashtable的源码进行逐一分析了，如果想深入了解的同学，可以参考此文章Hashtable源码剖析 HashMap 在多线程下如何处理，啥时会发生线程不安全问：您说HashMap不是线程安全的，那如果多线程下，它是如何处理的？并且什么情况下会发生线程不安全的情况？ 答： HashMap不是线程安全的，如果多个线程同时对同一个HashMap更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，HashMap会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个HashMap进行遍历时，在遍历期间，我们是不能对HashMap进行添加，删除等更改数据的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在put,remove等更改HashMap数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑使用ConcurrentHashMap。 而且，在多线程下操作HashMap，由于存在扩容机制，当HashMap调用resize()进行自动扩容时，可能会导致死循环的发生。 由于时间关系，我暂不带着大家一起去分析resize()方法导致死循环发生的现象造成原因了，迟点有空我会再补充上去，请见谅，大家可以参考如下文章： Java 8系列之重新认识HashMap 谈谈HashMap线程不安全的体现 使用 HashMap ，选取什么对象作为 key 键比较好问：我们在使用HashMap时，选取什么对象作为key键比较好，为什么？ 答： 可变对象：指创建后自身状态能改变的对象。换句话说，可变对象是该对象在创建后它的哈希值可能被改变。 我们在使用HashMap时，最好选择不可变对象作为key。例如String，Integer等不可变类型作为key是非常明智的。 如果key对象是可变的，那么key的哈希值就可能改变。在HashMap中可变对象作为Key会造成数据丢失。因为我们再进行hash &amp; (length - 1)取模运算计算位置查找对应元素时，位置可能已经发生改变，导致数据丢失。 详细例子说明请参考：危险！在HashMap中将可变对象用作Key 总结 HashMap是基于Map接口实现的一种键-值对&lt;key,value&gt;的存储结构，允许null值，同时非有序，非同步(即线程不安全)。HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分）。 HashMap定位元素位置是通过键key经过扰动函数扰动后得到hash值，然后再通过hash &amp; (length - 1)代替取模的方式进行元素定位的。 HashMap是使用链地址法解决hash冲突的，当有冲突元素放进来时，会将此元素插入至此位置链表的最后一位，形成单链表。当存在位置的链表长度 大于等于 8 时，HashMap会将链表 转变为 红黑树，以此提高查找效率。 HashMap的容量是2的n次方，有利于提高计算元素存放位置时的效率，也降低了hash冲突的几率。因此，我们使用HashMap存储大量数据的时候，最好先预先指定容器的大小为2的n次方，即使我们不指定为2的n次方，HashMap也会把容器的大小设置成最接近设置数的2的n次方，如，设置HashMap的大小为 7 ，则HashMap会将容器大小设置成最接近7的一个2的n次方数，此值为 8 。 HashMap的负载因子表示哈希表空间的使用程度（或者说是哈希表空间的利用率）。当负载因子越大，则HashMap的装载程度就越高。也就是能容纳更多的元素，元素多了，发生hash碰撞的几率就会加大，从而链表就会拉长，此时的查询效率就会降低。当负载因子越小，则链表中的数据量就越稀疏，此时会对空间造成浪费，但是此时查询效率高。 HashMap不是线程安全的，Hashtable则是线程安全的。但Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 在多线程下操作HashMap，由于存在扩容机制，当HashMap调用resize()进行自动扩容时，可能会导致死循环的发生。 我们在使用HashMap时，最好选择不可变对象作为key。例如String，Integer等不可变类型作为key是非常明智的。 由于最近工作较忙，也有拖延症发作的问题，所以文章迟迟未能完成发布，现时完成的文章其实对我而言，也不算太好，但还是打算先发出来让大家看看，一起学习学习，看有什么不好的地方，我再慢慢改进，如果此文对你有帮助，请给个赞，谢谢大家。 参考文章Java 8系列之重新认识HashMapJDK 源码中 HashMap 的 hash 方法原理是什么？深入理解HashMapHashMap负载因子Hashtable源码剖析危险！在HashMap中将可变对象用作Key谈谈HashMap线程不安全的体现]]></content>
      <categories>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList 源码分析]]></title>
    <url>%2F2017%2F12%2F09%2FArrayList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ArrayList 源码分析 前言以面试问答的形式学习我们的最常用的装载容器——ArrayList（源码分析基于JDK8） 问答内容ArrayList是什么，可以用来干嘛？问：ArrayList有用过吗？它是一个什么东西？可以用来干嘛？ 答：有用过，ArrayList就是数组列表，主要用来装载数据，当我们装载的是基本类型的数据int,long,boolean,short,byte...的时候我们只能存储他们对应的包装类，它的主要底层实现是数组Object[] elementData。与它类似的是LinkedList，和LinkedList相比，它的查找和访问元素的速度较快，但新增，删除的速度较慢。 示例代码： 12345678910// 创建一个ArrayList，如果没有指定初始大小，默认容器大小为10ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();// 往容器里面添加元素arrayList.add("张三");arrayList.add("李四");arrayList.add("王五");// 获取index下标为0的元素 张三String element = arrayList.get(0);// 删除index下标为1的元素 李四String removeElement = arrayList.remove(1); ArrayList底层实现示意图 ArrayList中不断添加数据会有什么问题吗？问：您说它的底层实现是数组，但是数组的大小是定长的，如果我们不断的往里面添加数据的话，不会有问题吗？ 答：ArrayList可以通过构造方法在初始化的时候指定底层数组的大小。 通过无参构造方法的方式ArrayList()初始化，则赋值底层数组Object[] elementData为一个默认空数组Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}所以数组容量为0，只有真正对数据进行添加add时，才分配默认DEFAULT_CAPACITY = 10的初始容量。示例代码： 12345678910111213141516// 定义ArrayList默认容量为10private static final int DEFAULT_CAPACITY = 10;// 空数组，当调用无参构造方法时默认复制这个空数组private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;// 真正保存数据的底层数组transient Object[] elementData; // ArrayList的实际元素数量private int size;public ArrayList() &#123; // 无参构造方法默认为空数组 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 通过指定容量初始大小的构造方法方式ArrayList(int initialCapacity)初始化，则赋值底层数组Object[] elementData为指定大小的数组this.elementData = new Object[initialCapacity];示例代码： 12345678910111213private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;// 通过构造方法出入指定的容量来设置默认底层数组大小 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125; 当我们添加的元素数量已经达到底层数组Object[] elementData的上限时，我们再往ArrayList元素，则会触发ArrayList的自动扩容机制，ArrayList会通过位运算int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);以1.5倍的方式初始化一个新的数组（如初始化数组大小为10，则扩容后的数组大小为15），然后使用Arrays.copyOf(elementData, newCapacity);方法将原数据的数据逐一复制到新数组上面去，以此达到ArrayList扩容的效果。虽然，Arrays.copyOf(elementData, newCapacity);方法最终调用的是native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length)是一个底层方法，效率还算可以，但如果我们在知道ArrayList想装多少个元素的情况下，却没有指定容器大小，则就会导致ArrayList频繁触发扩容机制，频繁进行底层数组之间的数据复制，大大降低使用效率。示例代码： 123456789101112131415161718192021222324252627282930313233public boolean add(E e) &#123; //确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); elementData[size++] = e; return true;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 容量不足，则调用grow方法进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * 扩容方法(重点) */private void grow(int minCapacity) &#123; // 获得原容量大小 int oldCapacity = elementData.length; // 新容量为原容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 再判断新容量是否已足够，如果扩容后仍然不足够，则复制为最小容量长度 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 判断是否超过最大长度限制 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 将原数组的数据复制至新数组， ArrayList的底层数组引用指向新数组 // 如果数据量很大，重复扩容，则会影响效率 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 因此，在我们使用ArrayList的时候，如果知道最终的存储容量capacity，则应该在初始化的时候就指定ArrayList的容量ArrayList(int initialCapacity)，如果初始化时无法预知装载容量，但在使用过程中，得知最终容量，我们可以通过调用ensureCapacity(int minCapacity)方法来指定ArrayList的容量，并且，如果我们在使用途中，如果确定容量大小，但是由于之前每次扩容都扩充50%，所以会造成一定的存储空间浪费，我们可以调用trimToSize()方法将容器最小化到存储元素容量，进而消除这些存储空间浪费。例如：我们当前存储了11个元素，我们不会再添加但是当前的ArrayList的大小为15，有4个存储空间没有被使用，则调用trimToSize()方法后，则会重新创建一个容量为11的数组Object[] elementData，将原有的11个元素复制至新数组，达到节省内存空间的效果。示例代码： 123456789101112131415161718192021222324252627/** * 将底层数组一次性指定到指定容量的大小 */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125;/** * 将容器最小化到存储元素容量 */public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125; ArrayList怎么 删除数据，为什么访问速度快，删除新增速度慢 ？问：那它是怎么样删除元素的？您上面说到ArrayList访问元素速度较快，但是新增和删除的速度较慢，为什么呢？ 答： 通过源码我们可以得知，ArrayList删除元素时，先获取对应的删除元素，然后把要删除元素对应索引index后的元素逐一往前移动1位，最后将最后一个存储元素清空并返回删除元素，以此达到删除元素的效果。 当我们通过下标的方式去访问元素时，我们假设访问一个元素所花费的时间为K，则通过下标一步到位的方式访问元素，时间则为1K，用“大O”表示法表示，则时间复杂度为O(1)。所以ArrayList的访问数据的数据是比较快的。 当我们去添加元素add(E e)时，我们是把元素添加至末尾，不需要移动元素，此时的时间复杂度为O(1)，但我们把元素添加到指定位置，最坏情况下，我们将元素添加至第一个位置add(int index, E element)，则整个ArrayList的n-1个元素都要往前移动位置，导致底层数组发生n-1次复制。通常情况下，我们说的时间复杂度都是按最坏情况度量的，此时的时间复杂度为O(n)。删除元素同理，删除最后一个元素不需要移动元素，时间复杂度为O(1)，但删除第一个元素，则需要移动n-1个元素，最坏情况下的时间复杂度也是O(n)。 所以ArrayList访问元素速度较快，但是新增和删除的速度较慢。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 将元素添加至末尾 */public boolean add(E e) &#123; // 确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;/** * 将元素添加至指定下标位置 */public void add(int index, E element) &#123; // 检查下标是否在合法范围内 rangeCheckForAdd(index); // 确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 将要添加的元素下标后的元素通过复制的方式逐一往后移动，腾出对应index下标的存储位置 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 将新增元素存储至指定下标索引index elementData[index] = element; // ArrayList的大小 + 1 size++;&#125;/** * 通过下标索引的方式删除元素 */public E remove(int index) &#123; // 检查下标是否在合法范围内 rangeCheck(index); modCount++; // 直接通过下标去访问底层数组的元素 E oldValue = elementData(index); // 计算数组需要移动的元素个数 int numMoved = size - index - 1; if (numMoved &gt; 0) // 将要删除的元素下标后的元素通过复制的方式逐一往前移动 System.arraycopy(elementData, index+1, elementData, index, numMoved); //将底层数组长度减1，并清空最后一个存储元素。 elementData[--size] = null; // clear to let GC do its work // 返回移除元素 return oldValue;&#125; ArrayList是线程安全的吗？问：ArrayList是线程安全的吗？ 答：ArrayList不是线程安全的，如果多个线程同时对同一个ArrayList更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，ArrayList会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个ArrayList进行遍历时，在遍历期间，我们是不能对ArrayList进行添加，修改，删除等更改数据的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在add,remove,clear等更改ArrayList数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑使用Vector、CopyOnWriteArrayList。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * AbstractList.Itr 的迭代器实现 */private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such //期望的modCount int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings("unchecked") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings("unchecked") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 总结 如果在初始化的时候知道ArrayList的初始容量，请一开始就指定容量ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(20);,如果一开始不知道容量，中途才得知，请调用list.ensureCapacity(20);来扩充容量，如果数据已经添加完毕，但仍需要保存在内存中一段时间，请调用list.trimToSize()将容器最小化到存储元素容量，进而消除这些存储空间浪费。 ArrayList是以1.5倍的容量去扩容的，如初始容量是10，则容量依次递增扩充为：15，22，33，49。扩容后把原始数据从旧数组复制至新数组中。 ArrayList访问元素速度较快，下标方式访问元素，时间复杂度为O(1)，添加与删除速度较慢，时间复杂度均为O(n)。 ArrayList不是线程安全的，但是在发生并发行为时，它会尽可能的抛出ConcurrentModificationException，此为fail-fast机制。]]></content>
      <categories>
        <category>ArrayList</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven仓库理解和优先级]]></title>
    <url>%2F2017%2F09%2F03%2FMaven-Priority%2F</url>
    <content type="text"><![CDATA[5 Seven 2017 前言使用 maven 也有一段时间了，有时候在配置 repository,mirror,profile的时候，总会导致 jar 拉取不到。所以认真的分析了 maven 获取 jar 包时候的优先级。 Maven 仓库的分类仓库分类：本地仓库和远程仓库。Maven根据坐标寻找构件的时候，它先会查看本地仓库，如果本地仓库存在构件，则直接使用；如果没有，则从远程仓库查找，找到后，下载到本地。 1）本地仓库默认情况下，每个用户在自己的用户目录下都有一个路径名为.m2/repository/的仓库目录。我们也可以在 settings.xml 文件配置本地仓库的地址 2）远程仓库本地仓库好比书房，而远程仓库就像是书店。对于Maven来说，每个用户只有一个本地仓库，但是可以配置多个远程仓库。下· 我们可以在 pom 文件配置多个 repository，但是随着项目越来也多我们每次都要在 pom 文件配置比较麻烦，所以我们可以在settings 文件配置 profile （私服）。这样我们每次创建新项目的时候就可以不用配置 repository。 3）中央仓库Maven必须要知道至少一个可用的远程仓库，中央仓库就是这样一个默认的远程仓库，Maven 默认有一个 super pom 文件。maven super pom 文件位置D:\apache-maven-3.0.4\lib 下的 maven-model-builder-3.0.4.jar 中的 org/apache/maven/model/pom-4.0.0.xml12345678910111213··· 省略其他 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;··· 这个时候我们就明白了，我们在 settings 文件配置一个 mirror 的 mirrorOf 为 central 的镜像就会替代 ‘中央仓库’ 的原因了。 Maven 镜像镜像（Mirroring）是冗余的一种类型，一个磁盘上的数据在另一个磁盘上存在一个完全相同的副本即为镜像。为什么配置镜像? 1.一句话，你有的我也有，你没有的我也有。（拥有远程仓库的所有 jar，包括远程仓库没有的 jar）2.还是一句话，我跑的比你快。（有时候远程仓库获取 jar 的速度可能比镜像慢，这也是为什么我们一般要配置中央仓库的原因，外国的 maven 仓库一般获取速度比较慢） 如果你配置 maven 镜像不是为了以上两点，那基本就不用配置镜像了。注意:当远程仓库被镜像匹配到的，则在获取 jar 包将从镜像仓库获取，而不是我们配置的 repository 仓库, repository 将失去作用 mirrorOf 标签mirrorOf 标签里面放置的是 repository 配置的 id,为了满足一些复杂的需求，Maven还支持更高级的镜像配置： external:* = 不在本地仓库的文件才从该镜像获取 repo,repo1 = 远程仓库 repo 和 repo1 从该镜像获取 *,!repo1 = 所有远程仓库都从该镜像获取，除 repo1 远程仓库以外 * = 所用远程仓库都从该镜像获取 私服私服是一种特殊的远程Maven仓库，它是架设在局域网内的仓库服务，私服一般被配置为互联网远程仓库的镜像，供局域网内的Maven用户使用。当Maven需要下载构件的时候，先向私服请求，如果私服上不存在该构件，则从外部的远程仓库下载，同时缓存在私服之上，然后为Maven下载请求提供下载服务，另外，对于自定义或第三方的jar可以从本地上传到私服，供局域网内其他maven用户使用。优点主要有： 1. 节省外网宽带 2. 加速Maven构建 3. 部署第三方构件：可以将公司项目的 jar 发布到私服上，方便项目与项目之间的调用 4. 提高稳定性、增强控制：原因是外网不稳定 5. 降低中央仓库的负荷：原因是中央仓库访问量太大 上面大概介绍了 Maven 仓库概念，接下来我们进入正题 Maven 仓库优先级为了方便测试，我准备了以下几个仓库 172.16.xxx.xxx 远程仓库 （私服） dev.xxx.wiki 远程仓库 （远程） localhost 仓库 是我自己在本机搭建的一个仓库 （镜像） maven.aliyun.com 中央仓库（中央） 本地仓库优先级Maven 本地仓库拥有该包，而远程、镜像、中央、私服都不包含该包。我们来看下 Maven 是怎么获取的123456789101112131415161718192021222324.......// 使用本地仓库，优先级(priority)为 10[DEBUG] Using local repository at E:\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\OperSource[INFO] Scanning for projects..........[INFO] Installing C:\Users\swipal\Desktop\abc\demo\target\demo-1.0-SNAPSHOT.jar to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[INFO] Installing C:\Users\swipal\Desktop\abc\demo\pom.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\OperSource\com\cjf\demo\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 1.874 s[INFO] Finished at: 2017-07-07T10:37:32+08:00[INFO] Final Memory: 23M/219M[INFO] ------------------------------------------------------------------------Process finished with exit code 0 从上面可以看出 Maven 一开始就使用本地仓库，并将本地仓库的优先级定制为 10 , 最后 jar 包也在本地仓库找到，Maven 成功打包。 远程仓库优先级前面我们知道了，本地仓库的优先级是最高的，现在我们继续研究远程仓库的优先级（以下的所有例子，都默认本地仓库不拥有我们需要的包） 这一次我们默认配置 profile（私服）为 172.16.xxx.xxx 远程仓库, repository 为 dev.xxx.wiki 远程仓库,mirror 为本地 localhost 仓库，还配置了一个 mirrorOf 为 central 远程仓库为 maven.aliyun.com 的中央仓库, 以下是配置信息settings.xml 文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253······&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;localhost&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo&lt;/mirrorOf&gt; &lt;!--拦截 pom 文件配置的 repository--&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;localhost2&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo2&lt;/mirrorOf&gt; &lt;!--配置一个拦截 foo2 的远程仓库的镜像--&gt; &lt;url&gt;http://localhost:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;!--覆盖 Maven 默认的配置的中央仓库--&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;!--配置私服--&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt;&lt;/activeProfiles&gt;······ pom.xml 文件 12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;!--xxx-cif-api 存在 172.16.xxx.xxx 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.xxx.cif&lt;/groupId&gt; &lt;artifactId&gt;xxx-cif-api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--Chapter1 存在 localhost 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--配置远程仓库--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;foo&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://dev.xxx.wiki:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 以下是 Maven 拉取包的日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108······· 省略部分日志信息[DEBUG] Using local repository at E:\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\OperSource[INFO] Scanning for projects...// 从这里可以看出我们配置的镜像替代了我们在 pom 配置的远程仓库[DEBUG] Using mirror localhost (http://localhost:8081/repository/maven-public/) for foo (http://dev.xxx.wiki:8081/nexus/content/groups/public/).替代了默认的中央仓库[DEBUG] Using mirror alimaven (http://maven.aliyun.com/nexus/content/groups/public/) for central (https://repo.maven.apache.org/maven2).// 从这里可以看出 Maven 使用哪些 dependencies 和 plugins 的地址，我们可以看出优先级最高的是 172.16.xxx.xxx,然后就是 localhost 最后才是 maven.aliyun.com// 注意：alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases) 从这里可以看出中央仓库只能获取 releases 包，所有的 snapshots 包都不从中央仓库获取。（可以看前面 central 的配置信息）[DEBUG] === PROJECT BUILD PLAN ================================================[DEBUG] Project: com.cjf:demo:1.0-SNAPSHOT[DEBUG] Dependencies (collect): [][DEBUG] Dependencies (resolve): [compile, runtime, test][DEBUG] Repositories (dependencies): [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public/, default, releases+snapshots), localhost (http://localhost:8081/repository/maven-public/, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] Repositories (plugins) : [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] =======================================================================// 寻找本地是否有 maven-metadata.xml 配置文件 ，从这里可以看出寻找不到（后面会详细讲该文件作用）[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\OperSource)// 由于寻找不到 Maven 只能从我们配置的远程仓库寻找，由于 Maven 也不知道那个仓库才有，所以同时寻找两个仓库[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\resolver-status.properties// 从这里可以看出在 172.16.xxx.xxx 找到 xxx-cif-api 的 maven-metadata.xml 文件并下载下来Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml (781 B at 7.0 KB/sec)// 追踪文件，resolver-status.properties 配置了 jar 包下载地址和时间[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\resolver-status.properties[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in localhost (http://localhost:8081/repository/maven-public/)// 在 localhost 远程仓库寻找不到 xxx-cif-api 的 maven-metadata.xml[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\OperSource)// 跳过的远程请求 [DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.[DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.// 默认以后获取 xxx-cif-api 的时候将不在从 localhost 寻找了，除非强制获取才会再次从 localhost 寻找这个包[DEBUG] Failure to find com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in http://localhost:8081/repository/maven-public/ was cached in the local repository, resolution will not be reattempted until the update interval of localhost has elapsed or updates are forced// 将 172.16.xxx.xxx 优先级升为 0 ，并下载 xxx-cif-api 的 pom 文件[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pomDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pom (930 B at 82.6 KB/sec)// _remote.repositories 记录的以后使用那个远程仓库获取 （ps:这个文件作用我要不是很清楚作用，以上观点是自己推测出来的。）[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\xxx-cif-api-0.0.1-20170515.040917-89.pom.lastUpdated// 后面获取 Chapter1 包的流程跟 com.xxx.cif 是一样的，不过最后是在 localhost 寻找到而已，所以这分日志就不贴出来了。// 最后在下载包的时候，都到对应的仓库下载[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jarDownloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jarDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jar (26 KB at 324.2 KB/sec)Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jar (68 KB at 756.6 KB/sec)[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\xxx-cif-api-0.0.1-20170515.040917-89.jar.lastUpdated[DEBUG] Writing tracking file E:\OperSource\com\xxx\util\xxx-util\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\util\xxx-util\0.0.1-SNAPSHOT\xxx-util-0.0.1-20170514.091041-31.jar.lastUpdated[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/Downloading: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jarDownloaded: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jar (8 KB at 167.0 KB/sec)[DEBUG] Writing tracking file E:\OperSource\com\cjf\Chapter1\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\cjf\Chapter1\0.0.1-SNAPSHOT\Chapter1-0.0.1-20170708.092339-1.jar.lastUpdated[INFO] Installing C:\Users\swipal\Desktop\abc\demo\target\demo-1.0-SNAPSHOT.jar to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[INFO] Installing C:\Users\swipal\Desktop\abc\demo\pom.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\OperSource\com\cjf\demo\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 10.549 s[INFO] Finished at: 2017-07-09T18:13:20+08:00[INFO] Final Memory: 26M/219M[INFO] ------------------------------------------------------------------------······· 好了，看了这么多的配置文件信息和日志信息，我们也总结一下 Maven 远程仓库优先级了。 主要有以下几点：1.从日志信息我们得出这几种maven仓库的优先级别为 本地仓库 &gt; 私服 （profile）&gt; 远程仓库（repository）和 镜像 （mirror） &gt; 中央仓库 （central） 2.镜像是一个特殊的配置，其实镜像等同与远程仓库，没有匹配远程仓库的镜像就毫无作用（如 foo2）。3.总结上面所说的，Maven 仓库的优先级就是 私服和远程仓库 的对比，没有其它的仓库类型。为什么这么说是因为，镜像等同远程，而中央其实也是 maven super xml 配置的一个repository 的一个而且。所以 maven 仓库真正的优先级为 本地仓库 &gt; 私服（profile）&gt; 远程仓库（repository） maven-metadata.xml 文件Maven Repository Metadata 可用于表示： 1. 一个没有版本的工件：它提供有关该工件的可用版本的信息 2. 快照伪像：它提供有关快照的精确信息 3. 包含Maven插件工件的组：它提供了有关此组中可用插件的信息。 元数据文件名是： 远程存储库中的 maven-metadata.xml， maven-metadata- &lt;repo-id&gt;.xml在本地存储库中，用于具有repo-id标识符的存储库中的元标记。 以上是 Maven 官网对该文件的解释。 作用问题：有时候我们更新最新包的时候，会发现最新的包被拉取下来的，但是项目使用的包还是旧的包。所以我们要分析下是什么原因导致的。 首先我们先大概的了解下 maven-metadata.xml 文件。1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;metadata modelVersion="1.1.0"&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;!--当前版本下的最新快照信息--&gt; &lt;timestamp&gt;20170710.071727&lt;/timestamp&gt; &lt;!--快照的时间戳--&gt; &lt;buildNumber&gt;6&lt;/buildNumber&gt; &lt;!--构件号--&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20170710071727&lt;/lastUpdated&gt;&lt;!--metadata文件被更新的时间--&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;!--当前版本下可用的子快照版本信息--&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt;&lt;!--子快照版本的信息--&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;!--这个子快照版本的更新时间--&gt; &lt;/snapshotVersion&gt; &lt;snapshotVersion&gt; &lt;extension&gt;pom&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/snapshotVersions&gt; &lt;/versioning&gt;&lt;/metadata&gt; 其中 lastUpdated 是最中要的一个属性，Maven 更新工程的 jar包时，会比较 lastUpdated 时间戳值，哪个值更大，就以哪个文件为准。 接下来我们看下 Maven 为我们生成了那些文件我们可以看到 maven-metadata.xml 一共有三个 1. maven-metadata-local.xml 本地的元数据, Maven install 的时候就会生成。 2. maven-metadata-snapshots.xml Maven deploy 时会生成 3. maven-metadata-localhost.xml 远程仓库获取的时候生成 (repository 的 id = localhost) 以上的文件其实都是 Maven 的过渡文件而已 例如 maven-metadata-snapshots 就是 Maven deploy 先从远程仓库对应包的 maven-metadata.xml 下载下来，然后修改快照信息后在上传到远程仓库上。 例如 maven-metadata-localhost 的作用是在 Maven 在拉取包的时候，会先跟本地 maven-metadata-local 比较下 lastUpdated 时间戳值，值大用哪个。如果是 Mavne 强制更新 的时候(没有强制更新是不会) 会下载远程的 maven-metadata.xml 比较远程，本地，和之前远程保存下来的 maven-metadata 文件。 所以有时候 maven 库上的 jar 包已经更新，而我们总是拉取不到 maven 的包原因就是本地的 maven-metadata-local 的 lastUpdated 比较大。 我们验证下 Maven deploy 例子123456789101112131415161718192021222324[INFO] --- maven-deploy-plugin:2.8.2:deploy (default-deploy) @ Chapter1 ---// 先从远程下载快照 maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 3.3 KB/sec)// 将项目的 jar 和 pom 文件更新到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jarUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jar (8 KB at 14.1 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pomUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pom (2 KB at 2.0 KB/sec)Downloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 1.6 KB/sec)// 上传 maven-metadata.xml 到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 1.0 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 0.4 KB/sec)[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.231 s[INFO] Finished at: 2017-07-10T20:13:13+08:00[INFO] Final Memory: 19M/226M[INFO] ------------------------------------------------------------------------ 总结原本以为两天就写好这篇文章，在自己理清思路的时候总是被自己绕晕了。比如在 Nexus 的 Central 配置的中央仓库获取，和 maven-metadata.xml 是如何比较的。 如果以上文章有误，等博客的评论系统搭建起来后欢迎大家指认出来。]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LogBack 使用]]></title>
    <url>%2F2017%2F09%2F03%2FLogback%2F</url>
    <content type="text"><![CDATA[26 Seven 2017 前言之前项目一直使用 logback ,现在大概写下了 logback 基础配置。 简介LogBack是一个日志框架，它是Log4j作者Ceki的又一个日志组件。 LogBack,Slf4j,Log4j之间的关系 slf4j是The Simple Logging Facade for Java的简称，是一个简单日志门面抽象框架，它本身只提供了日志Facade API和一个简单的日志类实现，一般常配合Log4j，LogBack，java.util.logging使用。Slf4j作为应用层的Log接入时，程序可以根据实际应用场景动态调整底层的日志实现框架(Log4j/LogBack/JdkLog…)； LogBack和Log4j都是开源日记工具库，LogBack是Log4j的改良版本，比Log4j拥有更多的特性，同时也带来很大性能提升。 LogBack官方建议配合Slf4j使用，这样可以灵活地替换底层日志框架。 LogBack的结构LogBack分为3个组件，logback-core, logback-classic 和 logback-access。其中logback-core提供了LogBack的核心功能，是另外两个组件的基础。logback-classic则实现了Slf4j的API，所以当想配合Slf4j使用时，则需要引入这个包。logback-access是为了集成Servlet环境而准备的，可提供HTTP-access的日志接口。 Log的行为级别：OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL从下向上，当选择了其中一个级别，则该级别向下的行为是不会被打印出来。举个例子，当选择了INFO级别，则INFO以下的行为则不会被打印出来。 获取 Logger 对象 我们先从获取 logger 对象开始1Logger logger = LoggerFactory.getLogger(xxx.class.getName()); LoggerFactory 是 slf4j 的日志工厂，获取 logger 方法就来自这里。123456以下代码摘自：org.slf4j.LoggerFactorypublic static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 这个方法里面有分为两个过程。第一个过程是获取ILoggerFactory，就是真正的日志工厂。第二个过程就是从真正的日志工厂中获取logger。接下来我们看下到底是怎么获取的12345678910111213141516171819202122232425262728以下代码摘自：org.slf4j.LoggerFactorypublic static ILoggerFactory getILoggerFactory() &#123;if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; // 第一次调用会去加载 StaticLoggerBinder.class 文件来决定 LoggerFactory 的实现类 // （补充下：不同日志包下都有 StaticLoggerBinder 这个类文件，这个会决定 LoggerFactory 初始化那种类型的日志） performInitialization();&#125;// INITIALIZATION_STATE 值判断是否有加载初始化过 ILoggerFactory 实例。switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: // 返回对应的 ILoggerFactory 实例 return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: // 当加载不到一个 StaticLoggerBinder 时，会走这里 // 返回一个 NOPLoggerFactory 实例 return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: // 初始化异常 throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://bugzilla.slf4j.org/show_bug.cgi?id=106 return TEMP_FACTORY;&#125;throw new IllegalStateException("Unreachable code");&#125; 接下来我们来看下是怎么加载 StaticLoggerBinder.class 文件的 1234567891011121314151617181920212223242526272829303132333435以下代码摘自：org.slf4j.LoggerFactory private final static void bind() &#123; try &#123; // 加载 StaticLoggerBinder Set staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); // 最后会随机选择一个StaticLoggerBinder.class来创建一个单例 StaticLoggerBinder.getSingleton(); // 改变 INITIALIZATION_STATE 值，表示成功初始化 Factory。 // 并且以后在获取 Logger 的时候并不会再次加载该方法 INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); emitSubstituteLoggerWarning(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; // 加载不到 StaticLoggerBinder 文件 INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.indexOf("org.slf4j.impl.StaticLoggerBinder.getSingleton()") != -1) &#123; // 初始化异常 INITIALIZATION_STATE = FAILED_INITIALIZATION; &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException("Unexpected initialization failure", e); &#125; &#125; 加载 StaticLoggerBinder.class12345678910111213141516以下代码摘自：org.slf4j.LoggerFactory.findPossibleStaticLoggerBinderPathSetprivate static String STATIC_LOGGER_BINDER_PATH = "org/slf4j/impl/StaticLoggerBinder.class";···if (loggerFactoryClassLoader == null) &#123; paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); &#125; else &#123; paths = loggerFactoryClassLoader .getResources(STATIC_LOGGER_BINDER_PATH); &#125; while (paths.hasMoreElements()) &#123; URL path = (URL) paths.nextElement(); staticLoggerBinderPathSet.add(path); &#125;··· 当项目中存在多个StaticLoggerBinder.class文件时，运行项目会出现以下日志：（这里获取的规则就近原则，如果在 maven 先配置 slf4j 而后面在配置 logback，则这里初始化的是 slf4j）12345SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/E:/OperSource/org/slf4j/slf4j-log4j12/1.7.12/slf4j-log4j12-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/E:/OperSource/ch/qos/logback/logback-classic/1.1.3/logback-classic-1.1.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] 返回实例123以下代码摘自：org.slf4j.LoggerFactory.getILoggerFactoryStaticLoggerBinder.getSingleton().getLoggerFactory(); LogBack 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 项目名称配置 --&gt; &lt;contextName&gt;example&lt;/contextName&gt; &lt;!-- 属性 --&gt; &lt;property name="APP_Name" value="example" /&gt; &lt;!-- 统一的时间格式，用于日志头输出 --&gt; &lt;timestamp key="timeStyle" datePattern="yyyy-MM-dd HH:mm:ss.SSS"/&gt; &lt;!--配置控制台输出,开发环境有--&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- encoder 默认配置为PatternLayoutEncoder --&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--文件输出配置--&gt; &lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_run.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_run.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="BUSINESS_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_business.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_business.%i.business.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt;&lt;!-- 只打印错误日志 --&gt; &lt;level&gt;WARE&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 异步输出 --&gt; &lt;appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref="FILE"/&gt; &lt;/appender&gt; &lt;appender name="BUSINESS_ASYNC" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref="BUSINESS_FILE"/&gt; &lt;/appender&gt; &lt;!-- 为数据库开启显示sql --&gt; &lt;logger name="com.cjf.example.repository" level="DEBUG"&gt;&lt;/logger&gt; &lt;logger name="com.cjf" level="INFO"&gt;&lt;/logger&gt; &lt;!--日志的root目录，用于定位日志输出级别--&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="ASYNC"/&gt; &lt;appender-ref ref="STDOUT"/&gt; &lt;/root&gt;&lt;/configuration&gt; 上面就是一个常用的日志配置模版，下面就从跟节点来解析每个节点 1.configurationscan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod：监测配置文件是否有修改的时间间隔，默认 60s。debug：是否打印 logback 内部日志，默认 false.2.contextName 项目名称logger 上下文容器名称，默认 ‘default’，用于区分不同应用程序的记录。（可以在日志输出的时候将项目名称打印处理方便系统间交互 比如上面配置的 %cn）3.property 设置变量定义变量后，可以使${}来使用变量。4.timestamp 设置时间戳格式key:标识此 的名字；datePattern：设置将当前时间（解析配置文件的时间）转换为字符串的模式，遵循Java.txt.SimpleDateFormat的格式。5.logger用来设置某一个包或者具体的某一个类的日志打印级别、以及指定。仅有一个name属性，一个可选的level和一个可选的addtivity属性。name: 用来指定受此loger约束的某一个包或者具体的某一个类。level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。如果未设置此属性，那么当前loger将会继承上级的级别。addtivity:是否向上级loger传递打印信息。默认是true。loger可以包含零个或多个appender-ref元素，标识这个appender将会添加到这个loger。6.root也是 loger 元素，但是它是根 loger。只有一个 level 属性，应为已经被命名为 “root”.root 可以包含零个或多个 appender-ref 元素，标识这个 appender 将会添加到这个 loger。 什么是 Appender？logback 将日志记录事件写入到名为 appender 的组件的任务,不同 appender 决定了日志的记录方式。appender 有多种实现的方式，下面简单介绍几种比较常用的配置。 更多详情请参考官方文档 ConsoleAppender把日志添加到控制台，有以下子节点： encoder：对日志进行格式化 target：字符串 System.out 或者 System.err ，默认 System.out; withJansi：日志彩色输出 例如123456789101112&lt;configuration&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="DEBUG"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/root&gt; &lt;/configuration&gt; RollingFileAppender滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。file：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。append：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。encoder：对记录事件进行格式化。rollingPolicy：当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名。triggeringPolicy：告知 RollingFileAppender 合适激活滚动。prudent：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。 rollingPolicy 有两种类型，分别是 TimeBasedRollingPolicy，FixedWindowRollingPolicy。 例如 TimeBasedRollingPolicy 配置123456789101112&lt;!--输出到文件--&gt;&lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.path&#125;&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;logback.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; fileNamePattern 定义了日志的切分方式——把每一天的日志归档到一个文件中maxHistory 表示只保留最近30天的日志，以防止日志填满整个磁盘空间。totalSizeCap 用来指定日志文件的上限大小，例如设置为1GB的话，那么到了这个值，就会删除旧的日志。 例如 FixedWindowRollingPolicy 配置1234567891011121314&lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_run.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_run.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 这里多了一个 SizeBasedTriggeringPolicy 触发机制，但 log 文件大于 10MB 的时候，就开始执行 rolling。minIndex 和 maxIndex 表示保存日志数量，但大于 maxIndex 的时候，会开始删除旧的日志。 必须包含“%i”例如，假设最小值和最大值分别为1和2，命名模式为mylog%i.log,会产生归档文件mylog1.log和mylog2.log。还可以指定文件压缩选项，例如，mylog%i.log.gz或者 没有log%i.log.zip AsyncAppender 异步输出这里就不写了，可以参考文章。 总结由于没有深入去了解 logback ,许多内容都是网上摘来的，写文章的时候也很费劲。思路不清晰。]]></content>
      <categories>
        <category>LogBack</category>
      </categories>
      <tags>
        <tag>LogBack</tag>
      </tags>
  </entry>
</search>