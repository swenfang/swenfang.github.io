<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基础面试题]]></title>
    <url>%2F2018%2F01%2F21%2F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[基础面试题以下各方面知识点的面试题，是为了将要出来工作的小师妹和小师弟而精心整理的。希望对你们都帮助。这些面试题都是很基础的，希望你们能够好好利用起来。有问题，或者不对的地方欢迎给我留言哈！ forward 和redirect的区别12forward是服务器请求资源，服务器直接访问目标地址的URL，把那个URL的响应内容读取过来，然后把这些内容再发给浏览器，浏览器根本不知道服务器发送的内容是从哪儿来的，所以它的地址栏中还是原来的地址。 redirect就是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址，一般来说浏览器会用刚才请求的所有参数重新请求，所以session,request参数都可以获取。 int 和 Integer 有什么区别123Java 提供两种不同的类型：引用类型和原始类型（或内置类型）。Int是java的原始数据类型，Integer是java为int提供的封装类。Java为每个原始类型提供了封装类。原始类型封装类,booleanBoolean,charCharacter,byteByte,shortShort,intInteger,longLong,floatFloat,doubleDouble引用类型和原始类型的行为完全不同，并且它们具有不同的语义。引用类型和原始类型具有不同的特征和用法，它们包括：大小和速度问题，这种类型以哪种类型的数据结构存储，当引用类型和原始类型用作某个类的实例数据时所指定的缺省值。对象引用实例变量的缺省值为 null，而原始类型实例变量的缺省值与它们的类型有关 error和exception有什么区别1error 表示恢复不是不可能但很困难的情况下的一种严重问题。比如说内存溢出。不可能指望程序能处理这样的情况。exception 表示一种设计或实现问题。也就是说，它表示如果程序运行正常，从不会发生的情况。 Overload和Override区别，Overloaded方法可以改变返回值的类型吗1方法的重写Overriding和重载Overloading是Java多态性的不同表现。重写Overriding是父类与子类之间多态性的一种表现，重载Overloading是一个类中多态性的一种表现。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写 (Overriding)。子类的对象使用这个方法时，将调用子类中的定义，对它而言，父类中的定义如同被&quot;屏蔽&quot;了。如果在一个类中定义了多个同名的方法，它们或有不同的参数个数或有不同的参数类型，则称为方法的重载(Overloading)。Overloaded的方法是可以改变返回值的类型。 java中有哪些集合，主要方法有哪些12345678910111213主要有LinkedList，ArrayList，Vector等。下面是详细：Collection├List│├LinkedList│├ArrayList│└Vector│ └Stack└SetMap├Hashtable├HashMap└WeakHashMap最常用的集合类是 List 和 Map。 List 的具体实现包括 ArrayList 和 Vector，它们是可变大小的列表，比较适合构建、存储和操作任何类型对象的元素列表。 List 适用于按数值索引访问元素的情形。 Map 提供了一个更通用的元素存储方法。 Map 集合类用于存储元素对（称作“键”和“值”）其中每个键映射到一个值。 List、Map、Set接口，存取元素时各自特点12List 以特定次序来持有元素，可有重复元素。Set 无法拥有重复元素,内部排序。Map 保存key-value值，value可多值。 List的遍历： List接口有size()和get()方法，用这两个方法可以实现对List的遍历。size()方法得到List中的元素个数。get()方法取得某个位置上的元素 HashMap与HashTable的区别123456789101、HashMap是非线程安全的，HashTable是线程安全的。2、HashMap的键和值都允许有null值存在，而HashTable则不行。3、因为线程安全的问题，HashMap效率比HashTable的要高。HashMap的实现机制：维护一个每个元素是一个链表的数组，而且链表中的每个节点是一个Entry[]键值对的数据结构。实现了数组+链表的特性，查找快，插入删除也快。对于每个key,他对应的数组索引下标是 int i = hash(key.hashcode)&amp;(len-1);每个新加入的节点放在链表首，然后该新加入的节点指向原链表首 HashMap，ConcurrentHashMap与LinkedHashMap的区别12345678910111213141516ConcurrentHashMap是使用了锁分段技术技术来保证线程安全的，锁分段技术：首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问ConcurrentHashMap 是在每个段（segment）中线程安全的LinkedHashMap维护一个双链表，可以将里面的数据按写入的顺序读出ConcurrentHashMap应用场景1：ConcurrentHashMap的应用场景是高并发，但是并不能保证线程安全，而同步的HashMap和HashMap的是锁住整个容器，而加锁之后ConcurrentHashMap不需要锁住整个容器，只需要锁住对应的Segment就好了，所以可以保证高并发同步访问，提升了效率。2：可以多线程写。ConcurrentHashMap把HashMap分成若干个Segmenet1.get时，不加锁，先定位到segment然后在找到头结点进行读取操作。而value是volatile变量，所以可以保证在竞争条件时保证读取最新的值，如果读到的value是null，则可能正在修改，那么久调用ReadValueUnderLock函数，加锁保证读到的数据是正确的。2.Put时会加锁，一律添加到hash链的头部。3.Remove时也会加锁，由于next是final类型不可改变，所以必须把删除的节点之前的节点都复制一遍。4.ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对Hash表的不同Segment进行的修改。ConcurrentHashMap的应用场景是高并发，但是并不能保证线程安全，而同步的HashMap和HashTable的是锁住整个容器，而加锁之后ConcurrentHashMap不需要锁住整个容器，只需要锁住对应的segment就好了，所以可以保证高并发同步访问，提升了效率。 Vector和ArrayList的区别12345 首先看这两类都实现List接口，而List接口一共有三个实现类，分别是ArrayList、Vector和LinkedList。List用于存放多个元素，能够维护元素的次序，并且允许元素的重复。3个具体实现类的相关区别如下：1.ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要讲已经有数组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。2.Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢。3.LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用。 ArrayList 与 LinkedList 的不区别123456789最明显的区别是 ArrrayList 底层的数据结构是数组，支持随机访问，而 LinkedList 的底层数据结构是链表，不支持随机访问。使用下标访问一个元素，ArrayList 的时间复杂度是 O(1)，而 LinkedList 是 O(n)。1.LinkedList内部存储的是Node&lt;E&gt;，不仅要维护数据域，还要维护prev和next，如果LinkedList中的结点特别多，则LinkedList比ArrayList更占内存。插入删除操作效率：2.LinkedList在做插入和删除操作时，插入或删除头部或尾部时是高效的，操作越靠近中间位置的元素时，需要遍历查找，速度相对慢一些，如果在数据量较大时，每次插入或删除时遍历查找比较费时。所以LinkedList插入与删除，慢在遍历查找，快在只需要更改相关结点的引用地址。ArrayList在做插入和删除操作时，插入或删除尾部时也一样是高效的，操作其他位置，则需要批量移动元素，所以ArrayList插入与删除，快在遍历查找，慢在需要批量移动元素。3.循环遍历效率：由于ArrayList实现了RandomAccess随机访问接口，所以使用for(int i = 0; i &lt; size; i++)遍历会比使用Iterator迭代器来遍历快而由于LinkedList未实现RandomAccess接口，所以推荐使用Iterator迭代器来遍历数据。因此，如果我们需要频繁在列表的中部改变插入或删除元素时，建议使用LinkedList，否则，建议使用ArrayList，因为ArrayList遍历查找元素较快，并且只需存储元素的数据域，不需要额外记录其他数据的位置信息，可以节省内存空间。 Java 中的 LinkedList 是单向链表还是双向链表1是双向链表。 String、StringBuffer、StringBuilder之间区别123 1.三者在执行速度方面的比较：StringBuilder &gt; StringBuffer &gt; String 2.在线程方面：StringBuilder是线程非安全的;StringBuffer是线程安全的 3. 对于三者的使用：如果要操作少量的数据用 = String；单线程操作字符串缓冲区 下操作大量数据 = StringBuilder；多线程操作字符串缓冲区 下操作大量数据 = StringBuffer； Object 的常用方有哪些1clone()、equals()、hashCode()、notify()、notifyAll()、toString()、wait()、finalize() Mysql 的分页 SQL 语句1select * from tablename limit m,n(n是指从第m+1条开始，取n条) Hibernate与MyBatis的异同12345678910相同点：Hibernate与MyBatis都可以是通过SessionFactoryBuider由XML配置文件生成SessionFactory，然后由SessionFactory 生成Session，最后由Session来开启执行事务和SQL语句。其中SessionFactoryBuider，SessionFactory，Session的生命周期都是差不多的。Hibernate和MyBatis都支持JDBC和JTA事务处理。Mybatis优势：MyBatis可以进行更为细致的SQL优化，可以减少查询字段。MyBatis容易掌握，而Hibernate门槛较高。Hibernate优势：Hibernate的DAO层开发比MyBatis简单，Mybatis需要维护SQL和结果映射。Hibernate对对象的维护和缓存要比MyBatis好，对增删改查的对象的维护要方便。Hibernate数据库移植性很好，MyBatis的数据库移植性不好，不同的数据库需要写不同SQL。Hibernate有更好的二级缓存机制，可以使用第三方缓存。MyBatis本身提供的缓存机制不佳。 Hibernate与MyBatis在sql优化方面异同1234Hibernate的查询会将表中的所有字段查询出来，这一点会有性能消耗。Hibernate也可以自己写SQL来指定需要查询的字段，但这样就破坏了Hibernate开发的简洁性。而Mybatis的SQL是手动编写的，所以可以按需求指定查询的字段。Hibernate HQL语句的调优需要将SQL打印出来，而Hibernate的SQL被很多人嫌弃因为太丑了。MyBatis的SQL是自己手动写的所以调整方便。但Hibernate具有自己的日志统计。Mybatis本身不带日志统计，使用Log4j进行日志记录。 Hibernate与MyBatis对象管理对比12Hibernate 是完整的对象/关系映射解决方案，它提供了对象状态管理（state management）的功能，使开发者不再需要理会底层数据库系统的细节。也就是说，相对于常见的 JDBC/SQL 持久层方案中需要管理 SQL 语句，Hibernate采用了更自然的面向对象的视角来持久化 Java 应用中的数据。换句话说，使用 Hibernate 的开发者应该总是关注对象的状态（state），不必考虑 SQL 语句的执行。这部分细节已经由 Hibernate 掌管妥当，只有开发者在进行系统性能调优的时候才需要进行了解。而MyBatis在这一块没有文档说明，用户需要对对象自己进行详细的管理。 Jsp九大内置对象1234567891.Request: request对象主要用于客户端请求处理2.Response: response对象提供了多个方法用来处理HTTP响应，可以调用response中的方法修改ContentType中的MIME类型以及实现页面的跳转等等，3.Page: page对象有点类似于Java编程中的this指针，就是指当前JSP页面本身。page是java.lang.Object类的对象。4.Session: session是与请求有关的会话期，它是java.servlet.http.HttpSession类的对象，用来表示和存储当前页面的请求信息。5.Application: application是javax.servlet.ServletContext类对象的一个实例，用于实现用户之间的数据共享6.Out:7.Exception: exception内置对象是用来处理页面出现的异常错误8.Config: config内置对象是ServletConfig类的一个实例。在Servlet初始化的时候，JSP引擎通过config向它传递信息。这种信息可以是属性名/值匹配的参数，也可以是通过ServletContext对象传递的服务器的有关信息。9.pageContext: pageContext对象是一个比较特殊的对象。它相当于页面中所有其他对象功能的最大集成者，即使用它可以访问到本页面中所有其他对象 Comparator 与 Comparable 有什么不同1Comparable 接口用于定义对象的自然顺序，而 comparator 通常用于定义用户定制的顺序。Comparable 总是只有一个，但是可以有多个 comparator 来定义对象的顺序。 Collection 和 Collections的区别12Collection是集合类的上级接口，继承与他的接口主要有Set 和List.Collections是针对集合类的一个帮助类，他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。 线程同步的方法1234wait():使一个线程处于等待状态，并且释放所持有的对象的lock。sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。Allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。 Volatile和Synchronized四个不同点123456789101112131415161. 粒度不同，前者锁对象和类，后者针对变量2. syn阻塞，volatile线程不阻塞3. syn保证三大特性，volatile不保证原子性4. syn编译器优化，volatile不优化volatile具备两种特性：保证此变量对所有线程的可见性，指一条线程修改了这个变量的值，新值对于其他线程来说是可见的，但并不是多线程安全的。禁止指令重排序优化。Volatile如何保证内存可见性:1.当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。2.当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。同步：就是一个任务的完成需要依赖另外一个任务，只有等待被依赖的任务完成后，依赖任务才能完成。异步：不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，只要自己任务完成了就算完成了，被依赖的任务是否完成会通知回来。（异步的特点就是通知）。打电话和发短信来比喻同步和异步操作。阻塞：CPU停下来等一个慢的操作完成以后，才会接着完成其他的工作。非阻塞：非阻塞就是在这个慢的执行时，CPU去做其他工作，等这个慢的完成后，CPU才会接着完成后续的操作。非阻塞会造成线程切换增加，增加CPU的使用时间能不能补偿系统的切换成本需要考虑。 SpringMVC运行原理123451. 客户端请求提交到DispatcherServlet2. 由DispatcherServlet控制器查询HandlerMapping，找到并分发到指定的Controller中。3. Controller调用业务逻辑处理后，返回ModelAndView4. DispatcherServlet查询一个或多个ViewResoler视图解析器，找到ModelAndView指定的视图5. 视图负责将结果显示到客户端 SpringMVC与Struts2区别与比较总结123456789101112131415161718191、Struts2是类级别的拦截， 一个类对应一个request上下文，SpringMVC是方法级别的拦截，一个方法对应一个request上下文，而方法同时又跟一个url对应,所以说从架构本身上SpringMVC就容易实现restful url,而struts2的架构实现起来要费劲，因为Struts2中Action的一个方法可以对应一个url，而其类属性却被所有方法共享，这也就无法用注解或其他方式标识其所属方法了。2、由上边原因，SpringMVC的方法之间基本上独立的，独享request response数据，请求数据通过参数获取，处理结果通过ModelMap交回给框架，方法之间不共享变量，而Struts2搞的就比较乱，虽然方法之间也是独立的，但其所有Action变量是共享的，这不会影响程序运行，却给我们编码 读程序时带来麻烦，每次来了请求就创建一个Action，一个Action对象对应一个request上下文。3、由于Struts2需要针对每个request进行封装，把request，session等servlet生命周期的变量封装成一个一个Map，供给每个Action使用，并保证线程安全，所以在原则上，是比较耗费内存的。4、 拦截器实现机制上，Struts2有以自己的interceptor机制，SpringMVC用的是独立的AOP方式，这样导致Struts2的配置文件量还是比SpringMVC大。5、SpringMVC的入口是servlet，而Struts2是filter（这里要指出，filter和servlet是不同的。以前认为filter是servlet的一种特殊），这就导致了二者的机制不同，这里就牵涉到servlet和filter的区别了。6、SpringMVC集成了Ajax，使用非常方便，只需一个注解@ResponseBody就可以实现，然后直接返回响应文本即可，而Struts2拦截器集成了Ajax，在Action中处理时一般必须安装插件或者自己写代码集成进去，使用起来也相对不方便。7、SpringMVC验证支持JSR303，处理起来相对更加灵活方便，而Struts2验证比较繁琐，感觉太烦乱。8、Spring MVC和Spring是无缝的。从这个项目的管理和安全上也比Struts2高（当然Struts2也可以通过不同的目录结构和相关配置做到SpringMVC一样的效果，但是需要xml配置的地方不少）。9、 设计思想上，Struts2更加符合OOP的编程思想， SpringMVC就比较谨慎，在servlet上扩展。10、SpringMVC开发效率和性能高于Struts2。11、SpringMVC可以认为已经100%零配置。 简单总结springMVC和struts2的区别1231. springmvc的入口是一个servlet即前端控制器，而struts2入口是一个filter过虑器。2. springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，可以设计为单例或多例(建议单例)，struts2是基于类开发，传递参数是通过类的属性，只能设计为多例。3. Struts采用值栈存储请求和响应的数据，通过OGNL存取数据， springmvc通过参数解析器是将request请求内容解析，并给方法形参赋值，将数据和视图封装成ModelAndView对象，最后又将ModelAndView中的模型数据通过reques域传输到页面。Jsp视图解析器默认使用jstl。 SpringMvc怎么和AJAX相互调用的12345通过Jackson框架就可以把Java里面的对象直接转化成Js可以识别的Json对象具体步骤如下1.加入Jackson.jar2.在配置文件中配置json的映射3.在接受Ajax方法里面可以直接返回Object,List等,但方法前面要加上@ResponseBody注解 Spring有哪些优点12345671.轻量级：Spring在大小和透明性方面绝对属于轻量级的，基础版本的Spring框架大约只有2MB。2.控制反转(IOC)：Spring使用控制反转技术实现了松耦合。依赖被注入到对象，而不是创建或寻找依赖对象。3.面向切面编程(AOP)： Spring支持面向切面编程，同时把应用的业务逻辑与系统的服务分离开来。4.容器：Spring包含并管理应用程序对象的配置及生命周期。5.MVC框架：Spring的web框架是一个设计优良的web MVC框架，很好的取代了一些web框架。6.事务管理：Spring对下至本地业务上至全局业务(JAT)提供了统一的事务管理接口。7.异常处理：Spring提供一个方便的API将特定技术的异常(由JDBC, Hibernate, 或JDO抛出)转化为一致的、Unchecked异常。 解释AOP模块1AOP模块用来开发Spring应用程序中具有切面性质的部分。该模块的大部分服务由AOP Aliance提供，这就保证了Spring框架和其他AOP框架之间的互操作性。另外，该模块将元数据编程引入到了Spring。 IoC容器是什么其优点123Spring IOC负责创建对象、管理对象(通过依赖注入)、整合对象、配置对象以及管理这些对象的生命周期。优点:IOC或依赖注入减少了应用程序的代码量。它使得应用程序的测试很简单，因为在单元测试中不再需要单例或JNDI查找机制。简单的实现以及较少的干扰机制使得松耦合得以实现。IOC容器支持勤性单例及延迟加载服务。 Spring 的依赖注入方式有哪一些123Spring 的依赖注入可以有两种方式来完成:setter 方法注入和构造方法注入。构造器依赖注入：构造器依赖注入在容器触发构造器的时候完成，该构造器有一系列的参数，每个参数代表注入的对象。Setter方法依赖注入：首先容器会触发一个无参构造函数或无参静态工厂方法实例化对象，之后容器调用bean中的setter方法完成Setter方法依赖注入。 Spring支持的事务管理类型123Spring支持如下两种方式的事务管理：编程式事务管理：这意味着你可以通过编程的方式管理事务，这种方式带来了很大的灵活性，但很难维护。声明式事务管理：这种方式意味着你可以将事务管理和业务代码分离。你只需要通过注解或者XML配置管理事务。 ThreadLocal(线程变量副本)123456789Synchronized实现内存共享，ThreadLocal为每个线程维护一个本地变量。采用空间换时间，它用于线程间的数据隔离，为每一个使用该变量的线程提供一个副本，每个线程都可以独立地改变自己的副本，而不会和其他线程的副本冲突。ThreadLocal类中维护一个Map，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值为对应线程的变量副本。ThreadLocal在Spring中发挥着巨大的作用，在管理Request作用域中的Bean、事务管理、任务调度、AOP等模块都出现了它的身影。Spring中绝大部分Bean都可以声明成Singleton作用域，采用ThreadLocal进行封装，因此有状态的Bean就能够以singleton的方式在多线程中正常工作了。 throw 和 throws 的区别12345throw 用于抛出 java.lang.Throwable 类的一个实例化对象，意思是说你可以通过关键字 throw 抛出一个 Error 或者 一个Exception，如：throw new IllegalArgumentException(“size must be multiple of 2″)而throws 的作用是作为方法声明和签名的一部分，方法被抛出相应的异常以便调用者能处理。Java 中，任何未处理的受检查异常强制在 throws 子句中声明。 final关键字的作用123final class 表示此类不允许有子类。final virable 表示一个常量。final method 表示一个方法不能被重写 String是最基本的数据类型吗1基本数据类型包括byte、int、char、long、float、double、boolean和short。java.lang.String类是final类型的，因此不可以继承这个类、不能修改这个类。为了提高效率节省空间，我们应该用StringBuffer类。 synchronized和java.util.concurrent.locks.Lock的异同1234567主要相同点:Lock能完成synchronized所实现的所有功能.(其它不重要)主要不同点:Lock有比synchronized更精确的线程语义和更好的性能(在相同点中回答此点也行)synchronized会自动释放锁.而Lock一定要求程序员手工释放.并且必须在finally从句中释放,如果没有答出在finally中释放不得分.就如Connection没有在finally中关闭一样.连最基本的资源释放都做不好,还谈什么多线程编程. spring的事务有几种它的隔离级别和传播行为123456789101112131415声明式事务和编程式事务隔离级别：- DEFAULT使用数据库默认的隔离级别- READ_UNCOMMITTED会出现脏读，不可重复读和幻影读问题- READ_COMMITTED会出现重复读和幻影读- REPEATABLE_READ会出现幻影读- SERIALIZABLE最安全，但是代价最大，性能影响极其严重和传播行：- REQUIRED存在事务就融入该事务，不存在就创建事务- SUPPORTS存在事务就融入事务，不存在则不创建事务- MANDATORY存在事务则融入该事务，不存在，抛异常- REQUIRES_NEW总是创建新事务- NOT_SUPPORTED存在事务则挂起，一直执行非事务操作- NEVER总是执行非事务，如果当前存在事务则抛异常- NESTED嵌入式事务 sleep() 和 wait() 有什么区别12sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，给执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 多线程和同步有几种实现方法12多线程有两种实现方法，分别是继承Thread类与实现Runnable接口 同步的实现方面有两种，分别是synchronized,wait与notify 启动一个线程是用run()还是start()1启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM调度并执行。这并不意味着线程就会立即运行。run()方法可以产生必须退出的标志来停止一个线程。 final,finally,finalize的区别123final—修饰符（关键字）如果一个类被声明为final，意味着它不能再派生出新的子类，不能作为父类被继承。因此一个类不能既被声明为 abstract的，又被声明为final的。将变量或方法声明为final，可以保证它们在使用中不被改变。被声明为final的变量必须在声明时给定初值，而在以后的引用中只能读取，不可修改。被声明为final的方法也同样只能使用，不能重载。 finally—再异常处理时提供 finally 块来执行任何清除操作。如果抛出一个异常，那么相匹配的 catch 子句就会执行，然后控制就会进入 finally 块（如果有的话）。 finalize—方法名。Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的。它是在 Object 类中定义的，因此所有的类都继承了它。子类覆盖 finalize() 方法以整理系统资源或者执行其他清理工作。finalize() 方法是在垃圾收集器删除对象之前对这个对象调用的。 abstract class和interface有什么区别123456抽象类与接口的区别：1.接口可以多重继承 ，抽象类不可以 2.接口定义方法，不给实现；而抽象类可以实现部分方法 3.接口中基本数据类型的数据成员，都默认为static和final，抽象类则不是 如果事先知道某种东西会成为基础类，那么第一个选择就是把它变成一个接口。 只有在必须使用方法定义或者成员变量的时候，才应考虑采用抽象类。 Set里的元素不能重复，用==还是equals ()判断12Set里的元素是不能重复的，那么用iterator()方法来区分重复与否。equals()是判读两个Set是否相等。equals()和==方法决定引用值是否指向同一对象equals()在类中被覆盖，为的是当两个分离的对象的内容和类型相配的话，返回真值。 struts 框架是如何体现MVC模式12struts 框架为开发者提供了MVC 的3个逻辑组成部分，主要由ActionServlet、Action和strust-config.xml配置文件组成控制层，由ActionForm 来承担模型层的功能，而struts 下的视图由JSP来完成。处理请求：由ActionServlet接收请求，然后根据 struts-config.xml 中的配置，类判断由于哪个Action来处理请求和由哪个ActionForm来保存数据，在通过Action的返回值来判断应该由哪个JSP来负责页面的展示，最后由 JSP 来完成结果响应。 Hibernate 的实体存在哪几种状态1234Hibernate 中的实体在它的生命周期里面，存在 3 中状态。瞬时：new语句创建的实体类对象是就是瞬时状态，它一般没有id。持久：存放在 Session 中的实体对象就属于持久状态，一般通过 save() 或 saveOrUpdate()等等，方法转换而来。托管：实体中Session中脱离出来的时候，它的状态就属于托管状态了，尽管它具有 id 值，但已经不存在Session 中了，即使 实体中的数据发生变化也不能同步到数据库中。通过 close()、evict()等方法转化而来。 Hibernate 的get()和load()的区别1Hibernate 对于 load() 方法该方法认为数据一定存在于数据，可以放心的代理来延迟加载，如果在使用过程中发现了问题，只能抛出异常，而get()方法可以不存在。 为什么wait和notify方法要在同步块中调用1主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。 什么是ThreadLocal变量1ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。线程局部变量的另一个不错的例子是ThreadLocalRandom类，它在多线程环境中减少了创建代价高昂的Random对象的个数。 如何避免死锁1234567Java多线程中的死锁死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件：互斥条件：一个资源每次只能被一个进程使用。请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。 Java中活锁和死锁有什么区别1这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主要区别是前者进程的状态可以改变但是却不能继续执行。 怎么检测一个线程是否拥有锁1我一直不知道我们竟然可以检测一个线程是否拥有锁，直到我参加了一次电话面试。在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。 Maven有哪些优点1234567优点如下：简化了项目依赖管理：易于上手，对于新手可能一个&quot;mvn clean package&quot;命令就可能满足他的工作便于与持续集成工具（jenkins）整合便于项目升级，无论是项目本身升级还是项目使用的依赖升级。有助于多模块项目的开发，一个模块开发好后，发布到仓库，依赖该模块时可以直接从仓库更新，而不用自己去编译。maven有很多插件，便于功能扩展，比如生产站点，自动发布版本等 Maven常见的依赖范围有哪些1234561.compile:编译依赖，默认的依赖方式，在编译（编译项目和编译测试用例），运行测试用例，运行（项目实际运行）三个阶段都有效，典型地有spring-core等jar。2.test:测试依赖，只在编译测试用例和运行测试用例有效，典型地有JUnit。provided:对于编译和测试有效，不会打包进发布包中，典型的例子为servlet-api,一般的web工程运行时都使用容器的servlet-api。3.runtime:只在运行测试用例和实际运行时有效，典型地是jdbc驱动jar包。4.system: 不从maven仓库获取该jar,而是通过systemPath指定该jar的路径。5.import: 用于一个dependencyManagement对另一个dependencyManagement的继承。 使用“Mvn Clean Package”进行项目打包,其过程执行了哪些动作123456789在这个命令中我们调用了maven的clean周期的clean阶段绑定的插件任务，以及default周期的package阶段绑定的插件任务默认执行的任务有（maven的术语叫goal, 也有人翻译成目标，我这里用任务啦）：maven-clean-plugin:clean-&gt;maven-resources-plugin:resources-&gt;maven-compile-plugin:compile-&gt;mavne-resources-plugin:testResources-&gt;maven-compile-plugin:testCompile-&gt;maven-jar-plugin:jar Maven 多模块如何聚合1配置一个打包类型为pom的聚合模块，然后在该pom中使用&lt;module&gt;元素声明要聚合的模块]]></content>
      <categories>
        <category>基础面试题</category>
      </categories>
      <tags>
        <tag>基础面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的基本要素]]></title>
    <url>%2F2018%2F01%2F15%2FPython%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%A6%81%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[Python 的基本要素 基本数据类型 对象引用 组合数据类型 逻辑操作符 控制流语句 算数操作符 输入/输出 函数的创建与调用 要素1：基本数据类型 任何数据语言都必须能够表示基本数据项目 Python 中的基本数据类型有 【1】Integral 类型 ​ （1）.整型：不可变类型 1num = 1 #被保存在内存中，是不可变的 ​ 注意：对象和变量都是不可变的 ​ （2）.布尔型 (Ture、False) ​ 注意：加引号 【2】浮点类型 ​ （1）. 浮点数字 ​ （2）. 复数 【3】字符串 ​ 注意：在这里字符串表示的序列。 1type(放任意的类型) # 输出变量的类型 ​ 要素2：对象引用（变量） Python 将所有数据存为内存对象 Python 中，对象事实上是只想内存对象的引用 动态类型：在任何时刻，只要需要，某个对象都可以重新引用一个不同的对象（可以是不同的数据类型） 内建函数type()用于返回给定数据项的数据类型 “=” 用于将变量名与内存中的某个对象进行绑定：如果对象事先存在，就直接绑定；否则用 “=” 创建引用的对象。 变量的命名规则 只能包含字母下、数字和下划线，且不能以数字开头。 区分数字大小写 禁止使用保留字段（Python2和Python3有所不同） 命名惯例 一单个下划线开头的变量名称 (_x) 不会被 from model import * 语句导入 前后都有下滑线的变量名(x ) 是系统定义的变量名称，对 Python 解释器有特殊的意义 以两个下划线开头但结尾没有下划线的变量名称(__x)是类的本地变量 交互模式下，变量名 “—” 用于保存最后表达式的结果 1234&gt;&gt;&gt; 1+12&gt;&gt;&gt; print(_)2 ​ 注意： 变量名没有类型，对象才有 变量可以指定任何类型（这是 Python 和其他语言不同的） 要素3：组合数据类型 数据结构：通过某种方式（例如对元素进行编码）组织在一起的数据元素的集合 Python 常用的组合数据类型 序列类型 列表：使用[]创建，如[‘Call’,’me’,’Ishmell’,’_’] 12345&gt;&gt;&gt; l1 = ['Call','me','Ishmell','_']&gt;&gt;&gt; l1[0]'Call'&gt;&gt;&gt; l1[0][0]'C' 注意：列表是可变的，可以在原处进行修改，且内容改变，id 不会改变 1234567891011121314&gt;&gt;&gt; print(l1)['Call', 'me', 'Ishmell', '_']&gt;&gt;&gt; print(l1[1])me&gt;&gt;&gt; l1[1] = 'your'&gt;&gt;&gt; print(l1)['Call', 'your', 'Ishmell', '_']&gt;&gt;&gt; id(l1)1543556324360&gt;&gt;&gt; l1[2]= 'Xshell'&gt;&gt;&gt; print(l1)['Call', 'your', 'Xshell', '_']&gt;&gt;&gt; id(l1)1543556324360 ​ 元组：使用 () 创建，如(‘one’,’two’) 12345&gt;&gt;&gt; t1 = ('This','is')&gt;&gt;&gt; t1[1]'is'&gt;&gt;&gt; t1[0]'This' 注意: 元组是不能做原处修改的，一旦修改就会引发异常 ​ 字符串也属于序列类型 优点：可以做字符串的切块操作 123456789101112131415&gt;&gt;&gt; name = 'jerry'&gt;&gt;&gt; name[0]'j'&gt;&gt;&gt; name[0:1]'j'&gt;&gt;&gt; name[0:2]'je'&gt;&gt;&gt; name[:2]'je'&gt;&gt;&gt; name[2:]'rry'&gt;&gt;&gt; name[0:4]'jerr'&gt;&gt;&gt; name[0:4:2]'jr' 注意：切块本身会创建新的对象（因为字符串本身是不可用的） 集合类型 集合（杂乱的数据） 映射类型 字典 列表是可变序列，元组是不可变序列 Python 中，组合数据类型也是对象，因此其可以嵌套 [‘hello’,’worle’,[1,2,3]] 实质上，列表和元组并不是真正存储数据，而是存放对象引用 Python 对象可以具有其可以被调用的特定 “方法（函数）” 元组、列表以及字符串等数据类型是“有大小的”，也即，其长度可用内置函数 len() 测量 要素4：逻辑操作符 逻辑运算是任何程序设计语言的基本共能 Python 提供了4 组逻辑运算符 身份操作符 is:判断左端对象引用是否等于右端对象引用；也可以与Node进行； 对象引用可以不同，但是对象 所属的类型有可能是相同 1234&gt;&gt;&gt; name="swfswf"&gt;&gt;&gt; test="swfswf"&gt;&gt;&gt; type(name) is type(test)True 比较操作符号 &lt;,&gt;,&lt;=,&gt;=,!=,== 成员操作符 in 或 not in :测试成员关系 逻辑运算符 and、or、not 要素5：控制流语句 控制流语句是过程式编程语言的基本控制机制 Python 的常见控制流语句 if 1234567if boolean_expression1: suite1else if boolean_expression2: suite2.....else: else_suite 注意：冒号是代码块起始的标志 while 12while boolean_expression: suite for…in 12for variable in iterable: suite try 要素6：算数操作符 Python 提供了完整的算数操作符集 很多的 Python 数据类型也可以使用增强的赋值操作符，如+=、-= 等 同样的功能使用增强型赋值操作符的性能较好。 Python 的 int 类型是不可变的，因此，增强型赋值的实际过程是创建了一个新的对象来存储结果后将变量名执行了重新绑定 要素7：输入/输出 现实中，具有实际共能的程序必须能够读取输入（如从键盘或文件中），以及产生输出，并写到终端或文件中 Python 的输入/输出 输出 Python3：print() 函数 Python2: print 语句 输入 input() 12345678910&gt;&gt;&gt; input("plz input a num:")plz input a num:a'a'&gt;&gt;&gt; input("plz input a num:")plz input a num:3'3'&gt;&gt;&gt; a = input("plz input a num:")plz input a num:Hello&gt;&gt;&gt; print(a)Hello row_input() Python 解释器提供了 3 中标准的文件对象，分别为标准输入、标准输出和标准错误，它们 sys 模块中分别以 sys.stdin、sys.stdout 和 sys.stderr 形式提供 Python 的 print 语句实现打印 从技术角度来讲，print 是把一个或多个对象转化为其文本表达形式，然后发送给标准输出或另一个类似文件的流 在 Python 中，打印与文件和流的概念联系紧密 文件写入方法是把字符串写入到任意文件 print 默认把对象打印到 stdout 流，并添加一些自动的格式化 实质上，print 语句只是 Python 的人性化特性的具体实现，它提供了 sys.stdout.write() 的简单接口，再加上一些默认的格式设置 print 接受一个逗号分隔的对象列表，并为行尾自动添加一个换行符，如果不需要，则在最后个元素后面添加逗号 实现格式化输出，print “String %format1%format2…”%(varialbe1,varialbe2,…….) | 字符 | 输出格式 || —- | ————————– || d,i | 十进制整数或长整型 || u | 无符号整数或长整型 || o | 八进制整数或长整型 || x | 十六进制整数或长整型 || X | 十六进制整数 || f | 浮点数 || e | 浮点数 || E | 浮点数 || g,G | 指数小于-4或更高精度时使用%e或%E,否则使用%f || s | 字符串火任意对象，格式化代码使用str()生成字符串 || r | 同 repr() 生成的字符串 || c | 单个字符 || % | 字面量% | ​ 1234567891011121314151617&gt;&gt;&gt; num = 7.9&gt;&gt;&gt; print("The num is %f" %num)The num is 7.900000&gt;&gt;&gt; print("The num is %d" %num)The num is 7&gt;&gt;&gt; num2 = 9.13&gt;&gt;&gt; print("The nums are %d and %f" %(num,num2))The nums are 7 and 9.130000&gt;&gt;&gt; print("The nums are %e and %f"%(num,3.1))The nums are 7.900000e+00 and 3.100000&gt;&gt;&gt; print("The nums are %d and %f"%(num,3.1))The nums are 7 and 3.100000&gt;&gt;&gt; name = "Jerry"&gt;&gt;&gt; print("The name is %s."%name)The name is Jerry.&gt;&gt;&gt; print("The name is %s."%num)The name is 7.9. 注意：Python 的输出是需要转换的。 数据转换类型： 显示转换 123456&gt;&gt;&gt; num = 7.9&gt;&gt;&gt; test3 = str(num)&gt;&gt;&gt; type(test3)&lt;class 'str'&gt;&gt;&gt;&gt; type(num)&lt;class 'float'&gt; 隐式转换 想知道内置有多少种类型 python3 123&gt;&gt;&gt; dir()['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'name', 'num', 'num2', 'test3']&gt;&gt;&gt; dir(__builtins__) python2 123&gt;&gt;&gt;dir(builtins)['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'name', 'num', 'num2', 'test3']&gt;&gt;&gt; dir(__builtins__) 想明确一个工具怎么使用 1234567891011&gt;&gt;&gt; help(str)Help on class str in module builtins:class str(object) | str(object='') -&gt; str | str(bytes_or_buffer[, encoding[, errors]]) -&gt; str | | Create a new string object from the given object. If encoding or | errors is specified, then the object must expose a data buffer | that will be decoded using the given encoding and error handler. .... % 后面可以使用的修饰符，（如果有只能按如下的顺序） 1%[(name)][flags][width][.precision]typecode 位于括号中的一个属性后面的字典的键名，用于选出一个具体项 下面标志中的一个或多个 减号（-）:表示左对齐，默认为右对齐 1234&gt;&gt;&gt; print("The name are %+10f and %+f"%(num,-3.1))The name are +7.900000 and -3.100000&gt;&gt;&gt; print("The name are %-20f and %+f"%(num,-3.1))The name are 7.900000 and -3.100000 ​ 加号（+）:表示包含数字符号，整数也会带 “+” 1234567891011&gt;&gt;&gt;num=7.9&gt;&gt;&gt; print("The name are %+e and %f"%(num,3.1))The name are +7.900000e+00 and 3.100000&gt;&gt;&gt; print("The name are %+e and %+f"%(num,3.1))The name are +7.900000e+00 and +3.100000&gt;&gt;&gt; print("The name are %+e and %f"%(num,-3.1))The name are +7.900000e+00 and -3.100000&gt;&gt;&gt; print("The name are %+e and %+f"%(num,-3.1))The name are +7.900000e+00 and -3.100000&gt;&gt;&gt; print("The name are %f and %f"%(num,-3.1))The name are 7.900000 and -3.100000 零（0）:表示一个零填充 一个指定最小宽度的数 一个小数,用于按照精度分割字段的宽度(如下例子：15指小数占15位数) 12&gt;&gt;&gt; print("The name are %-20.15f and %+f"%(num,-3.1))The name are 7.900000000000000 and -3.100000 一个数字,指定要打印字符串中的最大字符个数，浮点数中小数点之后的位数，或者整数最小位数。 字典：kv集合（键值对集合） 123456&gt;&gt;&gt; d1=&#123;'a':33,'b':66&#125;&gt;&gt;&gt; d1['a']33&gt;&gt;&gt; d1=&#123;0:33,1:66&#125; &gt;&gt;&gt; d1[0]33 注意字典也是可变对象;键可以是字符也可以是数字 12345&gt;&gt;&gt; d=&#123;'x':32,'y':27.490325,'z':65&#125; &gt;&gt;&gt; print("%(x)-10d %(y)0.3g"%d) 32 27.5 ​ 要素8：函数的创建与调用 函数实现模块化编程的组件 Python 使用 def 语句定义函数 12def functionName(arguments): suite 函数可以参数化，通过传递不同的参数来调用。 1234&gt;&gt;&gt; def printName(name): print(name)&gt;&gt;&gt; printName('Tony')Tony 注意：函数也是对象 每个 Python 函数都有一个返回值，默认为None,也可以使用 “return value” 明确定义返回值 def 会创建一个函数对象，并同时创建一个函数的对象引用 函数也是对象，可以存储在组合数据类型中，也可以作为参数传递给其他函数 callable() 可用于测试函数是否可调用 1234&gt;&gt;&gt; callable(name)False&gt;&gt;&gt; callable(printName)True Python 有众多内置函数 dir()、id()、type() 、str()、help()、len()、callable() 等等 Python 标准库拥有众多内置模块，这些模块拥有大量的函数 Python 模块实际上是包含 Python 代码的 .py 文件，其拥有自定义的函数与类及变量等 导入代码块使用 import 语句进行，后跟模块名称（不能指定模块文件的后缀.py） 导入一个模块后，可以访问其内部的任意函数、类及变量]]></content>
      <categories>
        <category>Python 基础</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 常用的内置（BIF）函数]]></title>
    <url>%2F2018%2F01%2F01%2F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python 常用的内置函数如果你遇到一个需求，且你认为这个需求很普遍，先想想有没有什么内置函数可以使用（BIF）。另外要记住：Python 3 包含 70 多个 BIF ，所以有大量现成的功能等着你来发现。 list()这是一个工厂函数，创建一个新的空列表。 1234import os;aTuole = (123,'xyz','zare','abc');aList = list(aTuole);print("列表元素：",aList); range()range() BIF 迭代固定次数。 可以提供你需要的控制来迭代指定的次数，而且可以用来生成一个从 0 直到（但不包含）某个数的数字列表。 一下是这个 BIF 的用法： 1234import os;# num 是目标标识符，会琢个赋值为 "range()" 生成的各个数字for num in range(4); print(num); F5 运行程序 enumerate()创建成对数据的一个编码列表，从 0 开始 先来做一个对比: 法1: 使用 range() 和 len() 来实现 123import os;aTuole = ('xyz','zare','abc'); print(i,aTuole[i]); 法2:使用enumerate () 来实现 1234import os;aTuole = ('xyz','zare','abc');for index,text in enumerate(aTuole): print(index,text); enumerate会将数组或列表组成一个索引序列。使我们再获取索引和索引内容的时候更加方便。 int()int()函数的作用是将一个数字或base类型的字符串转换成整数。 函数原型 int(x, base=10)，base缺省值为10，也就是说不指定base的值时，函数将x按十进制处理。 注意： x 可以是数字或字符串，但是base被赋值后 x 只能是字符串 x 作为字符串时必须是 base 类型，也就是说 x 变成数字时必须能用 base 进制表示 【1】 x 是数字的情况： 123int(2.345) # 2int(2e2) # 200int(23, 2) # 出错，base 被赋值后函数只接收字符串 【2】x 是字符串的情况： 12int('23', 16) # 35int('HI', 16) # 出错，HI不是个16进制数 【3】 base 可取值范围是 2~36，囊括了所有的英文字母(不区分大小写)，十六进制中F表示15，那么G将在二十进制中表示16，依此类推….Z在三十六进制中表示35 12int('FZ', 16) # 出错，FZ不能用十六进制表示int('FZ', 36) # 575 【4】字符串 0x 可以出现在十六进制中，视作十六进制的符号，同理 0b 可以出现在二进制中，除此之外视作数字 0 和字母 x 123int('0x10', 16) # 16，0x是十六进制的符号int('0x10', 17) # 出错，'0x10'中的 x 被视作英文字母 xint('0x10', 36) # 42804，36进制包含字母 x id()id(object)函数是返回对象object在其生命周期内位于内存中的地址，id函数的参数类型是一个对象。 注意： 我们需要明确一点就是在Python中一切皆对象，变量中存放的是对象的引用。这个确实有点难以理解，“一切皆对象”？对，在Python中确实是这样，包括我们之前经常用到的字符串常量，整型常量都是对象。 1234567import os;print(id(5));print( id('python'));x=2print(id(x));y='hello'print(id(y)); 这段代码的运行结果: 1234567import os;x=2print(id(2));print(id(x)); y='hello'print(id('hello')); print(id(y)); 运行结果: 结果说明:对于这个语句id(2)没有报错，就可以知道2在这里是一个对象。id(x)和id(2)的值是一样的，id(y)和id(‘hello’)的值也是一样的。 12345678x=2;print(id(x));y=2;print(id(y));s='hello';print(id(s));t=s;print(id(t)); 运行结果: 结果说明:id(x)和id(y)的结果是相同的，id(s)和id(t)的结果也是相同的。这说明x和y指向的是同一对象，而t和s也是指向的同一对象。x=2这句让变量x指向了int类型的对象2，而y=2这句执行时，并不重新为2分配空间，而是让y直接指向了已经存在的int类型的对象2.这个很好理解，因为本身只是想给y赋一个值2，而在内存中已经存在了这样一个int类型对象2，所以就直接让y指向了已经存在的对象。这样一来不仅能达到目的，还能节约内存空间。t=s这句变量互相赋值，也相当于是让t指向了已经存在的字符串类型的对象’hello’。 看这幅图就理解了： 1234567891011121314x=2;print(id(2)); print(id(x)); x=3;print(id(3)); print(id(x)); L=[1,2,3];M=L;print(id(L));print(id(M)); print(id(L[2])); L[0]=2;print(id(L)); print(M); 运行结果: 结果分析:两次的id(x)的值不同，这个可能让人有点难以理解。注意，在Python中，单一元素的对象是不允许更改的，比如整型数据、字符串、浮点数等。x=3这句的执行过程并不是先获取x原来指向的对象的地址，再把内存中的值更改为3，而是新申请一段内存来存储对象3，再让x去指向对象3，所以两次id(x)的值不同。然而为何改变了L中的某个子元素的值后，id(L)的值没有发生改变？在Python中，复杂元素的对象是允许更改的，比如列表、字典、元组等。Python中变量存储的是对象的引用，对于列表，其id()值返回的是列表第一个子元素L[0]的存储地址。就像上面的例子，L=[1,2,3]，这里的L有三个子元素L[0]，L[1]，L[2]，L[0]、L[1]、L[2]分别指向对象1、2、3，id(L)值和对象3的存储地址相同. 看下面这个图就明白了: 因为L和M指向的是同一对象，所以在更改了L中子元素的值后，M也相应改变了，但是id(L)值并没有改变，因为这句L[0]=2只是让L[0]重新指向了对象2，而L[0]本身的存储地址并没有发生改变，所以id(L)的值没有改变（ id(L)的值实际等于L[0]本身的存储地址）。 next()next()函数返回迭代器的下一个元素 1234567it = iter([10, 20, 30, 40])while True: try: x = next(it) print(x); # 或者 x = it.next() except StopIteration: break 运行结果:]]></content>
      <categories>
        <category>常用的内置（BIF）函数</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python发布包到pypi]]></title>
    <url>%2F2018%2F01%2F01%2F%E5%85%B1%E4%BA%AB%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[python发布包到pypipython更新太快了，甚至连这种发布上传机制都在不断的更新，这导致网上的一些关于python发布上传到pypi的教程都过时了，按着博文操作可能会失败。 pypi相关概念介绍关于pypi本身 pypi是专门用于存放第三方python包的地方，你可以在这里找别人分享的模块，也可以自己分享模块给别人。可以通过easy_install或者pip进行安装。pypi针对分享提供了两个平台，一个是测试发布平台，一个是正式发布平台，我们正式发布前可以先用测试发布平台发布，看是否正确，然后再采用正式发布平台． 关于python打包发布工具 python的打包安装工具也经历了很多次变化，由最早的distutils到setuptools到distribute又回到setuptools，后来还有disutils2以及distlib等，其中distutils是python标准库的一部分，它提出了采用setup.py机制安装和打包发布上传机制．setuptools(操作系统发布版本可能没有自带安装,需要自己额外安装)基于它扩展了很多功能，也是采用setup.py机制，针对安装额外提供了easy_install命令．distribute是setuptools的一个分之，后来又合并到setuptools了，所以姑且就把它看做是最新的setuptools吧！和我们打包最相关的貌似就是distutils或者setuptools，两者都可以用来打包发布并上传到pypi，后面介绍采用distutils，如果想更多的功能，比如想通过entry points扩展的一些功能，那么就要使用setuptools了．另外，还有一个工具可以用来发布到pypi，叫twine，需要额外安装．最后,需要确保自己的工具都是尽量新的,官方给出的版本参考:twine v1.8.0+ (recommended tool), setuptools 27+, or the distutils included with Python 3.4.6+,Python 3.5.3+, Python 3.6+, and 2.7.13+,升级的参考命令: sudo -H pip install -U pip setuptools twine 写一个 setup.py123456789from distutils.core import setup # 从 Python 发布工具导入 setup 函数setup( name='swfswf', # 要打包的模块名称 version='1.0', description='Python Distribution Utilities', author='shenwenfang', author_email='1978626782@qq.com', url='https://swenfang.github.io/', ) 也可参阅官方文档： https://docs.python.org/2/dis… 注意： 这里只是最基本的参考例子，执行打包会报警告，说缺少一些需要的文件，比如MANIFEST.in、readme.txt等等，暂时忽略即可。正式的项目中会复杂很多，甚至需要用到setuptools来扩展。这部分可以参考其他文档 为了保证效果，在打包之前我们可以验证setup.py的正确性。执行代码python setup.py check，输出一般是running check，如果有错误或者警告，就会在此之后显示.没有任何显示表示Distutils认可你这个setup.py文件 执行 python setup.py sdist upload -r pypi 创建发布并上传,如果想先上传到测试平台，可以执行 python setup.py sdist upload -r pypitest，成功后再执行上面命令上传到正式平台。注意，这一步的配置文件里面由于pypi的发布机制更新导致有一些问题的出现。 410错误：这个是pypi上传机制变更导致的,我虽然参考的是最新的blog，但是还是过时了！！！（.pypirc的repository过时了，很多博客说的repository: https://pypi.python.org/pypi会导致后面步骤操作出现410错误） ​ 打包发布到pypi基本流程： 注册 pypi 账号，如果期望测试发布，同时需要注册pypitest账号（可以采用相同的用户名和密码） 直接通过官网注册 https://pypi.python.org/pypi?…，填写用户名、密码、确认密码、邮箱， 但是需要验证邮件并确认激活。 创建配置文件, 该配置文件里面记录了你的账号信息以及要发布的平台信息，参考如下配置文件创建即可 在自己的用户目录下新建一个空白文件命名为.pypirc，内容如下： 123456789101112[distutils]index-servers=pypi[pypi]repository = https://upload.pypi.org/legacy/username = shenwenfangpassword = **************# 如果期望测试发布，同时需要#repository: https://test.pypi.org/legacy/#username= your_username#password= your_password 相关命令： 1python setup.py check #验证setup.py的正确性 1python setup.py sdist upload -r pypi #打包发布到pypi，返回 "Server response (200) : OK" 说明上传成功 查看上传记录： 如果你的包已经上传成功，那么当你登录PyPI网站后应该能在右侧导航栏看到管理入口。 测试代码块12import swfswf;swfswf.print_lol(参数1，参数2...) 管理你的包如果你的包已经上传成功，那么当你登录PyPI网站后应该能在右侧导航栏看到管理入口。 点击包名进去后你可以对你的包进行管理，当然你也可以从这里删除这个包。 让别人使用你的包包发布完成后，其他人只需要使用pip就可以安装你的包文件。比如： 1pip install package-name 如果你更新了包，别人可以可以通过--update参数来更新： 1pip install package-name --update 可能遇到的错误 410错误：.pypirc的repository过时了，很多博客说的repository: https://pypi.python.org/pypi会导致后面步骤操作出现410错误 403错误：是因为项目和已有 的项目重名了，可以先到 https://pypi.python.org/simple/ 上搜一下看看是否重名。解决的方法自然就是修改一下setup.py中setup函数中的name参数，删除之前生成的dist文件夹并重新生成，然后再upload 参考文章： https://www.xncoding.com/2015/10/26/python/setuptools.html https://segmentfault.com/a/1190000008663126 http://www.cnblogs.com/rongpmcu/p/7662821.html]]></content>
      <categories>
        <category>发布包到pypi</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 红黑树源码解读]]></title>
    <url>%2F2017%2F12%2F26%2FJava%20%E7%BA%A2%E9%BB%91%E6%A0%91%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[Java 红黑树源码解读目录红黑树的介绍红黑树(Red-Black Tree，简称R-B Tree)，它一种特殊的二叉查找树。红黑树是特殊的二叉查找树，意味着它满足二叉查找树的特征: 任意一个节点所包含的键值，大于等于左孩子的键值，小于等于右孩子的键值。除了具备该特性之外，红黑树还包括许多额外的信息。 红黑树的每个节点上都有存储位表示节点的颜色，颜色是红(Red)或黑(Black)。红黑树的特性:【1】 每个节点或者是黑色，或者是红色。【2】 根节点是黑色。【3】 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！]【4】 如果一个节点是红色的，则它的子节点必须是黑色的。【5】 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。 关于它的特性，需要注意的是：第一，特性(3)中的叶子节点，是只为空(NIL或null)的节点。第二，特性(5)，确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。 红黑树示意图如下： 红黑树的原理在研究红黑树原理，我们可以通过以下的实例进行 debug 调试，看它的整个执行过。接着再阅读以下内容，会比较容易理解红黑的原理，才能进一步深入研究清楚。 实例地址：https://github.com/KnIfER/RBTree-java 红黑树的实现(代码说明)红黑树的基本操作是添加、删除和旋转。在对红黑树进行添加或删除后，会用到旋转方法。为什么呢？道理很简单，添加或删除红黑树中的节点之后，红黑树就发生了变化，可能不满足红黑树的5条性质，也就不再是一颗红黑树了，而是一颗普通的树。而通过旋转，可以使这颗树重新成为红黑树。简单点说，旋转的目的是让树保持红黑树的特性。旋转包括两种：左旋 和 右旋。下面分别对红黑树的基本操作进行介绍。 1. 基本定义1234567891011121314151617181920212223242526public class RBTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private RBTNode&lt;T&gt; mRoot; // 根结点 private static final boolean RED = false; private static final boolean BLACK = true; public class RBTNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; boolean color; // 颜色 T key; // 关键字(键值) RBTNode&lt;T&gt; left; // 左孩子 RBTNode&lt;T&gt; right; // 右孩子 RBTNode&lt;T&gt; parent; // 父结点 public RBTNode(T key, boolean color, RBTNode&lt;T&gt; parent, RBTNode&lt;T&gt; left, RBTNode&lt;T&gt; right) &#123; this.key = key; this.color = color; this.parent = parent; this.left = left; this.right = right; &#125; &#125; ...&#125; RBTree是红黑树对应的类，RBTNode是红黑树的节点类。在RBTree中包含了根节点mRoot和红黑树的相关API。注意：在实现红黑树API的过程中，我重载了许多函数。重载的原因，一是因为有的API是内部接口，有的是外部接口；二是为了让结构更加清晰。 2. 左旋 对x进行左旋，意味着”将x变成一个左节点”。 左旋的实现代码(Java语言) 1234567891011121314151617181920212223242526272829303132333435363738394041/* * 对红黑树的节点(x)进行左旋转 * * 左旋示意图(对节点x进行左旋)： * px px * / / * x y * / \ --(左旋)-. / \ # * lx y x ry * / \ / \ * ly ry lx ly * * */private void leftRotate(RBTNode&lt;T&gt; x) &#123; // 设置x的右孩子为y RBTNode&lt;T&gt; y = x.right; // 将 “y的左孩子” 设为 “x的右孩子”； // 如果y的左孩子非空，将 “x” 设为 “y的左孩子的父亲” x.right = y.left; if (y.left != null) y.left.parent = x; // 将 “x的父亲” 设为 “y的父亲” y.parent = x.parent; if (x.parent == null) &#123; this.mRoot = y; // 如果 “x的父亲” 是空节点，则将y设为根节点 &#125; else &#123; if (x.parent.left == x) x.parent.left = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子” else x.parent.right = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子” &#125; // 将 “x” 设为 “y的左孩子” y.left = x; // 将 “x的父节点” 设为 “y” x.parent = y;&#125; 3. 右旋 对y进行左旋，意味着”将y变成一个右节点”。 右旋的实现代码(Java语言) 1234567891011121314151617181920212223242526272829303132333435363738394041/* * 对红黑树的节点(y)进行右旋转 * * 右旋示意图(对节点y进行左旋)： * py py * / / * y x * / \ --(右旋)-. / \ # * x ry lx y * / \ / \ # * lx rx rx ry * */private void rightRotate(RBTNode&lt;T&gt; y) &#123; // 设置x是当前节点的左孩子。 RBTNode&lt;T&gt; x = y.left; // 将 “x的右孩子” 设为 “y的左孩子”； // 如果"x的右孩子"不为空的话，将 “y” 设为 “x的右孩子的父亲” y.left = x.right; if (x.right != null) x.right.parent = y; // 将 “y的父亲” 设为 “x的父亲” x.parent = y.parent; if (y.parent == null) &#123; this.mRoot = x; // 如果 “y的父亲” 是空节点，则将x设为根节点 &#125; else &#123; if (y == y.parent.right) y.parent.right = x; // 如果 y是它父节点的右孩子，则将x设为“y的父节点的右孩子” else y.parent.left = x; // (y是它父节点的左孩子) 将x设为“x的父节点的左孩子” &#125; // 将 “y” 设为 “x的右孩子” x.right = y; // 将 “y的父节点” 设为 “x” y.parent = x;&#125; 4. 添加将一个节点插入到红黑树中，需要执行哪些步骤呢？首先，将红黑树当作一颗二叉查找树，将节点插入；然后，将节点着色为红色；最后，通过”旋转和重新着色”等一系列操作来修正该树，使之重新成为一颗红黑树。详细描述如下：第一步: 将红黑树当作一颗二叉查找树，将节点插入。​ 红黑树本身就是一颗二叉查找树，将节点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。此外，无论是左旋还是右旋，若旋转之前这棵树是二叉查找树，旋转之后它一定还是二叉查找树。这也就意味着，任何的旋转和重新着色操作，都不会改变它仍然是一颗二叉查找树的事实。好吧？那接下来，我们就来想方设法的旋转以及重新着色，使这颗树重新成为红黑树！ 第二步：将插入的节点着色为”红色”。​ 为什么着色成红色，而不是黑色呢？为什么呢？在回答之前，我们需要重新温习一下红黑树的特性：(1) 每个节点或者是黑色，或者是红色。(2) 根节点是黑色。(3) 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！](4) 如果一个节点是红色的，则它的子节点必须是黑色的。(5) 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。​ 将插入的节点着色为红色，不会违背”特性(5)”！少违背一条特性，就意味着我们需要处理的情况越少。接下来，就要努力的让这棵树满足其它性质即可；满足了的话，它就又是一颗红黑树了。o(∩∩)o…哈哈 第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。​ 第二步中，将插入节点着色为”红色”之后，不会违背”特性(5)”。那它到底会违背哪些特性呢？​ 对于”特性(1)”，显然不会违背了。因为我们已经将它涂成红色了。​ 对于”特性(2)”，显然也不会违背。在第一步中，我们是将红黑树当作二叉查找树，然后执行的插入操作。而根据二叉查找数的特点，插入操作不会改变根节点。所以，根节点仍然是黑色。​ 对于”特性(3)”，显然不会违背了。这里的叶子节点是指的空叶子节点，插入非空节点并不会对它们造成影响。​ 对于”特性(4)”，是有可能违背的！​ 那接下来，想办法使之”满足特性(4)”，就可以将树重新构造成红黑树了。 添加操作的实现代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * 将结点插入到红黑树中 * * 参数说明： * node 插入的结点 // 对应《算法导论》中的node */private void insert(RBTNode&lt;T&gt; node) &#123; int cmp; RBTNode&lt;T&gt; y = null; RBTNode&lt;T&gt; x = this.mRoot; // 1. 将红黑树当作一颗二叉查找树，将节点添加到二叉查找树中。 while (x != null) &#123; y = x; cmp = node.key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else x = x.right; &#125; node.parent = y; if (y!=null) &#123; cmp = node.key.compareTo(y.key); if (cmp &lt; 0) y.left = node; else y.right = node; &#125; else &#123; this.mRoot = node; &#125; // 2. 设置节点的颜色为红色 node.color = RED; // 3. 将它重新修正为一颗二叉查找树 insertFixUp(node);&#125;/* * 新建结点(key)，并将其插入到红黑树中 * * 参数说明： * key 插入结点的键值 */public void insert(T key) &#123; RBTNode&lt;T&gt; node=new RBTNode&lt;T&gt;(key,BLACK,null,null,null); // 如果新建结点失败，则返回。 if (node != null) insert(node);&#125; 内部接口 – insert(node)的作用是将”node”节点插入到红黑树中。外部接口 – insert(key)的作用是将”key”添加到红黑树中。 添加修正操作的实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/* * 红黑树插入修正函数 * * 在向红黑树中插入节点之后(失去平衡)，再调用该函数； * 目的是将它重新塑造成一颗红黑树。 * * 参数说明： * node 插入的结点 // 对应《算法导论》中的z */private void insertFixUp(RBTNode&lt;T&gt; node) &#123; RBTNode&lt;T&gt; parent, gparent; // 若“父节点存在，并且父节点的颜色是红色” while (((parent = parentOf(node))!=null) &amp;&amp; isRed(parent)) &#123; // 获得祖父节点 gparent = parentOf(parent); //若“父节点”是“祖父节点的左孩子” if (parent == gparent.left) &#123; // Case 1条件：叔叔节点是红色 RBTNode&lt;T&gt; uncle = gparent.right; if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123; setBlack(uncle); setBlack(parent); setRed(gparent); node = gparent; continue; &#125; // Case 2条件：叔叔是黑色，且当前节点是右孩子 if (parent.right == node) &#123; RBTNode&lt;T&gt; tmp; leftRotate(parent); tmp = parent; parent = node; node = tmp; &#125; // Case 3条件：叔叔是黑色，且当前节点是左孩子。 setBlack(parent); setRed(gparent); rightRotate(gparent); &#125; else &#123; //若“z的父节点”是“z的祖父节点的右孩子” // Case 1条件：叔叔节点是红色 RBTNode&lt;T&gt; uncle = gparent.left; if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123; setBlack(uncle); setBlack(parent); setRed(gparent); node = gparent; continue; &#125; // Case 2条件：叔叔是黑色，且当前节点是左孩子 if (parent.left == node) &#123; RBTNode&lt;T&gt; tmp; rightRotate(parent); tmp = parent; parent = node; node = tmp; &#125; // Case 3条件：叔叔是黑色，且当前节点是右孩子。 setBlack(parent); setRed(gparent); leftRotate(gparent); &#125; &#125; // 将根节点设为黑色 setBlack(this.mRoot);&#125; insertFixUp(node)的作用是对应”上面所讲的第三步”。它是一个内部接口。 5. 删除操作将红黑树内的某一个节点删除。需要执行的操作依次是：首先，将红黑树当作一颗二叉查找树，将该节点从二叉查找树中删除；然后，通过”旋转和重新着色”等一系列来修正该树，使之重新成为一棵红黑树。详细描述如下：第一步：将红黑树当作一颗二叉查找树，将节点删除。​ 这和”删除常规二叉查找树中删除节点的方法是一样的”。分3种情况：① 被删除节点没有儿子，即为叶节点。那么，直接将该节点删除就OK了。② 被删除节点只有一个儿子。那么，直接删除该节点，并用该节点的唯一子节点顶替它的位置。③ 被删除节点有两个儿子。那么，先找出它的后继节点；然后把“它的后继节点的内容”复制给“该节点的内容”；之后，删除“它的后继节点”。在这里，后继节点相当于替身，在将后继节点的内容复制给”被删除节点”之后，再将后继节点删除。这样就巧妙的将问题转换为”删除后继节点”的情况了，下面就考虑后继节点。 在”被删除节点”有两个非空子节点的情况下，它的后继节点不可能是双子非空。既然”的后继节点”不可能双子都非空，就意味着”该节点的后继节点”要么没有儿子，要么只有一个儿子。若没有儿子，则按”情况① “进行处理；若只有一个儿子，则按”情况② “进行处理。 第二步：通过”旋转和重新着色”等一系列来修正该树，使之重新成为一棵红黑树。​ 因为”第一步”中删除节点之后，可能会违背红黑树的特性。所以需要通过”旋转和重新着色”来修正该树，使之重新成为一棵红黑树。 删除操作的实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/* * 删除结点(node)，并返回被删除的结点 * * 参数说明： * node 删除的结点 */private void remove(RBTNode&lt;T&gt; node) &#123; RBTNode&lt;T&gt; child, parent; boolean color; // 被删除节点的"左右孩子都不为空"的情况。 if ( (node.left!=null) &amp;&amp; (node.right!=null) ) &#123; // 被删节点的后继节点。(称为"取代节点") // 用它来取代"被删节点"的位置，然后再将"被删节点"去掉。 RBTNode&lt;T&gt; replace = node; // 获取后继节点 replace = replace.right; while (replace.left != null) replace = replace.left; // "node节点"不是根节点(只有根节点不存在父节点) if (parentOf(node)!=null) &#123; if (parentOf(node).left == node) parentOf(node).left = replace; else parentOf(node).right = replace; &#125; else &#123; // "node节点"是根节点，更新根节点。 this.mRoot = replace; &#125; // child是"取代节点"的右孩子，也是需要"调整的节点"。 // "取代节点"肯定不存在左孩子！因为它是一个后继节点。 child = replace.right; parent = parentOf(replace); // 保存"取代节点"的颜色 color = colorOf(replace); // "被删除节点"是"它的后继节点的父节点" if (parent == node) &#123; parent = replace; &#125; else &#123; // child不为空 if (child!=null) setParent(child, parent); parent.left = child; replace.right = node.right; setParent(node.right, replace); &#125; replace.parent = node.parent; replace.color = node.color; replace.left = node.left; node.left.parent = replace; if (color == BLACK) removeFixUp(child, parent); node = null; return ; &#125; if (node.left !=null) &#123; child = node.left; &#125; else &#123; child = node.right; &#125; parent = node.parent; // 保存"取代节点"的颜色 color = node.color; if (child!=null) child.parent = parent; // "node节点"不是根节点 if (parent!=null) &#123; if (parent.left == node) parent.left = child; else parent.right = child; &#125; else &#123; this.mRoot = child; &#125; if (color == BLACK) removeFixUp(child, parent); node = null;&#125;/* * 删除结点(z)，并返回被删除的结点 * * 参数说明： * tree 红黑树的根结点 * z 删除的结点 */public void remove(T key) &#123; RBTNode&lt;T&gt; node; if ((node = search(mRoot, key)) != null) remove(node);&#125; 内部接口 – remove(node)的作用是将”node”节点插入到红黑树中。外部接口 – remove(key)删除红黑树中键值为key的节点。 删除修正操作的实现代码(Java语言) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/* * 红黑树删除修正函数 * * 在从红黑树中删除插入节点之后(红黑树失去平衡)，再调用该函数； * 目的是将它重新塑造成一颗红黑树。 * * 参数说明： * node 待修正的节点 */private void removeFixUp(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123; RBTNode&lt;T&gt; other; while ((node==null || isBlack(node)) &amp;&amp; (node != this.mRoot)) &#123; if (parent.left == node) &#123; other = parent.right; if (isRed(other)) &#123; // Case 1: x的兄弟w是红色的 setBlack(other); setRed(parent); leftRotate(parent); other = parent.right; &#125; if ((other.left==null || isBlack(other.left)) &amp;&amp; (other.right==null || isBlack(other.right))) &#123; // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 setRed(other); node = parent; parent = parentOf(node); &#125; else &#123; if (other.right==null || isBlack(other.right)) &#123; // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 setBlack(other.left); setRed(other); rightRotate(other); other = parent.right; &#125; // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。 setColor(other, colorOf(parent)); setBlack(parent); setBlack(other.right); leftRotate(parent); node = this.mRoot; break; &#125; &#125; else &#123; other = parent.left; if (isRed(other)) &#123; // Case 1: x的兄弟w是红色的 setBlack(other); setRed(parent); rightRotate(parent); other = parent.left; &#125; if ((other.left==null || isBlack(other.left)) &amp;&amp; (other.right==null || isBlack(other.right))) &#123; // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 setRed(other); node = parent; parent = parentOf(node); &#125; else &#123; if (other.left==null || isBlack(other.left)) &#123; // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 setBlack(other.right); setRed(other); leftRotate(other); other = parent.left; &#125; // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。 setColor(other, colorOf(parent)); setBlack(parent); setBlack(other.left); rightRotate(parent); node = this.mRoot; break; &#125; &#125; &#125; if (node!=null) setBlack(node);&#125; removeFixup(node, parent)是对应”上面所讲的第三步”。它是一个内部接口。 红黑树的Java实现(完整源码)下面是红黑树实现的完整代码和相应的测试程序。(1) 除了上面所说的”左旋”、”右旋”、”添加”、”删除”等基本操作之后，还实现了”遍历”、”查找”、”打印”、”最小值”、”最大值”、”创建”、”销毁”等接口。(2) 函数接口大多分为内部接口和外部接口。内部接口是private函数，外部接口则是public函数。(3) 测试代码中提供了”插入”和”删除”动作的检测开关。默认是关闭的，打开方法可以参考”代码中的说明”。建议在打开开关后，在草稿上自己动手绘制一下红黑树。 红黑树的实现文件(RBTree.java) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692 1 /** 2 * Java 语言: 红黑树 3 * 4 * @author skywang 5 * @date 2013/11/07 6 */ 7 8 public class RBTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; 9 10 private RBTNode&lt;T&gt; mRoot; // 根结点 11 12 private static final boolean RED = false; 13 private static final boolean BLACK = true; 14 15 public class RBTNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; 16 boolean color; // 颜色 17 T key; // 关键字(键值) 18 RBTNode&lt;T&gt; left; // 左孩子 19 RBTNode&lt;T&gt; right; // 右孩子 20 RBTNode&lt;T&gt; parent; // 父结点 21 22 public RBTNode(T key, boolean color, RBTNode&lt;T&gt; parent, RBTNode&lt;T&gt; left, RBTNode&lt;T&gt; right) &#123; 23 this.key = key; 24 this.color = color; 25 this.parent = parent; 26 this.left = left; 27 this.right = right; 28 &#125; 29 30 public T getKey() &#123; 31 return key; 32 &#125; 33 34 public String toString() &#123; 35 return ""+key+(this.color==RED?"(R)":"B"); 36 &#125; 37 &#125; 38 39 public RBTree() &#123; 40 mRoot=null; 41 &#125; 42 43 private RBTNode&lt;T&gt; parentOf(RBTNode&lt;T&gt; node) &#123; 44 return node!=null ? node.parent : null; 45 &#125; 46 private boolean colorOf(RBTNode&lt;T&gt; node) &#123; 47 return node!=null ? node.color : BLACK; 48 &#125; 49 private boolean isRed(RBTNode&lt;T&gt; node) &#123; 50 return ((node!=null)&amp;&amp;(node.color==RED)) ? true : false; 51 &#125; 52 private boolean isBlack(RBTNode&lt;T&gt; node) &#123; 53 return !isRed(node); 54 &#125; 55 private void setBlack(RBTNode&lt;T&gt; node) &#123; 56 if (node!=null) 57 node.color = BLACK; 58 &#125; 59 private void setRed(RBTNode&lt;T&gt; node) &#123; 60 if (node!=null) 61 node.color = RED; 62 &#125; 63 private void setParent(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123; 64 if (node!=null) 65 node.parent = parent; 66 &#125; 67 private void setColor(RBTNode&lt;T&gt; node, boolean color) &#123; 68 if (node!=null) 69 node.color = color; 70 &#125; 71 72 /* 73 * 前序遍历"红黑树" 74 */ 75 private void preOrder(RBTNode&lt;T&gt; tree) &#123; 76 if(tree != null) &#123; 77 System.out.print(tree.key+" "); 78 preOrder(tree.left); 79 preOrder(tree.right); 80 &#125; 81 &#125; 82 83 public void preOrder() &#123; 84 preOrder(mRoot); 85 &#125; 86 87 /* 88 * 中序遍历"红黑树" 89 */ 90 private void inOrder(RBTNode&lt;T&gt; tree) &#123; 91 if(tree != null) &#123; 92 inOrder(tree.left); 93 System.out.print(tree.key+" "); 94 inOrder(tree.right); 95 &#125; 96 &#125; 97 98 public void inOrder() &#123; 99 inOrder(mRoot);100 &#125;101 102 103 /*104 * 后序遍历"红黑树"105 */106 private void postOrder(RBTNode&lt;T&gt; tree) &#123;107 if(tree != null)108 &#123;109 postOrder(tree.left);110 postOrder(tree.right);111 System.out.print(tree.key+" ");112 &#125;113 &#125;114 115 public void postOrder() &#123;116 postOrder(mRoot);117 &#125;118 119 120 /*121 * (递归实现)查找"红黑树x"中键值为key的节点122 */123 private RBTNode&lt;T&gt; search(RBTNode&lt;T&gt; x, T key) &#123;124 if (x==null)125 return x;126 127 int cmp = key.compareTo(x.key);128 if (cmp &lt; 0)129 return search(x.left, key);130 else if (cmp &gt; 0)131 return search(x.right, key);132 else133 return x;134 &#125;135 136 public RBTNode&lt;T&gt; search(T key) &#123;137 return search(mRoot, key);138 &#125;139 140 /*141 * (非递归实现)查找"红黑树x"中键值为key的节点142 */143 private RBTNode&lt;T&gt; iterativeSearch(RBTNode&lt;T&gt; x, T key) &#123;144 while (x!=null) &#123;145 int cmp = key.compareTo(x.key);146 147 if (cmp &lt; 0) 148 x = x.left;149 else if (cmp &gt; 0) 150 x = x.right;151 else152 return x;153 &#125;154 155 return x;156 &#125;157 158 public RBTNode&lt;T&gt; iterativeSearch(T key) &#123;159 return iterativeSearch(mRoot, key);160 &#125;161 162 /* 163 * 查找最小结点：返回tree为根结点的红黑树的最小结点。164 */165 private RBTNode&lt;T&gt; minimum(RBTNode&lt;T&gt; tree) &#123;166 if (tree == null)167 return null;168 169 while(tree.left != null)170 tree = tree.left;171 return tree;172 &#125;173 174 public T minimum() &#123;175 RBTNode&lt;T&gt; p = minimum(mRoot);176 if (p != null)177 return p.key;178 179 return null;180 &#125;181 182 /* 183 * 查找最大结点：返回tree为根结点的红黑树的最大结点。184 */185 private RBTNode&lt;T&gt; maximum(RBTNode&lt;T&gt; tree) &#123;186 if (tree == null)187 return null;188 189 while(tree.right != null)190 tree = tree.right;191 return tree;192 &#125;193 194 public T maximum() &#123;195 RBTNode&lt;T&gt; p = maximum(mRoot);196 if (p != null)197 return p.key;198 199 return null;200 &#125;201 202 /* 203 * 找结点(x)的后继结点。即，查找"红黑树中数据值大于该结点"的"最小结点"。204 */205 public RBTNode&lt;T&gt; successor(RBTNode&lt;T&gt; x) &#123;206 // 如果x存在右孩子，则"x的后继结点"为 "以其右孩子为根的子树的最小结点"。207 if (x.right != null)208 return minimum(x.right);209 210 // 如果x没有右孩子。则x有以下两种可能：211 // (01) x是"一个左孩子"，则"x的后继结点"为 "它的父结点"。212 // (02) x是"一个右孩子"，则查找"x的最低的父结点，并且该父结点要具有左孩子"，找到的这个"最低的父结点"就是"x的后继结点"。213 RBTNode&lt;T&gt; y = x.parent;214 while ((y!=null) &amp;&amp; (x==y.right)) &#123;215 x = y;216 y = y.parent;217 &#125;218 219 return y;220 &#125;221 222 /* 223 * 找结点(x)的前驱结点。即，查找"红黑树中数据值小于该结点"的"最大结点"。224 */225 public RBTNode&lt;T&gt; predecessor(RBTNode&lt;T&gt; x) &#123;226 // 如果x存在左孩子，则"x的前驱结点"为 "以其左孩子为根的子树的最大结点"。227 if (x.left != null)228 return maximum(x.left);229 230 // 如果x没有左孩子。则x有以下两种可能：231 // (01) x是"一个右孩子"，则"x的前驱结点"为 "它的父结点"。232 // (01) x是"一个左孩子"，则查找"x的最低的父结点，并且该父结点要具有右孩子"，找到的这个"最低的父结点"就是"x的前驱结点"。233 RBTNode&lt;T&gt; y = x.parent;234 while ((y!=null) &amp;&amp; (x==y.left)) &#123;235 x = y;236 y = y.parent;237 &#125;238 239 return y;240 &#125;241 242 /* 243 * 对红黑树的节点(x)进行左旋转244 *245 * 左旋示意图(对节点x进行左旋)：246 * px px247 * / /248 * x y 249 * / \ --(左旋)-. / \ #250 * lx y x ry 251 * / \ / \252 * ly ry lx ly 253 *254 *255 */256 private void leftRotate(RBTNode&lt;T&gt; x) &#123;257 // 设置x的右孩子为y258 RBTNode&lt;T&gt; y = x.right;259 260 // 将 “y的左孩子” 设为 “x的右孩子”；261 // 如果y的左孩子非空，将 “x” 设为 “y的左孩子的父亲”262 x.right = y.left;263 if (y.left != null)264 y.left.parent = x;265 266 // 将 “x的父亲” 设为 “y的父亲”267 y.parent = x.parent;268 269 if (x.parent == null) &#123;270 this.mRoot = y; // 如果 “x的父亲” 是空节点，则将y设为根节点271 &#125; else &#123;272 if (x.parent.left == x)273 x.parent.left = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子”274 else275 x.parent.right = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子”276 &#125;277 278 // 将 “x” 设为 “y的左孩子”279 y.left = x;280 // 将 “x的父节点” 设为 “y”281 x.parent = y;282 &#125;283 284 /* 285 * 对红黑树的节点(y)进行右旋转286 *287 * 右旋示意图(对节点y进行左旋)：288 * py py289 * / /290 * y x 291 * / \ --(右旋)-. / \ #292 * x ry lx y 293 * / \ / \ #294 * lx rx rx ry295 * 296 */297 private void rightRotate(RBTNode&lt;T&gt; y) &#123;298 // 设置x是当前节点的左孩子。299 RBTNode&lt;T&gt; x = y.left;300 301 // 将 “x的右孩子” 设为 “y的左孩子”；302 // 如果"x的右孩子"不为空的话，将 “y” 设为 “x的右孩子的父亲”303 y.left = x.right;304 if (x.right != null)305 x.right.parent = y;306 307 // 将 “y的父亲” 设为 “x的父亲”308 x.parent = y.parent;309 310 if (y.parent == null) &#123;311 this.mRoot = x; // 如果 “y的父亲” 是空节点，则将x设为根节点312 &#125; else &#123;313 if (y == y.parent.right)314 y.parent.right = x; // 如果 y是它父节点的右孩子，则将x设为“y的父节点的右孩子”315 else316 y.parent.left = x; // (y是它父节点的左孩子) 将x设为“x的父节点的左孩子”317 &#125;318 319 // 将 “y” 设为 “x的右孩子”320 x.right = y;321 322 // 将 “y的父节点” 设为 “x”323 y.parent = x;324 &#125;325 326 /*327 * 红黑树插入修正函数328 *329 * 在向红黑树中插入节点之后(失去平衡)，再调用该函数；330 * 目的是将它重新塑造成一颗红黑树。331 *332 * 参数说明：333 * node 插入的结点 // 对应《算法导论》中的z334 */335 private void insertFixUp(RBTNode&lt;T&gt; node) &#123;336 RBTNode&lt;T&gt; parent, gparent;337 338 // 若“父节点存在，并且父节点的颜色是红色”339 while (((parent = parentOf(node))!=null) &amp;&amp; isRed(parent)) &#123;340 gparent = parentOf(parent);341 342 //若“父节点”是“祖父节点的左孩子”343 if (parent == gparent.left) &#123;344 // Case 1条件：叔叔节点是红色345 RBTNode&lt;T&gt; uncle = gparent.right;346 if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123;347 setBlack(uncle);348 setBlack(parent);349 setRed(gparent);350 node = gparent;351 continue;352 &#125;353 354 // Case 2条件：叔叔是黑色，且当前节点是右孩子355 if (parent.right == node) &#123;356 RBTNode&lt;T&gt; tmp;357 leftRotate(parent);358 tmp = parent;359 parent = node;360 node = tmp;361 &#125;362 363 // Case 3条件：叔叔是黑色，且当前节点是左孩子。364 setBlack(parent);365 setRed(gparent);366 rightRotate(gparent);367 &#125; else &#123; //若“z的父节点”是“z的祖父节点的右孩子”368 // Case 1条件：叔叔节点是红色369 RBTNode&lt;T&gt; uncle = gparent.left;370 if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123;371 setBlack(uncle);372 setBlack(parent);373 setRed(gparent);374 node = gparent;375 continue;376 &#125;377 378 // Case 2条件：叔叔是黑色，且当前节点是左孩子379 if (parent.left == node) &#123;380 RBTNode&lt;T&gt; tmp;381 rightRotate(parent);382 tmp = parent;383 parent = node;384 node = tmp;385 &#125;386 387 // Case 3条件：叔叔是黑色，且当前节点是右孩子。388 setBlack(parent);389 setRed(gparent);390 leftRotate(gparent);391 &#125;392 &#125;393 394 // 将根节点设为黑色395 setBlack(this.mRoot);396 &#125;397 398 /* 399 * 将结点插入到红黑树中400 *401 * 参数说明：402 * node 插入的结点 // 对应《算法导论》中的node403 */404 private void insert(RBTNode&lt;T&gt; node) &#123;405 int cmp;406 RBTNode&lt;T&gt; y = null;407 RBTNode&lt;T&gt; x = this.mRoot;408 409 // 1. 将红黑树当作一颗二叉查找树，将节点添加到二叉查找树中。410 while (x != null) &#123;411 y = x;412 cmp = node.key.compareTo(x.key);413 if (cmp &lt; 0)414 x = x.left;415 else416 x = x.right;417 &#125;418 419 node.parent = y;420 if (y!=null) &#123;421 cmp = node.key.compareTo(y.key);422 if (cmp &lt; 0)423 y.left = node;424 else425 y.right = node;426 &#125; else &#123;427 this.mRoot = node;428 &#125;429 430 // 2. 设置节点的颜色为红色431 node.color = RED;432 433 // 3. 将它重新修正为一颗二叉查找树434 insertFixUp(node);435 &#125;436 437 /* 438 * 新建结点(key)，并将其插入到红黑树中439 *440 * 参数说明：441 * key 插入结点的键值442 */443 public void insert(T key) &#123;444 RBTNode&lt;T&gt; node=new RBTNode&lt;T&gt;(key,BLACK,null,null,null);445 446 // 如果新建结点失败，则返回。447 if (node != null)448 insert(node);449 &#125;450 451 452 /*453 * 红黑树删除修正函数454 *455 * 在从红黑树中删除插入节点之后(红黑树失去平衡)，再调用该函数；456 * 目的是将它重新塑造成一颗红黑树。457 *458 * 参数说明：459 * node 待修正的节点460 */461 private void removeFixUp(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123;462 RBTNode&lt;T&gt; other;463 464 while ((node==null || isBlack(node)) &amp;&amp; (node != this.mRoot)) &#123;465 if (parent.left == node) &#123;466 other = parent.right;467 if (isRed(other)) &#123;468 // Case 1: x的兄弟w是红色的 469 setBlack(other);470 setRed(parent);471 leftRotate(parent);472 other = parent.right;473 &#125;474 475 if ((other.left==null || isBlack(other.left)) &amp;&amp;476 (other.right==null || isBlack(other.right))) &#123;477 // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 478 setRed(other);479 node = parent;480 parent = parentOf(node);481 &#125; else &#123;482 483 if (other.right==null || isBlack(other.right)) &#123;484 // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 485 setBlack(other.left);486 setRed(other);487 rightRotate(other);488 other = parent.right;489 &#125;490 // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。491 setColor(other, colorOf(parent));492 setBlack(parent);493 setBlack(other.right);494 leftRotate(parent);495 node = this.mRoot;496 break;497 &#125;498 &#125; else &#123;499 500 other = parent.left;501 if (isRed(other)) &#123;502 // Case 1: x的兄弟w是红色的 503 setBlack(other);504 setRed(parent);505 rightRotate(parent);506 other = parent.left;507 &#125;508 509 if ((other.left==null || isBlack(other.left)) &amp;&amp;510 (other.right==null || isBlack(other.right))) &#123;511 // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 512 setRed(other);513 node = parent;514 parent = parentOf(node);515 &#125; else &#123;516 517 if (other.left==null || isBlack(other.left)) &#123;518 // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 519 setBlack(other.right);520 setRed(other);521 leftRotate(other);522 other = parent.left;523 &#125;524 525 // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。526 setColor(other, colorOf(parent));527 setBlack(parent);528 setBlack(other.left);529 rightRotate(parent);530 node = this.mRoot;531 break;532 &#125;533 &#125;534 &#125;535 536 if (node!=null)537 setBlack(node);538 &#125;539 540 /* 541 * 删除结点(node)，并返回被删除的结点542 *543 * 参数说明：544 * node 删除的结点545 */546 private void remove(RBTNode&lt;T&gt; node) &#123;547 RBTNode&lt;T&gt; child, parent;548 boolean color;549 550 // 被删除节点的"左右孩子都不为空"的情况。551 if ( (node.left!=null) &amp;&amp; (node.right!=null) ) &#123;552 // 被删节点的后继节点。(称为"取代节点")553 // 用它来取代"被删节点"的位置，然后再将"被删节点"去掉。554 RBTNode&lt;T&gt; replace = node;555 556 // 获取后继节点557 replace = replace.right;558 while (replace.left != null)559 replace = replace.left;560 561 // "node节点"不是根节点(只有根节点不存在父节点)562 if (parentOf(node)!=null) &#123;563 if (parentOf(node).left == node)564 parentOf(node).left = replace;565 else566 parentOf(node).right = replace;567 &#125; else &#123;568 // "node节点"是根节点，更新根节点。569 this.mRoot = replace;570 &#125;571 572 // child是"取代节点"的右孩子，也是需要"调整的节点"。573 // "取代节点"肯定不存在左孩子！因为它是一个后继节点。574 child = replace.right;575 parent = parentOf(replace);576 // 保存"取代节点"的颜色577 color = colorOf(replace);578 579 // "被删除节点"是"它的后继节点的父节点"580 if (parent == node) &#123;581 parent = replace;582 &#125; else &#123;583 // child不为空584 if (child!=null)585 setParent(child, parent);586 parent.left = child;587 588 replace.right = node.right;589 setParent(node.right, replace);590 &#125;591 592 replace.parent = node.parent;593 replace.color = node.color;594 replace.left = node.left;595 node.left.parent = replace;596 597 if (color == BLACK)598 removeFixUp(child, parent);599 600 node = null;601 return ;602 &#125;603 604 if (node.left !=null) &#123;605 child = node.left;606 &#125; else &#123;607 child = node.right;608 &#125;609 610 parent = node.parent;611 // 保存"取代节点"的颜色612 color = node.color;613 614 if (child!=null)615 child.parent = parent;616 617 // "node节点"不是根节点618 if (parent!=null) &#123;619 if (parent.left == node)620 parent.left = child;621 else622 parent.right = child;623 &#125; else &#123;624 this.mRoot = child;625 &#125;626 627 if (color == BLACK)628 removeFixUp(child, parent);629 node = null;630 &#125;631 632 /* 633 * 删除结点(z)，并返回被删除的结点634 *635 * 参数说明：636 * tree 红黑树的根结点637 * z 删除的结点638 */639 public void remove(T key) &#123;640 RBTNode&lt;T&gt; node; 641 642 if ((node = search(mRoot, key)) != null)643 remove(node);644 &#125;645 646 /*647 * 销毁红黑树648 */649 private void destroy(RBTNode&lt;T&gt; tree) &#123;650 if (tree==null)651 return ;652 653 if (tree.left != null)654 destroy(tree.left);655 if (tree.right != null)656 destroy(tree.right);657 658 tree=null;659 &#125;660 661 public void clear() &#123;662 destroy(mRoot);663 mRoot = null;664 &#125;665 666 /*667 * 打印"红黑树"668 *669 * key -- 节点的键值 670 * direction -- 0，表示该节点是根节点;671 * -1，表示该节点是它的父结点的左孩子;672 * 1，表示该节点是它的父结点的右孩子。673 */674 private void print(RBTNode&lt;T&gt; tree, T key, int direction) &#123;675 676 if(tree != null) &#123;677 678 if(direction==0) // tree是根节点679 System.out.printf("%2d(B) is root\n", tree.key);680 else // tree是分支节点681 System.out.printf("%2d(%s) is %2d's %6s child\n", tree.key, isRed(tree)?"R":"B", key, direction==1?"right" : "left");682 683 print(tree.left, tree.key, -1);684 print(tree.right,tree.key, 1);685 &#125;686 &#125;687 688 public void print() &#123;689 if (mRoot != null)690 print(mRoot, mRoot.key, 0);691 &#125;692 &#125; 红黑树的测试文件(RBTreeTest.java) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 1 /** 2 * Java 语言: 二叉查找树 3 * 4 * @author skywang 5 * @date 2013/11/07 6 */ 7 public class RBTreeTest &#123; 8 9 private static final int a[] = &#123;10, 40, 30, 60, 90, 70, 20, 50, 80&#125;;10 private static final boolean mDebugInsert = false; // "插入"动作的检测开关(false，关闭；true，打开)11 private static final boolean mDebugDelete = false; // "删除"动作的检测开关(false，关闭；true，打开)12 13 public static void main(String[] args) &#123;14 int i, ilen = a.length;15 RBTree&lt;Integer&gt; tree=new RBTree&lt;Integer&gt;();16 17 System.out.printf("== 原始数据: ");18 for(i=0; i&lt;ilen; i++)19 System.out.printf("%d ", a[i]);20 System.out.printf("\n");21 22 for(i=0; i&lt;ilen; i++) &#123;23 tree.insert(a[i]);24 // 设置mDebugInsert=true,测试"添加函数"25 if (mDebugInsert) &#123;26 System.out.printf("== 添加节点: %d\n", a[i]);27 System.out.printf("== 树的详细信息: \n");28 tree.print();29 System.out.printf("\n");30 &#125;31 &#125;32 33 System.out.printf("== 前序遍历: ");34 tree.preOrder();35 36 System.out.printf("\n== 中序遍历: ");37 tree.inOrder();38 39 System.out.printf("\n== 后序遍历: ");40 tree.postOrder();41 System.out.printf("\n");42 43 System.out.printf("== 最小值: %s\n", tree.minimum());44 System.out.printf("== 最大值: %s\n", tree.maximum());45 System.out.printf("== 树的详细信息: \n");46 tree.print();47 System.out.printf("\n");48 49 // 设置mDebugDelete=true,测试"删除函数"50 if (mDebugDelete) &#123;51 for(i=0; i&lt;ilen; i++)52 &#123;53 tree.remove(a[i]);54 55 System.out.printf("== 删除节点: %d\n", a[i]);56 System.out.printf("== 树的详细信息: \n");57 tree.print();58 System.out.printf("\n");59 &#125;60 &#125;61 62 // 销毁二叉树63 tree.clear();64 &#125;65 &#125; 红黑树的Java测试程序前面已经给出了红黑树的测试代码(RBTreeTest.java)，这里就不再重复说明。下面是测试程序的运行结果： 12345678910111213141516== 原始数据: 10 40 30 60 90 70 20 50 80 == 前序遍历: 30 10 20 60 40 50 80 70 90 == 中序遍历: 10 20 30 40 50 60 70 80 90 == 后序遍历: 20 10 50 40 70 90 80 60 30 == 最小值: 10== 最大值: 90== 树的详细信息: 30(B) is root10(B) is 30&apos;s left child20(R) is 10&apos;s right child60(R) is 30&apos;s right child40(B) is 60&apos;s left child50(R) is 40&apos;s right child80(B) is 60&apos;s right child70(R) is 80&apos;s left child90(R) is 80&apos;s right child]]></content>
      <categories>
        <category>红黑树</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap 源码解读]]></title>
    <url>%2F2017%2F12%2F26%2FJava%208%20ConcurrentHashMap%20%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[Java 8 ConcurrentHashMap 源码解读 ConcurrentHashMap 当之无愧是支持并发最好的键值对（Map）集合。在日常编码中，出场率也相当之高。在jdk8中，集合类 ConcurrentHashMap 经 Doug Lea 大师之手，借助volatile语义以及CAS操作进行优化，使得该集合类更好地发挥出了并发的优势。与jdk7中相比，在原有段锁（Segment）的基础上，引入了数组＋链表＋红黑树的存储模型，在查询效率上花费了不少心思。 基础数据结构ConcurrentHashMap内存存储结构图大致如下： 概述1、设计首要目的：维护并发可读性（get、迭代相关）；次要目的：使空间消耗比HashMap相同或更好，且支持多线程高效率的初始插入（empty table）。 2、HashTable线程安全，但采用synchronized，多线程下效率低下。线程1put时，线程2无法put或get。 阅前了解在真正阅读 ConcurrentHashMap 源码之前，我们简单复习下关于volatile和CAS的概念，这样才能更好地帮助我们理解源码中的关键方法。 volatile语义java提供的关键字volatile是最轻量级的同步机制。当定义一个变量为volatile时，它就具备了三层语义： - 可见性（Visibility）：在多线程环境下，一个变量的写操作总是对其后的读取线程可见 - 原子性（Atomicity）：volatile的读/写操作具有原子性 - 有序性（Ordering）：禁止指令的重排序优化，JVM会通过插入内存屏障（Memory Barrier）指令来保证 就同步性能而言，大多数场景下volatile的总开销是要比锁低的。在ConcurrentHashMap的源码中，我们能看到频繁的volatile变量读取与写入。 CAS操作CAS一般被理解为原子操作。在java中，正是利用了处理器的CMPXCHG（intel）指令实现CAS操作。CAS需要接受原有期望值expected以及想要修改的新值x，只有在原有期望值与当前值相等时才会更新为x，否则为失败。在ConcurrentHashMap的方法中，大量使用CAS获取/修改互斥量，以达到多线程并发环境下的正确性。 ConcurrentHashMap 的常量12// maximum_capacity table的最大容量，必须为2次幂形式private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30 12// default_capacity table的默认初始容量，必须为2次幂形式private static final int DEFAULT_CAPACITY = 16 12// max_array_size MAX_VALUE=2^31-1=2147483647static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8 12// default_concurrency_leve 未被用到，用来兼容之前版本private static finalint DEFAULT_CONCURRENCY_LEVEL = 16 123// load_factor table的负载因子，当前节点数量超过 n * LOAD_FACTOR，执行扩容// 位操作表达式为 n - (n &gt;&gt;&gt; 2)private static final float LOAD_FACTOR = 0.75f 12// treeify_threshold 针对每个桶（bin），链表转换为红黑树的节点数阈值static final int TREEIFY_THRESHOLD = 8 12// 针对每个桶（bin），红黑树退化为链表的节点数阈值static final int UNTREEIFY_THRESHOLD = 6 12// min_treeify_capacity 最小的树的容量static final int MIN_TREEIFY_CAPACITY = 64 1234// 扩容线程每次最少要迁移16个hash桶// min_transfer_stride 在扩容中，参与的单个线程允许处理的最少table桶首节点个数// 虽然适当添加线程，会使得整个扩容过程变快，但需要考虑多线程内存同时分配的问题private static final int MIN_TRANSFER_STRIDE = 16 12// resize stamp bits sizeCtl 中记录 size 的 bit 数private static int RESIZE_STAMP_BITS = 16 12// max_resizers 2^15-1 参与扩容的最大线程数private static final int MAX_RESIZERS = (1&lt;&lt;(32-RESIZE_STAMP_BITS))-1 12// 32 - 16 = 16, sizeCtl 中记录 size 大小的偏移量private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS = 16 12// 转为 nodes的hash值、标示位static final int MOVED = -1 12// 树的根节点的 hash 值static final int TREEBIN = -2 12// ReservationNode 的 hash 值static final int RESERVED = -3 12345// 一些特定的哈希值代表不同含义static final int MOVED = -1; // hash for forwarding nodesstatic final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash 12// CPU数static final int NCPU = Runtime.getRuntime().availableProcessors() 123456789101112131415161718192021222324252627/** * 真正存储Node数据（桶首）节点的数组table * 所有Node节点根据hash分桶存储 * table数组中存储的是所有桶（bin）的首节点 * hash值相同的节点以链表形式分装在桶中 * 当一个桶中节点数达到8个时，转换为红黑树，提高查询效率 * 装载Node的数组，作为ConcurrentHashMap的数据容器，采用懒加载的方式 * 直到第一次插入数据的时候才会进行初始化操作，数组的大小总是为2的幂次方。 */transient volatile Node&lt;K,V&gt;[] table;// 扩容时候使用,平时为null，只有在扩容的时候才为非nullprivate transient volatile Node&lt;K,V&gt;[] nextTable;// 没有竞争条件时，使用private transient volatile long baseCount;// 扩容时，将table中的元素迁移至nextTable . 扩容时非空private transient volatile Node&lt;K,V&gt;[] nextTable;/** * 重要控制变量 * 根据变量的数值不同，类实例处于不同阶段 * 1. = -1 : 正在初始化 * 2. &lt; -1 : 正在扩容，数值为 -(1 + 参与扩容的线程数) * 3. = 0 : 创建时初始为0 * 4. &gt; 0 : 下一次扩容的大小 */private transient volatile int sizeCtl; ConcurrentHashMap 重要属性NodeKey-value entry, 继承自Map.Entry对象。 Node节点是ConcurrentHashMap存储数据的最基本结构。一个数据mapping节点中，存储4个变量：当前节点hash值、节点的key值、节点的value值、指向下一个节点的指针next。其中在子类中的hash可以为负数，具有特殊的并发处理意义，后文会解释。除了具有特殊意义的子类，Node中的key和val不允许为null。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; // Node节点的hash值和key的hash值相同 // TreeNode节点的hash值 final int hash; final K key; volatile V val; //带有同步锁的value(保证可见性) volatile Node&lt;K,V&gt; next;//带有同步锁的next指针 Node(inthash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; // HashMap调用Objects.hashCode()，最终也是调用Object.hashCode()；效果一样 public final int hashCode() &#123; returnkey.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; returnkey + "=" + val; &#125; //不允许直接改变value的值 public final V setValue(V value) &#123; // 不允许修改value值，HashMap允许 throw new UnsupportedOperationException(); &#125; // HashMap使用if (o == this)，且嵌套if；concurrent使用&amp;&amp; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((oinstanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; Node&lt;K,V&gt; find(inth, Object k) &#123; // 增加find方法辅助get方法 Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; /** * 以链表形式查找桶中下一个Node信息 * 当转换为subclass红黑树节点TreeNode * 则使用TreeNode中的find进行查询操作 */ &#125; while ((e = e.next) != null); &#125; returnnull; &#125; &#125; 另外可以看出很多属性都是用volatile进行修饰的，也就是为了保证内存可见性。 这个Node内部类与HashMap中定义的Node类很相似，但是有一些差别 它对value和next属性设置了volatile同步锁 它不允许调用setValue方法直接改变Node的value域 它增加了find方法辅助map.get()方法 TreeNodeNode的子类，红黑树节点，当Node链表过长时，会转换成红黑树。 位于 ConcurrentHashMap 类的 2653行 或 搜索 / —————- TreeNodes ————– / 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// Nodes for use in TreeBins，链表&gt;8，才可能转为TreeNode. // HashMap的TreeNode继承至LinkedHashMap.Entry；而这里继承至自己实现的Node，将带有next指针，便于treebin访问。 static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(inthash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; Node&lt;K,V&gt; find(inth, Object k) &#123; return findTreeNode(h, k, null); &#125; /** * Returns the TreeNode (or null if not found) for the given key * starting at given root. */ // 查找hash为h，key为k的节点 final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) &#123; if (k != null) &#123; // 比HMap增加判空 TreeNode&lt;K,V&gt; p = this; do &#123; intph, dir; K pk; TreeNode&lt;K,V&gt; q; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right; if ((ph = p.hash) &gt; h) p = pl; elseif (ph &lt; h) p = pr; elseif ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) returnp; elseif (pl == null) p = pr; elseif (pr == null) p = pl; elseif ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; elseif ((q = pr.findTreeNode(h, k, kc)) != null) returnq; else p = pl; &#125; while (p != null); &#125; return null; &#125; &#125; // 和HashMap相比，这里的TreeNode相当简洁；ConcurrentHashMap链表转树时，并不会直接转，// 正如注释（Nodes for use in TreeBins）所说，只是把这些节点包装成TreeNode放到TreeBin中，// 再由TreeBin来转化红黑树。 树节点，继承于承载数据的Node类。而红黑树的操作是针对TreeBin类的，从该类的注释也可以看出，也就是TreeBin会将TreeNode进行再一次封装 TreeBin位于 ConcurrentHashMap 类的 2709 行 或 搜索 / —————- TreeBins ————– / 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// TreeBin用于封装维护TreeNode，包含putTreeVal、lookRoot、UNlookRoot、remove、// balanceInsetion、balanceDeletion等方法，这里只分析其构造函数。当链表转树时，// 用于封装TreeNode，也就是说，ConcurrentHashMap的红黑树存放的是TreeBin，而不是treeNode。 TreeBin(TreeNode&lt;K,V&gt; b) &#123; super(TREEBIN, null, null, null);//hash值为常量TREEBIN=-2,表示roots of trees this.first = b; TreeNode&lt;K,V&gt; r = null; for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (r == null) &#123; x.parent = null; x.red = false; r = x; &#125; else &#123; K k = x.key; inth = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = r;;) &#123; intdir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; elseif (ph &lt; h) dir = 1; elseif ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; r = balanceInsertion(r, x); break; &#125; &#125; &#125; &#125; this.root = r; assert checkInvariants(root); &#125; 这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象。 threeifyBin位于 ConcurrentHashMap 类的 2611 行 或 搜索 “private final void treeifyBin” 1234567891011121314151617181920212223242526private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; intn, sc; if (tab != null) &#123; // 数组的大小还未超过64 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); // 容量&lt;64，则table两倍扩容，不转树了 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; // 读写锁 if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125; &#125; ForwardingNode位于 ConcurrentHashMap 类的 2163 行 或 搜索 “static final class ForwardingNode” 123456789101112131415161718192021222324252627282930313233343536// A node inserted at head of bins during transfer operations.连接两个table // 并不是我们传统的包含key-value的节点，只是一个标志节点，并且指向nextTable，提供find方法而已。// 生命周期：仅存活于扩容操作且bin不为null时，一定会出现在每个bin的首位。 static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); // 此节点hash=-1，key、value、next均为null this.nextTable = tab; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; // 查nextTable节点，outer避免深度递归 outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; intn; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) returnnull; for (;;) &#123; // CAS算法多和死循环搭配！直到查到或null int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) returne; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125; &#125; &#125; 在扩容时才会出现的特殊节点，其key,value,hash全部为null。并拥有nextTable指针引用新的table数组。 Traverser123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102static class Traverser&lt;K,V&gt; &#123; Node&lt;K,V&gt;[] tab; //下一个要访问的entry Node&lt;K,V&gt; next; //发现forwardingNode时，保存当前tab相关信息 TableStack&lt;K,V&gt; stack, spare; //下一个要访问的hash桶索引 int index; //当前正在访问的初始tab的hash桶索引 int baseIndex; //初始tab的hash桶索引边界 int baseLimit; //初始tab的长度 final int baseSize; Traverser(Node&lt;K,V&gt;[] tab, int size, int index, int limit) &#123; this.tab = tab; this.baseSize = size; this.baseIndex = this.index = index; this.baseLimit = limit; this.next = null; &#125; // 如果有可能，返回下一个有效节点，否则返回null。 final Node&lt;K,V&gt; advance() &#123; Node&lt;K,V&gt; e; //获取Node链表的下一个元素e if ((e = next) != null) e = e.next; for (;;) &#123; Node&lt;K,V&gt;[] t; int i, n; // e不为空，返回e if (e != null) return next = e; //e为空，说明此链表已经遍历完成，准备遍历下一个hash桶 if (baseIndex &gt;= baseLimit || (t = tab) == null || (n = t.length) &lt;= (i = index) || i &lt; 0) //到达边界，返回null return next = null; //获取下一个hash桶对应的node链表的头节点 if ((e = tabAt(t, i)) != null &amp;&amp; e.hash &lt; 0) &#123; //转发节点,说明此hash桶中的节点已经迁移到了nextTable if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; e = null; //保存当前tab的遍历状态 pushState(t, i, n); continue; &#125; //红黑树 else if (e instanceof TreeBin) e = ((TreeBin&lt;K,V&gt;)e).first; else e = null; &#125; if (stack != null) // 此时遍历的是迁移目标nextTable,尝试回退到源table， // 继续遍历源table中的节点 recoverState(n); else if ((index = i + baseSize) &gt;= n) //初始tab的hash桶索引+1 ，即遍历下一个hash桶 index = ++baseIndex; &#125; &#125; // 在遇到转发节点时保存遍历状态。 private void pushState(Node&lt;K,V&gt;[] t, int i, int n) &#123; TableStack&lt;K,V&gt; s = spare; // reuse if possible if (s != null) spare = s.next; else s = new TableStack&lt;K,V&gt;(); s.tab = t; s.length = n; s.index = i; s.next = stack; stack = s; &#125;// 可能会弹出遍历状态 private void recoverState(int n) &#123; TableStack&lt;K,V&gt; s; int len; // (s = stack) != null :stack不空，说明此时遍历的是nextTable // (index += (len = s.length)) &gt;= n: 确保了按照index, //index+tab.length的顺序遍历nextTable,条件成立表示nextTable已经遍历完毕 //nextTable中的桶遍历完毕 while ((s = stack) != null &amp;&amp; (index += (len = s.length)) &gt;= n) &#123; //弹出tab，获取tab的遍历状态，开始遍历tab中的桶 n = len; index = s.index; tab = s.tab; s.tab = null; TableStack&lt;K,V&gt; next = s.next; s.next = spare; // save for reuse stack = next; spare = s; &#125; if (s == null &amp;&amp; (index += baseSize) &gt;= n) index = ++baseIndex; &#125;&#125; tryPresize(扩容)协调多个线程如何调用transfer方法进行hash桶的迁移（addCount，helpTransfer 方法中也有类似的逻辑） tryPresize在putAll以及treeifyBin中调用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private final void tryPresize(int size) &#123; //计算扩容的目标size // 给定的容量若&gt;=MAXIMUM_CAPACITY的一半，直接扩容到允许的最大值，否则调用函数扩容 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; //没有正在初始化或扩容，或者说表还没有被初始化 Node&lt;K,V&gt;[] tab = table; int n; //tab没有初始化 if(tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; // 扩容阀值取较大者 // 期间没有其他线程对表操作，则CAS将SIZECTL状态置为-1，表示正在进行初始化 //初始化之前，CAS设置sizeCtl=-1 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; //sc=0.75n,相当于扩容阈值 sc = n - (n &gt;&gt;&gt; 2); //无符号右移2位，此即0.75*n &#125; &#125; finally &#123; // 此时并没有通过CAS赋值，因为其他想要执行初始化的线程， // 发现sizeCtl=-1，就直接返回，从而确保任何情况， // 只会有一个线程执行初始化操作。 sizeCtl = sc; &#125; &#125; &#125;// 若欲扩容值不大于原阀值，或现有容量&gt;=最值，什么都不用做了 //目标扩容size小于扩容阈值，或者容量超过最大限制时，不需要扩容 else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; //扩容 else if (tab == table) &#123; int rs = resizeStamp(n); // sc&lt;0表示，已经有其他线程正在扩容 if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt;//RESIZE_STAMP_SHIFT=16,MAX_RESIZERS=2^15-1 // 1. (sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs ：扩容线程数 &gt; MAX_RESIZERS-1 // 2. sc == rs + 1 和 sc == rs + MAX_RESIZERS ：表示什么？？？ // 3. (nt = nextTable) == null ：表示nextTable正在初始化 // transferIndex &lt;= 0 ：表示所有hash桶均分配出去 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) //如果不需要帮其扩容，直接返回 break; //CAS设置sizeCtl=sizeCtl+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) //帮其扩容 transfer(tab, nt); &#125; // 第一个执行扩容操作的线程，将sizeCtl设置为： // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125; &#125; 123456789private static final int tableSizeFor(int c)&#123;//和HashMap一样,返回&gt;=n的最小2的自然数幂 int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; spread 重新哈希spread()重哈希，以减小Hash冲突。我们知道对于一个hash表来说，hash值分散的不够均匀的话会大大增加哈希冲突的概率，从而影响到hash表的性能。因此通过spread方法进行了一次重hash从而大大减小哈希冲突的可能性。spread方法为： 123static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; 该方法主要是将key的hashCode的低16位于高16位进行异或运算，这样不仅能够使得hash值能够分散能够均匀减小hash冲突的概率，另外另外只用到了异或运算，在性能开销上也能兼顾，做到平衡的trade-off。 get(查找)1234567891011121314151617181920212223242526272829303132public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 1. 重hash int h = spread(key.hashCode()); // 2. table[i]桶节点的key与查找的key相同，则直接返回 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; // 唯一一处volatile读操作 (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 注意：因为容器大小为2的次方，所以 h mod n = h &amp; (n -1) if ((eh = e.hash) == h) &#123;// 如果hash值相等 // 检查第一个Node if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // hash为负表示是扩容中的ForwardingNode节点 // 直接调用ForwardingNode的find方法(可以是代理到扩容中的nextTable) // 3. 当前节点hash小于0说明为树节点，在红黑树中查找即可 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表，对比key值 // 通过next指针，逐一查找 while ((e = e.next) != null) &#123; //4. 从链表中查找，查找到则返回该节点的value，否则就返回null即可 if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; 代码的逻辑请看注释，首先先看当前的hash桶数组节点即table[i]是否为查找的节点，若是则直接返回；若不是，则继续再看当前是不是树节点？通过看节点的hash值是否为小于0，如果小于0则为树节点。如果是树节点在红黑树中查找节点；如果不是树节点，那就只剩下为链表的形式的一种可能性了，就向后遍历查找节点，若查找到则返回节点的value即可，若没有找到就返回null。 这个 get 请求，我们需要 cas 来保证变量的原子性。如果 tab[i] 正被锁住，那么 CAS 就会失败，失败之后就会不断的重试。这也保证了在高并发情况下不会出错。 我们来分析一下哪些情况会导致 get 在并发的情况下可能取不到值。 一个线程在 get 的时候，另一个线程在对同一个 key 的 node 进行 remove 操作 一个线程在 get 的时候，另一个线程正在重排 table 。可能导致旧 table 取不到值 那么本质是，我在get的时候，有其他线程在对同一桶的链表或树进行修改。那么get是怎么保证同步性的呢？我们看到e = tabAt(tab, (n - 1) &amp; h)) != null，在看下tablAt到底是干嘛的： 123static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; 它是对tab[i]进行原子性的读取，因为我们知道putVal等对table的桶操作是有加锁的，那么一般情况下我们对桶的读也是要加锁的，但是我们这边为什么不需要加锁呢？因为我们用了Unsafe的getObjectVolatile，因为table是volatile类型，所以对tab[i]的原子请求也是可见的。因为如果同步正确的情况下，根据happens-before原则，对volatile域的写入操作happens-before于每一个后续对同一域的读操作。所以不管其他线程对table链表或树的修改，都对get读取可见。用一张图说明，协调读-写线程可见示意图： jdk7是没有用到CAS操作和Unsafe类的，下面是jdk7的get方法： 12345678910111213141516V get(Object key, int hash) &#123; if(count != 0) &#123; // 首先读 count 变量 HashEntry&lt;K,V&gt; e = getFirst(hash); while(e != null) &#123; if(e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if(v != null) return v; // 如果读到 value 域为 null，说明发生了重排序，加锁后重新读取 return readValueUnderLock(e); &#125; e = e.next; &#125; &#125; return null; &#125; 为什么我们在get的时候需要判断count不等于0呢？如果是在HashMap的源码中是没有这个判断的，不用判断不是也是可以的吗？这个就是用到线程安全发布情况下happens-before原则之volatile变量法则：对volatile域的写入操作happens-before于每一个后续对同一域的读操作，看下面的示意图： tabAt以 volatile 读的方式读取 table 数组中的元素 12345// 这边为什么i要等于((long)i &lt;&lt; ASHIFT) + ABASE呢,计算偏移量static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; // Key对应的数组元素的可见性，由Unsafe的getObjectVolatile方法保证。 return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; tabAt 方法用来获取table数组中索引为i的Node元素。 put/putValputVal是将一个新key-value mapping插入到当前ConcurrentHashMap的关键方法。 此方法的具体流程如下图： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // 不允许 key 和 value 为空 if (key == null || value == null) throw new NullPointerException(); // 1.计算 key 的 hash 值(计算新节点的hash值) int hash = spread(key.hashCode()); // 返回 (h^(h&gt;&gt;&gt;16))&amp;HASH_BITS int binCount = 0; // 获取当前table，进入死循环,直到插入成功！ for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 2. 如果当前 table 还没初始化先调用 initTable 方法将 tab 进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 如果table为空，执行初始化，也即是延迟初始化 // 3. tab中索引为i的位置的元素为null,则直接使用 CAS 将值插入即可 // 如果bin为空，则采用cas算法赋值，无需加锁 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null,new Node&lt;K,V&gt;(hash, key, value, null))) // 直接设置为桶首节点成功，退出死循环（出口之一） break; &#125; // 4. 当前正在扩容 // 当前桶首节点正在特殊的扩容状态下，当前线程尝试参与扩容 // 然后重新进入死循环 //f.hash == MOVED 表示为：ForwardingNode，说明其他线程正在扩容 else if ((fh = f.hash) == MOVED) // MOVED = -1 tab = helpTransfer(tab, f); // 当发现其他线程扩容时，帮其扩容 // 通过桶首节点，将新节点加入table else &#123; V oldVal = null; // 获取桶首节点实例对象锁，进入临界区进行添加操作 synchronized (f) &#123; // 再判断以此f是否仍是第一个Node，如果不是，退出临界区，重复添加操作 if (tabAt(tab, i) == f) &#123; //5. 当前为链表，在链表中插入新的键值对 if (fh &gt;= 0) &#123; // 桶首节点hash值&gt;0，表示为链表 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 找到hash值相同的key,覆盖旧值即可 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; // 仅 putIfAbsent() 方法中的 onlyIfAbsend 为 true; if (!onlyIfAbsent) // putIfAbsend() 包含 key 则返回 get ,否则 put 并返回 e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果到链表末尾仍未找到，则直接将新值插入到链表末尾即可 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 桶首节点为Node子类型TreeBin，表示为红黑树 // 6.当前为红黑树，将新的键值对插入到红黑树中 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; // 调用putTreeVal方法，插入新值 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; // key已经存在，则替换 oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // 7.插入完键值对后再根据实际大小看是否需要转换成红黑树 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) // 插入新节点后，达到链表转换红黑树阈值，则执行转换操作 // 此函数内部会判断是树化，还是扩容：tryPresize treeifyBin(tab, i); // 退出死循环（出口之二） if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 更新计算count时的base和counterCells数组 //8.对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容 addCount(1L, binCount); return null;&#125; 当table[i]为链表的头结点，在链表中插入新值在table[i]不为null并且不为forwardingNode时，并且当前Node f的hash值大于0（fh &gt;= 0）的话说明当前节点f为当前桶的所有的节点组成的链表的头结点。那么接下来，要想向ConcurrentHashMap插入新值的话就是向这个链表插入新值。通过synchronized (f)的方式进行加锁以实现线程安全性。往链表中插入节点的部分代码为： 12345678910111213141516171819202122if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 找到hash值相同的key,覆盖旧值即可 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; //如果到链表末尾仍未找到，则直接将新值插入到链表末尾即可 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125;&#125; 这部分代码很好理解，就是两种情况：1. 在链表中如果找到了与待插入的键值对的key相同的节点，就直接覆盖即可；2. 如果直到找到了链表的末尾都没有找到的话，就直接将待插入的键值对追加到链表的末尾即可。 当table[i]为红黑树的根节点，在红黑树中插入新值按照之前的数组+链表的设计方案，这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，甚至在极端情况下，查找一个节点会出现时间复杂度为O(n)的情况，则会严重影响ConcurrentHashMap的性能，于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高ConcurrentHashMap的性能，其中会用到红黑树的插入、删除、查找等算法。当table[i]为红黑树的树节点时的操作为： 12345678910if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125;&#125; 首先在if中通过f instanceof TreeBin判断当前table[i]是否是树节点，这下也正好验证了我们在最上面介绍时说的TreeBin会对TreeNode做进一步封装，对红黑树进行操作的时候针对的是TreeBin而不是TreeNode。这段代码很简单，调用putTreeVal方法完成向红黑树插入新节点，同样的逻辑，如果在红黑树中存在于待插入键值对的Key相同（hash值相等并且equals方法判断为true）的节点的话，就覆盖旧值，否则就向红黑树追加新节点。 当table[i]为红黑树的根节点，在红黑树中插入新值。按照之前的数组+链表的设计方案，这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，甚至在极端情况下，查找一个节点会出现时间复杂度为O(n)的情况，则会严重影响ConcurrentHashMap的性能，于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高ConcurrentHashMap的性能，其中会用到红黑树的插入、删除、查找等算法。当table[i]为红黑树的树节点时的操作为： 123456789if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125;&#125; 首先在if中通过f instanceof TreeBin判断当前table[i]是否是树节点，这下也正好验证了我们在最上面介绍时说的TreeBin会对TreeNode做进一步封装，对红黑树进行操作的时候针对的是TreeBin而不是TreeNode。这段代码很简单，调用putTreeVal方法完成向红黑树插入新节点，同样的逻辑，如果在红黑树中存在于待插入键值对的Key相同（hash值相等并且equals方法判断为true）的节点的话，就覆盖旧值，否则就向红黑树追加新节点。 根据当前节点个数进行调整当完成数据新节点插入之后，会进一步对当前链表大小进行调整，这部分代码为： 1234567if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break;&#125; 很容易理解，如果当前链表节点个数大于等于8（TREEIFY_THRESHOLD）的时候，就会调用treeifyBin方法将tabel[i]（第i个散列桶）拉链转换成红黑树。 关于Put方法的逻辑就基本说的差不多了，现在来做一些总结： 整体流程： 首先对于每一个放入的值，首先利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在 table中的位置； 如果当前table数组还未初始化，先将table数组进行初始化操作； 如果这个位置是null的，那么使用CAS操作直接放入； 如果这个位置存在结点，说明发生了hash碰撞，首先判断这个节点的类型。如果该节点fh==MOVED(代表forwardingNode,数组正在进行扩容)的话，说明正在进行扩容； 如果是链表节点（fh&gt;0）,则得到的结点就是hash值相同的节点组成的链表的头节点。需要依次向后遍历确定这个新加入的值所在位置。如果遇到hash值与key值都与新加入节点是一致的情况，则只需要更新value值即可。否则依次向后遍历，直到链表尾插入这个结点； 如果这个节点的类型是TreeBin的话，直接调用红黑树的插入方法进行插入新的节点； 插入完节点之后再次检查链表长度，如果长度大于8，就把这个链表转换成红黑树； 对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容。 该流程中，可以细细品味的环节有： - 初始化方法 initTable - 扩容方法 transfer (在多线程扩容方法 helpTransfer 中被调用) initTableinitTable方法允许多线程同时进入，但只有一个线程可以完成table的初始化，其他线程都会通过yield方法让出cpu。 12345678910111213141516171819202122232425262728293031323334353637private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; // 前文提及sizeCtl是重要的控制变量 // sizeCtl = -1 表示正在初始化 if ((sc = sizeCtl) &lt; 0) // 已经有其他线程在执行初始化，则主动让出cpu // 1. 保证只有一个线程正在进行初始化操作 Thread.yield(); // 利用CAS操作设置sizeCtl为-1 // 设置成功表示当前线程为执行初始化的唯一线程 // 此处进入临界区 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; // 由于让出cpu的线程也会后续进入该临界区 // 需要进行再次确认table是否为null if ((tab = table) == null || tab.length == 0) &#123; // 2. 得出数组的大小 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") // 3. 这里才真正的初始化数组，即分配Node数组 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 默认负载为0.75 // 4. 计算数组中可用的大小：实际大小n*0.75（加载因子） sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; // 退出死循环的唯一出口 break; &#125; &#125; return tab;&#125; 代码的逻辑请见注释，有可能存在一个情况是多个线程同时走到这个方法中，为了保证能够正确初始化，在第1步中会先通过if进行判断，若当前已经有一个线程正在初始化即sizeCtl值变为-1，这个时候其他线程在If判断为true从而调用Thread.yield()让出CPU时间片。正在进行初始化的线程会调用U.compareAndSwapInt方法将sizeCtl改为-1即正在初始化的状态。另外还需要注意的事情是，在第四步中会进一步计算数组中可用的大小即为数组实际大小n乘以加载因子0.75.可以看看这里乘以0.75是怎么算的，0.75为四分之三，这里n - (n &gt;&gt;&gt; 2)是不是刚好是n-(1/4)n=(3/4)n，挺有意思的吧:)。如果选择是无参的构造器的话，这里在new Node数组的时候会使用默认大小为DEFAULT_CAPACITY（16），然后乘以加载因子0.75为12，也就是说数组的可用大小为12。 casTabAt(原子操作方法)以 CAS 的方式，将元素插入到 table 数组 123456789101112/* *这边为什么i要等于((long)i &lt;&lt; ASHIFT) + ABASE呢,计算偏移量 *ASHIFT是指tab[i]中第i个元素在相对于数组第一个元素的偏移量，而ABASE就算第一数组的内存素的偏移地址 *所以呢，((long)i &lt;&lt; ASHIFT) + ABASE就算i最后的地址 * 那么compareAndSwapObject的作用就算tab[i]和c比较，如果相等就tab[i]=v否则tab[i]=c; */ // 利用CAS算法设置i位置上的Node节点（将c和table[i]比较，相同则插入v）。 static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; //原子的执行如下逻辑：如果tab[i]==c,则设置tab[i]=v，并返回ture.否则返回false return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v); &#125; 利用CAS操作设置table数组中索引为i的元素 setTabAt以 valatile 写的方式，将元素插入 table 数组 123static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; 该方法用来设置table数组中索引为i的元素 实例构造器方法在使用ConcurrentHashMap第一件事自然而然就是new 出来一个ConcurrentHashMap对象，一共提供了如下几个构造器方法： 12345678910// 1. 构造一个空的map，即table数组还未初始化，初始化放在第一次插入数据时，默认大小为16ConcurrentHashMap()// 2. 给定map的大小ConcurrentHashMap(int initialCapacity) // 3. 给定一个mapConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m)// 4. 给定map的大小以及加载因子ConcurrentHashMap(int initialCapacity, float loadFactor)// 5. 给定map大小，加载因子以及并发度（预计同时操作数据的线程）ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) ConcurrentHashMap一共给我们提供了5中构造器方法，具体使用请看注释，我们来看看第2种构造器，传入指定大小时的情况，该构造器源码为： 1234567891011public ConcurrentHashMap(int initialCapacity) &#123; //1. 小于0直接抛异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(); //2. 判断是否超过了允许的最大值，超过了话则取最大值，否则再对该值进一步处理 int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); //3. 赋值给sizeCtl this.sizeCtl = cap;&#125; 这段代码的逻辑请看注释，很容易理解，如果小于0就直接抛出异常，如果指定值大于了所允许的最大值的话就取最大值，否则，在对指定值做进一步处理。最后将cap赋值给sizeCtl,关于sizeCtl的说明请看上面的说明，当调用构造器方法之后，sizeCtl的大小应该就代表了ConcurrentHashMap的大小，即table数组长度。tableSizeFor做了哪些事情了？源码为： tableSizeFor12345678910private static final int tableSizeFor(int c) &#123; int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 通过注释就很清楚了，该方法会将调用构造器方法时指定的大小转换成一个2的幂次方数，也就是说ConcurrentHashMap的大小一定是2的幂次方，比如，当指定大小为18时，为了满足2的幂次方特性，实际上concurrentHashMapd的大小为2的5次方（32）。另外，需要注意的是，调用构造器方法的时候并未构造出table数组（可以理解为ConcurrentHashMap的数据容器），只是算出table数组的长度，当第一次向ConcurrentHashMap插入数据的时候才真正的完成初始化创建table数组的工作。 helpTransfer(协助扩容)123456789101112131415161718192021// 协助扩容方法。多线程下，当前线程检测到其他线程正进行扩容操作，则协助其一起扩容；（只有这种情况会被调用）从某种程度上说，其“优先级”很高，只要检测到扩容，就会放下其他工作，先扩容。 // 调用之前，nextTable一定已存在。 final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; intsc; if (tab != null &amp;&amp; (finstanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; intrs = resizeStamp(tab.length); //标志位 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab);//调用扩容方法，直接进入复制阶段 break; &#125; &#125; return nextTab; &#125; return table; &#125; addCount在put方法结尾处调用了addCount方法，把当前ConcurrentHashMap的元素个数+1这个方法一共做了两件事,更新baseCount的值，检测是否进行扩容。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //利用CAS方法更新baseCount的值 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123;// 1 CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; // 多线程 CAS 发生失败的时候执行 fullAddCount(x, uncontended); // 2 return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; //如果check值大于等于0 则需要检验是否需要进行扩容操作 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; // 当条件满足的时候开始扩容 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); // 如果小于0 说明已经有线程在进行扩容了 if (sc &lt; 0) &#123; // 一下的情况说明已经有在扩容或者多线程进行了扩容，其他线程直接 break 不要进入扩容 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 如果已经有其他线程在执行扩容操作 // 如果相等说明已经完成，可以继续扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 当前线程是唯一的或是第一个发起扩容的线程 此时nextTable=null // 这个时候 sizeCtl 已经等于(rs&lt;&lt;RESIZE_STAMP_SHIFT)+2 等于一个大的负数，这边 // 加上2很巧，因为 transfer 后面对 sizeCtl-- 操作的时候，最多只能减两个就结束 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125; &#125; 看上面的注释1,每次都会对 baseCount 加1,如果并发竞争太大，那么可能导致 U.compareAndSwapLong(this,BASECOUNT,b=baseCount,s = b + x) 失败,那么为了提高高并发的时候 baseCount 可见性的失败的问题,又避免一直重试，这样性能会有很大的影响,那么在 jdk 8的时候是有引入一个类 Striped64 ,其中 LongAdder 和 DoubleAdder 就是对这个类的实现。这两个方法都是为了解决高并发场景而生的，是 AtomicLong 的加强版,AtomicLong 在高并发场景性能会比 LongAdder 差。但是 LongAdder 的空间复杂度会高点。 fullAddCount123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293private final void fullAddCount(long x, boolean wasUncontended) &#123; int h; // 获取当前线程的 probe 值作为 hash 值,如果0则强制初始化当前线程的 Probe 值， // 初始化 probe 值不为 0 if ((h = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); // force initialization h = ThreadLocalRandom.getProbe(); // 设置未竞争标记为true wasUncontended = true; &#125; boolean collide = false; // True if last slot nonempty for (;;) &#123; CounterCell[] as; CounterCell a; int n; long v; if ((as = counterCells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; if ((a = as[(n - 1) &amp; h]) == null) &#123; // Try to attach new Cell 如果当前没有 CounterCell 就创建一个 if (cellsBusy == 0) &#123; CounterCell r = new CounterCell(x); // Optimistic create if (cellsBusy == 0 &amp;&amp; // 这边加上 cellsBusy 锁 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean created = false; try &#123; // Recheck under lock CounterCell[] rs; int m, j; if ((rs = counterCells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; rs[j] = r; created = true; &#125; &#125; finally &#123; // 释放 cellsBusy 锁定，让其他线程可以进来 cellsBusy = 0; &#125; if (created) break; continue; // Slot is now non-empty &#125; &#125; collide = false; &#125; // wasUncontended 为 false 说明已经发生了竞争，重置为true重新执行上面代码 else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash // 对 cell 的值进行累计x(1) else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; // 表明 as 已经过时，说明 cells 已经初始化完成，看下面， // 重置 collide 为 false 表明已经存在竞争 else if (counterCells != as || n &gt;= NCPU) collide = false; // At max size or stale else if (!collide) collide = true; else if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; try &#123; // 下面的方法主要是给 counterCells 扩容，尽可能避免冲突 if (counterCells == as) &#123;// Expand table unless stale CounterCell[] rs = new CounterCell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; counterCells = rs; &#125; &#125; finally &#123; cellsBusy = 0; &#125; collide = false; continue; // Retry with expanded table &#125; h = ThreadLocalRandom.advanceProbe(h); &#125; // 表明 counterCells 还没初始化，则初始化，这边用 cellsBusy 加锁 else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean init = false; try &#123; // Initialize table if (counterCells == as) &#123; CounterCell[] rs = new CounterCell[2]; rs[h &amp; 1] = new CounterCell(x); counterCells = rs; init = true; &#125; &#125; finally &#123; cellsBusy = 0; &#125; if (init) break; &#125; // 最终如果上面的都失败就把 x 累计到 baseCount else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; // Fall back on using base &#125; &#125; 回到 addCount 来,我们每次竞争都对 baseCount 进行加 1 当达到一定的容量时，就需要对 table 进行扩容。 使用 transfer 方法。 transfer负责迁移node节点 扩容transfer方法是一个设计极为精巧的方法。通过互斥读写ForwardingNode，多线程可以协同完成扩容任务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //计算每次迁移的node个数（MIN_TRANSFER_STRIDE该值作为下限，以避免扩容线程过多） if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) // 确保每次迁移的node个数不少于16个 stride = MIN_TRANSFER_STRIDE; // nextTab为扩容中的临时table if (nextTab == null) &#123; try &#123; //扩容一倍 @SuppressWarnings("unchecked") // 1. 新建一个 node 数组，容量为之前的两倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; // transferIndex为扩容复制过程中的桶首节点遍历索引 // 所以从n开始，表示从后向前遍历 transferIndex = n; &#125; int nextn = nextTab.length; // ForwardingNode是Node节点的直接子类，是扩容过程中的特殊桶首节点 // 该类中没有key,value,next // hash值为特定的-1 // 附加Node&lt;K,V&gt;[] nextTable变量指向扩容中的nextTab // 在find方法中，将扩容中的查询操作导入到nextTab上 //2. 新建forwardingNode引用，在之后会用到 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; // 循环的关键变量，判断是否已经扩容完成，完成就 return , 退出循环 boolean finishing = false; //【1】逆序迁移已经获取到的hash桶集合，如果迁移完毕，则更新transferIndex， // 获取下一批待迁移的hash桶 //【2】如果transferIndex=0，表示所以hash桶均被分配，将i置为-1， // 准备退出transfer方法 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // 3. 确定遍历中的索引i（更新待迁移的hash桶索引） // 循环的关键 i , i-- 操作保证了倒叙遍历数组 while (advance) &#123; int nextIndex, nextBound; // 更新迁移索引i if (--i &gt;= bound || finishing) advance = false; // transferIndex = 0表示table中所有数组元素都已经有其他线程负责扩容 // nextIndex=transferIndex=n=tab.length(默认16) else if ((nextIndex = transferIndex) &lt;= 0) &#123; // transferIndex&lt;=0表示已经没有需要迁移的hash桶， // 将i置为-1，线程准备退出 i = -1; advance = false; &#125; //cas无锁算法设置 transferIndex = transferIndex - stride // 尝试更新transferIndex，获取当前线程执行扩容复制的索引区间 // 更新成功，则当前线程负责完成索引为(nextBound，nextIndex)之间的桶首节点扩容 //当迁移完bound这个桶后，尝试更新transferIndex，获取下一批待迁移的hash桶 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //退出transfer //4.将原数组中的元素复制到新数组中去 //4.5 for循环退出，扩容结束修改sizeCtl属性// i&lt;0 说明已经遍历完旧的数组tab;i&gt;=n什么时候有可能呢？在下面看到i=n,所以目前i最大应该是n吧// i+n&gt;=nextn,nextn=nextTab.length,所以如果满足i+n&gt;=nextn说明已经扩容完成 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; // a //最后一个迁移的线程，recheck后，做收尾工作，然后退出 nextTable = null; table = nextTab; // 扩容成功，设置新sizeCtl，仍然为总大小的0.75 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; // 第一个扩容的线程，执行transfer方法之前，会设置 sizeCtl = // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 后续帮其扩容的线程，执行transfer方法之前，会设置 sizeCtl = sizeCtl+1 // 每一个退出transfer的方法的线程，退出之前，会设置 sizeCtl = sizeCtl-1 // 那么最后一个线程退出时： // 必然有sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2)， // 即 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 如果有多个线程进行扩容，那么这个值在第二个线程以后就不会相等，因为 // sizeCtl 已经被减1了，所以后面的线程只能直接返回， // 始终保证只有一个线程执行了a(上面的注释a) if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // finishing 和 advance 保证线程已经扩容完成了可以退出循环 finishing = advance = true; //最后退出的线程要重新check下是否全部迁移完毕 i = n; &#125; &#125; // 当前table节点为空，不需要复制，直接放入ForwardingNode //4.1 当前数组中第i个元素为null，用CAS设置成特殊节点forwardingNode(可以理解成占位符) // 如果 tab[i] 为 null,那么就把 fwd 插入到 tab[i],表明这个节点已经处理过了 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 当前table节点已经是ForwardingNode // 表示已经被其他线程处理了，则直接往前遍历 // 通过CAS读写ForwardingNode节点状态，达到多线程互斥处理 // 4.2 如果遍历到ForwardingNode节点说明这个点已经被处理过了直接跳过 // 这里是控制并发扩容的核心 // 如果 f.hash=-1 的话说明该节点为 ForwardingNode,说明该节点已经处理过了 else if ((fh = f.hash) == MOVED) advance = true; //迁移node节点 else &#123; // 锁住当前桶首节点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // 链表节点复制(链表迁移) if (fh &gt;= 0) &#123; // 4.3 处理当前节点为链表的头结点的情况，构造两个链表，一个是原链表 // 另一个是原链表的反序排列 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; //将node链表，分成2个新的node链表 // 这边还对链表进行遍历，这边的算法和hashMap的算法又不一样了，对半拆分 // 把链表拆分为，hash&amp;n 等于0和不等于0的，然后分别放在新表的i和i+n位置 // 此方法同 HashMap 的 resize for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //将新node链表赋给nextTab //在nextTable的i位置上插入一个链表 setTabAt(nextTab, i, ln); //在nextTable的i+n的位置上插入另一个链表 setTabAt(nextTab, i + n, hn); // 扩容成功后，设置ForwardingNode节点 //在table的i位置上插入forwardNode节点表示已经处理过该节点 // 把已经替换的节点的旧tab的i的位置用fwd替换，fwd包含nextTab setTabAt(tab, i, fwd); //设置advance为true 返回到上面的while循环中 就可以执行i--操作 advance = true; &#125; // 红黑树节点复制(红黑树迁移) //4.4 处理当前节点是TreeBin时的情况，操作和上面的类似 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 判断扩容后是否还需要红黑树 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); // 扩容成功后，设置ForwardingNode节点 setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125; &#125; 代码逻辑请看注释,整个扩容操作分为两个部分： 第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。新建table数组的代码为:Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1],在原容量大小的基础上右移一位。 第二个部分就是将原来table中的元素复制到nextTable中，主要是遍历复制的过程。根据运算得到当前遍历的数组的位置i，然后利用tabAt方法获得i位置的元素再进行判断： 如果这个位置为空，就在原table中的i位置放入forwardNode节点，这个也是触发并发扩容的关键点； 如果这个位置是Node节点（fh&gt;=0），如果它是一个链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上 如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要untreefi，把处理的结果分别放在nextTable的i和i+n的位置上 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。设置为新容量的0.75倍代码为 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1)，仔细体会下是不是很巧妙，n&lt;&gt;&gt;1左右一位相当于n除以2即0.5n,然后两者相减为2n-0.5n=1.5n,是不是刚好等于新容量的0.75倍即2n*0.75=1.5n。最后用一个示意图来进行总结（图片摘自网络）： mappingCount 与 sizemappingCount与size方法的类似 从给出的注释来看，应该使用mappingCount代替size方法 两个方法都没有直接返回basecount 而是统计一次这个值，而这个值其实也是一个大概的数值，因此可能在统计的时候有其他线程正在执行插入或删除操作。 1234567891011121314151617181920212223242526272829303132public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125; /** * Returns the number of mappings. This method should be used * instead of &#123;@link #size&#125; because a ConcurrentHashMap may * contain more mappings than can be represented as an int. The * value returned is an estimate; the actual count may differ if * there are concurrent insertions or removals. * * @return the number of mappings * @since 1.8 */public long mappingCount() &#123; long n = sumCount(); return (n &lt; 0L) ? 0L : n; // ignore transient negative values&#125; final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value;//所有counter的值求和 &#125; &#125; return sum;&#125; remove和put方法一样，多个remove线程请求不同的hash桶时，可以并发执行 如图所示：删除的node节点的next依然指着下一个元素。此时若有一个遍历线程正在遍历这个已经删除的节点，这个遍历线程依然可以通过next属性访问下一个元素。从遍历线程的角度看，他并没有感知到此节点已经删除了，这说明了ConcurrentHashMap提供了弱一致性的迭代器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public V remove(Object key) &#123; return replaceNode(key, null, null); &#125; // 当参数 value == null 时，删除节点。否则更新节点的值为value // cv 是个期望值，当 map[key].value 等于期望值 cv 或 cv == null 时， // 删除节点，或者更新节点的值 final V replaceNode(Object key, V value, Object cv) &#123; int hash = spread(key.hashCode()); for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // table 还没初始化或key对应的 hash 桶为空 if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; // 正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; boolean validated = false; synchronized (f) &#123; // CAS 获取 tab[i] ,如果此时 tab[i] != f,说明其他线程修改了 tab[i] // 回到 for 循环开始处，重新执行 if (tabAt(tab, i) == f) &#123; // node 链表 if (fh &gt;= 0) &#123; validated = true; for (Node&lt;K,V&gt; e = f, pred = null;;) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; V ev = e.val; // ev 代表参数期望值 // cv == null:直接更新value/删除节点 // cv 不为空，则只有在 key 的 oldVal 等于 // 期望值的时候，才更新 value/删除节点 if (cv == null || cv == ev || (ev != null &amp;&amp; cv.equals(ev))) &#123; oldVal = ev; //更新value if (value != null) e.val = value; //删除非头节点 else if (pred != null) pred.next = e.next; //删除头节点 else // 因为已经获取了头结点锁，所以此时 // 不需要使用casTabAt setTabAt(tab, i, e.next); &#125; break; &#125; //当前节点不是目标节点，继续遍历下一个节点 pred = e; if ((e = e.next) == null) //到达链表尾部，依旧没有找到，跳出循环 break; &#125; &#125; //红黑树 else if (f instanceof TreeBin) &#123; validated = true; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; r, p; if ((r = t.root) != null &amp;&amp; (p = r.findTreeNode(hash, key, null)) != null) &#123; V pv = p.val; if (cv == null || cv == pv || (pv != null &amp;&amp; cv.equals(pv))) &#123; oldVal = pv; if (value != null) p.val = value; else if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); &#125; &#125; &#125; &#125; &#125; if (validated) &#123; if (oldVal != null) &#123; //如果删除了节点，更新size if (value == null) addCount(-1L, -1); return oldVal; &#125; break; &#125; &#125; &#125; return null; &#125; ForwardingNode1234567891011121314151617181920212223242526272829303132333435static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; //hash值为MOVED（-1）的节点就是ForwardingNode super(MOVED, null, null, null); this.nextTable = tab; &#125; //通过此方法，访问被迁移到nextTable中的数据 Node&lt;K,V&gt; find(int h, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; int n; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) return null; for (;;) &#123; int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125; &#125;&#125; 总结JDK6,7中的ConcurrentHashmap主要使用Segment来实现减小锁粒度，分割成若干个Segment，在put的时候需要锁住Segment，get时候不加锁，使用volatile来保证可见性，当要统计全局时（比如size），首先会尝试多次计算modcount来确定，这几次尝试中，是否有其他线程进行了修改操作，如果没有，则直接返回size。如果有，则需要依次锁住所有的Segment来计算。 而在1.8的时候摒弃了segment臃肿的设计，这种设计在定位到具体的桶时，要先定位到具体的segment，然后再在segment中定位到具体的桶。而到了1.8的时候是针对的是Node[] tale数组中的每一个桶，进一步减小了锁粒度。并且防止拉链过长导致性能下降，当链表长度大于8的时候采用红黑树的设计。 主要设计上的变化有以下几点: 不采用segment而采用node，锁住node来实现减小锁粒度。 设计了MOVED状态 当resize的中过程中 线程2还在put数据，线程2会帮助resize。 使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。 sizeCtl的不同值来代表不同含义，起到了控制的作用。 采用synchronized而不是ReentrantLock volatile语义提供更细颗粒度的轻量级锁，使得多线程可以(几乎)同时读写实例中的关键量，正确理解当前类所处的状态，进入对应if语句中执行相关逻辑。 采用更加细粒度的hash桶级别锁，扩容期间，依然可以保证写操作的并发度。 多线程无锁扩容的关键就是通过CAS设置sizeCtl与transferIndex变量，协调多个线程对table数组中的node进行迁移。 参考文章：http://www.cnblogs.com/huaizuo/p/5413069.html 参考文章：http://www.bijishequ.com/detail/560964?p= 参考文章：https://bentang.me/tech/2016/12/01/jdk8-concurrenthashmap-1/ 参考文章: http://www.jianshu.com/p/5bc70d9e5410 扩容原理: http://www.jianshu.com/p/487d00afe6ca 遍历操作：http://www.jianshu.com/p/3e85ac8f8662 改进说明带例子:http://www.voidcn.com/article/p-gdbewnlb-qh.html http://nannan408.iteye.com/blog/2217042]]></content>
      <categories>
        <category>ConcurrentHashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap的使用]]></title>
    <url>%2F2017%2F12%2F26%2FConcurrentHashMap%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap的使用缓存的使用 高性能本地缓存：对系统中常用到的业务数据放到缓存中以提高系统性能，限制是单服务器模式 分布式缓存：常用分布式缓存技术memcached、redis等 ConcurrentHashMap就是常用的高并发下的缓存对象。 接下来直接上例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class ConcurrentMapTest &#123; public static ConcurrentMap&lt;String, Future&lt;String&gt;&gt; cMap = new ConcurrentHashMap&lt;&gt;(); public static ConcurrentHashMap&lt;String, String&gt; cMap2 = new ConcurrentHashMap&lt;&gt;(); public static int index = 0; public static void main(String[] args) &#123; for (int i = 0; i &lt; 5; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; concurrentMap2("3"); try &#123; concurrentMap("123"); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125; /** * 解决并发写的线程安全问题。但是高并发可读取会造成重复写的问题... * 如果put的业务计算复杂将耗费不必要的资源 * 解决缓存读取问题，但可能会出现缓存重复写 */ private static void concurrentMap2(String key) &#123; System.out.println(Thread.currentThread().getName() + " start ...."); String f = cMap2.get(key); // ConcurrentMap读不加锁，写加锁。 // 当并发量高时会出现重复compute的操作，然后才put到map中 if (f == null) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cMap2.put(key, "dataTest" + index); System.out.println(Thread.currentThread().getName() + " compute , index================== " + index++); &#125; System.out.println(Thread.currentThread().getName() + " end .... " + cMap2.get(key)); &#125; /** * 解决并发写问题，同时避免了重复put计算的问题 解决缓存读写的问题 * * @param key * @throws InterruptedException * @throws ExecutionException * @throws TimeoutException */ private static void concurrentMap(String key) throws InterruptedException, ExecutionException, TimeoutException &#123; System.out.println(Thread.currentThread().getName() + " start ...."); Future&lt;String&gt; f = null; f = cMap.get(key); if (f == null) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; FutureTask&lt;String&gt; fTask = new FutureTask&lt;String&gt; (new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + " compute , index=============== " + index++); return "456789123"; &#125; &#125;); f = cMap.putIfAbsent(key, fTask); // 相当于get-if-absent-compute， //而且是原子执行，解决了并发读的问题。（FutureTask解决compute步骤） if (f == null) &#123; f = fTask; // f的值是FutureTask对象引用，解决了call的重复调用问题, // 只用一个线程会执行run()方法 fTask.run(); &#125; &#125; System.out.println("end ==========="); // get会等待FutureTask的计算结果，可以设置等待超时事件,超时会抛出超时异常 System.out.println(Thread.currentThread().getName() + " end ....====== " + f.get(3000, TimeUnit.MILLISECONDS)); // get会等待FutureTask的计算结果，永久等待 System.out.println(Thread.currentThread().getName() + " end .... " + f.get()); &#125;&#125; concurrentMap2的执行结果 Thread-0 start ….Thread-2 start ….Thread-4 start ….Thread-1 start ….Thread-3 start ….Thread-4 compute , index================== 0Thread-0 compute , index================== 2Thread-0 end …. dataTest0Thread-2 compute , index================== 1Thread-2 end …. dataTest0Thread-4 end …. dataTest0Thread-3 compute , index================== 3Thread-1 compute , index================== 4Thread-1 end …. dataTest3Thread-3 end …. dataTest3 可以看到put方法被重复执行…. concurrentMap的执行结果 Thread-1 start ….Thread-3 start ….Thread-0 start ….Thread-2 start ….Thread-4 start ….end ===========end ===========end ===========end ===========Thread-1 compute , index=============== 0Thread-3 end ….====== 456789123Thread-3 end …. 456789123end ===========Thread-1 end ….====== 456789123Thread-1 end …. 456789123Thread-0 end ….====== 456789123Thread-0 end …. 456789123Thread-2 end ….====== 456789123Thread-2 end …. 456789123Thread-4 end ….====== 456789123Thread-4 end …. 456789123 可以看到put运算只执行一次…. 总结： 如果缓存对象可以在系统启动时进行初始化加载，可以不使用ConcurrentHashMap 如果缓存在put时计算比较复杂，那么推荐直接使用concurrentMap写法 ConcurrentHashMap缺陷就是缓存无法回收，导致内存溢出问题。此问题在google发布Guava的Cache很好的进行了处理，可查看另一篇文章Guava Cache的使用]]></content>
      <categories>
        <category>ConcurrentHashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 款最好的 Python IDE]]></title>
    <url>%2F2017%2F12%2F21%2F10%E6%AC%BE%E6%9C%80%E5%A5%BD%E7%9A%84Python%20IDE%2F</url>
    <content type="text"><![CDATA[10 款最好的 Python IDE Vim Eclipse PyDev Sublime Text Emacs Komodo PyCharm Wing PyScripter The Eric Python IDE Interactive Editor for Python]]></content>
      <categories>
        <category>Python IDE</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime Text 3 搭建Python开发环境]]></title>
    <url>%2F2017%2F12%2F21%2FSublime%20Text%203%20%E6%90%AD%E5%BB%BAPython%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[Sublime Text 3 搭建Python开发环境前言 Sublime Text：一款具有代码高亮、语法提示、自动完成且反应快速的编辑器软件，不仅具有华丽的界面，还支持插件扩展机制，用她来写代码，绝对是一种享受。相比于难于上手的 Vim ，浮肿沉重的 Eclipse ， VS ，即便体积轻巧迅速启动的 Editplus 、 Notepad++ ，在 Sublime Text 面前也略显失色，无疑这款性感无比的编辑器是 Coding 和 Writing 最佳的选择，没有之一。 Sublime Text 3 的功能实在是太强大了，搭配各种 package ，码代码、美如画。对于 Sublime Text 3 的介绍网上一大堆，博主就不再这里赘述了。本篇博文主要是记录一下博主如何在 Sublime Text 3 下优雅的编写、编译、运行 python 代码。 安装 我使用的版本是 Sublime Text Build 3143 ，大家自行下载后直接安装即可，安装完之后需要 License 来激活我们的软件。 ​ Sublime Text Build 3143的下载路径： ​ https://code.aliyun.com/shenwenfang106/SublimeTextBuild3143.git 直接将下面的 License 复制过去就好，亲测可用： 12345678910111213—– BEGIN LICENSE —– TwitterInc 200 User License EA7E-890007 1D77F72E 390CDD93 4DCBA022 FAF60790 61AA12C0 A37081C5 D0316412 4584D136 94D7F7D4 95BC8C1C 527DA828 560BB037 D1EDDD8C AE7B379F 50C9D69D B35179EF 2FE898C4 8E4277A8 555CE714 E1FB0E43 D5D52613 C3D12E98 BC49967F 7652EED2 9D2D2E61 67610860 6D338B72 5CF95C69 E36B85CC 84991F19 7575D828 470A92AB —— END LICENSE ——12345678910111213 配置Package Control 按 Ctrl+` 调出 console ，粘贴以下代码到底部命令行并回车： 1import urllib.request,os,hashlib; h = '6f4c264a24d933ce70df5dedcf1dcaee' + 'ebe013ee18cced0ef93d5f746d80ef60'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)1 重启 Sublime Text 3。如果在 Perferences-&gt;package settings 中看到 package control 这一项，则安装成功。按下 Ctrl+Shift+P 调出命令面板输入 install 调出 Install Package 选项并回车，然后在列表中选中要安装的插件。 下面介绍几个比较实用的 package 。 SideBarEnhancements SideBarEnhancements 扩展了侧边栏中菜单选项的数量，从而提升你的工作效率。诸如 “New file” 和 “Duplicate” 这样的选项对于 ST3 来说实在是太重要了，而且仅凭 “Delete” 这一个功能就让这个插件值得下载。这个功能将你会在你删除文件的时候把它放入回收站。虽然这个功能乍一看没什么用，但是当你没有使用这样的功能而彻底删除了一个文件的时候，除非你用了版本管理软件，否则你将很难恢复这个文件。 Anaconda Anaconda 是一个终极 Python 插件。它为 ST3 增添了多项 IDE 类似的功能，例如： Autocompletion 自动完成，该选项默认开启，同时提供多种配置选项。 Code linting 使用支持 pep8 标准的 PyLint 或者 PyFlakes。 McCabe code complexity checker 让你可以在特定的文件中使用 McCabe complexity checker. Goto Definitions 能够在你的整个工程中查找并且显示任意一个变量，函数，或者类的定义。 Find Usage 能够快速的查找某个变量，函数或者类在某个特定文件中的什么地方被使用了。 Show Documentation： 能够显示一个函数或者类的说明性字符串(当然，是在定义了字符串的情况下) 但是，刚安装完之后，打开一个 python 文档，所有代码都会被白色细线框中，如图所示； ​ 强迫症的我看着好难受，决心要搞一搞这东西。后来发现在 Sublime &gt; Preferences &gt; Package Settings &gt; Anaconda &gt; Settings – Default 下修改 linting behaviour 选项即可，我这里改成了只有在保存的时候linting工作。 12345678/* Sets the linting behaviour for anaconda: "always" - Linting works always even while you are writing (in the background) "load-save" - Linting works in file load and save only "save-only" - Linting works in file save only*/"anaconda_linting_behaviour": "save-only", SublimeREPL 这可能是对程序员来说最有用的插件。SublimeREPL 允许你在 Sublime Text 中运行各种语言（NodeJS ，Python，Ruby， Scala 和 Haskell 等等）。 在 Sublime &gt; Tools &gt; SublimeREPL 下我们可以看到 SublimeREPL 支持运行的所有语言。 下面的代码是在 AppData\Roaming\Sublime Text 3\Packages\SublimeREPL\config\Python 下的 Default.sublime-commands 文件，从中我们可以看到 SublimeREPL 所支持的 python 的各种运行方式。 1234567891011121314151617181920212223242526272829303132333435363738[ &#123; "caption": "SublimeREPL: Python", "command": "run_existing_window_command", "args": &#123; "id": "repl_python", "file": "config/Python/Main.sublime-menu" &#125; &#125;, &#123; "caption": "SublimeREPL: Python - PDB current file", "command": "run_existing_window_command", "args": &#123; "id": "repl_python_pdb", "file": "config/Python/Main.sublime-menu" &#125; &#125;, &#123; "caption": "SublimeREPL: Python - RUN current file", "command": "run_existing_window_command", "args": &#123; "id": "repl_python_run", "file": "config/Python/Main.sublime-menu" &#125; &#125;, &#123; "command": "python_virtualenv_repl", "caption": "SublimeREPL: Python - virtualenv" &#125;, &#123; "caption": "SublimeREPL: Python - IPython", "command": "run_existing_window_command", "args": &#123; "id": "repl_python_ipython", "file": "config/Python/Main.sublime-menu" &#125; &#125;] 接下来配置快捷键，打开 Sublime &gt; Preferences &gt; Key Building ，在右侧栏（ User 部分）添加下面的代码。下面的代码用 F5 来执行当前 Python 脚本，用 F4 来实现切换至 Python 命令行窗口。 12345678910111213[ &#123;"keys":["f5"], "caption": "SublimeREPL: Python - RUN current file", "command": "run_existing_window_command", "args": &#123;"id": "repl_python_run", "file": "config/Python/Main.sublime-menu"&#125;&#125; , &#123;"keys":["f4"], "caption": "SublimeREPL: Python", "command": "run_existing_window_command", "args": &#123;"id": "repl_python", "file": "config/Python/Main.sublime-menu"&#125;&#125;] 【1】Shift+Ctrl+Alt+p 创建 python 文件 先保存再执行。 【2】F5 执行代码 （如果你没有设置快捷键就 win+b） 【3】 看 Python 命令行窗口 ​ 当然，如果你电脑里面安装了两个版本的 Python ，而你想指定使用某个版本，则需要修改下面的代码。下面的代码是在 AppData\Roaming\Sublime Text 3\Packages\SublimeREPL\config\Python 下的 Main.sublime-menu 文件，主要修改 “cmd” 后面跟着的 python 命令。比如我电脑里 python2.7 的执行程序命名是 python.exe ，而 python3.6 的执行程序命名为 python3.exe ，我想要使用 python3 ，所以把所有 “cmd” 后面跟着的命令都改为 “python3” 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[ &#123; "id": "tools", "children": [&#123; "caption": "SublimeREPL", "mnemonic": "R", "id": "SublimeREPL", "children": [ &#123;"caption": "Python", "id": "Python", "children":[ &#123;"command": "repl_open", "caption": "Python", "id": "repl_python", "mnemonic": "P", "args": &#123; "type": "subprocess", "encoding": "utf8", "cmd": ["python3", "-i", "-u"], "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123;"PYTHONIOENCODING": "utf-8"&#125; &#125; &#125;, &#123;"command": "python_virtualenv_repl", "id": "python_virtualenv_repl", "caption": "Python - virtualenv"&#125;, &#123;"command": "repl_open", "caption": "Python - PDB current file", "id": "repl_python_pdb", "mnemonic": "D", "args": &#123; "type": "subprocess", "encoding": "utf8", "cmd": ["python3", "-i", "-u", "-m", "pdb", "$file_basename"], "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123;"PYTHONIOENCODING": "utf-8"&#125; &#125; &#125;, &#123;"command": "repl_open", "caption": "Python - RUN current file", "id": "repl_python_run", "mnemonic": "R", "args": &#123; "type": "subprocess", "encoding": "utf8", "cmd": ["python3", "-u", "$file_basename"], "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123;"PYTHONIOENCODING": "utf-8"&#125; &#125; &#125;, &#123;"command": "repl_open", "caption": "Python - IPython", "id": "repl_python_ipython", "mnemonic": "I", "args": &#123; "type": "subprocess", "encoding": "utf8", "autocomplete_server": true, "cmd": &#123; "osx": ["python3", "-u", "$&#123;packages&#125;/SublimeREPL/config/Python/ipy_repl.py"], "linux": ["python3", "-u", "$&#123;packages&#125;/SublimeREPL/config/Python/ipy_repl.py"], "windows": ["python3", "-u", "$&#123;packages&#125;/SublimeREPL/config/Python/ipy_repl.py"] &#125;, "cwd": "$file_path", "syntax": "Packages/Python/Python.tmLanguage", "external_id": "python", "extend_env": &#123; "PYTHONIOENCODING": "utf-8", "SUBLIMEREPL_EDITOR": "$editor" &#125; &#125; &#125; ]&#125; ] &#125;] &#125;] 别忘了， Sublime Text 3 也有自己的 build 功能，即也支持 python 等语言的代码构建（ ctrl + b ）。同样的，我们如何添加不同的 python 版本到我们的构建系统呢？很简单，Sublime &gt; Tools &gt; Build System &gt; New Build System，分别添加如下代码之后，再分别保存为 python2.sublime-build 和 python3.sublime-build ，这样，当我们再次打开 Sublime &gt; Tools &gt; Build System 之后，就会发现我们新添加的 python2 和 python3 构建系统了。 12345&#123; "cmd": ["D:/Program Files/Python/Python27/python.exe", "-u", "$file"], "file_regex": "^[ ]*File \"(...*?)\", line([0-9]*)", "selector": "source.python"&#125; 12345&#123; "cmd": ["D:/Program Files/Python/Python36/python3.exe", "-u", "$file"], "file_regex": "^[ ]*File \"(...*?)\", line([0-9]*)", "selector": "source.python"&#125; SublimeTmpl 快速生成文件模板 ，SublimeTmpl能新建html、css、javascript、php、python、ruby六种类型的文件模板，所有的文件模板都在插件目录的templates文件夹里，可以自定义编辑文件模板。 SublimeTmpl默认的快捷键: 123456ctrl+alt+h htmlctrl+alt+j javascriptctrl+alt+c cssctrl+alt+p phpctrl+alt+r rubyctrl+alt+shift+p python 这里我想修改一下python模板，所以就需要进行如下操作：Sublime &gt; Preferences &gt; Package Settings &gt; SublimeTmpl &gt; Settings – User 添加如下代码。然后 ctrl+alt+shift+p 来新建一个模板试试看。 123456789&#123; "disable_keymap_actions": false, // "all"; "html,css" "date_format" : "%Y-%m-%d %H:%M:%S", "attr": &#123; "author": "WordZzzz", "email": "wordzzzz@foxmail.com", "link": "http://blog.csdn.net/u011475210" &#125; &#125; 快捷键也是可以更改的，全部在 Sublime &gt; Preferences &gt; Package Settings &gt; SublimeTmpl 的设置中。 如果想要新建其他类型的文件模板的话，先自定义文件模板方在templates文件夹里，再分别打开Default (Windows).sublime-keymap、Default.sublime-commands、Main.sublime-menu、SublimeTmpl.sublime-settings这四个文件照着里面的格式自定义想要新建的类型，这里就不详细介绍了，请各位自己折腾哈~ 快捷键 跳转到任意内容 (“cmd+p”) 用来快速查找和打开文件。你仅仅只需要工程中文件的一部分路径或者文件名你就可以很容易的打开这个文件。这在一个大型的 Django 工程中显得非常方便。 跳转到指定行 (“ctrl+g”) 让你在当前文件中跳转到指定行数。 跳转到标志 (“cmd+r”) 可以列出当前文件中所有的函数或者类，让你更方便查找。你可以通过输入关键字来查找你所需要的函数或者类。 跳转到行首 (cmd+left-arrow-key) 与 跳转到行尾 (cmd+right-arrow-key) 删除当前行(ctrl+shift+k) 多重编辑 是我迄今为止最喜欢的快捷键选定一个单词，点击 “cmd+d”来选择同样的单词，再次点击 “cmd+d”*继续选择下一个单词…或者 “cmd+单击”来指定多个你想要同时修改的地方。 块编辑 (option+left-mouse-click) 用于选择一整块的内容。通常在整理 CSV 文件的时候用于删除空白内容。 自定义命令 你可以很容易地使用 Python 来编辑你自己的自定义命令和快捷键组合。例如： 拷贝当前文件路径到剪贴板 – 链接 关闭除当前活动标签页以外的所有其他标签页 – 链接 通过文件选项打开你的 Package 文件夹(Sublime &gt; Preferences &gt; Browse Packages)，然后打开 User 文件夹，接下来将上述的 Python 文件添加到 “/Sublime Text 3/Packages/User” 文件夹中。 最后请在 Key Bindings – User file (Sublime Text &gt; Preferences &gt; Package Settings &gt; AdvancedNewFile &gt; Key Bindings – User) 文件中完成快捷键绑定。 1234567891011[ // Copy file name &#123; "keys": ["cmd+shift+c"], "command": "copy_path_to_clipboard" &#125;, // Close all other tabs &#123; "keys": ["cmd+alt+w"], "command": "close_tabs" &#125; 参看文章：http://blog.csdn.net/u011475210/article/details/78168341]]></content>
      <categories>
        <category>搭建Python开发环境</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据迭代的基本用法]]></title>
    <url>%2F2017%2F12%2F20%2Fpython%E5%88%97%E8%A1%A8%E8%BF%AD%E4%BB%A3%2F</url>
    <content type="text"><![CDATA[数据迭代的基本用法：for 循环的使用12345&gt;&gt;&gt;fav_movies = ["The Holy Crail","The Life of Brian"]&gt;&gt;&gt;for each_flick in fav_movies:print(each_flick)The Holy CrailThe Life of Brian while 循环的使用1234567&gt;&gt;&gt;count=2&gt;&gt;&gt;while count&gt;0: 【注意加冒号了再回车】 print("aaaa") 【如果正确会自动缩进】 count = count-1 aaaa 【输出结果】aaaa enumerate，dict，zip 使用通过一个练习，看看这三个函数怎么用的哈。小丽，你也跟着敲一下代码，看看运行效果 题目：现有: 123list1=[&apos;neil&apos;,&apos;mike&apos;,&apos;lucy&apos;]list2=[&apos;123456&apos;,&apos;xuiasj==&apos;,&apos;passWD123&apos;]list3=[&apos;www.abc.com&apos;,&apos;www.mike.org&apos;,&apos;www.lucy.gov&apos;] 需要形成列表： 1fin_list = [&#123;&apos;name&apos;:&apos;neil&apos;,&apos;passwd&apos;:&apos;123456&apos;,&apos;url&apos;:&apos;www.abc.com&apos;&#125;,&#123;&apos;name&apos;:&apos;mike&apos;,&apos;passwd&apos;:&apos;xuiasj==&apos;,&apos;url&apos;:&apos;www.mike.org&apos;&#125;,&#123;&apos;name&apos;:&apos;lucy&apos;,&apos;passwd&apos;:&apos;passWD123&apos;,&apos;url&apos;:&apos;www.lucy.gov&apos;&#125;] python新手的小丽啊，这要如何实现呢？你先自己好好想想怎么实现，动手敲敲代码哈。 在这里我提供两种方法： 方法1: 使用 enumerate 函数来实现 123456789101112131415【按题目定义3个列表】&gt;&gt;&gt;list1 = ['neil','mike','lucy']&gt;&gt;&gt;list2 = ['123456','xuiasj==','passWD123']&gt;&gt;&gt;list3 = ['www.abc.com','www.mike.org','www.lucy.gov']&gt;&gt;&gt;fin_list = []&gt;&gt;&gt;for i , name in enumerate(list1): d = &#123;&#125; d['name'] = name d['password'] = list2[i] d['url'] = list3[i] fin_list.append(d) 【小丽你回车,会空格一行】&gt;&gt;&gt;fin_list 【再输入要输出的这个列表名】【这是输出的结果】[&#123;'name': 'neil', 'password': '123456', 'url': 'www.abc.com'&#125;, &#123;'name': 'mike', 'password': 'xuiasj==', 'url': 'www.mike.org'&#125;, &#123;'name': 'lucy', 'password': 'passWD123', 'url': 'www.lucy.gov'&#125;] 之前你问我:python 中 in 的使用 和 enumerate 函数，在这里我来回答你，你要认真看哈！ enumerate 函数一般情况下我们对一个列表或数组既要遍历索引又要遍历元素时，会这样写： 12&gt;&gt;&gt;for i in range (0,len(list)): 【其实，在 ypthon 中 for... in .. 它就是一个语法】&gt;&gt;&gt;print i ,list[i] 【range 是取一个范围的值】 但是这种方法有些累赘，使用内置enumerrate函数会有更加直接，优美的做法，先看看enumerate的定义： 1234567&gt;&gt;&gt;def enumerate(collection): 【def 函数我在下面会跟你讲】&gt;&gt;&gt; 'Generates an indexed series: (0,coll[0]), (1,coll[1])'&gt;&gt;&gt; i = 0 &gt;&gt;&gt; it = iter(collection) &gt;&gt;&gt; while 1: &gt;&gt;&gt; yield (i, it.next()) &gt;&gt;&gt; i += 1 enumerate会将数组或列表组成一个索引序列。使我们再获取索引和索引内容的时候更加方便如下： 12&gt;&gt;&gt;for index，text in enumerate(list)):&gt;&gt;&gt; print index ,text 如果你要计算文件的行数，可以这样写： 1&gt;&gt;&gt;count = len(open(thefilepath,‘rU’).readlines()) 前面这种方法简单，但是可能比较慢，当文件比较大时甚至不能工作，下面这种循环读取的方法更合适些。 1234&gt;&gt;&gt;Count = -1 &gt;&gt;&gt;For count,line in enumerate(open(thefilepath,‘rU’))：&gt;&gt;&gt; Pass&gt;&gt;&gt;Count += 1 小丽，计算文件的行数的这两种方法，看不懂没关系，你只要知道就可以了。 看到这里你必须掌握的是：for 的迭代 和 enumerate 行数的使用 在来看看 def 函数 def 函数对于某些需要重复调用的程序，可以使用函数进行定义，基本形式为： def 函数名(参数1, 参数2, ……, 参数N): 执行语句函数名为调用的表示名，参数则是传入的参数。 1234567891011# 例1：简单的函数使用# coding=gb2312 # 定义函数def hello(): print 'hello python!' # 调用函数 hello() &gt;&gt;&gt; hello python! 函数可以带参数和返回值，参数将按从左到右的匹配，参数可设置默认值，当使用函数时没给相应的参数时，会按照默认值进行赋值。 1234567891011121314151617181920# 例2：累加计算值# coding=gb2312 # 定义函数def myadd(a=1,b=100): result = 0 i = a while i &lt;= b: # 默认值为1+2+3+……+100 result += i i += 1 return result # 打印1+2+……+10 print myadd(1,10)print myadd() # 使用默认参数1，100print myadd(50) # a赋值50，b使用默认值 &gt;&gt;&gt; 55&gt;&gt;&gt; 5050&gt;&gt;&gt; 3825 Python 函数的参数传递时，值得注意的是参数传入时若为变量会被当作临时赋值给参数变量，如果是对象则会被引用。 12345678910111213141516# 例3：# coding=gb2312 def testpara(p1,p2): p1 = 10 p2.append('hello') l = [] # 定义一数组对像a = 20 # 给变量a赋值testpara(a,l) # 变量a与对象数组l作为参数传入print a # 打印运行参数后的值for v in l: # 打印数组对象的成员 print v &gt;&gt;&gt; 20 # 调用函数后a变量并未被复值&gt;&gt;&gt; hello # 而对象l数组则增加成员hello 方法2: 使用 dict 和 zip 函数来实现** 1234567891011121314【按题目定义3个列表】&gt;&gt;&gt;list1 = ['neil','mike','lucy']&gt;&gt;&gt;list2 = ['123456','xuiasj==','passWD123']&gt;&gt;&gt;list3 = ['www.abc.com','www.mike.org','www.lucy.gov']&gt;&gt;&gt;fin_list = []&gt;&gt;&gt;style = ['name','passwd','url']&gt;&gt;&gt;fin_list.append(dict(zip(style,list1)))&gt;&gt;&gt;fin_list.append(dict(zip(style,list2)))&gt;&gt;&gt;fin_list.append(dict(zip(style,list3)))&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;print(fin_list)【这是输出的结果】[&#123;'name': 'neil', 'password': '123456', 'url': 'www.abc.com'&#125;, &#123;'name': 'mike', 'password': 'xuiasj==', 'url': 'www.mike.org'&#125;, &#123;'name': 'lucy', 'password': 'passWD123', 'url': 'www.lucy.gov'&#125;]]]></content>
      <categories>
        <category>数据迭代</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3 安装]]></title>
    <url>%2F2017%2F12%2F20%2F%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Python3 安装Linux下默认安装的是Python2.7，要使用Python3，需要自行安装。Python3最新的版本是Python3.6。 在这里介绍在CentOS，Debian和Windows上安装Python3.6。 小丽，你跳过前面的，只看Windows上安装Python3.6哈。 CentOS安装Python3.6更详细的安装过程查看：CentOS7安装Python3.6 IUS软件源中包含了Python3.6，可以使用IUS软件源安装Python3.6，查看如何安装使用IUS软件源 1）安装IUS软件源 12345复制#安装EPEL依赖sudo yum install epel-release#安装IUS软件源sudo yum install https://centos7.iuscommunity.org/ius-release.rpm 2）安装Python3.6 1复制sudo yum install python36u 安装Python3完成后的shell命令为python3.6，为了使用方便，创建一个到python3的符号链接 1复制sudo ln -s /bin/python3.6 /bin/python3 3）安装pip3 安装完成python36u并没有安装pip，安装pip 1复制sudo yum install python36u-pip 安装pip完成后的shell命令为pip3.6，为了使用方便，创建一个到pip3的符号链接 1复制sudo ln -s /bin/pip3.6 /bin/pip3 Debian安装Python3.6Debian8的软件源中包含了Python3.4，要安装Python3.6，需要下载源文件安装： 1）安装编译，安装Python源文件的依赖包，GCC编译器，Make编译程序，Zlib压缩库： 1复制sudo aptitude -y install gcc make zlib1g-dev 2）运行如下命令安装Python3.6，以下命令依次为获取Python3.6源文件，解压，配置环境，编译，安装Python3.6 123456复制wget https://www.python.org/ftp/python/3.6.0/Python-3.6.0.tar.xztar xJf Python-3.6.0.tar.xzcd Python-3.6.0sudo ./configuresudo makesudo make install 安装完成后，Python安装在了/usr/local文件夹中，可运行文件/usr/local/bin，库文件/usr/local/lib，可以使用如下命令查看安装位置和版本 3）查看安装位置： 123复制anxin@bogon:~$ which python3/usr/local/bin/python3 4）验证Python3.6版本 123复制anxin@bogon:~$ python3 -VPython 3.6.0 Windows安装Python3.61）进入Python下载页面下载对应版本的Python安装包，本例下载Python3.6 64位Windows安装包 python-3.6.2-amd64.exe 如果你的电脑系统是32 位的,你就直接点击箭头的按钮下载就好了! 如果你的电脑系统是64 位的,就按下面流程下载哈 下载下来： 2）双击Python3.6安装包，开始安装Python3.6。 1. 选择 Install Now 安装方式方式 其实你也可以一步就完成 Python3.6 的安装，如果选择 Install Now 安装方式，以后下的步骤你可以全部不用做。 查看安装是否成功，打开cmd 输入 python 即可 2. 选择选择自定义安装（Customize installation）方式，可以选择安装的内容和目录： 注：安装Python3.6时，可以选中 Add Python 3.6 to PATH ，这样Python会自动把Python3.6的路径加入当前用户的PATH路径下，而不是系统的PATH路径下。 3）选择要安装的内容（如果你清除它们是什么），一般可以选择默认，即：所有内容，点击Next 4）选择一些安装选择，一般选择默认，在这一步可以选择安装目录，也可以直接输入目录地址，点击“浏览（Browse）”按钮： 5）选择安装的目录，最好先创建好目录如 python36 ，点击“确定”按钮： 6）如图所示选择好Python3.6的安装目录，点击“Install”按钮，开始安装Python3.6 7）如不出什么以外，会提示你安装完成 恭喜你，成功的在Windows安装了Python 3.6！ 配置Python3.6环境变量你也可以在安装完成Python3.6后，自己手动配置Python3.6的环境变量。 Win7进入控制面板–&gt;系统和安全–&gt;系统–&gt;高级系统设置–&gt;环境变量–&gt;系统变量，选中Path，双击编辑Path环境变量，添加路径\和\Scripts\： 在本例中我们添加的Python3.6环境变量的路径为：;C:\python36\Scripts\;C:\python36\，注意：Windows的环境变量已 ; 分隔。 我们敲代码的地方 打开箭头指向的 IDLE ，就是我们的编辑器。]]></content>
      <categories>
        <category>Python3 安装</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap扩容实现机制]]></title>
    <url>%2F2017%2F12%2F14%2FConcurrentHashMap%E6%89%A9%E5%AE%B9%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap扩容实现机制jdk8中，采用多线程扩容。整个扩容过程，通过CAS设置sizeCtl，transferIndex等变量协调多个线程进行并发扩容。 扩容相关的属性nextTable扩容期间，将table数组中的元素 迁移到 nextTable。 12345/** * The next table to use; non-null only while resizing. 扩容时，将table中的元素迁移至nextTable . 扩容时非空 */private transient volatile Node&lt;K,V&gt;[] nextTable; sizeCtl属性1private transient volatile int sizeCtl; 多线程之间，以volatile的方式读取sizeCtl属性，来判断ConcurrentHashMap当前所处的状态。通过cas设置sizeCtl属性，告知其他线程ConcurrentHashMap的状态变更。 不同状态，sizeCtl所代表的含义也有所不同。 未初始化： sizeCtl=0：表示没有指定初始容量。 sizeCtl&gt;0：表示初始容量。 初始化中： sizeCtl=-1,标记作用，告知其他线程，正在初始化 正常状态： sizeCtl=0.75n ,扩容阈值 扩容中: sizeCtl &lt; 0 : 表示有其他线程正在执行扩容 sizeCtl = (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2 :表示此时只有一个线程在执行扩容 ConcurrentHashMap的状态图如下： transferIndex属性1234567private transient volatile int transferIndex; /** 扩容线程每次最少要迁移16个hash桶 */private static final int MIN_TRANSFER_STRIDE = 16; 扩容索引，表示已经分配给扩容线程的table数组索引位置。主要用来协调多个线程，并发安全地获取迁移任务（hash桶）。 1 在扩容之前，transferIndex 在数组的最右边 。此时有一个线程发现已经到达扩容阈值，准备开始扩容。 2 扩容线程，在迁移数据之前，首先要将transferIndex右移（以cas的方式修改 transferIndex=transferIndex-stride(要迁移hash桶的个数)），获取迁移任务。每个扩容线程都会通过for循环+CAS的方式设置transferIndex，因此可以确保多线程扩容的并发安全。 换个角度，我们可以将待迁移的table数组，看成一个任务队列，transferIndex看成任务队列的头指针。而扩容线程，就是这个队列的消费者。扩容线程通过CAS设置transferIndex索引的过程，就是消费者从任务队列中获取任务的过程。为了性能考虑，我们当然不会每次只获取一个任务（hash桶），因此ConcurrentHashMap规定，每次至少要获取16个迁移任务（迁移16个hash桶，MIN_TRANSFER_STRIDE = 16） cas设置transferIndex的源码如下： 123456789101112131415161718private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; //计算每次迁移的node个数 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // 确保每次迁移的node个数不少于16个 ... for (int i = 0, bound = 0;;) &#123; ... //cas无锁算法设置 transferIndex = transferIndex - stride if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; ... ... &#125; ...//省略迁移逻辑 &#125; &#125; ForwardingNode节点 标记作用，表示其他线程正在扩容，并且此节点已经扩容完毕 关联了nextTable,扩容期间可以通过find方法，访问已经迁移到了nextTable中的数据 123456789101112 static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; //hash值为MOVED（-1）的节点就是ForwardingNode super(MOVED, null, null, null); this.nextTable = tab; &#125; //通过此方法，访问被迁移到nextTable中的数据 Node&lt;K,V&gt; find(int h, Object k) &#123; ... &#125;&#125; 何时扩容1 当前容量超过阈值12345final V putVal(K key, V value, boolean onlyIfAbsent) &#123; ... addCount(1L, binCount); ...&#125; 123456789101112private final void addCount(long x, int check) &#123; ... if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //s&gt;=sizeCtl 即容量达到扩容阈值，需要扩容 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; //调用transfer()扩容 ... &#125; &#125; &#125; 2 当链表中元素个数超过默认设定（8个），当数组的大小还未超过64的时候，此时进行数组的扩容，如果超过则将链表转化成红黑树123456789101112final V putVal(K key, V value, boolean onlyIfAbsent) &#123; ... if (binCount != 0) &#123; //链表中元素个数超过默认设定（8个） if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; ...&#125; 12345678910111213private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; //数组的大小还未超过64 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) //扩容 tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; //转换成红黑树 ... &#125; &#125;&#125; 3 当发现其他线程扩容时，帮其扩容1234567final V putVal(K key, V value, boolean onlyIfAbsent) &#123; ... //f.hash == MOVED 表示为：ForwardingNode，说明其他线程正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); ...&#125; 扩容过程分析 线程执行put操作，发现容量已经达到扩容阈值，需要进行扩容操作，此时transferindex=tab.length=32 扩容线程A 以cas的方式修改transferindex=32-16=16 ,然后按照降序迁移table[32]–table[16]这个区间的hash桶 迁移hash桶时，会将桶内的链表或者红黑树，按照一定算法，拆分成2份，将其插入nextTable[i]和nextTable[i+n]（n是table数组的长度）。 迁移完毕的hash桶,会被设置成ForwardingNode节点，以此告知访问此桶的其他线程，此节点已经迁移完毕。 相关代码如下： 123456789101112131415161718private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; ...//省略无关代码 synchronized (f) &#123; //将node链表，分成2个新的node链表 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //将新node链表赋给nextTab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); &#125; ...//省略无关代码&#125; 此时线程2访问到了ForwardingNode节点，如果线程2执行的put或remove等写操作，那么就会先帮其扩容。如果线程2执行的是get等读方法，则会调用ForwardingNode的find方法，去nextTable里面查找相关元素。 线程2加入扩容操作 如果准备加入扩容的线程，发现以下情况，放弃扩容，直接返回。 发现transferIndex=0,即所有node均已分配 发现扩容线程已经达到最大扩容线程数 部分源码分析tryPresize方法协调多个线程如何调用transfer方法进行hash桶的迁移（addCount，helpTransfer 方法中也有类似的逻辑） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960private final void tryPresize(int size) &#123;//计算扩容的目标size int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; //tab没有初始化 if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; //初始化之前，CAS设置sizeCtl=-1 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; //sc=0.75n,相当于扩容阈值 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // 此时并没有通过CAS赋值，因为其他想要执行初始化的线程， // 发现sizeCtl=-1，就直接返回，从而确保任何情况， // 只会有一个线程执行初始化操作。 sizeCtl = sc; &#125; &#125; &#125; //目标扩容size小于扩容阈值，或者容量超过最大限制时，不需要扩容 else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; //扩容 else if (tab == table) &#123; int rs = resizeStamp(n); //sc&lt;0表示，已经有其他线程正在扩容 if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt; //1 (sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs ：扩容线程数 &gt; MAX_RESIZERS-1 //2 sc == rs + 1 和 sc == rs + MAX_RESIZERS ：表示什么？？？ //3 (nt = nextTable) == null ：表示nextTable正在初始化 //4 transferIndex &lt;= 0 ：表示所有hash桶均分配出去 //如果不需要帮其扩容，直接返回 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //CAS设置sizeCtl=sizeCtl+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) //帮其扩容 transfer(tab, nt); &#125; // 第一个执行扩容操作的线程，将sizeCtl设置为： // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125; &#125; transfer方法负责迁移node节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //计算需要迁移多少个hash桶（MIN_TRANSFER_STRIDE该值作为下限，以避免扩容线程过多） if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; //扩容一倍 @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // 1.逆序迁移已经获取到的hash桶集合，如果迁移完毕， // 则更新transferIndex，获取下一批待迁移的hash桶 // 2.如果transferIndex=0，表示所以hash桶均被分配， // 将i置为-1，准备退出transfer方法 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; //更新待迁移的hash桶索引 while (advance) &#123; int nextIndex, nextBound; //更新迁移索引i。 if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; // transferIndex&lt;=0表示已经没有需要迁移的hash桶， // 将i置为-1，线程准备退出 i = -1; advance = false; &#125; // 当迁移完bound这个桶后，尝试更新transferIndex， // 获取下一批待迁移的hash桶 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //退出transfer if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; //最后一个迁移的线程，recheck后，做收尾工作，然后退出 nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 第一个扩容的线程，执行transfer方法之前，会设置 sizeCtl = // (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 后续帮其扩容的线程，执行transfer方法之前，会设置 sizeCtl = sizeCtl+1 // 每一个退出transfer的方法的线程，退出之前，会设置 sizeCtl = sizeCtl-1 // 那么最后一个线程退出时： // 必然有sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2)， // 即 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT //不相等，说明不到最后一个线程，直接退出transfer方法 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; //最后退出的线程要重新check下是否全部迁移完毕 i = n; // recheck before commit &#125; &#125; else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) advance = true; // already processed //迁移node节点 else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; //链表迁移 if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; //将node链表，分成2个新的node链表 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //将新node链表赋给nextTab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; //红黑树迁移 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 总结多线程无锁扩容的关键就是通过CAS设置sizeCtl与transferIndex变量，协调多个线程对table数组中的node进行迁移。 勘误：tab.length为32，扩容阈值是32*0.75=24]]></content>
      <categories>
        <category>ConcurrentHashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 版本控制的使用]]></title>
    <url>%2F2017%2F12%2F13%2FIDEA%20%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[版本控制的使用IntelliJ IDEA 下的版本控制介绍这一章节放在这么靠前位置来讲是因为版本控制在我心目中的地位比后面的实战知识点都来得重要。不管是个人开发或是团队开发，版本控制都是可以很好地被使用的，目前我找不到任何开发者不使用版本控制的理由。而且对于 IDE 来讲，集成版本控制的本身就是它最大的亮点之一，很多开发者也是为此而使用它。 在本章节中也会对 IntelliJ IDEA 的相关版本控制进行了介绍，会开始涉及到一些 IntelliJ IDEA 人性化设置，也希望你能从这一讲开始认识到 IntelliJ IDEA 的优雅。 很多人认为 IntelliJ IDEA 自带了 SVN 或是 Git 等版本控制工具，认为只要安装了 IntelliJ IDEA 就可以完全使用版本控制应有的功能。这完全是一种错误的解读，IntelliJ IDEA 是自带对这些版本控制工具的支持插件，但是该装什么版本控制客户端还是要照样装的。 如上图标注 1 所示，IntelliJ IDEA 对版本控制的支持是以插件化的方式来实现的。旗舰版默认支持目前主流的版本控制软件：CVS、Subversion（SVN）、Git、ClearCase、Mercurial、Perforce、TFS。又因为目前太多人使用 Github 进行协同或是项目版本管理，所以 IntelliJ IDEA 同时自带了 Github 插件，方便 Checkout 和管理你的 Github 项目。 SVN 的配置要在 IntelliJ IDEA 中使用 SVN，需要先安装 SVN 客户端或是 TortoiseSVN 这类图形化工具，Windows 系统这里推荐安装 TortoiseSVN，即使在不使用 IntelliJ IDEA 也可以方便管理我们的项目。 SVN 主要使用的版本有 1.6、1.7、1.8，最新的是 1.9。推荐大家使用 1.8 的。如果你的项目使用的是 1.6 的版本，在安装 1.8 之后是可以直接对项目文件进行升级的，所以无需担心，也因此更加推荐大家使用 1.8。 Subversion 官网下载：https://subversion.apache.org/download/#recommended-release TortoiseSVN 官网下载：http://tortoisesvn.net/downloads.zh.html 如上图箭头所示，在安装 TortoiseSVN 的时候，默认 command line client tools，是不安装的，这里建议勾选上。 如上图标注 1 所示，勾选 Use command line client 如上图标注 2 所示，建议 svn 的路径自己根据安装后的路径进行选择，不然有时候 IntelliJ IDEA 无法识别到会报：Cannot run program &quot;svn&quot; 这类错误。 如上图标注 3 所示，当使用一段时间 SVN 以后，发现各种 SVN 相关问题无法解决，可以考虑点击此按钮进行清除一下缓存。 根据目前的使用经验来看，IntelliJ IDEA 下 SVN 的使用经历并不算愉快，至少比 Git 不好用很多，经常遇到很多问题，所以这里也算是先给大家提个醒。如果紧急情况下 IntelliJ IDEA 无法更新、提交的时候，要记得使用 TortoiseSVN 来操作。 Git 的配置要在 IntelliJ IDEA 中使用 Git，需要先安装 Git 客户端，这里推荐安装官网版本。 Git 主要的版本有 1.X、2.X，最新的是 2.X，使用版本随意，但是不要太新了，不然可能 IntelliJ IDEA 小旧版本会无法支持可能。 Git 官网下载：http://git-scm.com/ TortoiseGit 官网下载：http://download.tortoisegit.org/tgit/ 如上图标注 1 所示，确定好该路径下是否有对应的可执行文件。 Github 的配置和使用 如上图标注 1 所示，填写你的 Github 登录账号和密码，点击 Test 可以进行测试是否可以正确连上。 如上图标注 1 所示，支持直接从你当前登录的 Github 账号上 Checkout 项目。 如上图标注 1 所示，支持把当前本地项目分享到你的 Github 账号上。 如上图标注 1 所示，支持创建 Gist。Github 的 Gist 官网地址：https://gist.github.com/ 版本控制主要操作按钮 如上图标注 1 所示，对目录进行右键弹出的菜单选项。 如上图标注 1 所示，对文件进行右键弹出的菜单选项。 如上图标注红圈所示，为工具栏上版本控制操作按钮，基本上大家也都是使用这里进行操作。 第一个按钮：Update Project 更新项目。 第二个按钮：Commit changes 提交项目上所有变化文件。点击这个按钮不会立马提交所有文件，而是先弹出一个被修改文件的一个汇总框，具体操作下面会有图片进行专门介绍。 第三个按钮：Compare with the Same Repository Version 当前文件与服务器上该文件通版本的内容进行比较。如果当前编辑的文件没有修改，则是灰色不可点击。 第四个按钮：Show history 显示当前文件的历史记录。 第五个按钮：Revert 还原当前被修改的文件到未被修改的版本状态下。如果当前编辑的文件没有修改，则是灰色不可点击。 如上图标注 1 所示，菜单栏上的版本控制操作区。 版本控制相关的常用设置说明 如上图标注 1 所示，当前项目使用的版本控制是 Git。如果你不愿意这个项目继续使用版本控制可以点击旁边的减号按钮，如果你要切换版本控制，可以点击 Git，会出现 IntelliJ IDEA 支持的各种版本控制选择列表，但是我们一般情况下一个项目不会有多个版本控制的。 如上图标注 2 所示，Show directories with changed descendants 表示子目录有文件被修改了，则该文件的所有上层目录都显示版本控制被概念的颜色。默认是不勾选的，我一般建议勾选此功能。 如上图标注 1 所示，When files are created 表示当有新文件放进项目中的时候 IntelliJ IDEA 做如何处理，默认是 Show options before adding to version control 表示弹出提示选项，让开发者决定这些新文件是加入到版本控制中还是不加入。如果不想弹出提示，则选择下面两个选项进行默认操作。 如上图标注 2 所示，When files are deleted 表示当有新文件在项目中被删除的时候 IntelliJ IDEA 做如何处理，默认是 Show options before removing from version control 表示弹出提示选项，让开发者决定这些被删除的是否从版本控制中删除。如果不想弹出提示，则选择下面两个选项进行默认操作。 如上图标注 1 所示，对于不想加入到版本控制的文件，可以添加要此忽略的列表中。但是如果已经加入到版本控制的文件使用此功能，则表示该文件 或 目录无法再使用版本控制相关的操作，比如提交、更新等。我个人使用过程中发现在 SVN 上此功能不太好用，Git 上是可以用的。 上图所示的弹出层就是本文上面说的 Commit Changes 点击后弹出的变动文件汇总弹出层。 如上图标注 1 所示，可以在文件上右键进行操作。 Show Diff 当前文件与服务器上该文件通版本的内容进行比较。 Move to Another Changelist 将选中的文件转移到其他的 Change list 中。Change list 是一个重要的概念，这里需要进行重点说明。很多时候，我们开发一个项目同时并发的任务可能有很多，每个任务涉及到的文件可能都是基于业务来讲的。所以就会存在一个这样的情况：我改了 30 个文件，其中 15 个文件是属于订单问题，剩下 15 个是会员问题，那我希望提交代码的时候是根据业务区分这些文件的，这样我填写 Commit Message 是好描述的，同时在文件多的情况下，我也好区分这些要提交的文件业务模块。所以我一般会把属于订单的 15 个文件转移到其他的 Change list中，先把专注点集中在 15 个会员问题的文件，先提交会员问题的 Change list，然后在提交订单会员的 Change list。我个人还有一种用法是把一些文件暂时不提交的文件转移到一个我指定的 Change list，等后面我觉得有必要提交了，再做提交操作，这样这些文件就不会干扰我当前修改的文件提交。总结下 Change list 的功能就是为了让你更好地管理你的版本控制文件，让你的专注点得到更好的集中，从而提供效率。 Jump to Source 打开并跳转到被选中。 如上图标注 2 所示，可以根据工具栏按钮进行操作，操作的对象会鼠标选中的文件，多选可以按 Ctrl后不放，需要注意的是这个更前面的复选框是没有多大关系的。 如上图标注 3 所示，可以在提交前自动对被提交的文件进行一些操作事件（该项目使用的 Git，使用其他版本控制可能有些按钮有差异。）： Reformat code 格式化代码，如果是 Web 开发建议不要勾选，因为格式化 JSP 类文件，格式化效果不好。如果都是 Java 类则可以安心格式化。 Rearrange code 重新编排代码，IntelliJ IDEA 支持各种复杂的编排设置选项，这个会在后面说。设置好了编码功能之后，这里就可以尝试勾选这个进行自动编排。 Optimize imports 优化导入包，会在自动去掉没有使用的包。这个建议都勾选，这个只对 Java 类有作用，所以不用担心有副作用。 Perform code analysis 进行代码分析，这个建议不用在提交的时候处理，而是在开发完之后，要专门养成对代码进行分析的习惯。IntelliJ IDEA 集成了代码分析功能。 Check TODO 检查代码中的 TODO。TODO 功能后面也会有章节进行讲解，这里简单介绍：这是一个记录待办事项的功能。 Cleanup 清除下版本控制系统，去掉一些版本控制系统的错误信息，建议勾选（主要针对 SVN，Git 不适用）。 如上图标注 4 所示，填写提交的信息。 如上图标注 5 所示，Change list 改变列表，这是一个下拉选项，说明我们可以切换不同的 Change list，提交不同的 Change list 文件。 如上图标注箭头所示，我们可以查看我们提交历史中使用的 Commit Message，有些时候，我们做得是同一个任务，但是需要提交多次，为了更好管理项目，建议是提交的 Message 是保持一致的。 如上图标注箭头所示，如果你使用的 Git，点击此位置可以切换分支和创建分支，以及合并、删除分支等操作。 SVN 的使用SVN 的这个窗口有的 IntelliJ IDEA 上叫 Changes，有的叫 Version Control，具体是什么原因引起这样的差异，我暂时还不清楚。但是不管叫法如何里面的结构是一样的，所以对使用者来讲没多大影响，但是你需要知道他们其实是一样的功能即可。 上图 Local Changes 这个 Tab 表示当前项目的 SVN 中各个文件的总的情况预览。这里的 Default 是 IntelliJ IDEA 的默认 change list 名称，no commit 是我自己创建的一个change list，我个人有一个习惯是把一些暂时不需要提交的先放这个 list 里面。change list 很常用而且重要，本文前面也有强调过了，所以一定好认真对待。unversioned Files表示项目中未加到版本控制系统中的文件，你可以点击 Click to browse，会弹出一个弹出框列表显示这些未被加入的文件。 上图 Repository 这个 Tab 表示项目的 SVN 信息汇总，内容非常的详细，也是我平时用最多的地方。如果你点击这个 Tab 没看到数据，是因为你需要点击上图红圈这个刷新按钮。初次使用下默认的过滤条件不是我上图这样的，我习惯根据 User 进行过滤筛选，所以上图箭头中的 Filter 我是选择 User。选择之后，如上图标注 1 所示，显示了这个项目中参与提交的各个用户名，选择一个用户之后，上图标注 2 所以会显示出该用户提交了哪些记录。选择标注 2 区域中的某个提交记录后，标注 3 显示对应的具体提交细节，我们可以对这些文件进行右键操作，具体操作内容跟本文上面提到的那些提交时的操作按钮差不多，这里不多讲。 总的来说，SVN 这个功能用来管理和审查开发团队中人员的代码是非常好用的，所以非常非常建议你一定要学会该功能。 Git 常见问题 更新的时候报： 1Can&apos;t update: no tracked branch 解决办法：打开 git-bash（路径：C:\Program Files\Git\git-bash.exe），切换到这个更新不下来的项目的根目录，然后输入：git branch --set-upstream-to origin/master master，回车之后重新回到 IntelliJ IDEA 进行更新，正常就可以了。 输错密码后，弹出验证的登录框没有再出现： 解决办法如下图：选择 Do not save, forget passwords after restart 等你确定你的密码没错后再选择保存密码方案。 Git Flow 的介绍Git Flow 概念 Git Flow 是一个 git 扩展集，按 Vincent Driessen 的分支模型提供高层次的库操作。这里的重点是 Vincent Driessen 的分支模型思想，下面讲解的内容也是基于 Vincent Driessen 思想。 Vincent Driessen 的观点：http://nvie.com/posts/a-successful-git-branching-model/ Git Flow 是一个 git 扩展集 你可以理解 Git Flow 是一个基于 Git 的插件，这个插件简化了 Git 一些复杂的命令，比如 Git Flow 用一条命令，就可以代替 Git 原生 10 条命令。 Git Flow 对原生的 Git 不会有任何影响，你可以照旧用 Git 原生命令，也可以使用 Git Flow 命令。 还有其他的一些分支管理模型思想，具体可以看：http://www.ruanyifeng.com/blog/2015/12/git-workflow.html Git Flow 核心概念 必须有的两个核心分支（长期分支）： master，Git 代码仓库中默认的一条主分支。这条分支上的代码一般都建议为是正式版本的代码，并且这条分支不能进行代码修改，只能用来合并其他分支。 develop，一般用于存储开发过程的代码分支，并且这条分支也不能进行代码修改，只能用来合并其他辅助分支。 根据情况创建的辅助分支（临时分支） feature branches（功能分支） 基于 develop 分支上创建 开发完成后合并到 develop 分支上 当要开始一个新功能的开发时，我门可以创建一个 Feature branches 。等待这个新功能开发完成并确定应用到新版本中就合并回 develop 对于单人开发的 feature branches，start 之后，开发完成后可以直接 finish。 对于多人开发的 feature branches，start 之后，开发完成后先 publish 给其他开发人员进行合并，最后大家都开发完成后再 finish。这个思路也同样适用下面几个辅助分支场景。 feature branches 开发过程有 bug，直接在 feature branches 上修改、提交。 release branches（预发布分支） 基于 develop 分支上创建 测试确定新功能没有问题，合并到 develop 分支和 master 分支上 用来做新版本发布前的准备工作，在上面可以做一些小的 bug 修复、准备发布版本号等等和发布有关的小改动，其实已经是一个比较成熟的版本了。另外这样我们既可以在预发布分支上做一些发布前准备，也不会影响 “develop” 分支上下一版本的新功能开发。 hotfix branches（基于 master 基础上的生产环境 bug 的修复分支） 基于 master 分支上创建 修复测试无误后合并到 master 分支和 develop 分支上 主要用于处理线上版本出现的一些需要立刻修复的 bug 情况 Git Flow 安装 Windows：如果你安装 Git 用的是 Git for Windows，那它已经内置了。 Mac：brew install git-flow-avh Linux：wget --no-check-certificate -q https://raw.githubusercontent.com/petervanderdoes/gitflow-avh/develop/contrib/gitflow-installer.sh &amp;&amp; sudo bash gitflow-installer.sh install stable; rm gitflow-installer.sh 更多版本：https://github.com/petervanderdoes/gitflow-avh/wiki/Installation 在系统环境上支持之后，再安装 IntelliJ IDEA 对 Git Flow 支持的插件：https://plugins.jetbrains.com/plugin/7315-git-flow-integration Git Flow 基础命令资料 https://danielkummer.github.io/git-flow-cheatsheet/index.zh_CN.html http://www.jianshu.com/p/9e4291078853 http://stormzhang.com/git/2014/01/29/git-flow/ Hotfix/Release/Develop/Feature/ Git Flow Integration 插件的使用· 如果你已经理解了上面的理论，再看下面这些截图你能理解对应的是什么意思。]]></content>
      <categories>
        <category>IntelliJ IDEA</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 调试教程]]></title>
    <url>%2F2017%2F12%2F12%2FIntelliJ%20IDEA%20%20%E8%B0%83%E8%AF%95%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[IntelliJ IDEA 调试教程在调试代码的时候，你的项目得debug模式启动，也就是点那个绿色的甲虫启动服务器，然后，就可以在代码里面断点调试啦。下面不要在意，这个快捷键具体是啥，因为，这个keymap是可以自己配置的，有的人keymap是mac版的，有的是Windows版的。我的就是Windows，而且修改keymap为eclipse的keymap，因为我算是eclipse转过来的吧。 看图，每一个按钮（按钮对应图中的数字）都是什么功能 rerun XXX，这个就是直接重新跑某个程序。 这个相当于eclipse里面的f8，直接跑完，到下一个断点停下，没有就直接跑完程序。 停止项目或者程序。要是自己的main呢，点一下就停下了，要是Java web项目，则点2下，就把服务器给停了。 查看所有的断点设置情况。具体详情，下面有示意图，再细细解释。 直接取消所有断点，让所有断点无效。 要是你一不小心把这个下面的布局给弄乱了，你点这个，就把下面的布局给还原咯。 跳转到当前代码所执行的地方，也就是说你在看代码的时候，点到其他地方，一点这个按钮，就到了程序执行到当前哪行的代码的地方。 下一步，如果是方法，他是不会跳进去的。就是一行行的往下走。（eclipse里面的快捷键就是f6） 跳转到详情，如果下一行调试代码是可执行方法，就可以f7进去，查看这个方法的运行详细情况。重点就是点进去执行 从详情跳出去，和上面的9相反。 看字面意思就是跳转到下一个断点 这个点开之后，可以计算你想要看的代码段的值，后面详细上图。 看意思，同eclipse里面的watch，查看某个对象的值，自定义的对象。 把自定义的查看对象的值，分开到另一个tab页。 有时候当我们步入方法体之后，还想回退到方法体外，点这个按钮后，断点重新回到方法体之外。在继续还是可以再次进到方法内 查看断点处的某个对象的值，可以 如下几个方法：1，选中对象后，鼠标悬停在对象上 2 秒左右2，在watch里面添加这个对象，3，下面也许会自动列出来你代码里面有的4，使用上面图上标注的12的那个按钮 下面就再详细说下 4，12，13，144，查看所有的断点的详情，点开如下所示。在图中condition中可以设置断点的条件，当i==4的时候，才停下。查看具体断点内容。 关于设置断点条件，还可以，直接在代码断点处，右键设置，完啦之后，done，设置完成。 12，这个用的也比较多，这个就比较随意。可以根据你的输入，计算你要的结果，不局限代码里面的变量啥的。这个在debug的时候，使用起来是很方便的。 13，14，这2个点完之后，效果如下图，只是把自定义的变量和代码里面自带的变量分在两个tab页面展示。你可以点13号按钮，自行添加，你想查看的变量的值。 还有个需求，就是在调试代码的时候，实时的修改，运行状态的代码变量的值。 仔细看下图，就知道，怎么在实时调试代码的时候，怎么设置某些变量的值，可以看到，我上面在输入a之后，下面就有类似你写代码时候的提示，你就可以在这地方修改变量的值啦 关于调试的时候，设置运行时的参数，如下： 入口如下，2个地方都可以。 一般都是跑简单的main方法，跑main方法的时候，还带参数文件的，还是第一次，顺带做个记录吧。 更新：这个编辑器为了方便从eclipse编辑器转过来的同学们，他可以设置keymap的。具体看图。 因为我就是刚刚开始的时候，使用的就是eclipse，后来转过来的，所以，在使用的时候，就先设置了一下，这个键盘映射。使用的还是以前在eclipse上使用的快捷键。不需要再次去记一遍新的快捷键映射。这个也是极其方便的。 所以，在这个debug的快捷键上和使用eclipse时候，是一样的f5进去，f6是下一步。]]></content>
      <categories>
        <category>IntelliJ IDEA</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程面试题]]></title>
    <url>%2F2017%2F12%2F10%2FJava%E7%BA%BF%E7%A8%8B%E9%9D%A2%E8%AF%95%E9%A2%98%20Top%2050%2F</url>
    <content type="text"><![CDATA[Java线程面试题摘要： 不管你是新程序员还是老手，你一定在面试中遇到过有关线程的问题。Java语言一个重要的特点就是内置了对并发的支持，让Java大受企业和程序员的欢迎。大多数待遇丰厚的Java开发职位都要求开发者精通多线程技术并且有丰富的Java程序开发、调试、优化经验，所以线程相关的问题在面试中经常会被提到。 不管你是新程序员还是老手，你一定在面试中遇到过有关线程的问题。Java语言一个重要的特点就是内置了对并发的支持，让Java大受企业和程序员的欢迎。大多数待遇丰厚的Java开发职位都要求开发者精通多线程技术并且有丰富的Java程序开发、调试、优化经验，所以线程相关的问题在面试中经常会被提到。 在典型的Java面试中， 面试官会从线程的基本概念问起, 如：为什么你需要使用线程， 如何创建线程，用什么方式创建线程比较好（比如：继承thread类还是调用Runnable接口），然后逐渐问到并发问题像在Java并发编程的过程中遇到了什么挑战，Java内存模型，JDK1.5引入了哪些更高阶的并发工具，并发编程常用的设计模式，经典多线程问题如生产者消费者，哲学家就餐，读写器或者简单的有界缓冲区问题。仅仅知道线程的基本概念是远远不够的， 你必须知道如何处理死锁，竞态条件，内存冲突和线程安全等并发问题。掌握了这些技巧，你就可以轻松应对多线程和并发面试了。 许多Java程序员在面试前才会去看面试题，这很正常。因为收集面试题和练习很花时间，所以我从许多面试者那里收集了Java多线程和并发相关的50个热门问题。我只收集了比较新的面试题且没有提供全部答案。想必聪明的你对这些问题早就心中有数了， 如果遇到不懂的问题，你可以用Google找到答案。若你实在找不到答案，可以在文章的评论中向我求助。你也可以在这找到一些答案Java线程问答Top 12。 50道Java线程面试题 下面是Java线程相关的热门面试题，你可以用它来好好准备面试。 什么是线程？ 线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。程序员可以通过它进行多处理器编程，你可以使用多线程对运算密集型任务提速。比如，如果一个线程完成一个任务要100毫秒，那么用十个线程完成改任务只需10毫秒。Java在语言层面对多线程提供了卓越的支持，它也是一个很好的卖点。欲了解更多详细信息请点击这里。 线程和进程有什么区别？ 线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。别把它和栈内存搞混，每个线程都拥有单独的栈内存用来存储本地数据。更多详细信息请点击这里。 如何在Java中实现线程？ 在语言层面有两种方式。java.lang.Thread 类的实例就是一个线程但是它需要调用java.lang.Runnable接口来执行，由于线程类本身就是调用的Runnable接口所以你可以继承java.lang.Thread 类或者直接调用Runnable接口来重写run()方法实现线程。更多详细信息请点击这里. 用Runnable还是Thread？ 这个问题是上题的后续，大家都知道我们可以通过继承Thread类或者调用Runnable接口来实现线程，问题是，那个方法更好呢？什么情况下使用它？这个问题很容易回答，如果你知道Java不支持类的多重继承，但允许你调用多个接口。所以如果你要继承其他类，当然是调用Runnable接口好了。更多详细信息请点击这里。 Thread 类中的start() 和 run() 方法有什么区别？ 这个问题经常被问到，但还是能从此区分出面试者对Java线程模型的理解程度。start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。更多讨论请点击这里 Java中Runnable和Callable有什么不同？ Runnable和Callable都代表那些要在不同的线程中执行的任务。Runnable从JDK1.0开始就有了，Callable是在JDK1.5增加的。它们的主要区别是Callable的 call() 方法可以返回值和抛出异常，而Runnable的run()方法没有这些功能。Callable可以返回装载有计算结果的Future对象。我的博客有更详细的说明。 Java中CyclicBarrier 和 CountDownLatch有什么不同？ CyclicBarrier 和 CountDownLatch 都可以用来让一组线程等待其它线程。与 CyclicBarrier 不同的是，CountdownLatch 不能重新使用。点此查看更多信息和示例代码。 Java内存模型是什么？ Java内存模型规定和指引Java程序在不同的内存架构、CPU和操作系统间有确定性地行为。它在多线程的情况下尤其重要。Java内存模型对一个线程所做的变动能被其它线程可见提供了保证，它们之间是先行发生关系。这个关系定义了一些规则让程序员在并发编程时思路更清晰。比如，先行发生关系确保了： 线程内的代码能够按先后顺序执行，这被称为程序次序规则。对于同一个锁，一个解锁操作一定要发生在时间上后发生的另一个锁定操作之前，也叫做管程锁定规则。前一个对volatile的写操作在后一个volatile的读操作之前，也叫volatile变量规则。一个线程内的任何操作必需在这个线程的start()调用之后，也叫作线程启动规则。一个线程的所有操作都会在线程终止之前，线程终止规则。一个对象的终结操作必需在这个对象构造完成之后，也叫对象终结规则。可传递性 我强烈建议大家阅读《Java并发编程实践》第十六章来加深对Java内存模型的理解。 Java中的volatile 变量是什么？ volatile是一个特殊的修饰符，只有成员变量才能使用它。在Java并发程序缺少同步类的情况下，多线程对成员变量的操作对其它线程是透明的。volatile变量可以保证下一个读取操作会在前一个写操作之后发生，就是上一题的volatile变量规则。点击这里查看更多volatile的相关内容。 什么是线程安全？Vector是一个线程安全类吗？ （详见这里) 如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。 Java中什么是竞态条件？ 举个例子说明。 竞态条件会导致程序在并发情况下出现一些bugs。多线程对一些资源的竞争的时候就会产生竞态条件，如果首先要执行的程序竞争失败排到后面执行了，那么整个程序就会出现一些不确定的bugs。这种bugs很难发现而且会重复出现，因为线程间的随机竞争。一个例子就是无序处理，详见答案。 Java中如何停止一个线程？ Java提供了很丰富的API但没有为停止线程提供API。JDK 1.0本来有一些像stop(), suspend() 和 resume()的控制方法但是由于潜在的死锁威胁因此在后续的JDK版本中他们被弃用了，之后Java API的设计者就没有提供一个兼容且线程安全的方法来停止一个线程。当run() 或者 call() 方法执行完的时候线程会自动结束,如果要手动结束一个线程，你可以用volatile 布尔变量来退出run()方法的循环或者是取消任务来中断线程。点击这里查看示例代码。 一个线程运行时发生异常会怎样？ 这是我在一次面试中遇到的一个很刁钻的Java面试题, 简单的说，如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。 如何在两个线程间共享数据？ 你可以通过共享对象来实现这个目的，或者是使用像阻塞队列这样并发的数据结构。这篇教程《Java线程间通信》(涉及到在两个线程间共享对象)用wait和notify方法实现了生产者消费者模型。 Java中notify 和 notifyAll有什么区别？ 这又是一个刁钻的问题，因为多线程可以等待单监控锁，Java API 的设计人员提供了一些方法当等待条件改变的时候通知它们，但是这些方法没有完全实现。notify()方法不能唤醒某个具体的线程，所以只有一个线程在等待的时候它才有用武之地。而notifyAll()唤醒所有线程并允许他们争夺锁确保了至少有一个线程能继续运行。我的博客有更详细的资料和示例代码。 为什么wait, notify 和 notifyAll这些方法不在thread类里面？ 这是个设计相关的问题，它考察的是面试者对现有系统和一些普遍存在但看起来不合理的事物的看法。回答这些问题的时候，你要说明为什么把这些方法放在Object类里是有意义的，还有不把它放在Thread类里的原因。一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。你也可以查看这篇文章了解更多。 什么是ThreadLocal变量？ ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。线程局部变量的另一个不错的例子是ThreadLocalRandom类，它在多线程环境中减少了创建代价高昂的Random对象的个数。查看答案了解更多。 什么是FutureTask？ 在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。 Java中interrupted 和 isInterruptedd方法的区别？ interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。简单的说就是任何抛出InterruptedException异常的方法都会将中断状态清零。无论如何，一个线程的中断状态有有可能被其它线程调用中断来改变。 为什么wait和notify方法要在同步块中调用？ 主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。 为什么你应该在循环中检查等待条件? 处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。因此，当一个等待线程醒来时，不能认为它原来的等待状态仍然是有效的，在notify()方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用wait()方法效果更好的原因，你可以在Eclipse中创建模板调用wait和notify试一试。如果你想了解更多关于这个问题的内容，我推荐你阅读《Effective Java》这本书中的线程和同步章节。 Java中的同步集合与并发集合有什么区别？ 同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在Java1.5之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。更多内容详见答案。 Java中堆和栈有什么不同？ 为什么把这个问题归类在多线程和并发面试题里？因为栈是一块和线程紧密相关的内存区域。每个线程都有自己的栈内存，用于存储本地变量，方法参数和栈调用，一个线程中存储的变量对其它线程是不可见的。而堆是所有线程共享的一片公用内存区域。对象都在堆里创建，为了提升效率线程会从堆中弄一个缓存到自己的栈，如果多个线程使用该变量就可能引发问题，这时volatile 变量就可以发挥作用了，它要求线程从主存中读取变量的值。 更多内容详见答案。 什么是线程池？ 为什么要使用它？ 创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创建的线程数有限。为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。从JDK1.5开始，Java API提供了Executor框架让你可以创建不同的线程池。比如单线程池，每次处理一个任务；数目固定的线程池或者是缓存线程池（一个适合很多生存期短的任务的程序的可扩展线程池）。更多内容详见这篇文章。 如何写代码来解决生产者消费者问题？ 在现实中你解决的许多线程问题都属于生产者消费者模型，就是一个线程生产任务供其它线程进行消费，你必须知道怎么进行线程间通信来解决这个问题。比较低级的办法是用wait和notify来解决这个问题，比较赞的办法是用Semaphore 或者 BlockingQueue来实现生产者消费者模型，这篇教程有实现它。 如何避免死锁？http://www.cnblogs.com&amp;iframeId=iframe_0.21145907562000632“ frameborder=”0” scrolling=”no” height=”20”&gt; Java多线程中的死锁 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件： 互斥条件：一个资源每次只能被一个进程使用。请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。这篇教程有代码示例和避免死锁的讨论细节。 Java中活锁和死锁有什么区别？ 这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主要区别是前者进程的状态可以改变但是却不能继续执行。 怎么检测一个线程是否拥有锁？ 我一直不知道我们竟然可以检测一个线程是否拥有锁，直到我参加了一次电话面试。在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。你可以查看这篇文章了解更多。 你如何在Java中获取线程堆栈？ 对于不同的操作系统，有多种方法来获得Java进程的线程堆栈。当你获取线程堆栈时，JVM会把所有线程的状态存到日志文件或者输出到控制台。在Windows你可以使用Ctrl + Break组合键来获取线程堆栈，Linux下用kill -3命令。你也可以用jstack这个工具来获取，它对线程id进行操作，你可以用jps这个工具找到id。 JVM中哪个参数是用来控制线程的栈堆栈小的 这个问题很简单， -Xss参数用来控制线程的堆栈大小。你可以查看JVM配置列表来了解这个参数的更多信息。 Java中synchronized 和 ReentrantLock 有什么不同？ Java在过去很长一段时间只能通过synchronized关键字来实现互斥，它有一些缺点。比如你不能扩展锁之外的方法或者块边界，尝试获取锁时不能中途取消等。Java 5 通过Lock接口提供了更复杂的控制来解决这些问题。 ReentrantLock 类实现了 Lock，它拥有与 synchronized 相同的并发性和内存语义且它还具有可扩展性。你可以查看这篇文章了解更多 有三个线程T1，T2，T3，怎么确保它们按顺序执行？ 在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用T2，T2调用T1)，这样T1就会先完成而T3最后完成。你可以查看这篇文章了解更多。 Thread类中的yield方法有什么作用？ Yield方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行。点击这里查看更多yield方法的相关内容。 Java中ConcurrentHashMap的并发度是什么？ ConcurrentHashMap把实际map划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是ConcurrentHashMap类构造函数的一个可选参数，默认值为16，这样在多线程情况下就能避免争用。欲了解更多并发度和内部大小调整请阅读我的文章How ConcurrentHashMap works in Java。 Java中Semaphore是什么？ Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。更多详细信息请点击这里。 如果你提交任务时，线程池队列已满。会时发会生什么？ 这个问题问得很狡猾，许多程序员会认为该任务会阻塞直到线程池队列有空位。事实上如果一个任务不能被调度执行那么ThreadPoolExecutor’s submit()方法将会抛出一个RejectedExecutionException异常。 Java线程池中submit() 和 execute()方法有什么区别？ 两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中, 而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。更多详细信息请点击这里。 什么是阻塞式方法？ 阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。更多详细信息请点击这里。 Swing是线程安全的吗？ 为什么？ 你可以很肯定的给出回答，Swing不是线程安全的，但是你应该解释这么回答的原因即便面试官没有问你为什么。当我们说swing不是线程安全的常常提到它的组件，这些组件不能在多线程中进行修改，所有对GUI组件的更新都要在AWT线程中完成，而Swing提供了同步和异步两种回调方法来进行更新。点击这里查看更多swing和线程安全的相关内容。 Java中invokeAndWait 和 invokeLater有什么区别？ 这两个方法是Swing API 提供给Java开发者用来从当前线程而不是事件派发线程更新GUI组件用的。InvokeAndWait()同步更新GUI组件，比如一个进度条，一旦进度更新了，进度条也要做出相应改变。如果进度被多个线程跟踪，那么就调用invokeAndWait()方法请求事件派发线程对组件进行相应更新。而invokeLater()方法是异步调用更新组件的。更多详细信息请点击这里。 Swing API中那些方法是线程安全的？ 这个问题又提到了swing和线程安全，虽然组件不是线程安全的但是有一些方法是可以被多线程安全调用的，比如repaint(), revalidate()。 JTextComponent的setText()方法和JTextArea的insert() 和 append() 方法也是线程安全的。 如何在Java中创建Immutable对象？ 这个问题看起来和多线程没什么关系， 但不变性有助于简化已经很复杂的并发程序。Immutable对象可以在没有同步的情况下共享，降低了对该对象进行并发访问时的同步化开销。可是Java没有@Immutable这个注解符，要创建不可变类，要实现下面几个步骤：通过构造方法初始化所有成员、对变量不要提供setter方法、将所有的成员声明为私有的，这样就不允许直接访问这些成员、在getter方法中，不要直接返回对象本身，而是克隆对象，并返回对象的拷贝。我的文章how to make an object Immutable in Java有详细的教程，看完你可以充满自信。 Java中的ReadWriteLock是什么？ 一般而言，读写锁是用来提升并发程序性能的锁分离技术的成果。Java中的ReadWriteLock是Java 5 中新增的一个接口，一个ReadWriteLock维护一对关联的锁，一个用于只读操作一个用于写。在没有写线程的情况下一个读锁可能会同时被多个读线程持有。写锁是独占的，你可以使用JDK中的ReentrantReadWriteLock来实现这个规则，它最多支持65535个写锁和65535个读锁。 多线程中的忙循环是什么? 忙循环就是程序员用循环让一个线程等待，不像传统方法wait(), sleep() 或 yield() 它们都放弃了CPU控制，而忙循环不会放弃CPU，它就是在运行一个空循环。这么做的目的是为了保留CPU缓存，在多核系统中，一个等待线程醒来的时候可能会在另一个内核运行，这样会重建缓存。为了避免重建缓存和减少等待重建的时间就可以使用它了。你可以查看这篇文章获得更多信息。 volatile 变量和 atomic 变量有什么不同？ 这是个有趣的问题。首先，volatile 变量和 atomic 变量看起来很像，但功能却不一样。Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。 如果同步块内的线程抛出异常会发生什么？ 这个问题坑了很多Java程序员，若你能想到锁是否释放这条线索来回答还有点希望答对。无论你的同步块是正常还是异常退出的，里面的线程都会释放锁，所以对比锁接口我更喜欢同步块，因为它不用我花费精力去释放锁，该功能可以在finally block里释放锁实现。 单例模式的双检锁是什么？ 这个问题在Java面试中经常被问到，但是面试官对回答此问题的满意度仅为50%。一半的人写不出双检锁还有一半的人说不出它的隐患和Java1.5是如何对它修正的。它其实是一个用来创建线程安全的单例的老方法，当单例实例第一次被创建时它试图用单个锁进行性能优化，但是由于太过于复杂在JDK1.4中它是失败的，我个人也不喜欢它。无论如何，即便你也不喜欢它但是还是要了解一下，因为它经常被问到。你可以查看how double checked locking on Singleton works这篇文章获得更多信息。 如何在Java中创建线程安全的Singleton？ 这是上面那个问题的后续，如果你不喜欢双检锁而面试官问了创建Singleton类的替代方法，你可以利用JVM的类加载和静态变量初始化特征来创建Singleton实例，或者是利用枚举类型来创建Singleton，我很喜欢用这种方法。你可以查看这篇文章获得更多信息。 写出3条你遵循的多线程最佳实践 这种问题我最喜欢了，我相信你在写并发代码来提升性能的时候也会遵循某些最佳实践。以下三条最佳实践我觉得大多数Java程序员都应该遵循： 给你的线程起个有意义的名字。 这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比 Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要框架甚至JDK都遵循这个最佳实践。避免锁定和缩小同步的范围 锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。多用同步类少用wait 和 notify 首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。多用并发集合少用同步集合 这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程时使用并发集合效果更好。如果下一次你需要用到map，你应该首先想到用ConcurrentHashMap。我的文章Java并发集合有更详细的说明。 如何强制启动一个线程？ 这个问题就像是如何强制进行Java垃圾回收，目前还没有觉得方法，虽然你可以使用System.gc()来进行垃圾回收，但是不保证能成功。在Java里面没有办法强制启动一个线程，它是被线程调度器控制着且Java没有公布相关的API。 Java中的fork join框架是什么？ fork join框架是JDK7中出现的一款高效的工具，Java开发人员可以通过它充分利用现代服务器上的多处理器。它是专门为了那些可以递归划分成许多子模块设计的，目的是将所有可用的处理能力用来提升程序的性能。fork join框架一个巨大的优势是它使用了工作窃取算法，可以完成更多任务的工作线程可以从其它线程中窃取任务来执行。你可以查看这篇文章获得更多信息。 Java多线程中调用wait() 和 sleep()方法有什么不同？ Java程序中wait 和 sleep都会造成某种形式的暂停，它们可以满足不同的需要。wait()方法用于线程间通信，如果等待条件为真且其它线程被唤醒时它会释放锁，而sleep()方法仅仅释放CPU资源或者让当前线程停止执行一段时间，但不会释放锁。你可以查看这篇文章获得更多信息。 以上就是50道热门Java多线程和并发面试题啦。我没有分享所有题的答案但给未来的阅读者提供了足够的提示和线索来寻找答案。如果你真的找不到某题的答案，联系我吧，我会加上去的。这篇文章不仅可以用来准备面试，还能检查你对多线程、并发、设计模式和竞态条件、死锁和线程安全等线程问题的理解。我打算把这篇文章的问题弄成所有Java多线程问题的大合集，但是没有你的帮助恐怖是不能完成的，你也可以跟我分享其它任何问题，包括那些你被问到却还没有找到答案的问题。这篇文章对初学者或者是经验丰富的Java开发人员都很有用，过两三年甚至五六年你再读它也会受益匪浅。它可以扩展初学者尤其有用因为这个可以扩展他们的知识面，我会不断更新这些题，大家可以在文章后面的评论中提问，分享和回答问题一起把这篇面试题完善。]]></content>
      <categories>
        <category>Java线程</category>
      </categories>
      <tags>
        <tag>面试精髓</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(两到三年)Java 面试精髓]]></title>
    <url>%2F2017%2F12%2F10%2F(%E4%B8%A4%E5%88%B0%E4%B8%89%E5%B9%B4)Java%20%E9%9D%A2%E8%AF%95%E7%B2%BE%E9%AB%93%2F</url>
    <content type="text"><![CDATA[(两到三年)Java 面试精髓Struts2框架的执行流程 ?从客户端发送请求过来,先经过前端控制器（核心过滤器）过滤器中,执行一组拦截器（一组拦截器 就会完成部分功能代码）执行目标Action, 在Action中返回一个结果视图,根据Result的配置进行页面的跳转. Struts2和Struts1没有任何联系.Struts2内核是webwork的内核. hibernate框架的理解?定义: Hibernate是一个开放源代码的对象关系映射（ORM）框架，它对JDBC进行了非常轻量级的对象封装， 使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库.可以通过对象保存到关系型数据库中,仅提供sava/get方法即可 Hibernate是一个持久层的ORM框架. Spring框架的理解?Spring是一个开源框架,核心是控制反转（IOC编程思想）和面向切面（AOP）。简单来说，Spring是一个分层的JavaSE/EEfull-stack(一站式) 轻量级开源框架 Spring的AOP的理解:通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术,利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率.可以在不修改源代码的前提下，对程序进行增强. 例如:在以前配置事务的时候,进行事务的回滚,提交等操作,配置AOP 以后可以将事务的权限交给Spring框架去管理,自动管理 SpringMVC的理解?springMvc:是一个表现层框架,就是从请求中接收传入的参数, 将处理后的结果数据返回给页面展示 基本类型:string,double,float,integer,long.boolean Mybatis的理解?MyBatis是一个优秀的持久层框架，它对jdbc的操作数据库的过程进行封装，使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、结果集检索等jdbc繁杂的过程代码。 Mybatis通过xml或注解的方式将要执行的各种statement（statement、preparedStatement、CallableStatement）配置起来，并通过java对象和statement中的sql进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射成java对象并返回。 #{}可以有效防止sql注入 Servlet的理解?* GET和POST区别? * GET：请求参数会显示到地址栏.GET方式有大小的限制.GET方式没有请求体 * POST：请求参数不会显示到地址栏.在请求体中.POST没有大小限制.POST方式有请求体. * 只有表单设置为method=”post”才是post请求.其他的都是get请求 生命周期:客户端第一次访问该Servlet的时候才会创建一个Servlet的对象,那么Servlet中的init方法就会执行.任何一次从客户端发送的请求,那么服务器创建一个新的线程执行Servlet中service方法为这次请求服务. service方法的内部根据请求的方式的不同调用不同doXXX的方法.当Servlet从服务器中移除或者关闭服务器的时候Servlet对象就会被销毁.destroy的方法就会执行. Struts2与SpringMVC的区别?1)springmvc的入口是一个servlet即前端控制器，而struts2入口是一个filter过虑器。 2)springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，可以设计为单例或多例(建议单例)，struts2是基于类开发，传递参数是通过类的属性，只能设计为多例。 3)Struts采用值栈存储请求和响应的数据，通过OGNL存取数据， springmvc通过参数解析器是将request请求内容解析，并给方法形参赋值，将数据和视图封装成ModelAndView对象，最后又将ModelAndView中的模型数据通过reques域传输到页面。Jsp视图解析器默认使用jstl。 Jsp的核心及核心标签?a) Servlet b) Core XML Database Funcations Redis什么情况下使用，redis持久化方案?a) 处理大数据量的时候 b) Redis的所有数据都是保存在内存中， Rdb：快照形式，定期把内存中当前时刻的数据保存到磁盘，redis默认支持的持久化方案 aof形式：append only file。把所有对redis数据库操作的命令，增删改操作命令，保存到文件中，数据库恢复是把所有命令执行一遍即可。 Hibernate和Mybatis的区别和优劣?a) Sql优化方面：hibernate的查询会将表中所有的字段查询出来，这一点会有性能的消耗 Mybatis的sql是手动编写的，所以可以按需求指定查询的字段，sql会更灵活，可控性更好 b) Hibernate是在JDBC上进行了一次封装 Mybatis是基于原生的JDBC，运行速度有优势 c) Mybatis mapper xml支持动态sql；Hibernate不支持 d) Hibernate与具体数据库的关联只需在xml文件中配置即可，所有hql语句与具体的数据库无关，移植性好 Mybatis项目所有的sql语句都是依赖所用的数据库的，所以不同数据库类型的支持不好 StringBuffer、StringBuilder的区别?StringBuffer、StringBuilder是容器，是可变的字符串序列，存放于堆内存。 StringBuffer是JDK1.0版本的，线程是安全的，效率比较低。StringBuilder是JDK1.5出现的，线程不安全，效率高。 说一下SOLR?solr就是一个中文搜索引擎,做完分词之后会做热度排名,核心是中文分词器,全文搜索支持,索引值指向对应的文档,相当于是一个字典,默认为collection的一个域对象,查询快,效率高. 可以在Redis里做分词之后的缓存,每次搜索一次就次数加一,里面还有一个投票容错机制,主机挂掉还有备份机,一般配置都为奇数态配置. Solr与Lucene的区别?Lucene是一个开放源代码的全文检索引擎工具包，它不是一个完整的全文检索引擎，Lucene提供了完整的查询引擎和索引引擎，目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者以Lucene为基础构建全文检索引擎。 Solr的目标是打造一款企业级的搜索引擎系统，它是一个搜索引擎服务，可以独立运行，通过Solr可以非常快速的构建企业的搜索引擎，通过Solr也可以高效的完成站内搜索功能。 什么是Redis?1) Redis的高性能是由于其将所有数据都存储在了内存中，为了使Redis在重启之后仍能保证数据不丢失，需要将数据从内存中同步到硬盘中，这一过程就是持久化。 Redis支持两种方式的持久化，一种是RDB方式，一种是AOF方式。可以单独使用其中一种或将二者结合使用。 1.1RDB持久化 RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的数据进行快照并持久化到硬盘。 每次进行访问进行存储,如果服务器一旦崩溃,会导致数据丢失 RDB是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置： save 900 1 , save 300 10, save 60 10000 save 开头的一行就是持久化配置，可以配置多个条件（每行配置一个条件），每个条件之间是“或”的关系，“save 900 1”表示15分钟（900秒钟）内 至少 1个键被更改则进行快照，“save 300 10”表示5分钟（300秒）内至少10个键被更改则进行快照。 在redis.conf中： 配置dir指定 rdb快照文件的位置;配置dbfilenam指定rdb快照文件的名称 Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。 通常将记录一千万个字符串类型键、大小为1GB的快照文件载入到内存中需要花费20～30秒钟。 问题总结： 通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化。 1.2AOF持久化 默认情况下Redis没有开启AOF（append only file）方式的持久化，访问一段存储一段,效率高. 可以通过appendonly参数开启：appendonly yes开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件 AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：appendfilename appendonly.aof 2)主从复制（了解） 2.1什么是主从复制 持久化保证了即使redis服务重启也会丢失数据，因为redis服务重启后会将硬盘上持久化的数据恢复到内存中，但是当redis服务器的硬盘损坏了可能会导致数据丢失，如果通过redis的主从复制机制就可以避免这种单点故障，如下图： 说明： n主redis中的数据有两个副本（replication）即从redis1和从redis2，即使一台redis服务器宕机其它两台redis服务也可以继续提供服务。 n主redis中的数据和从redis上的数据保持实时同步，当主redis写入数据时通过主从复制机制会复制到两个从redis服务上。 n只有一个主redis，可以有多个从redis。 n主从复制不会阻塞master，在同步数据时，master 可以继续处理client 请求 n一个redis可以即是主又是从，如下图： 2.2主从配置 2.2.1主redis配置 无需特殊配置。 2.2.2从redis配置 修改从redis服务器上的redis.conf文件，添加slaveof主redisip主redis端口 上边的配置说明当前该从redis服务器所对应的主redis是192.168.101.3，端口是6379 2.3主从复制过程 2.3.1完整复制 在redis2.8版本之前主从复制过程如下图： 复制过程说明： 1、slave 服务启动，slave 会建立和master 的连接，发送sync 命令。 2、master启动一个后台进程将数据库快照保存到RDB文件中 注意：此时如果生成RDB文件过程中存在写数据操作会导致RDB文件和当前主redis数据不一致，所以此时master 主进程会开始收集写命令并缓存起来。 3、master 就发送RDB文件给slave 4、slave 将文件保存到磁盘上，然后加载到内存恢复 5、master把缓存的命令转发给slave 注意：后续master 收到的写命令都会通过开始建立的连接发送给slave。 当master 和slave 的连接断开时slave 可以自动重新建立连接。如果master 同时收到多个slave 发来的同步连接命令，只会启动一个进程来写数据库镜像，然后发送给所有slave。 完整复制的问题： 在redis2.8之前从redis每次同步都会从主redis中复制全部的数据，如果从redis是新创建的从主redis中复制全部的数据这是没有问题的，但是，如果当从redis停止运行，再启动时可能只有少部分数据和主redis不同步，此时启动redis仍然会从主redis复制全部数据，这样的性能肯定没有只复制那一小部分不同步的数据高。 2.3.2部分复制 部分复制说明： 从机连接主机后，会主动发起 PSYNC 命令，从机会提供 master的runid(机器标识，随机生成的一个串) 和 offset（数据偏移量，如果offset主从不一致则说明数据不同步），主机验证 runid 和 offset 是否有效， runid 相当于主机身份验证码，用来验证从机上一次连接的主机，如果runid验证未通过则，则进行全同步，如果验证通过则说明曾经同步过，根据offset同步部分数据。 2)redis是一个nosql(not only sql不仅仅只有sql)数据库.翻译成中文叫做非关系型型数据库. 关系型数据库:以二维表形式存储数据 非关系型数据库: 以键值对形式存储数据(key, value形式) Redis是用C语言开发的一个开源的高性能键值对（key-value）数据库。它通过提供多种键值数据类型来适应不同场景下的存储需求， 目前为止Redis支持的键值数据类型如下： 字符串类型 散列类型 列表类型 集合类型 有序集合类型。 3)redis的应用场景 缓存（数据查询、短连接、新闻内容、商品内容等等）。（最多使用） 分布式集群架构中的session分离。 聊天室的在线好友列表。 任务队列。（秒杀、抢购、12306等等） 应用排行榜。 网站访问统计。 数据过期处理（可以精确到毫秒） redis是将数据存放到内存中,由于内容存取速度快所以redis被广泛应用在互联网项目中, redis有点:存取速度快,官方称读取速度会达到30万次每秒,写速度在10万次每秒最有,具体限制于硬件. 缺点:对持久化支持不够良好, 所以redis一般不作为数据的主数据库存储,一般配合传统的关系型数据库使用. 4) redis应用领域 分布式缓存 分布式session 保存博客或者论坛的留言回复等. 总之是用在数据量大,并发量高的情况下 谈下DUBBO?Dubbo就是资源调度和治理中心的管理工具。 调用关系说明： \0. 服务容器负责启动，加载，运行服务提供者。 \1. 服务提供者在启动时，向注册中心注册自己提供的服务。 \2. 服务消费者在启动时，向注册中心订阅自己所需的服务。 \3. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 \4. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 \5. 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 解决跨域问题?JSONP–&gt;Script Tags 秒杀方案：1、把商品的数量放到redis中。 2、秒杀时使用decr命令对商品数量减一。如果不是负数说明抢到。 3、一旦返回数值变为0说明商品已售完。 ZOOKeeper?Zookeeper 作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，但是 Zookeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控你存储的数据的状态变化。 通过监控这些数据状态的变化，从而可以达到基于数据的集群管理 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力小。使用dubbo-2.3.3以上版本，建议使用zookeeper注册中心。 Zookeeper是Apacahe Hadoop的子项目，是一个树型的目录服务，支持变更推送，适合作为Dubbo服务的注册中心，工业强度较高，可用于生产环境，并推荐使用 ActiveMQ的消息形式一种是点对点的，即一个生产者和一个消费者一一对应；可进行缓存,只允许单人登录查看 另一种是发布/订阅模式，即一个生产者产生消息并进行发送后，可以由多个消费者进行接收。无法进行缓存,支持多人访问. JMS定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。 StreamMessage – Java原始值的数据流 MapMessage–一套名称-值对 TextMessage–一个字符串对象 ObjectMessage–一个序列化的 Java对象 BytesMessage–一个字节的数据流 1.订单系统 1.1.功能分析 1、在购物车页面点击“去结算”按钮跳转到订单确认页面。 a)展示商品列表 b)配送地址列表 c)选择支付方式 2、展示订单确认页面之前，应该确认用户身份。 a)使用拦截器实现。 b)Cookie中取token c)取不到token跳转到登录页面 d)取到token，根据token查询用户信息。 e)如果没有用户信息，登录过期跳转到登录页面 f)取到用户信息，放行。 3、提交订单 a)生成订单 b)展示订单提交成功页面。 订单系统系统：订单确认页面、订单提交成功页面。 订单服务系统 1.1.展示订单确认页面 1.1.1.功能分析 1、在购物车页面点击“去结算”按钮跳转到订单确认页面。 2、请求的url： /order/order-cart 3、参数：没有参数。 4、购物车商品数据从cookie中取出来的。可以在订单系统中取到cookie中的购物车数据。 5、配送地址列表，需要用户登录。需要根据用户id查询收货地址列表。静态数据。 6、支付方式。静态数据。 7、返回值：逻辑视图String，展示订单确认页面。 1.1.2.Dao层、Service层（没有） 需要根据用户id查询收货地址列表。没有此功能。 1.1.3.表现层 请求的url：/order/order-cart 参数：无 业务逻辑： 从cookie中取商品列表展示到页面。 返回值：逻辑视图。 1.1.用户身份认证 在展示订单确认页面之前，需要对用户身份进行认证，要求用户必须登录。 1.1.1.功能分析 1、使用springmvc的拦截器实现。需要实现一个接口HandlerInterceptor接口。 2、业务逻辑 a)从cookie中取token。 b)没有token，需要跳转到登录页面。 c)有token。调用sso系统的服务，根据token查询用户信息。 d)如果查不到用户信息。用户登录已经过期。需要跳转到登录页面。 e)查询到用户信息。放行。 3、在springmvc.xml中配置拦截器。 1.1.2.拦截器实现 1.1.1.功能分析 1、在订单确认页面点击“提交订单”按钮生成订单。 2、请求的url：/order/create 3、参数：提交的是表单的数据。保存的数据：订单、订单明细、配送地址。 a)向tb_order中插入记录。 i.订单号需要手动生成。 要求订单号不能重复。 订单号可读性号。 可以使用redis的incr命令生成订单号。订单号需要一个初始值。 ii.Payment：表单数据 iii.payment_type：表单数据 iv.user_id：用户信息 v.buyer_nick：用户名 vi.其他字段null b)向tb_order_item订单明细表插入数据。 i.Id：使用incr生成 ii.order_id：生成的订单号 iii.其他的都是表单中的数据。 c)tb_order_shipping，订单配送信息 i.order_id：生成的订单号 ii.其他字段都是表单中的数据。 d)使用pojo接收表单的数据。 可以扩展TbOrder，在子类中添加两个属性一个是商品明细列表，一个是配送信息。 把pojo放到taotao-order-interface工程中。 业务逻辑： 1、接收表单的数据 2、生成订单id 3、向订单表插入数据。 4、向订单明细表插入数据 5、向订单物流表插入数据。 6、返回TaotaoResult。 返回值：TaotaoResult 1.1.1.Dao层 可以使用逆向工程。 1.1.2.Service层 参数：OrderInfo 单点登录单点登录就是我们是做了分布式，tomcat集群之后会有session复制的问题，影响利群数量。所以把注册登录拿出来单独做了一个单点登录系统。做的时候是用的redis，key是用uuid生成的一个token,类似于session id,是用户的唯一标识，value是用户的信息。设置了有效期是7天。然后把redis放到了cookie中，实现了cookie的二级跨域。当我们进行操作时，首先要从cookie里面取出token如果取不到，就跳到单点登录系统进行登录操作如果取到了，再看看token有没有过期，如果过期了，也是跳到单点登录系统登录一下，没过期就继续用户的操作。密码进行了加密，用Md5 HashMap 和 HashTable 的区别1）容器整体结构： HashMap的key和value都允许为null，HashMap遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理。 Hashtable的key和value都不允许为null。Hashtable遇到null，直接返回NullPointerException。 2） 容量设定与扩容机制： HashMap默认初始化容量为 16，并且容器容量一定是2的n次方，扩容时，是以原容量 2倍 的方式 进行扩容。 Hashtable默认初始化容量为 11，扩容时，是以原容量 2倍 再加 1的方式进行扩容。即int newCapacity = (oldCapacity &lt;&lt; 1) + 1;。 3） 散列分布方式（计算存储位置）： HashMap是先将key键的hashCode经过扰动函数扰动后得到hash值，然后再利用 hash &amp; (length - 1)的方式代替取模，得到元素的存储位置。 Hashtable则是除留余数法进行计算存储位置的（因为其默认容量也不是2的n次方。所以也无法用位运算替代模运算），int index = (hash &amp; 0x7FFFFFFF) % tab.length;。 由于HashMap的容器容量一定是2的n次方，所以能使用hash &amp; (length - 1)的方式代替取模的方式计算元素的位置提高运算效率，但Hashtable的容器容量不一定是2的n次方，所以不能使用此运算方式代替。 4）线程安全（最重要）： HashMap 不是线程安全，如果想线程安全，可以通过调用synchronizedMap(Map&lt;K,V&gt; m)使其线程安全。但是使用时的运行效率会下降，所以建议使用ConcurrentHashMap容器以此达到线程安全。 Hashtable则是线程安全的，每个操作方法前都有synchronized修饰使其同步，但运行效率也不高，所以还是建议使用ConcurrentHashMap容器以此达到线程安全。 因此，Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 ArrayList和LinkedList 的区别 LinkedList内部存储的是Node&lt;E&gt;，不仅要维护数据域，还要维护prev和next，如果LinkedList中的结点特别多，则LinkedList比ArrayList更占内存。 插入删除操作效率：LinkedList在做插入和删除操作时，插入或删除头部或尾部时是高效的，操作越靠近中间位置的元素时，需要遍历查找，速度相对慢一些，如果在数据量较大时，每次插入或删除时遍历查找比较费时。所以LinkedList插入与删除，慢在遍历查找，快在只需要更改相关结点的引用地址。ArrayList在做插入和删除操作时，插入或删除尾部时也一样是高效的，操作其他位置，则需要批量移动元素，所以ArrayList插入与删除，快在遍历查找，慢在需要批量移动元素。 循环遍历效率： 由于ArrayList实现了RandomAccess随机访问接口，所以使用for(int i = 0; i &lt; size; i++)遍历会比使用Iterator迭代器来遍历快 而由于LinkedList未实现RandomAccess接口，所以推荐使用Iterator迭代器来遍历数据。 因此，如果我们需要频繁在列表的中部改变插入或删除元素时，建议使用LinkedList，否则，建议使用ArrayList，因为ArrayList遍历查找元素较快，并且只需存储元素的数据域，不需要额外记录其他数据的位置信息，可以节省内存空间。]]></content>
      <categories>
        <category>Java 面试精髓</category>
      </categories>
      <tags>
        <tag>基础面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试感悟：工作经验java程序员应有的技能]]></title>
    <url>%2F2017%2F12%2F10%2F%E9%9D%A2%E8%AF%95%E6%84%9F%E6%82%9F%EF%BC%9A%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8Cjava%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E6%9C%89%E7%9A%84%E6%8A%80%E8%83%BD%2F</url>
    <content type="text"><![CDATA[面试感悟：工作经验java程序员应有的技能前言因为和同事有约定再加上LZ自己也喜欢做完一件事之后进行总结，因此有了这篇文章。这篇文章大部分内容都是面向整个程序员群体的，当然因为LZ本身是做Java开发的，因此有一部分内容也是专门面向咱们Java程序员的。 简单先说一下，LZ坐标杭州，13届本科毕业，算上年前在阿里巴巴B2B事业部的面试，一共有面试了有6家公司（因为LZ不想请假，因此只是每个晚上去其他公司面试，所以面试的公司比较少），其中成功的有4家，另外两家失败的原因在于： 1、阿里巴巴B2B事业部的面试，两轮技术面试都过了，最后一轮面试是对方的主管，由于听说技术面试过了基本上90%都面试成功了，所以LZ在和主管的交谈中也是毫无顾忌，说得天花乱坠，很多自己介于知道和不知道的东西都直接脱口而出了，结果多次被对方一反问就问得哑口无言。事后想来，模棱两可的答案是面试中最忌讳的，这次的失败也让LZ认真地对待后面的每一次面试 2、另外一家失败的是一家小公司，也就20来个人吧，整个团队是支付宝出来创业的，非常厉害。面试完LZ多方了解了一下，对方认为我基本功什么的都不错，但是实际项目经验还是欠缺一些，因为对方是创业型公司，需要人上手就能干活，因此我在这个时候还不是特别适合他们团队 至于其他成功的四家公司，给LZ的面试评价都挺高的貌似，但LZ也不想记流水账，因此就不一一列举每家公司的面试过程了，下面LZ主要谈谈作为一名工作三年左右的Java程序员应该具备的一些技能以及个人的一些其他感悟。 关于程序员的几个阶段每个程序员、或者说每个工作者都应该有自己的职业规划，如果看到这里的朋友没有自己的职业规划，希望你可以思考一下自己的将来。 LZ常常思考自己的未来，也从自己的思考中总结出了一些东西，作为第一部分来谈谈。LZ认为一名程序员应该有几个阶段（以下时间都算上实习期）： 第一阶段：三年 我认为三年对于程序员来说是第一个门槛，这个阶段将会淘汰掉一批不适合写代码的人。这一阶段，我们走出校园，迈入社会，成为一名程序员，正式从书本上的内容迈向真正的企业级开发。我们知道如何团队协作、如何使用项目管理工具、项目版本如何控制、我们写的代码如何测试如何在线上运行等等，积累了一定的开发经验，也对代码有了一定深入的认识，是一个比较纯粹的Coder的阶段 第二阶段：五年 五年又是区分程序员的第二个门槛。有些人在三年里，除了完成工作，在空余时间基本不会研究别的东西，这些人永远就是个Coder，年纪大一些势必被更年轻的人给顶替；有些人在三年里，除了写代码之外，还热衷于研究各种技术实现细节、看了N多好书、写一些博客、在Github上分享技术，这些人在五年后必然具备在技术上独当一面的能力并且清楚自己未来的发展方向，从一个Coder逐步走向系统分析师或是架构师，成为项目组中不可或缺的人物 第三阶段：十年 十年又是另一个门槛了，转行或是继续做一名程序员就在这个节点上。如果在前几年就抱定不转行的思路并且为之努力的话，那么在十年的这个节点上，有些人必然成长为一名对行业有着深入认识、对技术有着深入认识、能从零开始对一个产品进行分析的程序员，这样的人在公司基本担任的都是CTO、技术专家、首席架构师等最关键的职位，这对于自己绝对是一件荣耀的事，当然老板在经济上也绝不会亏待你 第一部分总结一下，我认为，随着你工作年限的增长、对生活对生命认识的深入，应当不断思考三个问题： 1、我到底适不适合当一名程序员？ 2、我到底应不应该一辈子以程序员为职业？ 3、我对编程到底持有的是一种什么样的态度，是够用就好呢还是不断研究？ 最终，明确自己的职业规划，对自己的规划负责并为之努力。 关于项目经验LZ在网上经常看到一些别的朋友有提出项目经验的问题，依照LZ面试的感觉来说，面试主要看几点：项目经验+基本技术+个人潜力（也就是值不值得培养）。 关于项目经验，我认为并发编程网的创始人方腾飞老师讲的一段话非常好： 介绍产品时面试官会考察应聘者的沟通能力和思考能力，我们大部分情况都是做产品的一个功能或一个模块，但是即使是这样，自己有没有把整个系统架构或产品搞清楚，并能介绍清楚，为什么做这个系统？这个系统的价值是什么？这个系统有哪些功能？优缺点有哪些？如果让你重新设计这个系统你会如何设计？ 我觉得这就已经足以概括了。也许你仅仅工作一年，也许你做的是项目中微不足道的模块，当然这些一定是你的劣势且无法改变，但是如何弥补这个劣势，从方老师的话中我总结几点： 1、明确你的项目到底是做什么的，有哪些功能 2、明确你的项目的整体架构，在面试的时候能够清楚地画给面试官看并且清楚地指出从哪里调用到哪里、使用什么方式调用 3、明确你的模块在整个项目中所处的位置及作用 4、明确你的模块用到了哪些技术，更好一些的可以再了解一下整个项目用到了哪些技术 在你无法改变自己的工作年限、自己的不那么有说服力的项目经验的情况下（这一定是扣分项），可以通过这种方式来一定程度上地弥补并且增进面试官对你的好感度。 关于专业技能写完项目接着写写一名3年工作经验的Java程序员应该具备的技能，这可能是Java程序员们比较关心的内容。我这里要说明一下，以下列举的内容不是都要会的东西—-但是如果你掌握得越多，最终能得到的评价、拿到的薪水势必也越高。 1、基本语法 这包括static、final、transient等关键字的作用，foreach循环的原理等等。今天面试我问你static关键字有哪些作用，如果你答出static修饰变量、修饰方法我会认为你合格，答出静态块，我会认为你不错，答出静态内部类我会认为你很好，答出静态导包我会对你很满意，因为能看出你非常热衷研究技术。 最深入的一次，LZ记得面试官直接问到了我Volatile关键字的底层实现原理（顺便插一句，面试和被面试本身就是相对的，面试官能问这个问题同时也让面试者感觉到面试官也是一个喜爱研究技术的人，增加了面试者对公司的好感，LZ最终选择的就是问了这个问题的公司），不要觉得这太吹毛求疵了—-越简单的问题越能看出一个人的水平，别人对你技术的考量绝大多数都是以深度优先、广度次之为标准的，切记。 2、集合 非常重要，也是必问的内容。基本上就是List、Map、Set，问的是各种实现类的底层实现原理，实现类的优缺点。 集合要掌握的是ArrayList、LinkedList、Hashtable、HashMap、ConcurrentHashMap、HashSet的实现原理，能流利作答，当然能掌握CopyOnWrite容器和Queue是再好不过的了。另外多说一句，ConcurrentHashMap的问题在面试中问得特别多，大概是因为这个类可以衍生出非常多的问题，关于ConcurrentHashMap，我给网友朋友们提供三点回答或者是研究方向： （1）ConcurrentHashMap的锁分段技术 （2）ConcurrentHashMap的读是否要加锁，为什么 （3）ConcurrentHashMap的迭代器是强一致性的迭代器还是弱一致性的迭代器 3、设计模式 本来以为蛮重要的一块内容，结果只在阿里巴巴B2B事业部面试的时候被问了一次，当时问的是装饰器模式。 当然咱们不能这么功利，为了面试而学习，设计模式在工作中还是非常重要、非常有用的，23种设计模式中重点研究常用的十来种就可以了，面试中关于设计模式的问答主要是三个方向： （1）你的项目中用到了哪些设计模式，如何使用 （2）知道常用设计模式的优缺点 （3）能画出常用设计模式的UML图 4、多线程 这也是必问的一块了。因为三年工作经验，所以基本上不会再问你怎么实现多线程了，会问得深入一些比如说Thread和Runnable的区别和联系、多次start一个线程会怎么样、线程有哪些状态。当然这只是最基本的，出乎意料地，几次面试几乎都被同时问到了一个问题，问法不尽相同，总结起来是这么一个意思： 假如有Thread1、Thread2、ThreaD3、Thread4四条线程分别统计C、D、E、F四个盘的大小，所有线程都统计完毕交给Thread5线程去做汇总，应当如何实现？ 聪明的网友们对这个问题是否有答案呢？不难，java.util.concurrent下就有现成的类可以使用。 另外，线程池也是比较常问的一块，常用的线程池有几种？这几种线程池之间有什么区别和联系？线程池的实现原理是怎么样的？实际一些的，会给你一些具体的场景，让你回答这种场景该使用什么样的线程池比较合适。 最后，虽然这次面试问得不多，但是多线程同步、锁这块也是重点。synchronized和ReentrantLock的区别、synchronized锁普通方法和锁静态方法、死锁的原理及排查方法等等，关于多线程，我在之前有些过文章总结过多线程的40个问题，可以参看40个Java多线程问题总结。 5、JDK源码 要想拿高工资，JDK源码不可不读。上面的内容可能还和具体场景联系起来，JDK源码就是实打实地看你平时是不是爱钻研了。LZ面试过程中被问了不少JDK源码的问题，其中最刁钻的一个问了LZ，String的hashCode()方法是怎么实现的，幸好LZ平时String源代码看得多，答了个大概。JDK源码其实没什么好总结的，纯粹看个人，总结一下比较重要的源码： （1）List、Map、Set实现类的源代码 （2）ReentrantLock、AQS的源代码 （3）AtomicInteger的实现原理，主要能说清楚CAS机制并且AtomicInteger是如何利用CAS机制实现的 （4）线程池的实现原理 （5）Object类中的方法以及每个方法的作用 这些其实要求蛮高的，LZ去年一整年基本把JDK中重要类的源代码研究了个遍，真的花费时间、花费精力，当然回头看，是值得的—-不仅仅是为了应付面试。 6、框架 老生常谈，面试必问的东西。一般来说会问你一下你们项目中使用的框架，然后给你一些场景问你用框架怎么做，比如我想要在Spring初始化bean的时候做一些事情该怎么做、想要在bean销毁的时候做一些事情该怎么做、MyBatis中$和#的区别等等，这些都比较实际了，平时积累得好、有多学习框架的使用细节自然都不成问题。 如果上面你的问题答得好，面试官往往会深入地问一些框架的实现原理。问得最多的就是Spring AOP的实现原理，当然这个很简单啦，两句话就搞定的的事儿，即使你不会准备一下就好了。LZ遇到的最变态的是让LZ画一下Spring的Bean工厂实现的UML图，当然面对这样一个有深度的问题，LZ是绝对答不出来的/(ㄒoㄒ)/~~ 7、数据库 数据库十有八九也都会问到。一些基本的像union和union all的区别、left join、几种索引及其区别就不谈了，比较重要的就是数据库性能的优化，如果对于数据库的性能优化一窍不通，那么有时间，还是建议你在面试前花一两天专门把SQL基础和SQL优化的内容准备一下。 不过数据库倒是不用担心，一家公司往往有很多部门，如果你对数据库不熟悉而基本技术又非常好，九成都是会要你的，估计会先把你放到对数据库使用不是要求非常高的部门锻炼一下。 8、数据结构和算法分析 数据结构和算法分析，对于一名程序员来说，会比不会好而且在工作中绝对能派上用场。数组、链表是基础，栈和队列深入一些但也不难，树挺重要的，比较重要的树AVL树、红黑树，可以不了解它们的具体实现，但是要知道什么是二叉查找树、什么是平衡树，AVL树和红黑树的区别。记得某次面试，某个面试官和我聊到了数据库的索引，他问我： 你知道索引使用的是哪种数据结构实现吗？ LZ答到用的Hash表吧，答错。他又问，你知道为什么要使用树吗？LZ答到因为Hash表可能会出现比较多的冲突，在千万甚至是上亿级别的数据面前，会大大增加查找的时间复杂度。而树比较稳定，基本保证最多二三十次就能找到想要的数据，对方说不完全对，最后我们还是交流了一下这个问题，我也明白了为什么要使用树，这里不说，网友朋友们觉得索引为什么要使用树来实现呢？ 至于算法分析，不会、不想研究就算了，记得某次面试对方问我，Collections.sort方法使用的是哪种排序方法，额，吐血三升。当然为了显示LZ的博学，对算法分析也有一定的研究(⊙﹏⊙)b，LZ还是硬着头皮说了一句可能是冒泡排序吧。当然答案肯定不是，有兴趣的网友朋友们可以去看一下Collections.sort方法的源代码，用的是一种叫做TimSort的排序法，也就是增强型的归并排序法。 9、Java虚拟机 出乎LZ的意料，Java虚拟机应该是很重要的一块内容，结果在这几家公司中被问到的概率几乎为0。要知道，LZ去年可是花了大量的时间去研究Java虚拟机的，光周志明老师的《深入理解Java虚拟机：JVM高级特性与最佳实践》，LZ就读了不下五遍。 言归正传，虽然Java虚拟机没问到，但我觉得还是有必要研究的，LZ就简单地列一个提纲吧，谈谈Java虚拟机中比较重要的内容： （1）Java虚拟机的内存布局 （2）GC算法及几种垃圾收集器 （3）类加载机制，也就是双亲委派模型 （4）Java内存模型 （5）happens-before规则 （6）volatile关键字使用规则 也许面试无用，但在走向大牛的路上，不可不会。 10、Web方面的一些问题 Java主要面向Web端，因此Web的一些问题也是必问的。LZ碰到过问得最多的两个问题是： 谈谈分布式Session的几种实现方式 常用的四种能答出来自然是让面试官非常满意的，另外一个常问的问题是： 讲一下Session和Cookie的区别和联系以及Session的实现原理 这两个问题之外，web.xml里面的内容是重点，Filter、Servlet、Listener，不说对它们的实现原理一清二楚吧，至少能对它们的使用知根知底。另外，一些细节的方面比如get/post的区别、forward/重定向的区别、HTTPS的实现原理也都可能会被考察到。 噢，想起来了，一致性Hash算法貌似也被问到了几次，这个LZ以前专门深入研究过并且写了两篇博文，因此问到这个问题LZ自然是答得毫不费力。文章是MemCache超详细解读和对一致性Hash算法，Java代码实现的深入研究，特别说明，LZ真的不是在为自已以前写的文章打广告啊啊啊啊啊啊。 最后，如果有兴趣有时间，建议学习、研究一下SOA和RPC，面向服务体系，大型分布式架构必备，救命良方、包治百病、屡试不爽。 关于HR面试如果你过五关斩六将，成功地通过了所有的技术面，那么恭喜你，你离升职加薪、出任CEO、迎娶白富美、走向人生巅峰又进了一步。但是还没有到谈薪资待遇的时候，最后还有一个考验：HR面试。基本所有的大公司都有这一轮的面试，不要小看HR面试，很多公司的HR对于面试者都有一票否决权的—-即使前面的面试对你的评价再高。 所以，这轮的面试也必须重视起来，HR面试主要问的是几点： 1、简历中写的过去工作经历的离职原因 2、当前公司薪资待遇 3、期望能到怎样的一家公司 4、个人未来的发展方向 我专门提一下第2点。可能有人比较排斥也不想说这个，我个人倒是持开放状态，问了就说了，当然一些的夸大还是必要的，当前公司薪资待遇多报个一千块钱完全没问题（毕竟是一家互联网公司总多多少少有些补贴啊什么的嘛）。因为这和你在新公司能拿到的薪水关系不大，新公司能拿到的薪水的决定因素是整个公司的薪资情况以及根据你的面试情况在公司的定位，都是有固定的薪资范围的。HR问这个主要也就是心里有个数并且看你是否诚信—-有些公司入职时会要求你提供最近一家单位的银行流水号。 HR面试就说到这里了，总结起来其实就是四个字：滴水不漏。整个面试过程态度积极向上，不要有任何悲观消极的态度（尤其在谈到以前公司情况的时候，即使有再多的不满），就不会有问题。 关于面试心态这个嘛，LZ其实在公司也面试过几个人，一半以上的面试者回答问题的时候都属于那种双腿发抖、声音颤抖的类型。在LZ看来这大可不必并且这还是扣分项，回答问题的时候最最基本的两个要求： 1、不紧不慢，平心静气 2、条理清晰 表达能力绝对是面试的时候重要的考察项目。咱们做的是程序员这一行，讲究的是团队协作，不是写作、画画，一支笔、一个人就行了，一个表达能力不行的程序员，要来又有什么用呢？ 除此之外，就是保持良好的心态。古语说得好，只要功夫深，铁杵磨成针，面试的成功与否，在于平时的积累，临时抱抱佛脚，看两道面试题是没有用的，只要平时足够努力，成功是水到渠成的事情，平时不怎么研究技术的，那也就是个听天由命的事情，只要充分地展示平时自己的所学就可以了。 因此在我看来，不要把面试当作面试，当做一次技术交流，把面试的心态从我要找到一份工作转变为我要通过面试去发现不足、提升自己，这样就会平和多了，即使失败也不会有太多失望的感觉。 另外，如果平时自己热衷于研究技术的朋友，真的要有自信，不要觉得别人面试你别人就比你厉害。面试官未必比你优秀，他问的问题往往都是他平时研究得比较多的问题，你一样有很多自己的研究面试官未必知道。 关于Java网上常看到一种说法：Java比较简单。某种程度上这会打击Java程序员的信心—-原来咱们平时用的是这种小儿科的玩意儿啊，在我看来这种想法大可不必，这一部分我来讲讲对于这个话题的看法。 这种说法有些片面，得分开两部分来看，我用四个自总结一下就是：易学难精。 1、易学部分 Java易学我认为有两部分的原因： （1）很多培训公司包括大四的学生找工作都会学习Java，绝大多数是因为易学。Java从C/C++发展而来，感谢前人的智慧，它消除了C/C++中最复杂和让人困惑的语法、它消除了平台的差异性、它不需要用户手动释放内存空间、它避免了Java程序员和本地语言的交互，让程序员只需要专注于语法层面和应用层面。 （2）Java作为一门面向对象的语言，在企业级开发中体现出了它无与伦比的特性，整个开发流程比较固定化、模块化，需求分析起来也相对容易。我举个自己以前的例子吧，我在大一学习C语言的时候，用C语言写了一个图书管理系统写了2000+的代码，大四学了C++之后，用面向对象的语言C++取代面向过程的语言C语言重新写了一个功能相似的图书管理系统，只写了1100行的样子，这就是面向对象的优势。 2、难精部分 接着咱们聊聊难精的部分。 Java语言的设计者帮助Java程序员做了这么多事情，这有利也有弊。有利的部分前面已经说过了，让Java易学，不过有弊的部分同样明显。假如在应用运行过程中遇到了语法层面和应用层面之外的错误，应当如何处理？比如线上环境出现内存溢出怎么办？GC时间过长怎么办？IO长时间没反应怎么办？方法抛出莫名其妙的异常怎么办？ 凡此种种，绝不是一名只会写几个if…else…的Java程序员就可以解决的，这需要大量的经历、大量的实践、大量对Java底层实现细节的研究，而这往往是最难、最考验Java程序员的部分，一些人根本就不想往深去研究，另外一些人研究了一点点就研究不下去了。 Java为什么难精？就是这个原因。除非你水平特别高，否则五年工作经验以下的Java程序员在简历上写”精通Java”绝对是一件非常愚蠢的事情。 结语文章写到这里，感觉有点像鸡汤文了，那就以最后的鸡汤作为结尾吧。 在以前博客园的一篇文章中，讲到了奔三程序员的困惑，大致说的是三十岁之后程序员要转行之类的云云，LZ在博文中留下了如下的评论： 就以这段话自勉、共勉吧。越努力、越幸运，如果你不是官二代、富二代、红二代，那么请记住：勤奋才是改变你命运的唯一捷径。]]></content>
      <categories>
        <category>工作经验java程序员应有的技能</category>
      </categories>
      <tags>
        <tag>面试精髓</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList 源码分析]]></title>
    <url>%2F2017%2F12%2F09%2FLinkedList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LinkedList 源码分析前言有了ArrayList，自然少不了LinkedList了。 下面我就以面试问答的形式学习我们的常用的装载容器——LinkedList（源码分析基于JDK8） 问答内容LinkedList 用来做什么，怎么使用？问：请简单介绍一下您所了解的LinkedList，它可以用来做什么，怎么使用？ 答： LinkedList底层是双向链表，同时实现了List接口和Deque接口，所以它既可以看作是一个顺序容器，也可以看作是一个队列(Queue)，同时也可以看作是一个栈(Stack)，但如果想使用栈或队列等数据结构的话，推荐使用ArrayDeque，它作为栈或队列会比LinkedList有更好的使用性能。 示例代码： 12345678910111213141516171819// 创建一个LinkedList，链表的每个节点的内存空间都是实时分配的，所以无须事先指定容器大小LinkedList&lt;String&gt; linkedList = new LinkedList&lt;String&gt;();// 往容器里面添加元素linkedList.add("张三");linkedList.add("李四");// 在张三与李四之间插入一个王五linkedList.add(1, "王五");// 在头部插入一个小三linkedList.addFirst("小三");// 获取index下标为2的元素 王五String element = linkedList.get(2);// 修改index下标为2的元素 王五 为小四linkedList.set(2, "小四");// 删除index下标为1的元素 张三String removeElement = linkedList.remove(1);// 删除第一个元素String removeFirstElement = linkedList.removeFirst();// 删除最后一个元素String removeLastElement = linkedList.removeLast(); LinkedList底层实现是双向链表，核心组成元素有：int size = 0用于记录链表长度；Node&lt;E&gt; first;用于记录头（第一个）结点（储存的是头结点的引用）；Node&lt;E&gt; last;用于记录尾（最后一个）结点（储存的是尾结点的引用）。 示例代码： 123456789101112131415161718192021public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; // 记录链表长度 transient int size = 0; /** * Pointer to first node. 指向第一个结点 * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. 指向最后一个结点 * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last;&#125; 双向链表的核心组成元素还有一个最重要的Node&lt;E&gt;，Node&lt;E&gt;包含：E item; 用于存储元素数据，Node&lt;E&gt; next; 指向当前元素的后继结点，Node&lt;E&gt; prev; 指向当前元素的前驱结点。 示例代码： 1234567891011121314151617/** * 定义LinkedList底层的结点实现 */private static class Node&lt;E&gt; &#123; E item; // 存储元素数据 Node&lt;E&gt; next;// 指向当前元素的后继结点 Node&lt;E&gt; prev;// 指向当前元素的前驱结点 /** * Node结点构造方法 */ Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element;// 存储的元素 this.next = next;// 后继结点 this.prev = prev;// 前驱结点 &#125;&#125; 双向链表底层实现，图片来自网络 上图中的head即Node first; tail即Node last; LinkedList 的操作和对应的时间复杂度。问：请分别分析一下它是如何获取元素，修改元素，新增元素与删除元素，并分析这些操作对应的时间复杂度。 答： 获取元素：LinkedList提供了三种获取元素的方法，分别是： 获取第一个元素getFirst()，获取第一个元素，直接返回Node&lt;E&gt; first指向的结点即可，所以时间复杂度为O(1)。 获取最后一个元素getLast()，获取最后一个元素，直接返回Node&lt;E&gt; last指向的结点即可，所以时间复杂度也为O(1)。 获取指定索引index位置的元素get(int index)，由于Node&lt;E&gt;结点在内存中存储的空间不是连续存储的，所以查找某一位置的结点，只能通过遍历链表的方式查找结点，因此LinkedList会先通过判断index &lt; (size &gt;&gt; 1)，size&gt;&gt;1即为size/2当前链表长度的一半，判断index的位置是在链表的前半部分还是后半部分。决定是从头部遍历查找数据还是从尾部遍历查找数据。最坏情况下，获取中间元素，则需要遍历n/2次才能获取到对应元素，所以此方法的时间复杂度为O(n)。 综上所述，LinkedList获取元素的时间复杂度为O(n)。 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 返回列表中指定位置的元素 * * @param index 指定index位置 * @return 返回指定位置的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 遍历列表获取对应index位置的元素 return node(index).item;&#125;/** * 检查下标是否合法 */private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size;&#125;/** * 返回指定位置的结点元素（重点） */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 判断index位置是在链表的前半部分还是后半部分 if (index &lt; (size &gt;&gt; 1)) &#123; // 从头结点开始，从前往后遍历找到对应位置的结点元素 Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; // 从尾结点开始，从后往前遍历找到对应位置的结点元素 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 修改元素：LinkedList提供了一种修改元素数据的方法set(int index, E element)，修改元素数据的步骤是：1.检查index索引是否合法[0,size)。2.折半查询获取对应索引元素。3.将新元素赋值，返回旧元素。由获取元素的分析可知，折半查询的时间复杂度为O(n)，故修改元素数据的时间复杂度为O(n)。 示例代码： 123456789101112131415161718/** * 修改指定位置结点的存储数据 * * @param index 指定位置 * @param element 修改的存储数据 * @return 返回未修改前的存储数据 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 折半查询获取对应索引元素 Node&lt;E&gt; x = node(index); // 将新元素赋值，返回旧元素 E oldVal = x.item; x.item = element; return oldVal;&#125; 新增元素：LinkedList提供了四种新增元素的方法，分别是： 将指定元素插入到链表的第一个位置中addFirst(E e)，只需将头结点first指向新元素结点，将原第一结点的前驱指针指向新元素结点即可。不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度为O(1)。 将指定元素插入到链表的最后一个位置中addLast(E e)，只需将尾结点last指向新元素结点，将原最后一个结点的后继指针指向新元素结点即可。不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 添加元素方法add(E e) 等价于addLast(E e)。 将指定元素插入到链表的指定位置index中add(int index, E element)，需要先根据位置index调用node(index)遍历链表获取该位置的原结点，然后将新结点插入至原该位置结点的前面，不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 综上所述，LinkedList新增元素的时间复杂度为O(1)，单纯论插入新元素，操作是非常高效的，特别是插入至头部或插入到尾部。但如果是通过索引index的方式插入，插入的位置越靠近链表中间所费时间越长，因为需要对链表进行遍历查找。 添加元素结点示意图，图片来自《大话数据结构》 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/** * 将指定元素插入到链表的第一个位置中 * * @param e 要插入的元素 */public void addFirst(E e) &#123; linkFirst(e);&#125;/** * 将元素e作为第一个元素 */private void linkFirst(E e) &#123; // 获取原头结点 final Node&lt;E&gt; f = first; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); // 头指针指向新元素结点 first = newNode; // 如果是第一个元素（链表为空） if (f == null) // 将尾指针也指向新元素结点 last = newNode; else // 链表不会空 // 原头结点的前驱指针指向新结点 f.prev = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125;/** * 将指定元素插入到链表的最后一个位置中 * * &lt;p&gt;此方法等同与add(E e)方法 &#123;@link #add&#125;. * * @param e 要插入的元素 */public void addLast(E e) &#123; linkLast(e);&#125;/** * 将指定元素插入到链表的最后一个位置中 * * &lt;p&gt;此方法等同与addLast(E e)方法 &#123;@link #addLast&#125;. * * @param e 要插入的元素 * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** * 将元素e作为最后一个元素 */void linkLast(E e) &#123; // 获取原尾结点 final Node&lt;E&gt; l = last; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 位指针指向新元素结点 last = newNode; // 如果是第一个元素（链表为空） if (l == null) // 将头指针也指向新元素结点 first = newNode; else // 链表不会空 // 原尾结点的后继指针指向新结点 l.next = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125;/** * 将指定元素插入到链表的指定位置index中 * * @param index 元素要插入的位置index * @param element 要插入的元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; // 检查插入位置是否合法[0,size] checkPositionIndex(index); // 如果插入的位置和当前链表长度相等，则直接将元素插入至链表的尾部 if (index == size) // 将元素插入至链表的尾部 linkLast(element); else //将元素插入至指定位置,node(index)先获取占有该index位置的原结点 linkBefore(element, node(index));&#125;/** * 检查位置是否合法 */private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;/** * 检查位置是否合法 */private boolean isPositionIndex(int index) &#123; //合法位置为[0,size] return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;/** * 将新元素e插入至旧元素succ前面 */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; // 记录旧元素结点succ的前驱指针 final Node&lt;E&gt; pred = succ.prev; // 初始化新元素结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 旧元素结点的前驱指针指向新元素结点(即新元素结点放至在旧元素结点的前面，取代了原本旧元素的位置) succ.prev = newNode; // 如果旧元素结点的前驱指针为空，则证明旧元素结点是头结点， // 将新元素结点插入至旧元素结点前面，所以现时新的头结点是新元素结点 if (pred == null) first = newNode; else //不是插入至头部 // 旧元素的前驱结点的后继指针指向新元素结点 pred.next = newNode; // 记录链表长度的size + 1 size++; modCount++;&#125; 删除元素：LinkedList提供了四种删除元素的方法，分别是： 删除链表中的第一个元素removeFirst()，只需将头结点first指向删除元素结点的后继结点并将其前驱结点指针信息prev清空即可。不需要移动原数据存储位置，只需操作相关结点的指针域信息即可。所以时间复杂度为O(1)。 删除链表中的最后一个元素removeLast()，只需将尾结点last指向删除元素结点的前驱结点并将其后继结点指针信息next清空即可。不需要移动原数据存储位置，只需操作相关结点的指针域信息即可，所以时间复杂度也为O(1)。 将指定位置index的元素删除remove(int index)，需要先根据位置index调用node(index)遍历链表获取该位置的原结点，然后将删除元素结点的前驱结点的next后继结点指针域指向删除元素结点的后继结点node.prev.next = node.next，删除元素结点的后继结点的prev前驱结点指针域指向删除元素结点的前驱结点即可node.next.prev = node.prev（此处可能有些绕，不太理解的同学自行学习一下双向链表的数据结构吧），不需要移动原数据存储位置，只需交换一下相关结点的指针域信息即可。所以时间复杂度也为O(1)。 删除元素结点示意图，图片来自《大话数据结构》 删除传入的Object o指定对象，比较对象是否一致通过o.equals方法比较remove(Object o)，和3.的思路基本差不多，关键是比较对象是通过o.equals方法，记住这点即可。 综上所述，LinkedList删除元素的时间复杂度为O(1)，单纯论删除元素，操作是非常高效的，特别是删除第一个结点或删除最后一个结点。但如果是通过索引index的方式或者object对象的方式删除，则需要对链表进行遍历查找对应index索引的对象或者利用equals方法判断对象。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169/** * 删除链表中的第一个元素并返回 * * @return 链表中的第一个元素 * @throws NoSuchElementException if this list is empty */public E removeFirst() &#123; //根据头结点获取第一个元素结点 final Node&lt;E&gt; f = first; if (f == null) // 没有元素结点则抛出异常 throw new NoSuchElementException(); return unlinkFirst(f);&#125;/** * 移除第一个元素 */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; // 记录要移除元素结点的数据域 final E element = f.item; // 记录要移除元素结点的后继结点指针 final Node&lt;E&gt; next = f.next; // 清空要删除结点的数据域和next指针域信息，以帮助垃圾回收 f.item = null; f.next = null; // help GC // 头结点指向要移除元素结点的后继结点 first = next; // 如果要移除元素结点的后继结点为空，则证明链表只有一个元素 // 所以需要将尾结点的指针信息也要清空 if (next == null) last = null; else // 将新的第一个结点的前驱结点指针信息清空 next.prev = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125;/** * 删除链表中的最后一个元素并返回 * * @return 链表中的最后一个元素 * @throws NoSuchElementException if this list is empty */public E removeLast() &#123; // 根据尾结点获取最后一个元素结点 final Node&lt;E&gt; l = last; if (l == null)// 没有元素结点则抛出异常 throw new NoSuchElementException(); return unlinkLast(l);&#125;/** * 移除最后一个元素 */private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; // 记录要移除元素结点的数据域 final E element = l.item; // 记录要移除元素结点的前驱结点指针 final Node&lt;E&gt; prev = l.prev; // 清空要删除结点的数据域和prev指针域信息，以帮助垃圾回收 l.item = null; l.prev = null; // help GC // 头结点指向要移除元素结点的前驱结点 last = prev; // 如果要移除元素结点的前驱结点为空，则证明链表只有一个元素 // 所以需要将头结点的指针信息也要清空 if (prev == null) first = null; else // 将新的最后一个结点的后继结点指针信息清空 prev.next = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125;/** * 将指定位置index的元素删除 * * @param index 要删除的位置index * @return 要删除位置的原元素 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; // 检查index下标是否合法[0,size) checkElementIndex(index); // 根据index进行遍历链表获取要删除的结点，再调用unlink方法进行删除 return unlink(node(index));&#125;/** * 删除传入的Object o指定对象，比较对象是否一致通过o.equals方法比较 * @param o 要删除的Object o指定对象 * @return &#123;@code true&#125; 是否存在要删除对象o */public boolean remove(Object o) &#123; // 如果删除对象为null，则遍历链表查找node.item数据域为null的结点并移除 if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 从头开始遍历链表，并通过equals方法逐一比较node.item是否相等 // 相等则对象一致，删除此对象。 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;/** * 移除指定结点x */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; // 记录要移除元素结点的数据域 final E element = x.item; // 记录要移除元素结点的后继结点指针 final Node&lt;E&gt; next = x.next; // 记录要移除元素结点的前驱结点指针 final Node&lt;E&gt; prev = x.prev; // 如果要移除元素结点的前驱结点为空，则证明要删除结点为第一个结点 if (prev == null) &#123; // 头结点指向要删除元素结点的后继结点 first = next; &#125; else &#123; // 要删除元素结点的前驱结点的后继指针指向要删除元素结点的后继结点 prev.next = next; // 清空要删除结点的前驱结点指针信息，以帮助GC x.prev = null; &#125; // 如果要移除元素结点的后继结点为空，则证明要删除结点为最后一个结点 if (next == null) &#123; // 尾结点指向要删除元素结点的前驱结点 last = prev; &#125; else &#123; // 要删除元素结点的后继结点的前驱指针指向要删除元素结点的前驱结点 next.prev = prev; // 清空要删除结点的后继结点指针信息，以帮助GC x.next = null; &#125; // 清空要删除元素的数据域，以帮助GC x.item = null; // 记录链表长度的size - 1 size--; modCount++; // 返回移除元素结点的数据域 return element;&#125; ArrayList和LinkedList 的区别问：那您可以比较一下ArrayList和LinkedList吗? 答： LinkedList内部存储的是Node&lt;E&gt;，不仅要维护数据域，还要维护prev和next，如果LinkedList中的结点特别多，则LinkedList比ArrayList更占内存。 插入删除操作效率：LinkedList在做插入和删除操作时，插入或删除头部或尾部时是高效的，操作越靠近中间位置的元素时，需要遍历查找，速度相对慢一些，如果在数据量较大时，每次插入或删除时遍历查找比较费时。所以LinkedList插入与删除，慢在遍历查找，快在只需要更改相关结点的引用地址。ArrayList在做插入和删除操作时，插入或删除尾部时也一样是高效的，操作其他位置，则需要批量移动元素，所以ArrayList插入与删除，快在遍历查找，慢在需要批量移动元素。 循环遍历效率： 由于ArrayList实现了RandomAccess随机访问接口，所以使用for(int i = 0; i &lt; size; i++)遍历会比使用Iterator迭代器来遍历快： 12345678for (int i=0, n=list.size(); i &lt; n; i++) &#123; list.get(i);&#125;runs faster than this loop:for (Iterator i=list.iterator(); i.hasNext(); ) &#123; i.next();&#125; 而由于LinkedList未实现RandomAccess接口，所以推荐使用Iterator迭代器来遍历数据。 因此，如果我们需要频繁在列表的中部改变插入或删除元素时，建议使用LinkedList，否则，建议使用ArrayList，因为ArrayList遍历查找元素较快，并且只需存储元素的数据域，不需要额外记录其他数据的位置信息，可以节省内存空间。 LinkedList是线程安全的吗？问：LinkedList是线程安全的吗？ 答：LinkedList不是线程安全的，如果多个线程同时对同一个LinkedList更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，LinkedList会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个LinkedList进行遍历时，在遍历期间，我们是不能对LinkedList进行添加，删除等更改数据结构的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在add,remove等更改LinkedList数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑调用Collections.synchronizedCollection(Collection&lt;T&gt; c)方法。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; public boolean hasPrevious() &#123; return nextIndex &gt; 0; &#125; public E previous() &#123; checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; &#125; public int nextIndex() &#123; return nextIndex; &#125; public int previousIndex() &#123; return nextIndex - 1; &#125; public void remove() &#123; checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; &#125; public void set(E e) &#123; if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; &#125; public void add(E e) &#123; checkForComodification(); lastReturned = null; if (next == null) linkLast(e); else linkBefore(e, next); nextIndex++; expectedModCount++; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &#123; action.accept(next.item); lastReturned = next; next = next.next; nextIndex++; &#125; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 总结LinkedList的结论已在第三个问题中展现了一部分了，所以不再重复说明了，我以面试问答的形式和大家一同学习了LinkedList，由于没有时间画图，可能此次没有ArrayList说的那么清楚，如果大家有看不懂的地方，请自行看一下关于链表的数据结构吧。如果此文对你有帮助，麻烦点个喜欢，谢谢各位。]]></content>
      <categories>
        <category>LinkedList</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap 的详细分析]]></title>
    <url>%2F2017%2F12%2F09%2FHashMap%20%E7%9A%84%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap 的详细分析前言这次我和大家一起学习HashMap，HashMap我们在工作中经常会使用，而且面试中也很频繁会问到，因为它里面蕴含着很多知识点，可以很好的考察个人基础。但一个这么重要的东西，我为什么没有在一开始就去学习它呢，因为它是由多种基础的数据结构和一些代码设计思想组成的。我们要学习了这些基础，再学习HashMap，这样我们才能更好的去理解它。古人云：无欲速，无见小利。欲速则不达，见小利则大事不成。 HashMap其实就是ArrayList和LinkedList的数据结构加上hashCode和equals方法的思想设计出来的。没有理解上述说的知识点的同学可以翻开我过往的文章记录。 下面我就以面试问答的形式学习我们的——HashMap（源码分析基于JDK8，辅以JDK7），问答内容只是对HashMap的一个总结归纳，因为现时已经有大牛把HashMap通俗易懂的剖析了一遍，我学习HashMap也是主要通过这篇文章学习的，强烈推荐：美团点评技术团队的Java 8系列之重新认识HashMap 问答内容HashMap 的主要用途问：HashMap有用过吗？您能给我说说他的主要用途吗？ 答： 有用过，我在平常工作中经常会用到HashMap这种数据结构，HashMap是基于Map接口实现的一种键-值对&lt;key,value&gt;的存储结构，允许null值，同时非有序，非同步(即线程不安全)。HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分）。它存储和查找数据时，是根据键key的hashCode的值计算出具体的存储位置。HashMap最多只允许一条记录的键key为null，HashMap增删改查等常规操作都有不错的执行效率，是ArrayList和LinkedList等数据结构的一种折中实现。 示例代码： 12345678910111213141516171819202122232425262728293031323334// 创建一个HashMap，如果没有指定初始大小，默认底层hash表数组的大小为16HashMap&lt;String, String&gt; hashMap = new HashMap&lt;String, String&gt;();// 往容器里面添加元素hashMap.put("小明", "好帅");hashMap.put("老王", "坑爹货");hashMap.put("老铁", "没毛病");hashMap.put("掘金", "好地方");hashMap.put("王五", "别搞事");// 获取key为小明的元素 好帅String element = hashMap.get("小明");// value : 好帅System.out.println(element);// 移除key为王五的元素String removeElement = hashMap.remove("王五");// value : 别搞事System.out.println(removeElement);// 修改key为小明的元素的值value 为 其实有点丑hashMap.replace("小明", "其实有点丑");// &#123;老铁=没毛病, 小明=其实有点丑, 老王=坑爹货, 掘金=好地方&#125;System.out.println(hashMap);// 通过put方法也可以达到修改对应元素的值的效果hashMap.put("小明", "其实还可以啦,开玩笑的");// &#123;老铁=没毛病, 小明=其实还可以啦,开玩笑的, 老王=坑爹货, 掘金=好地方&#125;System.out.println(hashMap);// 判断key为老王的元素是否存在(捉奸老王)boolean isExist = hashMap.containsKey("老王");// true , 老王竟然来搞事System.out.println(isExist);// 判断是否有 value = "坑爹货" 的人boolean isHasSomeOne = hashMap.containsValue("坑爹货");// true 老王是坑爹货System.out.println(isHasSomeOne);// 查看这个容器里面还有几个家伙 value : 4System.out.println(hashMap.size()); HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分），核心组成元素有： int size;用于记录HashMap实际存储元素的个数； float loadFactor;负载因子（默认是0.75，此属性后面详细解释）。 int threshold;下一次扩容时的阈值，达到阈值便会触发扩容机制resize（阈值 threshold = 容器容量 capacity * 负载因子 load factor）。也就是说，在容器定义好容量之后，负载因子越大，所能容纳的键值对元素个数就越多。 Node&lt;K,V&gt;[] table; 底层数组，充当哈希表的作用，用于存储对应hash位置的元素Node&lt;K,V&gt;，此数组长度总是2的N次幂。（具体原因后面详细解释） 示例代码： 12345678910111213141516171819202122232425262728293031323334public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123;····· /* ---------------- Fields -------------- */ /** * 哈希表，在第一次使用到时进行初始化，重置大小是必要的操作， * 当分配容量时，长度总是2的N次幂。 */ transient Node&lt;K,V&gt;[] table; /** * 实际存储的key - value 键值对 个数 */ transient int size; /** * 下一次扩容时的阈值 * (阈值 threshold = 容器容量 capacity * 负载因子 load factor). * @serial */ int threshold; /** * 哈希表的负载因子 * * @serial */ final float loadFactor;·····&#125; 其中Node&lt;K,V&gt;[] table;哈希表存储的核心元素是Node&lt;K,V&gt;,Node&lt;K,V&gt;包含： final int hash;元素的哈希值，决定元素存储在Node&lt;K,V&gt;[] table;哈希表中的位置。由final修饰可知，当hash的值确定后，就不能再修改。 final K key; 键，由final修饰可知，当key的值确定后，就不能再修改。 V value; 值 Node&lt;K,V&gt; next; 记录下一个元素结点(单链表结构，用于解决hash冲突) 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 定义HashMap存储元素结点的底层实现 */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash;//元素的哈希值 由final修饰可知，当hash的值确定后，就不能再修改 final K key;// 键，由final修饰可知，当key的值确定后，就不能再修改 V value; // 值 Node&lt;K,V&gt; next; // 记录下一个元素结点(单链表结构，用于解决hash冲突) /** * Node结点构造方法 */ Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash;//元素的哈希值 this.key = key;// 键 this.value = value; // 值 this.next = next;// 记录下一个元素结点 &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; /** * 为Node重写hashCode方法，值为：key的hashCode 异或 value的hashCode * 运算作用就是将2个hashCode的二进制中，同一位置相同的值为0，不同的为1。 */ public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; /** * 修改某一元素的值 */ public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; /** * 为Node重写equals方法 */ public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; hashMap内存结构图 - 图片来自于《美团点评技术团队文章》 HashMap 常用操作的底层实现原理问：您能说说HashMap常用操作的底层实现原理吗？如存储put(K key, V value)，查找get(Object key)，删除remove(Object key)，修改replace(K key, V value)等操作。 答： 调用put(K key, V value)操作添加key-value键值对时，进行了如下操作： 判断哈希表Node&lt;K,V&gt;[] table是否为空或者null，是则执行resize()方法进行扩容。 根据插入的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]。如果存储位置没有元素存放，则将新增结点存储在此位置table[i]。 如果存储位置已经有键值对元素存在，则判断该位置元素的hash值和key值是否和当前操作元素一致，一致则证明是修改value操作，覆盖value即可。 当前存储位置即有元素，又不和当前操作元素一致，则证明此位置table[i]已经发生了hash冲突，则通过判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，已红黑树的方式新增结点。 如果不是红黑树，则证明是单链表，将新增结点插入至链表的最后位置，随后判断当前链表长度是否 大于等于 8，是则将当前存储位置的链表转化为红黑树。遍历过程中如果发现key已经存在，则直接覆盖value。 插入成功后，判断当前存储键值对的数量 大于 阈值threshold 是则扩容。 hashMap put方法执行流程图- 图片来自于《美团点评技术团队文章》 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * 添加key-value键值对 * * @param key 键 * @param value 值 * @return 如果原本存在此key，则返回旧的value值，如果是新增的key- * value，则返回nulll */public V put(K key, V value) &#123; //实际调用putVal方法进行添加 key-value 键值对操作 return putVal(hash(key), key, value, false, true);&#125;/** * 根据key 键 的 hashCode 通过 “扰动函数” 生成对应的 hash值 * 经过此操作后，使每一个key对应的hash值生成的更均匀， * 减少元素之间的碰撞几率（后面详细说明） */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;/** * 添加key-value键值对的实际调用方法（重点） * * @param hash key 键的hash值 * @param key 键 * @param value 值 * @param onlyIfAbsent 此值如果是true, 则如果此key已存在value，则不执 * 行修改操作 * @param evict 此值如果是false，哈希表是在初始化模式 * @return 返回原本的旧值, 如果是新增，则返回null */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // 用于记录当前的链表结点 Node&lt;K,V&gt; p; // n用于记录hash表的长度，i用于记录当前操作索引index int n, i; // 当前hash表为空 if ((tab = table) == null || (n = tab.length) == 0) // 初始化hash表，并把初始化后的hash表长度值赋值给n n = (tab = resize()).length; // 1）通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 2）确定当前元素的存储位置，此运算等价于 当前元素的hash值 % hash表的长度 // 3）计算出的存储位置没有元素存在 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 4) 则新建一个Node结点，在该位置存储此元素 tab[i] = newNode(hash, key, value, null); else &#123; // 当前存储位置已经有元素存在了(不考虑是修改的情况的话，就代表发生hash冲突了) // 用于存放新增结点 Node&lt;K,V&gt; e; // 用于临时存在某个key值 K k; // 1)如果当前位置已存在元素的hash值和新增元素的hash值相等 // 2)并且key也相等，则证明是同一个key元素，想执行修改value操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;// 将当前结点引用赋值给e else if (p instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构，则已红黑树结点结构新增元素 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123;// 排除上述情况，则证明已发生hash冲突，并hash冲突位置现时的结构是单链表结构 for (int binCount = 0; ; ++binCount) &#123; //遍历单链表，将新元素结点放置此链表的最后一位 if ((e = p.next) == null) &#123; // 将新元素结点放在此链表的最后一位 p.next = newNode(hash, key, value, null); // 新增结点后，当前结点数量是否大于等于 阈值 8 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 大于等于8则将链表转换成红黑树 treeifyBin(tab, hash); break; &#125; // 如果链表中已经存在对应的key，则覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // 已存在对应key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //如果允许修改，则修改value为新值 e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 当前存储键值对的数量 大于 阈值 是则扩容 if (++size &gt; threshold) // 重置hash大小，将旧hash表的数据逐一复制到新的hash表中（后面详细讲解） resize(); afterNodeInsertion(evict); // 返回null，则证明是新增操作，而不是修改操作 return null;&#125; 调用get(Object key)操作根据键key查找对应的key-value键值对时，进行了如下操作： 1.先调用 hash(key)方法计算出 key 的 hash值 2.根据查找的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]，判断存储位置是否有元素存在 。 如果存储位置有元素存放，则首先比较头结点元素，如果头结点的key的hash值 和 要获取的key的hash值相等，并且 头结点的key本身 和要获取的 key 相等，则返回该位置的头结点。 如果存储位置没有元素存放，则返回null。 3.如果存储位置有元素存放，但是头结点元素不是要查找的元素，则需要遍历该位置进行查找。 4.先判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，以红色树的方式遍历查找该结点，没有则返回null。 5.如果不是红黑树，则证明是单链表。遍历单链表，逐一比较链表结点，链表结点的key的hash值 和 要获取的key的hash值相等，并且 链表结点的key本身 和要获取的 key 相等，则返回该结点，遍历结束仍未找到对应key的结点，则返回null。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 返回指定 key 所映射的 value 值 * 或者 返回 null 如果容器里不存在对应的key * * 更确切地讲，如果此映射包含一个满足 (key==null ? k==null :key.equals(k)) * 的从 k 键到 v 值的映射关系， * 则此方法返回 v；否则返回 null。（最多只能有一个这样的映射关系。） * * 返回 null 值并不一定 表明该映射不包含该键的映射关系； * 也可能该映射将该键显示地映射为 null。可使用containsKey操作来区分这两种情况。 * * @see #put(Object, Object) */public V get(Object key) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用getNode方法获取对应key所映射的value值 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * 获取哈希表结点的方法实现 * * @param hash key 键的hash值 * @param key 键 * @return 返回对应的结点，如果结点不存在，则返回null */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // first用于记录对应hash位置的第一个结点，e充当工作结点的作用 Node&lt;K,V&gt; first, e; // n用于记录hash表的长度 int n; // 用于临时存放Key K k; // 通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 判断当前元素的存储位置是否有元素存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123;//元素存在的情况 // 如果头结点的key的hash值 和 要获取的key的hash值相等 // 并且 头结点的key本身 和要获取的 key 相等 if (first.hash == hash &amp;&amp; // always check first node 总是检查头结点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 返回该位置的头结点 return first; if ((e = first.next) != null) &#123;// 头结点不相等 if (first instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式获取对应key结点 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123;// 当前位置不是红黑树，则证明是单链表 // 遍历单链表，逐一比较链表结点 // 链表结点的key的hash值 和 要获取的key的hash值相等 // 并且 链表结点的key本身 和要获取的 key 相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 找到对应的结点则返回 return e; &#125; while ((e = e.next) != null); &#125; &#125; // 通过上述查找均无找到，则返回null return null;&#125; 调用remove(Object key)操作根据键key删除对应的key-value键值对时，进行了如下操作： 1.先调用 hash(key)方法计算出 key 的 hash值 2.根据查找的键值key的hash值，通过(n - 1) &amp; hash当前元素的hash值 &amp; hash表长度 - 1（实际就是 hash值 % hash表长度） 计算出存储位置table[i]，判断存储位置是否有元素存在 。 如果存储位置有元素存放，则首先比较头结点元素，如果头结点的key的hash值 和 要获取的key的hash值相等，并且 头结点的key本身 和要获取的 key 相等，则该位置的头结点即为要删除的结点，记录此结点至变量node中。 如果存储位置没有元素存放，则没有找到对应要删除的结点，则返回null。 3.如果存储位置有元素存放，但是头结点元素不是要删除的元素，则需要遍历该位置进行查找。 4.先判断头结点是否是treeNode，如果是treeNode则证明此位置的结构是红黑树，以红色树的方式遍历查找并删除该结点，没有则返回null。 5.如果不是红黑树，则证明是单链表。遍历单链表，逐一比较链表结点，链表结点的key的hash值 和 要获取的key的hash值相等，并且 链表结点的key本身 和要获取的 key 相等，则此为要删除的结点，记录此结点至变量node中，遍历结束仍未找到对应key的结点，则返回null。 6.如果找到要删除的结点node，则判断是否需要比较value也是否一致，如果value值一致或者不需要比较value值，则执行删除结点操作，删除操作根据不同的情况与结构进行不同的处理。 如果当前结点是树结点，则证明当前位置的链表已变成红黑树结构，通过红黑树结点的方式删除对应结点。 如果不是红黑树，则证明是单链表。如果要删除的是头结点，则当前存储位置table[i]的头结点指向删除结点的下一个结点。 如果要删除的结点不是头结点，则将要删除的结点的后继结点node.next赋值给要删除结点的前驱结点的next域，即p.next = node.next;。 7.HashMap当前存储键值对的数量 - 1，并返回删除结点。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/** * 从此映射中移除指定键的映射关系（如果存在）。 * * @param key 其映射关系要从映射中移除的键 * @return 与 key 关联的旧值；如果 key 没有任何映射关系，则返回 null。 * （返回 null 还可能表示该映射之前将 null 与 key 关联。） */public V remove(Object key) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用removeNode方法删除对应key所映射的结点 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * 删除哈希表结点的方法实现 * * @param hash 键的hash值 * @param key 键 * @param value 用于比较的value值，当matchValue 是 true时才有效, 否则忽略 * @param matchValue 如果是 true 只有当value相等时才会移除 * @param movable 如果是 false当执行移除操作时，不删除其他结点 * @return 返回删除结点node，不存在则返回null */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; // 用于记录当前的hash表 Node&lt;K,V&gt;[] tab; // 用于记录当前的链表结点 Node&lt;K,V&gt; p; // n用于记录hash表的长度，index用于记录当前操作索引index int n, index; // 通过 (n - 1) &amp; hash 当前元素的hash值 &amp; hash表长度 - 1 // 判断当前元素的存储位置是否有元素存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123;// 元素存在的情况 // node 用于记录找到的结点，e为工作结点 Node&lt;K,V&gt; node = null, e; K k; V v; // 如果头结点的key的hash值 和 要获取的key的hash值相等 // 并且 头结点的key本身 和要获取的 key 相等 // 则证明此头结点就是要删除的结点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 记录要删除的结点的引用地址至node中 node = p; else if ((e = p.next) != null) &#123;// 头结点不相等 if (p instanceof TreeNode)// 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式获取对应key结点 // 记录要删除的结点的引用地址至node中 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123;// 当前位置不是红黑树，则证明是单链表 do &#123; // 遍历单链表，逐一比较链表结点 // 链表结点的key的hash值 和 要获取的key的hash值相等 // 并且 链表结点的key本身 和要获取的 key 相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; // 找到则记录要删除的结点的引用地址至node中，中断遍历 node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 如果找到要删除的结点，则判断是否需要比较value也是否一致 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; // value值一致或者不需要比较value值，则执行删除结点操作 if (node instanceof TreeNode) // 如果当前结点是树结点 // 则证明当前位置的链表已变成红黑树结构 // 通过红黑树结点的方式删除对应结点 ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) // node 和 p相等，则证明删除的是头结点 // 当前存储位置的头结点指向删除结点的下一个结点 tab[index] = node.next; else // 删除的不是头结点 // p是删除结点node的前驱结点，p的next改为记录要删除结点node的后继结点 p.next = node.next; ++modCount; // 当前存储键值对的数量 - 1 --size; afterNodeRemoval(node); // 返回删除结点 return node; &#125; &#125; // 不存在要删除的结点，则返回null return null;&#125; 调用replace(K key, V value)操作根据键key查找对应的key-value键值对，随后替换对应的值value，进行了如下操作： 先调用 hash(key)方法计算出 key 的 hash值 随后调用getNode方法获取对应key所映射的value值 。 记录元素旧值，将新值赋值给元素，返回元素旧值，如果没有找到元素，则返回null。 示例代码： 123456789101112131415161718192021222324/** * 替换指定 key 所映射的 value 值 * * @param key 对应要替换value值元素的key键 * @param value 要替换对应元素的新value值 * @return 返回原本的旧值，如果没有找到key对应的元素，则返回null * @since 1.8 JDK1.8新增方法 */public V replace(K key, V value) &#123; Node&lt;K,V&gt; e; // 1.先调用 hash(key)方法计算出 key 的 hash值 // 2.随后调用getNode方法获取对应key所映射的value值 if ((e = getNode(hash(key), key)) != null) &#123;// 如果找到对应的元素 // 元素旧值 V oldValue = e.value; // 将新值赋值给元素 e.value = value; afterNodeAccess(e); // 返回元素旧值 return oldValue; &#125; // 没有找到元素，则返回null return null;&#125; HashMap 若要新增的这个元素存在了或hash冲突了怎么办问 1：您上面说，存放一个元素时，先计算它的hash值确定它的存储位置，然后再把这个元素放到对应的位置上，那万一这个位置上面已经有元素存在呢，新增的这个元素怎么办？ 问 2：hash冲突（或者叫hash碰撞）是什么？为什么会出现这种现象，如何解决hash冲突？ 答： hash冲突： 当我们调用put(K key, V value)操作添加key-value键值对，这个key-value键值对存放在的位置是通过扰动函数(key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16)计算键key的hash值。随后将 这个hash值 % 模上 哈希表Node&lt;K,V&gt;[] table的长度 得到具体的存放位置。所以put(K key, V value)多个元素，是有可能计算出相同的存放位置。此现象就是hash冲突或者叫hash碰撞。 例子如下：元素 A 的hash值 为 9，元素 B 的hash值 为 17。哈希表Node&lt;K,V&gt;[] table的长度为8。则元素 A 的存放位置为9 % 8 = 1，元素 B 的存放位置为17 % 8 = 1。两个元素的存放位置均为table[1]，发生了hash冲突。 hash冲突的避免：既然会发生hash冲突，我们就应该想办法避免此现象的发生，解决这个问题最关键就是如果生成元素的hash值。Java是使用“扰动函数”生成元素的hash值。 示例代码： 123456789101112131415161718/** * JDK 7 的 hash方法 */ final int hash(int h) &#123; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125;/** * JDK 8 的 hash方法 */ static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; Java7做了4次16位右位移异或混合，Java 8中这步已经简化了，只做一次16位右位移异或混合，而不是四次，但原理是不变的。例子如下： 扰动函数执行例子 - 图片来自于《知乎》 右位移16位，正好是32bit的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。 上述扰动函数的解释参考自：JDK 源码中 HashMap 的 hash 方法原理是什么？ hash冲突解决：解决hash冲突的方法有很多，常见的有：开发定址法，再散列法，链地址法，公共溢出区法（详细说明请查看我的文章JAVA基础-自问自答学hashCode和equals）。HashMap是使用链地址法解决hash冲突的，当有冲突元素放进来时，会将此元素插入至此位置链表的最后一位，形成单链表。但是由于是单链表的缘故，每当通过hash % length找到该位置的元素时，均需要从头遍历链表，通过逐一比较hash值，找到对应元素。如果此位置元素过多，造成链表过长，遍历时间会大大增加，最坏情况下的时间复杂度为O(N)，造成查找效率过低。所以当存在位置的链表长度 大于等于 8 时，HashMap会将链表 转变为 红黑树，红黑树最坏情况下的时间复杂度为O(logn)。以此提高查找效率。 HashMap 的容量为什么一定要是2的n次方问：HashMap的容量为什么一定要是2的n次方？ 答： 因为调用put(K key, V value)操作添加key-value键值对时，具体确定此元素的位置是通过 hash值 % 模上 哈希表Node&lt;K,V&gt;[] table的长度 hash % length 计算的。但是”模”运算的消耗相对较大，通过位运算h &amp; (length-1)也可以得到取模后的存放位置，而位运算的运行效率高，但只有length的长度是2的n次方时，h &amp; (length-1) 才等价于 h % length。 而且当数组长度为2的n次幂的时候，不同的key算出的index相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。 例子： hash &amp; (length-1)运算过程.jpg 上图中，左边两组的数组长度是16（2的4次方），右边两组的数组长度是15。两组的hash值均为8和9。 当数组长度是15时，当它们和1110进行&amp;与运算（相同为1，不同为0）时，计算的结果都是1000，所以他们都会存放在相同的位置table[8]中，这样就发生了hash冲突，那么查询时就要遍历链表，逐一比较hash值，降低了查询的效率。 同时，我们可以发现，当数组长度为15的时候，hash值均会与14（1110）进行&amp;与运算，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率。 所以，HashMap的容量是2的n次方，有利于提高计算元素存放位置时的效率，也降低了hash冲突的几率。因此，我们使用HashMap存储大量数据的时候，最好先预先指定容器的大小为2的n次方，即使我们不指定为2的n次方，HashMap也会把容器的大小设置成最接近设置数的2的n次方，如，设置HashMap的大小为 7 ，则HashMap会将容器大小设置成最接近7的一个2的n次方数，此值为 8 。 上述回答参考自：深入理解HashMap 示例代码： 12345678910111213/** * 返回一个比指定数cap大的，并且大小是2的n次方的数 * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; HashMap 的负载因子是什么，有什么作用问：HashMap的负载因子是什么，有什么作用？ 答：负载因子表示哈希表空间的使用程度（或者说是哈希表空间的利用率）。 例子如下：底层哈希表Node&lt;K,V&gt;[] table的容量大小capacity为 16，负载因子load factor为 0.75，则当存储的元素个数size = capacity 16 * load factor 0.75等于 12 时，则会触发HashMap的扩容机制，调用resize()方法进行扩容。 当负载因子越大，则HashMap的装载程度就越高。也就是能容纳更多的元素，元素多了，发生hash碰撞的几率就会加大，从而链表就会拉长，此时的查询效率就会降低。 当负载因子越小，则链表中的数据量就越稀疏，此时会对空间造成浪费，但是此时查询效率高。 我们可以在创建HashMap 时根据实际需要适当地调整load factor 的值；如果程序比较关心空间开销、内存比较紧张，可以适当地增加负载因子；如果程序比较关心时间开销，内存比较宽裕则可以适当的减少负载因子。通常情况下，默认负载因子 (0.75) 在时间和空间成本上寻求一种折衷，程序员无需改变负载因子的值。 因此，如果我们在初始化HashMap时，就预估知道需要装载key-value键值对的容量size，我们可以通过size / load factor 计算出我们需要初始化的容量大小initialCapacity，这样就可以避免HashMap因为存放的元素达到阈值threshold而频繁调用resize()方法进行扩容。从而保证了较好的性能。 HashMap 和 HashTable 的区别问：您能说说HashMap和HashTable的区别吗？ 答：HashMap和HashTable有如下区别： 1）容器整体结构： HashMap的key和value都允许为null，HashMap遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理。 Hashtable的key和value都不允许为null。Hashtable遇到null，直接返回NullPointerException。 2） 容量设定与扩容机制： HashMap默认初始化容量为 16，并且容器容量一定是2的n次方，扩容时，是以原容量 2倍 的方式 进行扩容。 Hashtable默认初始化容量为 11，扩容时，是以原容量 2倍 再加 1的方式进行扩容。即int newCapacity = (oldCapacity &lt;&lt; 1) + 1;。 3） 散列分布方式（计算存储位置）： HashMap是先将key键的hashCode经过扰动函数扰动后得到hash值，然后再利用 hash &amp; (length - 1)的方式代替取模，得到元素的存储位置。 Hashtable则是除留余数法进行计算存储位置的（因为其默认容量也不是2的n次方。所以也无法用位运算替代模运算），int index = (hash &amp; 0x7FFFFFFF) % tab.length;。 由于HashMap的容器容量一定是2的n次方，所以能使用hash &amp; (length - 1)的方式代替取模的方式计算元素的位置提高运算效率，但Hashtable的容器容量不一定是2的n次方，所以不能使用此运算方式代替。 4）线程安全（最重要）： HashMap 不是线程安全，如果想线程安全，可以通过调用synchronizedMap(Map&lt;K,V&gt; m)使其线程安全。但是使用时的运行效率会下降，所以建议使用ConcurrentHashMap容器以此达到线程安全。 Hashtable则是线程安全的，每个操作方法前都有synchronized修饰使其同步，但运行效率也不高，所以还是建议使用ConcurrentHashMap容器以此达到线程安全。 因此，Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 此处不再对Hashtable的源码进行逐一分析了，如果想深入了解的同学，可以参考此文章Hashtable源码剖析 HashMap 在多线程下如何处理，啥时会发生线程不安全问：您说HashMap不是线程安全的，那如果多线程下，它是如何处理的？并且什么情况下会发生线程不安全的情况？ 答： HashMap不是线程安全的，如果多个线程同时对同一个HashMap更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，HashMap会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个HashMap进行遍历时，在遍历期间，我们是不能对HashMap进行添加，删除等更改数据的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在put,remove等更改HashMap数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑使用ConcurrentHashMap。 而且，在多线程下操作HashMap，由于存在扩容机制，当HashMap调用resize()进行自动扩容时，可能会导致死循环的发生。 由于时间关系，我暂不带着大家一起去分析resize()方法导致死循环发生的现象造成原因了，迟点有空我会再补充上去，请见谅，大家可以参考如下文章： Java 8系列之重新认识HashMap 谈谈HashMap线程不安全的体现 使用 HashMap ，选取什么对象作为 key 键比较好问：我们在使用HashMap时，选取什么对象作为key键比较好，为什么？ 答： 可变对象：指创建后自身状态能改变的对象。换句话说，可变对象是该对象在创建后它的哈希值可能被改变。 我们在使用HashMap时，最好选择不可变对象作为key。例如String，Integer等不可变类型作为key是非常明智的。 如果key对象是可变的，那么key的哈希值就可能改变。在HashMap中可变对象作为Key会造成数据丢失。因为我们再进行hash &amp; (length - 1)取模运算计算位置查找对应元素时，位置可能已经发生改变，导致数据丢失。 详细例子说明请参考：危险！在HashMap中将可变对象用作Key 总结 HashMap是基于Map接口实现的一种键-值对&lt;key,value&gt;的存储结构，允许null值，同时非有序，非同步(即线程不安全)。HashMap的底层实现是数组 + 链表 + 红黑树（JDK1.8增加了红黑树部分）。 HashMap定位元素位置是通过键key经过扰动函数扰动后得到hash值，然后再通过hash &amp; (length - 1)代替取模的方式进行元素定位的。 HashMap是使用链地址法解决hash冲突的，当有冲突元素放进来时，会将此元素插入至此位置链表的最后一位，形成单链表。当存在位置的链表长度 大于等于 8 时，HashMap会将链表 转变为 红黑树，以此提高查找效率。 HashMap的容量是2的n次方，有利于提高计算元素存放位置时的效率，也降低了hash冲突的几率。因此，我们使用HashMap存储大量数据的时候，最好先预先指定容器的大小为2的n次方，即使我们不指定为2的n次方，HashMap也会把容器的大小设置成最接近设置数的2的n次方，如，设置HashMap的大小为 7 ，则HashMap会将容器大小设置成最接近7的一个2的n次方数，此值为 8 。 HashMap的负载因子表示哈希表空间的使用程度（或者说是哈希表空间的利用率）。当负载因子越大，则HashMap的装载程度就越高。也就是能容纳更多的元素，元素多了，发生hash碰撞的几率就会加大，从而链表就会拉长，此时的查询效率就会降低。当负载因子越小，则链表中的数据量就越稀疏，此时会对空间造成浪费，但是此时查询效率高。 HashMap不是线程安全的，Hashtable则是线程安全的。但Hashtable是一个遗留容器，如果我们不需要线程同步，则建议使用HashMap，如果需要线程同步，则建议使用ConcurrentHashMap。 在多线程下操作HashMap，由于存在扩容机制，当HashMap调用resize()进行自动扩容时，可能会导致死循环的发生。 我们在使用HashMap时，最好选择不可变对象作为key。例如String，Integer等不可变类型作为key是非常明智的。 由于最近工作较忙，也有拖延症发作的问题，所以文章迟迟未能完成发布，现时完成的文章其实对我而言，也不算太好，但还是打算先发出来让大家看看，一起学习学习，看有什么不好的地方，我再慢慢改进，如果此文对你有帮助，请给个赞，谢谢大家。 参考文章Java 8系列之重新认识HashMapJDK 源码中 HashMap 的 hash 方法原理是什么？深入理解HashMapHashMap负载因子Hashtable源码剖析危险！在HashMap中将可变对象用作Key谈谈HashMap线程不安全的体现]]></content>
      <categories>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList 源码分析]]></title>
    <url>%2F2017%2F12%2F09%2FArrayList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ArrayList 源码分析 前言以面试问答的形式学习我们的最常用的装载容器——ArrayList（源码分析基于JDK8） 问答内容ArrayList是什么，可以用来干嘛？问：ArrayList有用过吗？它是一个什么东西？可以用来干嘛？ 答：有用过，ArrayList就是数组列表，主要用来装载数据，当我们装载的是基本类型的数据int,long,boolean,short,byte...的时候我们只能存储他们对应的包装类，它的主要底层实现是数组Object[] elementData。与它类似的是LinkedList，和LinkedList相比，它的查找和访问元素的速度较快，但新增，删除的速度较慢。 示例代码： 12345678910// 创建一个ArrayList，如果没有指定初始大小，默认容器大小为10ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();// 往容器里面添加元素arrayList.add("张三");arrayList.add("李四");arrayList.add("王五");// 获取index下标为0的元素 张三String element = arrayList.get(0);// 删除index下标为1的元素 李四String removeElement = arrayList.remove(1); ArrayList底层实现示意图 ArrayList中不断添加数据会有什么问题吗？问：您说它的底层实现是数组，但是数组的大小是定长的，如果我们不断的往里面添加数据的话，不会有问题吗？ 答：ArrayList可以通过构造方法在初始化的时候指定底层数组的大小。 通过无参构造方法的方式ArrayList()初始化，则赋值底层数组Object[] elementData为一个默认空数组Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}所以数组容量为0，只有真正对数据进行添加add时，才分配默认DEFAULT_CAPACITY = 10的初始容量。示例代码： 12345678910111213141516// 定义ArrayList默认容量为10private static final int DEFAULT_CAPACITY = 10;// 空数组，当调用无参构造方法时默认复制这个空数组private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;// 真正保存数据的底层数组transient Object[] elementData; // ArrayList的实际元素数量private int size;public ArrayList() &#123; // 无参构造方法默认为空数组 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 通过指定容量初始大小的构造方法方式ArrayList(int initialCapacity)初始化，则赋值底层数组Object[] elementData为指定大小的数组this.elementData = new Object[initialCapacity];示例代码： 12345678910111213private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;// 通过构造方法出入指定的容量来设置默认底层数组大小 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125; 当我们添加的元素数量已经达到底层数组Object[] elementData的上限时，我们再往ArrayList元素，则会触发ArrayList的自动扩容机制，ArrayList会通过位运算int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);以1.5倍的方式初始化一个新的数组（如初始化数组大小为10，则扩容后的数组大小为15），然后使用Arrays.copyOf(elementData, newCapacity);方法将原数据的数据逐一复制到新数组上面去，以此达到ArrayList扩容的效果。虽然，Arrays.copyOf(elementData, newCapacity);方法最终调用的是native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length)是一个底层方法，效率还算可以，但如果我们在知道ArrayList想装多少个元素的情况下，却没有指定容器大小，则就会导致ArrayList频繁触发扩容机制，频繁进行底层数组之间的数据复制，大大降低使用效率。示例代码： 123456789101112131415161718192021222324252627282930313233public boolean add(E e) &#123; //确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); elementData[size++] = e; return true;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 容量不足，则调用grow方法进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * 扩容方法(重点) */private void grow(int minCapacity) &#123; // 获得原容量大小 int oldCapacity = elementData.length; // 新容量为原容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 再判断新容量是否已足够，如果扩容后仍然不足够，则复制为最小容量长度 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 判断是否超过最大长度限制 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 将原数组的数据复制至新数组， ArrayList的底层数组引用指向新数组 // 如果数据量很大，重复扩容，则会影响效率 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 因此，在我们使用ArrayList的时候，如果知道最终的存储容量capacity，则应该在初始化的时候就指定ArrayList的容量ArrayList(int initialCapacity)，如果初始化时无法预知装载容量，但在使用过程中，得知最终容量，我们可以通过调用ensureCapacity(int minCapacity)方法来指定ArrayList的容量，并且，如果我们在使用途中，如果确定容量大小，但是由于之前每次扩容都扩充50%，所以会造成一定的存储空间浪费，我们可以调用trimToSize()方法将容器最小化到存储元素容量，进而消除这些存储空间浪费。例如：我们当前存储了11个元素，我们不会再添加但是当前的ArrayList的大小为15，有4个存储空间没有被使用，则调用trimToSize()方法后，则会重新创建一个容量为11的数组Object[] elementData，将原有的11个元素复制至新数组，达到节省内存空间的效果。示例代码： 123456789101112131415161718192021222324252627/** * 将底层数组一次性指定到指定容量的大小 */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125;/** * 将容器最小化到存储元素容量 */public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125; ArrayList怎么 删除数据，为什么访问速度快，删除新增速度慢 ？问：那它是怎么样删除元素的？您上面说到ArrayList访问元素速度较快，但是新增和删除的速度较慢，为什么呢？ 答： 通过源码我们可以得知，ArrayList删除元素时，先获取对应的删除元素，然后把要删除元素对应索引index后的元素逐一往前移动1位，最后将最后一个存储元素清空并返回删除元素，以此达到删除元素的效果。 当我们通过下标的方式去访问元素时，我们假设访问一个元素所花费的时间为K，则通过下标一步到位的方式访问元素，时间则为1K，用“大O”表示法表示，则时间复杂度为O(1)。所以ArrayList的访问数据的数据是比较快的。 当我们去添加元素add(E e)时，我们是把元素添加至末尾，不需要移动元素，此时的时间复杂度为O(1)，但我们把元素添加到指定位置，最坏情况下，我们将元素添加至第一个位置add(int index, E element)，则整个ArrayList的n-1个元素都要往前移动位置，导致底层数组发生n-1次复制。通常情况下，我们说的时间复杂度都是按最坏情况度量的，此时的时间复杂度为O(n)。删除元素同理，删除最后一个元素不需要移动元素，时间复杂度为O(1)，但删除第一个元素，则需要移动n-1个元素，最坏情况下的时间复杂度也是O(n)。 所以ArrayList访问元素速度较快，但是新增和删除的速度较慢。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 将元素添加至末尾 */public boolean add(E e) &#123; // 确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;/** * 将元素添加至指定下标位置 */public void add(int index, E element) &#123; // 检查下标是否在合法范围内 rangeCheckForAdd(index); // 确保底层数组容量，如果容量不足，则扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 将要添加的元素下标后的元素通过复制的方式逐一往后移动，腾出对应index下标的存储位置 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 将新增元素存储至指定下标索引index elementData[index] = element; // ArrayList的大小 + 1 size++;&#125;/** * 通过下标索引的方式删除元素 */public E remove(int index) &#123; // 检查下标是否在合法范围内 rangeCheck(index); modCount++; // 直接通过下标去访问底层数组的元素 E oldValue = elementData(index); // 计算数组需要移动的元素个数 int numMoved = size - index - 1; if (numMoved &gt; 0) // 将要删除的元素下标后的元素通过复制的方式逐一往前移动 System.arraycopy(elementData, index+1, elementData, index, numMoved); //将底层数组长度减1，并清空最后一个存储元素。 elementData[--size] = null; // clear to let GC do its work // 返回移除元素 return oldValue;&#125; ArrayList是线程安全的吗？问：ArrayList是线程安全的吗？ 答：ArrayList不是线程安全的，如果多个线程同时对同一个ArrayList更改数据的话，会导致数据不一致或者数据污染。如果出现线程不安全的操作时，ArrayList会尽可能的抛出ConcurrentModificationException防止数据异常，当我们在对一个ArrayList进行遍历时，在遍历期间，我们是不能对ArrayList进行添加，修改，删除等更改数据的操作的，否则也会抛出ConcurrentModificationException异常，此为fail-fast（快速失败）机制。从源码上分析，我们在add,remove,clear等更改ArrayList数据时，都会导致modCount的改变，当expectedModCount != modCount时，则抛出ConcurrentModificationException。如果想要线程安全，可以考虑使用Vector、CopyOnWriteArrayList。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * AbstractList.Itr 的迭代器实现 */private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such //期望的modCount int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings("unchecked") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings("unchecked") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 总结 如果在初始化的时候知道ArrayList的初始容量，请一开始就指定容量ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(20);,如果一开始不知道容量，中途才得知，请调用list.ensureCapacity(20);来扩充容量，如果数据已经添加完毕，但仍需要保存在内存中一段时间，请调用list.trimToSize()将容器最小化到存储元素容量，进而消除这些存储空间浪费。 ArrayList是以1.5倍的容量去扩容的，如初始容量是10，则容量依次递增扩充为：15，22，33，49。扩容后把原始数据从旧数组复制至新数组中。 ArrayList访问元素速度较快，下标方式访问元素，时间复杂度为O(1)，添加与删除速度较慢，时间复杂度均为O(n)。 ArrayList不是线程安全的，但是在发生并发行为时，它会尽可能的抛出ConcurrentModificationException，此为fail-fast机制。]]></content>
      <categories>
        <category>ArrayList</category>
      </categories>
      <tags>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven仓库理解和优先级]]></title>
    <url>%2F2017%2F09%2F03%2FMaven-Priority%2F</url>
    <content type="text"><![CDATA[5 Seven 2017 前言使用 maven 也有一段时间了，有时候在配置 repository,mirror,profile的时候，总会导致 jar 拉取不到。所以认真的分析了 maven 获取 jar 包时候的优先级。 Maven 仓库的分类仓库分类：本地仓库和远程仓库。Maven根据坐标寻找构件的时候，它先会查看本地仓库，如果本地仓库存在构件，则直接使用；如果没有，则从远程仓库查找，找到后，下载到本地。 1）本地仓库默认情况下，每个用户在自己的用户目录下都有一个路径名为.m2/repository/的仓库目录。我们也可以在 settings.xml 文件配置本地仓库的地址 2）远程仓库本地仓库好比书房，而远程仓库就像是书店。对于Maven来说，每个用户只有一个本地仓库，但是可以配置多个远程仓库。下· 我们可以在 pom 文件配置多个 repository，但是随着项目越来也多我们每次都要在 pom 文件配置比较麻烦，所以我们可以在settings 文件配置 profile （私服）。这样我们每次创建新项目的时候就可以不用配置 repository。 3）中央仓库Maven必须要知道至少一个可用的远程仓库，中央仓库就是这样一个默认的远程仓库，Maven 默认有一个 super pom 文件。maven super pom 文件位置D:\apache-maven-3.0.4\lib 下的 maven-model-builder-3.0.4.jar 中的 org/apache/maven/model/pom-4.0.0.xml12345678910111213··· 省略其他 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;··· 这个时候我们就明白了，我们在 settings 文件配置一个 mirror 的 mirrorOf 为 central 的镜像就会替代 ‘中央仓库’ 的原因了。 Maven 镜像镜像（Mirroring）是冗余的一种类型，一个磁盘上的数据在另一个磁盘上存在一个完全相同的副本即为镜像。为什么配置镜像? 1.一句话，你有的我也有，你没有的我也有。（拥有远程仓库的所有 jar，包括远程仓库没有的 jar）2.还是一句话，我跑的比你快。（有时候远程仓库获取 jar 的速度可能比镜像慢，这也是为什么我们一般要配置中央仓库的原因，外国的 maven 仓库一般获取速度比较慢） 如果你配置 maven 镜像不是为了以上两点，那基本就不用配置镜像了。注意:当远程仓库被镜像匹配到的，则在获取 jar 包将从镜像仓库获取，而不是我们配置的 repository 仓库, repository 将失去作用 mirrorOf 标签mirrorOf 标签里面放置的是 repository 配置的 id,为了满足一些复杂的需求，Maven还支持更高级的镜像配置： external:* = 不在本地仓库的文件才从该镜像获取 repo,repo1 = 远程仓库 repo 和 repo1 从该镜像获取 *,!repo1 = 所有远程仓库都从该镜像获取，除 repo1 远程仓库以外 * = 所用远程仓库都从该镜像获取 私服私服是一种特殊的远程Maven仓库，它是架设在局域网内的仓库服务，私服一般被配置为互联网远程仓库的镜像，供局域网内的Maven用户使用。当Maven需要下载构件的时候，先向私服请求，如果私服上不存在该构件，则从外部的远程仓库下载，同时缓存在私服之上，然后为Maven下载请求提供下载服务，另外，对于自定义或第三方的jar可以从本地上传到私服，供局域网内其他maven用户使用。优点主要有： 1. 节省外网宽带 2. 加速Maven构建 3. 部署第三方构件：可以将公司项目的 jar 发布到私服上，方便项目与项目之间的调用 4. 提高稳定性、增强控制：原因是外网不稳定 5. 降低中央仓库的负荷：原因是中央仓库访问量太大 上面大概介绍了 Maven 仓库概念，接下来我们进入正题 Maven 仓库优先级为了方便测试，我准备了以下几个仓库 172.16.xxx.xxx 远程仓库 （私服） dev.xxx.wiki 远程仓库 （远程） localhost 仓库 是我自己在本机搭建的一个仓库 （镜像） maven.aliyun.com 中央仓库（中央） 本地仓库优先级Maven 本地仓库拥有该包，而远程、镜像、中央、私服都不包含该包。我们来看下 Maven 是怎么获取的123456789101112131415161718192021222324.......// 使用本地仓库，优先级(priority)为 10[DEBUG] Using local repository at E:\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\OperSource[INFO] Scanning for projects..........[INFO] Installing C:\Users\swipal\Desktop\abc\demo\target\demo-1.0-SNAPSHOT.jar to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[INFO] Installing C:\Users\swipal\Desktop\abc\demo\pom.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\OperSource\com\cjf\demo\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 1.874 s[INFO] Finished at: 2017-07-07T10:37:32+08:00[INFO] Final Memory: 23M/219M[INFO] ------------------------------------------------------------------------Process finished with exit code 0 从上面可以看出 Maven 一开始就使用本地仓库，并将本地仓库的优先级定制为 10 , 最后 jar 包也在本地仓库找到，Maven 成功打包。 远程仓库优先级前面我们知道了，本地仓库的优先级是最高的，现在我们继续研究远程仓库的优先级（以下的所有例子，都默认本地仓库不拥有我们需要的包） 这一次我们默认配置 profile（私服）为 172.16.xxx.xxx 远程仓库, repository 为 dev.xxx.wiki 远程仓库,mirror 为本地 localhost 仓库，还配置了一个 mirrorOf 为 central 远程仓库为 maven.aliyun.com 的中央仓库, 以下是配置信息settings.xml 文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253······&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;localhost&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo&lt;/mirrorOf&gt; &lt;!--拦截 pom 文件配置的 repository--&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;localhost2&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo2&lt;/mirrorOf&gt; &lt;!--配置一个拦截 foo2 的远程仓库的镜像--&gt; &lt;url&gt;http://localhost:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;!--覆盖 Maven 默认的配置的中央仓库--&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;!--配置私服--&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt;&lt;/activeProfiles&gt;······ pom.xml 文件 12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;!--xxx-cif-api 存在 172.16.xxx.xxx 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.xxx.cif&lt;/groupId&gt; &lt;artifactId&gt;xxx-cif-api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--Chapter1 存在 localhost 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--配置远程仓库--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;foo&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://dev.xxx.wiki:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 以下是 Maven 拉取包的日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108······· 省略部分日志信息[DEBUG] Using local repository at E:\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\OperSource[INFO] Scanning for projects...// 从这里可以看出我们配置的镜像替代了我们在 pom 配置的远程仓库[DEBUG] Using mirror localhost (http://localhost:8081/repository/maven-public/) for foo (http://dev.xxx.wiki:8081/nexus/content/groups/public/).替代了默认的中央仓库[DEBUG] Using mirror alimaven (http://maven.aliyun.com/nexus/content/groups/public/) for central (https://repo.maven.apache.org/maven2).// 从这里可以看出 Maven 使用哪些 dependencies 和 plugins 的地址，我们可以看出优先级最高的是 172.16.xxx.xxx,然后就是 localhost 最后才是 maven.aliyun.com// 注意：alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases) 从这里可以看出中央仓库只能获取 releases 包，所有的 snapshots 包都不从中央仓库获取。（可以看前面 central 的配置信息）[DEBUG] === PROJECT BUILD PLAN ================================================[DEBUG] Project: com.cjf:demo:1.0-SNAPSHOT[DEBUG] Dependencies (collect): [][DEBUG] Dependencies (resolve): [compile, runtime, test][DEBUG] Repositories (dependencies): [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public/, default, releases+snapshots), localhost (http://localhost:8081/repository/maven-public/, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] Repositories (plugins) : [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] =======================================================================// 寻找本地是否有 maven-metadata.xml 配置文件 ，从这里可以看出寻找不到（后面会详细讲该文件作用）[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\OperSource)// 由于寻找不到 Maven 只能从我们配置的远程仓库寻找，由于 Maven 也不知道那个仓库才有，所以同时寻找两个仓库[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\resolver-status.properties// 从这里可以看出在 172.16.xxx.xxx 找到 xxx-cif-api 的 maven-metadata.xml 文件并下载下来Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml (781 B at 7.0 KB/sec)// 追踪文件，resolver-status.properties 配置了 jar 包下载地址和时间[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\resolver-status.properties[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in localhost (http://localhost:8081/repository/maven-public/)// 在 localhost 远程仓库寻找不到 xxx-cif-api 的 maven-metadata.xml[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\OperSource)// 跳过的远程请求 [DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.[DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.// 默认以后获取 xxx-cif-api 的时候将不在从 localhost 寻找了，除非强制获取才会再次从 localhost 寻找这个包[DEBUG] Failure to find com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in http://localhost:8081/repository/maven-public/ was cached in the local repository, resolution will not be reattempted until the update interval of localhost has elapsed or updates are forced// 将 172.16.xxx.xxx 优先级升为 0 ，并下载 xxx-cif-api 的 pom 文件[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pomDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pom (930 B at 82.6 KB/sec)// _remote.repositories 记录的以后使用那个远程仓库获取 （ps:这个文件作用我要不是很清楚作用，以上观点是自己推测出来的。）[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\xxx-cif-api-0.0.1-20170515.040917-89.pom.lastUpdated// 后面获取 Chapter1 包的流程跟 com.xxx.cif 是一样的，不过最后是在 localhost 寻找到而已，所以这分日志就不贴出来了。// 最后在下载包的时候，都到对应的仓库下载[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jarDownloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jarDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jar (26 KB at 324.2 KB/sec)Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jar (68 KB at 756.6 KB/sec)[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\cif\xxx-cif-api\0.0.1-SNAPSHOT\xxx-cif-api-0.0.1-20170515.040917-89.jar.lastUpdated[DEBUG] Writing tracking file E:\OperSource\com\xxx\util\xxx-util\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\xxx\util\xxx-util\0.0.1-SNAPSHOT\xxx-util-0.0.1-20170514.091041-31.jar.lastUpdated[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/Downloading: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jarDownloaded: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jar (8 KB at 167.0 KB/sec)[DEBUG] Writing tracking file E:\OperSource\com\cjf\Chapter1\0.0.1-SNAPSHOT\_remote.repositories[DEBUG] Writing tracking file E:\OperSource\com\cjf\Chapter1\0.0.1-SNAPSHOT\Chapter1-0.0.1-20170708.092339-1.jar.lastUpdated[INFO] Installing C:\Users\swipal\Desktop\abc\demo\target\demo-1.0-SNAPSHOT.jar to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[INFO] Installing C:\Users\swipal\Desktop\abc\demo\pom.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\OperSource\com\cjf\demo\1.0-SNAPSHOT\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\OperSource\com\cjf\demo\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 10.549 s[INFO] Finished at: 2017-07-09T18:13:20+08:00[INFO] Final Memory: 26M/219M[INFO] ------------------------------------------------------------------------······· 好了，看了这么多的配置文件信息和日志信息，我们也总结一下 Maven 远程仓库优先级了。 主要有以下几点：1.从日志信息我们得出这几种maven仓库的优先级别为 本地仓库 &gt; 私服 （profile）&gt; 远程仓库（repository）和 镜像 （mirror） &gt; 中央仓库 （central） 2.镜像是一个特殊的配置，其实镜像等同与远程仓库，没有匹配远程仓库的镜像就毫无作用（如 foo2）。3.总结上面所说的，Maven 仓库的优先级就是 私服和远程仓库 的对比，没有其它的仓库类型。为什么这么说是因为，镜像等同远程，而中央其实也是 maven super xml 配置的一个repository 的一个而且。所以 maven 仓库真正的优先级为 本地仓库 &gt; 私服（profile）&gt; 远程仓库（repository） maven-metadata.xml 文件Maven Repository Metadata 可用于表示： 1. 一个没有版本的工件：它提供有关该工件的可用版本的信息 2. 快照伪像：它提供有关快照的精确信息 3. 包含Maven插件工件的组：它提供了有关此组中可用插件的信息。 元数据文件名是： 远程存储库中的 maven-metadata.xml， maven-metadata- &lt;repo-id&gt;.xml在本地存储库中，用于具有repo-id标识符的存储库中的元标记。 以上是 Maven 官网对该文件的解释。 作用问题：有时候我们更新最新包的时候，会发现最新的包被拉取下来的，但是项目使用的包还是旧的包。所以我们要分析下是什么原因导致的。 首先我们先大概的了解下 maven-metadata.xml 文件。1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;metadata modelVersion="1.1.0"&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;!--当前版本下的最新快照信息--&gt; &lt;timestamp&gt;20170710.071727&lt;/timestamp&gt; &lt;!--快照的时间戳--&gt; &lt;buildNumber&gt;6&lt;/buildNumber&gt; &lt;!--构件号--&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20170710071727&lt;/lastUpdated&gt;&lt;!--metadata文件被更新的时间--&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;!--当前版本下可用的子快照版本信息--&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt;&lt;!--子快照版本的信息--&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;!--这个子快照版本的更新时间--&gt; &lt;/snapshotVersion&gt; &lt;snapshotVersion&gt; &lt;extension&gt;pom&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/snapshotVersions&gt; &lt;/versioning&gt;&lt;/metadata&gt; 其中 lastUpdated 是最中要的一个属性，Maven 更新工程的 jar包时，会比较 lastUpdated 时间戳值，哪个值更大，就以哪个文件为准。 接下来我们看下 Maven 为我们生成了那些文件我们可以看到 maven-metadata.xml 一共有三个 1. maven-metadata-local.xml 本地的元数据, Maven install 的时候就会生成。 2. maven-metadata-snapshots.xml Maven deploy 时会生成 3. maven-metadata-localhost.xml 远程仓库获取的时候生成 (repository 的 id = localhost) 以上的文件其实都是 Maven 的过渡文件而已 例如 maven-metadata-snapshots 就是 Maven deploy 先从远程仓库对应包的 maven-metadata.xml 下载下来，然后修改快照信息后在上传到远程仓库上。 例如 maven-metadata-localhost 的作用是在 Maven 在拉取包的时候，会先跟本地 maven-metadata-local 比较下 lastUpdated 时间戳值，值大用哪个。如果是 Mavne 强制更新 的时候(没有强制更新是不会) 会下载远程的 maven-metadata.xml 比较远程，本地，和之前远程保存下来的 maven-metadata 文件。 所以有时候 maven 库上的 jar 包已经更新，而我们总是拉取不到 maven 的包原因就是本地的 maven-metadata-local 的 lastUpdated 比较大。 我们验证下 Maven deploy 例子123456789101112131415161718192021222324[INFO] --- maven-deploy-plugin:2.8.2:deploy (default-deploy) @ Chapter1 ---// 先从远程下载快照 maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 3.3 KB/sec)// 将项目的 jar 和 pom 文件更新到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jarUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jar (8 KB at 14.1 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pomUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pom (2 KB at 2.0 KB/sec)Downloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 1.6 KB/sec)// 上传 maven-metadata.xml 到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 1.0 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 0.4 KB/sec)[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.231 s[INFO] Finished at: 2017-07-10T20:13:13+08:00[INFO] Final Memory: 19M/226M[INFO] ------------------------------------------------------------------------ 总结原本以为两天就写好这篇文章，在自己理清思路的时候总是被自己绕晕了。比如在 Nexus 的 Central 配置的中央仓库获取，和 maven-metadata.xml 是如何比较的。 如果以上文章有误，等博客的评论系统搭建起来后欢迎大家指认出来。]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LogBack 使用]]></title>
    <url>%2F2017%2F09%2F03%2FLogback%2F</url>
    <content type="text"><![CDATA[26 Seven 2017 前言之前项目一直使用 logback ,现在大概写下了 logback 基础配置。 简介LogBack是一个日志框架，它是Log4j作者Ceki的又一个日志组件。 LogBack,Slf4j,Log4j之间的关系 slf4j是The Simple Logging Facade for Java的简称，是一个简单日志门面抽象框架，它本身只提供了日志Facade API和一个简单的日志类实现，一般常配合Log4j，LogBack，java.util.logging使用。Slf4j作为应用层的Log接入时，程序可以根据实际应用场景动态调整底层的日志实现框架(Log4j/LogBack/JdkLog…)； LogBack和Log4j都是开源日记工具库，LogBack是Log4j的改良版本，比Log4j拥有更多的特性，同时也带来很大性能提升。 LogBack官方建议配合Slf4j使用，这样可以灵活地替换底层日志框架。 LogBack的结构LogBack分为3个组件，logback-core, logback-classic 和 logback-access。其中logback-core提供了LogBack的核心功能，是另外两个组件的基础。logback-classic则实现了Slf4j的API，所以当想配合Slf4j使用时，则需要引入这个包。logback-access是为了集成Servlet环境而准备的，可提供HTTP-access的日志接口。 Log的行为级别：OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL从下向上，当选择了其中一个级别，则该级别向下的行为是不会被打印出来。举个例子，当选择了INFO级别，则INFO以下的行为则不会被打印出来。 获取 Logger 对象 我们先从获取 logger 对象开始1Logger logger = LoggerFactory.getLogger(xxx.class.getName()); LoggerFactory 是 slf4j 的日志工厂，获取 logger 方法就来自这里。123456以下代码摘自：org.slf4j.LoggerFactorypublic static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 这个方法里面有分为两个过程。第一个过程是获取ILoggerFactory，就是真正的日志工厂。第二个过程就是从真正的日志工厂中获取logger。接下来我们看下到底是怎么获取的12345678910111213141516171819202122232425262728以下代码摘自：org.slf4j.LoggerFactorypublic static ILoggerFactory getILoggerFactory() &#123;if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; // 第一次调用会去加载 StaticLoggerBinder.class 文件来决定 LoggerFactory 的实现类 // （补充下：不同日志包下都有 StaticLoggerBinder 这个类文件，这个会决定 LoggerFactory 初始化那种类型的日志） performInitialization();&#125;// INITIALIZATION_STATE 值判断是否有加载初始化过 ILoggerFactory 实例。switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: // 返回对应的 ILoggerFactory 实例 return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: // 当加载不到一个 StaticLoggerBinder 时，会走这里 // 返回一个 NOPLoggerFactory 实例 return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: // 初始化异常 throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://bugzilla.slf4j.org/show_bug.cgi?id=106 return TEMP_FACTORY;&#125;throw new IllegalStateException("Unreachable code");&#125; 接下来我们来看下是怎么加载 StaticLoggerBinder.class 文件的 1234567891011121314151617181920212223242526272829303132333435以下代码摘自：org.slf4j.LoggerFactory private final static void bind() &#123; try &#123; // 加载 StaticLoggerBinder Set staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); // 最后会随机选择一个StaticLoggerBinder.class来创建一个单例 StaticLoggerBinder.getSingleton(); // 改变 INITIALIZATION_STATE 值，表示成功初始化 Factory。 // 并且以后在获取 Logger 的时候并不会再次加载该方法 INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); emitSubstituteLoggerWarning(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; // 加载不到 StaticLoggerBinder 文件 INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.indexOf("org.slf4j.impl.StaticLoggerBinder.getSingleton()") != -1) &#123; // 初始化异常 INITIALIZATION_STATE = FAILED_INITIALIZATION; &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException("Unexpected initialization failure", e); &#125; &#125; 加载 StaticLoggerBinder.class12345678910111213141516以下代码摘自：org.slf4j.LoggerFactory.findPossibleStaticLoggerBinderPathSetprivate static String STATIC_LOGGER_BINDER_PATH = "org/slf4j/impl/StaticLoggerBinder.class";···if (loggerFactoryClassLoader == null) &#123; paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); &#125; else &#123; paths = loggerFactoryClassLoader .getResources(STATIC_LOGGER_BINDER_PATH); &#125; while (paths.hasMoreElements()) &#123; URL path = (URL) paths.nextElement(); staticLoggerBinderPathSet.add(path); &#125;··· 当项目中存在多个StaticLoggerBinder.class文件时，运行项目会出现以下日志：（这里获取的规则就近原则，如果在 maven 先配置 slf4j 而后面在配置 logback，则这里初始化的是 slf4j）12345SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/E:/OperSource/org/slf4j/slf4j-log4j12/1.7.12/slf4j-log4j12-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/E:/OperSource/ch/qos/logback/logback-classic/1.1.3/logback-classic-1.1.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] 返回实例123以下代码摘自：org.slf4j.LoggerFactory.getILoggerFactoryStaticLoggerBinder.getSingleton().getLoggerFactory(); LogBack 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 项目名称配置 --&gt; &lt;contextName&gt;example&lt;/contextName&gt; &lt;!-- 属性 --&gt; &lt;property name="APP_Name" value="example" /&gt; &lt;!-- 统一的时间格式，用于日志头输出 --&gt; &lt;timestamp key="timeStyle" datePattern="yyyy-MM-dd HH:mm:ss.SSS"/&gt; &lt;!--配置控制台输出,开发环境有--&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- encoder 默认配置为PatternLayoutEncoder --&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--文件输出配置--&gt; &lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_run.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_run.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="BUSINESS_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_business.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_business.%i.business.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt;&lt;!-- 只打印错误日志 --&gt; &lt;level&gt;WARE&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 异步输出 --&gt; &lt;appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref="FILE"/&gt; &lt;/appender&gt; &lt;appender name="BUSINESS_ASYNC" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref="BUSINESS_FILE"/&gt; &lt;/appender&gt; &lt;!-- 为数据库开启显示sql --&gt; &lt;logger name="com.cjf.example.repository" level="DEBUG"&gt;&lt;/logger&gt; &lt;logger name="com.cjf" level="INFO"&gt;&lt;/logger&gt; &lt;!--日志的root目录，用于定位日志输出级别--&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="ASYNC"/&gt; &lt;appender-ref ref="STDOUT"/&gt; &lt;/root&gt;&lt;/configuration&gt; 上面就是一个常用的日志配置模版，下面就从跟节点来解析每个节点 1.configurationscan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod：监测配置文件是否有修改的时间间隔，默认 60s。debug：是否打印 logback 内部日志，默认 false.2.contextName 项目名称logger 上下文容器名称，默认 ‘default’，用于区分不同应用程序的记录。（可以在日志输出的时候将项目名称打印处理方便系统间交互 比如上面配置的 %cn）3.property 设置变量定义变量后，可以使${}来使用变量。4.timestamp 设置时间戳格式key:标识此 的名字；datePattern：设置将当前时间（解析配置文件的时间）转换为字符串的模式，遵循Java.txt.SimpleDateFormat的格式。5.logger用来设置某一个包或者具体的某一个类的日志打印级别、以及指定。仅有一个name属性，一个可选的level和一个可选的addtivity属性。name: 用来指定受此loger约束的某一个包或者具体的某一个类。level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。如果未设置此属性，那么当前loger将会继承上级的级别。addtivity:是否向上级loger传递打印信息。默认是true。loger可以包含零个或多个appender-ref元素，标识这个appender将会添加到这个loger。6.root也是 loger 元素，但是它是根 loger。只有一个 level 属性，应为已经被命名为 “root”.root 可以包含零个或多个 appender-ref 元素，标识这个 appender 将会添加到这个 loger。 什么是 Appender？logback 将日志记录事件写入到名为 appender 的组件的任务,不同 appender 决定了日志的记录方式。appender 有多种实现的方式，下面简单介绍几种比较常用的配置。 更多详情请参考官方文档 ConsoleAppender把日志添加到控制台，有以下子节点： encoder：对日志进行格式化 target：字符串 System.out 或者 System.err ，默认 System.out; withJansi：日志彩色输出 例如123456789101112&lt;configuration&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="DEBUG"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/root&gt; &lt;/configuration&gt; RollingFileAppender滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。file：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。append：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。encoder：对记录事件进行格式化。rollingPolicy：当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名。triggeringPolicy：告知 RollingFileAppender 合适激活滚动。prudent：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。 rollingPolicy 有两种类型，分别是 TimeBasedRollingPolicy，FixedWindowRollingPolicy。 例如 TimeBasedRollingPolicy 配置123456789101112&lt;!--输出到文件--&gt;&lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.path&#125;&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;logback.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; fileNamePattern 定义了日志的切分方式——把每一天的日志归档到一个文件中maxHistory 表示只保留最近30天的日志，以防止日志填满整个磁盘空间。totalSizeCap 用来指定日志文件的上限大小，例如设置为1GB的话，那么到了这个值，就会删除旧的日志。 例如 FixedWindowRollingPolicy 配置1234567891011121314&lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;../logs/$&#123;APP_Name&#125;_run.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"&gt; &lt;fileNamePattern&gt;../logs/$&#123;APP_Name&#125;_run.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;10&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;timeStyle&#125;] [%cn] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 这里多了一个 SizeBasedTriggeringPolicy 触发机制，但 log 文件大于 10MB 的时候，就开始执行 rolling。minIndex 和 maxIndex 表示保存日志数量，但大于 maxIndex 的时候，会开始删除旧的日志。 必须包含“%i”例如，假设最小值和最大值分别为1和2，命名模式为mylog%i.log,会产生归档文件mylog1.log和mylog2.log。还可以指定文件压缩选项，例如，mylog%i.log.gz或者 没有log%i.log.zip AsyncAppender 异步输出这里就不写了，可以参考文章。 总结由于没有深入去了解 logback ,许多内容都是网上摘来的，写文章的时候也很费劲。思路不清晰。]]></content>
      <categories>
        <category>LogBack</category>
      </categories>
      <tags>
        <tag>LogBack</tag>
      </tags>
  </entry>
</search>